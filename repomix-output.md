This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where comments have been removed, line numbers have been added.

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Line numbers have been added to the beginning of each line
- Files are sorted by Git change count (files with more changes are at the bottom)

# Directory Structure
```
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    feature_request.md
  workflows/
    application_infra_destroying.yaml
    application_infra_provisioning.yaml
    backend_build_push.yaml
    backend_infra_destroying.yaml
    backend_infra_provisioning.yaml
    frontend_build_push.yaml
    tfstate_infra_destroying.yaml
    tfstate_infra_provisioning.yaml
application/
  backend/
    helm/
      ldap-2fa-backend/
        templates/
          tests/
            test-connection.yaml
          _helpers.tpl
          configmap.yaml
          deployment.yaml
          hpa.yaml
          ingress.yaml
          NOTES.txt
          secret.yaml
          service.yaml
          serviceaccount.yaml
        .helmignore
        Chart.yaml
        values.yaml
    src/
      app/
        api/
          __init__.py
          routes.py
        database/
          __init__.py
          connection.py
          models.py
        email/
          __init__.py
          client.py
        ldap/
          __init__.py
          client.py
        mfa/
          __init__.py
          totp.py
        redis/
          __init__.py
          client.py
        sms/
          __init__.py
          client.py
        config.py
        main.py
      requirements.txt
    Dockerfile
  frontend/
    helm/
      ldap-2fa-frontend/
        templates/
          tests/
            test-connection.yaml
          _helpers.tpl
          deployment.yaml
          hpa.yaml
          ingress.yaml
          NOTES.txt
          service.yaml
          serviceaccount.yaml
        .helmignore
        Chart.yaml
        values.yaml
    src/
      css/
        styles.css
      js/
        api.js
        main.js
      index.html
    Dockerfile
    nginx.conf
  helm/
    openldap-values.tpl.yaml
    postgresql-values.tpl.yaml
    redis-values.tpl.yaml
  modules/
    alb/
      main.tf
      outputs.tf
      README.md
      variables.tf
    argocd/
      main.tf
      outputs.tf
      README.md
      variables.tf
    argocd_app/
      main.tf
      outputs.tf
      README.md
      variables.tf
    cert-manager/
      main.tf
      outputs.tf
      README.md
      variables.tf
    network-policies/
      main.tf
      outputs.tf
      README.md
      variables.tf
    openldap/
      main.tf
      outputs.tf
      README.md
      variables.tf
    postgresql/
      main.tf
      outputs.tf
      README.md
      variables.tf
    redis/
      main.tf
      outputs.tf
      README.md
      variables.tf
    route53/
      main.tf
      outputs.tf
      README.md
      variables.tf
    route53_record/
      main.tf
      outputs.tf
      providers.tf
      README.md
      variables.tf
    ses/
      main.tf
      outputs.tf
      providers.tf
      README.md
      variables.tf
    sns/
      main.tf
      outputs.tf
      README.md
      variables.tf
  .terraform.lock.hcl
  CHANGELOG.md
  CROSS-ACCOUNT-ACCESS.md
  destroy-application.sh
  main.tf
  mirror-images-to-ecr.sh
  OPENLDAP-README.md
  OSIXIA-OPENLDAP-REQUIREMENTS.md
  outputs.tf
  PRD-2FA-APP.md
  PRD-ADMIN-FUNCS.md
  PRD-ALB.md
  PRD-ArgoCD.md
  PRD-DOMAIN.md
  PRD-SIGNUP-MAN.md
  PRD-SMS-MAN.md
  PRD.md
  providers.tf
  README.md
  SECURITY-IMPROVEMENTS.md
  set-k8s-env.sh
  setup-application.sh
  tfstate-backend-values-template.hcl
  variables.tf
backend_infra/
  modules/
    ebs/
      main.tf
      outputs.tf
      README.md
      variables.tf
    ecr/
      main.tf
      outputs.tf
      README.md
      variables.tf
    endpoints/
      main.tf
      outputs.tf
      README.md
      variables.tf
  .terraform.lock.hcl
  CHANGELOG.md
  destroy-backend.sh
  main.tf
  outputs.tf
  providers.tf
  README.md
  setup-backend.sh
  tfstate-backend-values-template.hcl
  variables.tf
docs/
  dark-theme.css
  favicon.ico
  header_banner.png
  index.html
  light-theme.css
tf_backend_state/
  .terraform.lock.hcl
  CHANGELOG.md
  get-state.sh
  main.tf
  outputs.tf
  providers.tf
  README.md
  set-state.sh
  variables.tf
.gitignore
CHANGELOG.md
LICENSE
README.md
repomix-instructions.md
SECRETS_REQUIREMENTS.md
WARP.md
```

# Files

## File: tf_backend_state/.terraform.lock.hcl
````hcl
 1: # This file is maintained automatically by "terraform init".
 2: # Manual edits may be lost in future updates.
 3: 
 4: provider "registry.terraform.io/hashicorp/aws" {
 5:   version     = "6.21.0"
 6:   constraints = "6.21.0"
 7:   hashes = [
 8:     "h1:lhPGtXHoctW6UiIg2Av8d6Dk7mLl2J2ORR91ZUYzRVk=",
 9:     "zh:03b65e7d275a48bbe5de9aed2bcacf841ea0a85352744587729d179ceb227994",
10:     "zh:1a50fc50365602769b6844c6eba920b5c6941161508c2ebd5c1a60f7577edd18",
11:     "zh:1bcbf2575e462849baa01554be469ac68dbd43fe7929819ab43eb8a849605ce9",
12:     "zh:28466d206962bfe00a32ecf0a4fa8553a5099521629fce010f486bae2a5f194f",
13:     "zh:3627c098788e4fc3eb88271101717212f260aa117dad15e648bde6f2889d3536",
14:     "zh:3f8ae239d1b60a5de3f089810728947c19854eff3c16f22c31e1c8b039dd93a0",
15:     "zh:62201751f1fc46b6e2720e5d7ea6bab75b98a7eb1f4c3460c258106be5bc5495",
16:     "zh:86c89c7dd5866fcb57c4d35e7ba6ec849caf70c2fdd2d23c9d05da919ec06c8b",
17:     "zh:94186ec3908ce6e89eaf98767b6b1e40acfb258de9fe8c09f2a100eb5cfca597",
18:     "zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425",
19:     "zh:9d5863a6970735c9e428be91c301789c1e228a3105f711d77efe9c6056bb8295",
20:     "zh:a94f9abe91656d68a0657d877665766931ae381825fa0b5121da26b3aa3ed15d",
21:     "zh:df2b293078bb3d31b45bcc6e83c17e790dca40198b8d7069dc3e3b387146937f",
22:     "zh:e7666954631899756e3bb428c64abcff1c94b7355f7d92eba29541c3d401e472",
23:     "zh:f142320e9d4a5c663f6e9924abe05274bbbc4031700bac3387e0a67ec6c951ef",
24:   ]
25: }
````

## File: LICENSE
````
 1: MIT License
 2: 
 3: Copyright (c) 2025 Tal Orlik
 4: 
 5: Permission is hereby granted, free of charge, to any person obtaining a copy
 6: of this software and associated documentation files (the "Software"), to deal
 7: in the Software without restriction, including without limitation the rights
 8: to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 9: copies of the Software, and to permit persons to whom the Software is
10: furnished to do so, subject to the following conditions:
11: 
12: The above copyright notice and this permission notice shall be included in all
13: copies or substantial portions of the Software.
14: 
15: THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
16: IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
17: FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
18: AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
19: LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
20: OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
21: SOFTWARE.
````

## File: repomix-instructions.md
````markdown
 1: # Repomix Instructions for ldap-2fa-on-k8s
 2: 
 3: ## Overview
 4: 
 5: You are an expert AWS DevOps and Platform Architect. This document is a packed
 6: snapshot of my repository "ldap-2fa-on-k8s". Use the directory tree at the top as
 7: the system-of-record for how components relate.
 8: 
 9: ## Primary Goal
10: 
11: Build an accurate mental model of the end-to-end deployment and runtime architecture,
12: focusing on:
13: 
14: - Multi-account deployment design (state/secrets account vs target deployment account),
15: IAM role chaining/assume-role boundaries, and how Terraform providers and workflows
16: prevent credential drift.
17: - Terraform stacks and module composition, especially:
18:   - tf_backend_state (remote state + locking)
19:   - backend_infra (VPC endpoints, EKS Auto Mode, ECR, storage classes)
20:   - application (ALB/IngressClassParams, LDAP stack via Helm, ArgoCD EKS Capability,
21:   ArgoCD Applications, DNS/ACM integration)
22: - CI/CD and GitOps:
23:   - GitHub Actions workflows for terraform plan/apply and any image build/push flows
24:   - ArgoCD application definitions and how changes propagate to the cluster
25:   (automated sync, paths, environments/branches)
26: - Security and network posture:
27:   - Private-by-default design (LDAP not exposed externally)
28:   - ALB ingress grouping, TLS termination via ACM, Route53 records
29:   - VPC endpoints usage and any egress constraints
30:   - Kubernetes network policies and namespace isolation
31: 
32: ## Extraction Instructions
33: 
34: 1. Start by summarizing the repository's stack boundaries and deployment order
35: (what must exist before what).
36: 2. Enumerate all AWS accounts/roles/profiles referenced and map which actions run
37: under which identity (local and GitHub Actions).
38: 3. Trace external request flows:
39:    - Web: ALB -> frontend -> /api -> backend -> LDAP, plus optional SMS (SNS)
40:    - CLI: ALB -> /api -> backend -> LDAP, plus optional SMS (SNS)
41: 4. Identify all inputs/outputs between stacks (Terraform remote_state outputs,
42: Helm values, variables, secrets) and where each value originates.
43: 5. List "gotchas" and invariants (single ALB via group.name + group.order, one
44: app domain with path routing, backend endpoints under /api, no global credential
45: switching inside scripts).
46: 
47: ## Ignore Patterns
48: 
49: - Non-essential markdown boilerplate, badges, and screenshots.
50: - Generated files, local caches, Terraform .terraform directories, plan/state artifacts,
51: node_modules, Python venvs.
52: 
53: ## Ambiguity Handling
54: 
55: When something is ambiguous, state the assumption explicitly and point to the
56: exact file/path that would confirm it.
````

## File: .github/ISSUE_TEMPLATE/bug_report.md
````markdown
 1: ---
 2: name: Bug report
 3: about: Create a report to help us improve
 4: title: "[BUG] "
 5: labels: bug
 6: assignees: talorlik
 7: 
 8: ---
 9: 
10: ## Bug Description
11: A clear and concise description of what the bug is.
12: 
13: ## Steps to Reproduce
14: Steps to reproduce the behavior:
15: 1. 
16: 2. 
17: 3. 
18: 
19: ## Expected Behavior
20: A clear and concise description of what you expected to happen.
21: 
22: ## Actual Behavior
23: A clear and concise description of what actually happened.
24: 
25: ## Environment
26: - OS: [e.g. Ubuntu 22.04, macOS 14.0]
27: - Terraform Version: [e.g. 1.6.0]
28: - Cloud Provider: [e.g. AWS, Azure, GCP]
29: - Other relevant tools/versions:
30: 
31: ## Logs/Screenshots
32: If applicable, add logs or screenshots to help explain your problem.
33: 
34: ```
35: [paste relevant logs here]
36: ```
37: 
38: ## Additional Context
39: Add any other context about the problem here.
40: 
41: ## Possible Solution
42: If you have suggestions on how to fix the issue, please describe them here.
````

## File: .github/ISSUE_TEMPLATE/feature_request.md
````markdown
 1: ---
 2: name: Feature request
 3: about: Suggest a new feature or enhancement
 4: title: "[FEATURE] "
 5: labels: enhancement
 6: assignees: talorlik
 7: 
 8: ---
 9: 
10: ## Feature Description
11: A clear and concise description of the feature you'd like to see.
12: 
13: ## Problem Statement
14: Describe the problem this feature would solve. Ex. I'm always frustrated when [...]
15: 
16: ## Proposed Solution
17: A clear and concise description of what you want to happen.
18: 
19: ## Alternatives Considered
20: Describe any alternative solutions or features you've considered.
21: 
22: ## Use Case
23: Describe how this feature would be used and who would benefit from it.
24: 
25: ## Implementation Details
26: If you have ideas about how this could be implemented, please share them here.
27: 
28: ## Additional Context
29: Add any other context, mockups, or screenshots about the feature request here.
30: 
31: ## Acceptance Criteria
32: List the specific criteria that must be met for this feature to be considered complete:
33: - [ ] 
34: - [ ] 
35: - [ ]
````

## File: application/backend/helm/ldap-2fa-backend/templates/tests/test-connection.yaml
````yaml
 1: apiVersion: v1
 2: kind: Pod
 3: metadata:
 4:   name: "{{ include "ldap-2fa-backend.fullname" . }}-test-connection"
 5:   labels:
 6:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 7:   annotations:
 8:     "helm.sh/hook": test
 9: spec:
10:   containers:
11:     - name: wget
12:       image: busybox
13:       command: ['wget']
14:       args: ['{{ include "ldap-2fa-backend.fullname" . }}:{{ .Values.service.port }}']
15:   restartPolicy: Never
````

## File: application/backend/helm/ldap-2fa-backend/templates/_helpers.tpl
````
 1: {{/*
 2: Expand the name of the chart.
 3: */}}
 4: {{- define "ldap-2fa-backend.name" -}}
 5: {{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
 6: {{- end }}
 7: 
 8: {{/*
 9: Create a default fully qualified app name.
10: We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec).
11: If release name contains chart name it will be used as a full name.
12: */}}
13: {{- define "ldap-2fa-backend.fullname" -}}
14: {{- if .Values.fullnameOverride }}
15: {{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
16: {{- else }}
17: {{- $name := default .Chart.Name .Values.nameOverride }}
18: {{- if contains $name .Release.Name }}
19: {{- .Release.Name | trunc 63 | trimSuffix "-" }}
20: {{- else }}
21: {{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
22: {{- end }}
23: {{- end }}
24: {{- end }}
25: 
26: {{/*
27: Create chart name and version as used by the chart label.
28: */}}
29: {{- define "ldap-2fa-backend.chart" -}}
30: {{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
31: {{- end }}
32: 
33: {{/*
34: Common labels
35: */}}
36: {{- define "ldap-2fa-backend.labels" -}}
37: helm.sh/chart: {{ include "ldap-2fa-backend.chart" . }}
38: {{ include "ldap-2fa-backend.selectorLabels" . }}
39: {{- if .Chart.AppVersion }}
40: app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
41: {{- end }}
42: app.kubernetes.io/managed-by: {{ .Release.Service }}
43: {{- end }}
44: 
45: {{/*
46: Selector labels
47: */}}
48: {{- define "ldap-2fa-backend.selectorLabels" -}}
49: app.kubernetes.io/name: {{ include "ldap-2fa-backend.name" . }}
50: app.kubernetes.io/instance: {{ .Release.Name }}
51: {{- end }}
52: 
53: {{/*
54: Create the name of the service account to use
55: */}}
56: {{- define "ldap-2fa-backend.serviceAccountName" -}}
57: {{- if .Values.serviceAccount.create }}
58: {{- default (include "ldap-2fa-backend.fullname" .) .Values.serviceAccount.name }}
59: {{- else }}
60: {{- default "default" .Values.serviceAccount.name }}
61: {{- end }}
62: {{- end }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/hpa.yaml
````yaml
 1: {{- if .Values.autoscaling.enabled }}
 2: apiVersion: autoscaling/v2
 3: kind: HorizontalPodAutoscaler
 4: metadata:
 5:   name: {{ include "ldap-2fa-backend.fullname" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 8: spec:
 9:   scaleTargetRef:
10:     apiVersion: apps/v1
11:     kind: Deployment
12:     name: {{ include "ldap-2fa-backend.fullname" . }}
13:   minReplicas: {{ .Values.autoscaling.minReplicas }}
14:   maxReplicas: {{ .Values.autoscaling.maxReplicas }}
15:   metrics:
16:     {{- if .Values.autoscaling.targetCPUUtilizationPercentage }}
17:     - type: Resource
18:       resource:
19:         name: cpu
20:         target:
21:           type: Utilization
22:           averageUtilization: {{ .Values.autoscaling.targetCPUUtilizationPercentage }}
23:     {{- end }}
24:     {{- if .Values.autoscaling.targetMemoryUtilizationPercentage }}
25:     - type: Resource
26:       resource:
27:         name: memory
28:         target:
29:           type: Utilization
30:           averageUtilization: {{ .Values.autoscaling.targetMemoryUtilizationPercentage }}
31:     {{- end }}
32: {{- end }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/ingress.yaml
````yaml
 1: {{- if .Values.ingress.enabled -}}
 2: apiVersion: networking.k8s.io/v1
 3: kind: Ingress
 4: metadata:
 5:   name: {{ include "ldap-2fa-backend.fullname" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 8:   {{- with .Values.ingress.annotations }}
 9:   annotations:
10:     {{- toYaml . | nindent 4 }}
11:   {{- end }}
12: spec:
13:   {{- with .Values.ingress.className }}
14:   ingressClassName: {{ . }}
15:   {{- end }}
16:   {{- if .Values.ingress.tls }}
17:   tls:
18:     {{- range .Values.ingress.tls }}
19:     - hosts:
20:         {{- range .hosts }}
21:         - {{ . | quote }}
22:         {{- end }}
23:       secretName: {{ .secretName }}
24:     {{- end }}
25:   {{- end }}
26:   rules:
27:     {{- range .Values.ingress.hosts }}
28:     - host: {{ .host | quote }}
29:       http:
30:         paths:
31:           {{- range .paths }}
32:           - path: {{ .path }}
33:             {{- with .pathType }}
34:             pathType: {{ . }}
35:             {{- end }}
36:             backend:
37:               service:
38:                 name: {{ include "ldap-2fa-backend.fullname" $ }}
39:                 port:
40:                   number: {{ $.Values.service.port }}
41:           {{- end }}
42:     {{- end }}
43: {{- end }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/NOTES.txt
````
 1: LDAP 2FA Backend API has been deployed!
 2: 
 3: 1. Get the application URL:
 4: {{- if .Values.ingress.enabled }}
 5: {{- range $host := .Values.ingress.hosts }}
 6:   {{- range .paths }}
 7:   https://{{ $host.host }}{{ .path }}
 8:   {{- end }}
 9: {{- end }}
10: {{- else if contains "NodePort" .Values.service.type }}
11:   export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "ldap-2fa-backend.fullname" . }})
12:   export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
13:   echo http://$NODE_IP:$NODE_PORT
14: {{- else if contains "LoadBalancer" .Values.service.type }}
15:   NOTE: It may take a few minutes for the LoadBalancer IP to be available.
16:         You can watch the status by running:
17:         kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "ldap-2fa-backend.fullname" . }}
18:   export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "ldap-2fa-backend.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
19:   echo http://$SERVICE_IP:{{ .Values.service.port }}
20: {{- else if contains "ClusterIP" .Values.service.type }}
21:   kubectl --namespace {{ .Release.Namespace }} port-forward svc/{{ include "ldap-2fa-backend.fullname" . }} 8000:{{ .Values.service.port }}
22:   echo "Visit http://127.0.0.1:8000/api/healthz"
23: {{- end }}
24: 
25: 2. API Endpoints:
26:    - Health Check: GET /api/healthz
27:    - Enroll MFA:   POST /api/auth/enroll
28:    - Login:        POST /api/auth/login
29: 
30: 3. Test the health endpoint:
31:    curl -s https://{{ (index .Values.ingress.hosts 0).host }}/api/healthz | jq
32: 
33: 4. Enroll a user for MFA:
34:    curl -X POST https://{{ (index .Values.ingress.hosts 0).host }}/api/auth/enroll \
35:      -H "Content-Type: application/json" \
36:      -d '{"username": "testuser", "password": "testpassword"}'
37: 
38: 5. Login with MFA:
39:    curl -X POST https://{{ (index .Values.ingress.hosts 0).host }}/api/auth/login \
40:      -H "Content-Type: application/json" \
41:      -d '{"username": "testuser", "password": "testpassword", "totp_code": "123456"}'
````

## File: application/backend/helm/ldap-2fa-backend/templates/secret.yaml
````yaml
 1: {{- if not .Values.externalSecret.enabled }}
 2: 
 3: 
 4: apiVersion: v1
 5: kind: Secret
 6: metadata:
 7:   name: {{ include "ldap-2fa-backend.fullname" . }}-secret
 8:   labels:
 9:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
10: type: Opaque
11: data:
12: 
13: 
14: 
15:   LDAP_ADMIN_PASSWORD: {{ "" | b64enc | quote }}
16: {{- end }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/service.yaml
````yaml
 1: apiVersion: v1
 2: kind: Service
 3: metadata:
 4:   name: {{ include "ldap-2fa-backend.fullname" . }}
 5:   labels:
 6:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 7: spec:
 8:   type: {{ .Values.service.type }}
 9:   ports:
10:     - port: {{ .Values.service.port }}
11:       targetPort: http
12:       protocol: TCP
13:       name: http
14:   selector:
15:     {{- include "ldap-2fa-backend.selectorLabels" . | nindent 4 }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/serviceaccount.yaml
````yaml
 1: {{- if .Values.serviceAccount.create -}}
 2: apiVersion: v1
 3: kind: ServiceAccount
 4: metadata:
 5:   name: {{ include "ldap-2fa-backend.serviceAccountName" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 8:   annotations:
 9:     {{- if .Values.serviceAccountIAM.roleArn }}
10:     eks.amazonaws.com/role-arn: {{ .Values.serviceAccountIAM.roleArn | quote }}
11:     {{- end }}
12:     {{- with .Values.serviceAccount.annotations }}
13:     {{- toYaml . | nindent 4 }}
14:     {{- end }}
15: automountServiceAccountToken: {{ .Values.serviceAccount.automount }}
16: {{- end }}
````

## File: application/backend/helm/ldap-2fa-backend/.helmignore
````
 1: # Patterns to ignore when building packages.
 2: # This supports shell glob matching, relative path matching, and
 3: # negation (prefixed with !). Only one pattern per line.
 4: .DS_Store
 5: # Common VCS dirs
 6: .git/
 7: .gitignore
 8: .bzr/
 9: .bzrignore
10: .hg/
11: .hgignore
12: .svn/
13: # Common backup files
14: *.swp
15: *.bak
16: *.tmp
17: *.orig
18: *~
19: # Various IDEs
20: .project
21: .idea/
22: *.tmproj
23: .vscode/
````

## File: application/backend/helm/ldap-2fa-backend/Chart.yaml
````yaml
 1: apiVersion: v2
 2: name: ldap-2fa-backend
 3: description: Backend API for LDAP 2FA authentication application
 4: 
 5: type: application
 6: 
 7: 
 8: version: 0.1.0
 9: 
10: 
11: appVersion: "1.0.0"
12: 
13: keywords:
14:   - ldap
15:   - 2fa
16:   - mfa
17:   - authentication
18:   - totp
19: 
20: maintainers:
21:   - name: Talo
22:     url: https://github.com/talorlik
23: 
24: home: https://github.com/talorlik/ldap-2fa-on-k8s
25: sources:
26:   - https://github.com/talorlik/ldap-2fa-on-k8s
````

## File: application/backend/src/app/api/__init__.py
````python
1: from app.api.routes import router
2: 
3: __all__ = ["router"]
````

## File: application/backend/src/app/database/connection.py
````python
 1: import logging
 2: from contextlib import asynccontextmanager
 3: from typing import AsyncGenerator
 4: 
 5: from sqlalchemy.ext.asyncio import (
 6:     AsyncSession,
 7:     async_sessionmaker,
 8:     create_async_engine,
 9: )
10: from sqlalchemy.pool import NullPool
11: 
12: from app.config import get_settings
13: 
14: logger = logging.getLogger(__name__)
15: 
16: 
17: _engine = None
18: AsyncSessionLocal: async_sessionmaker[AsyncSession] | None = None
19: 
20: 
21: async def init_db() -> None:
22: 
23:     global _engine, AsyncSessionLocal
24: 
25:     settings = get_settings()
26: 
27:     logger.info(f"Initializing database connection to: {settings.database_url.split('@')[-1]}")
28: 
29:     _engine = create_async_engine(
30:         settings.database_url,
31:         echo=settings.debug,
32:         poolclass=NullPool,  # Use NullPool for async
33:     )
34: 
35:     AsyncSessionLocal = async_sessionmaker(
36:         bind=_engine,
37:         class_=AsyncSession,
38:         expire_on_commit=False,
39:         autocommit=False,
40:         autoflush=False,
41:     )
42: 
43:     # Create tables
44:     from app.database.models import Base
45: 
46:     async with _engine.begin() as conn:
47:         await conn.run_sync(Base.metadata.create_all)
48: 
49:     logger.info("Database initialized successfully")
50: 
51: 
52: async def close_db() -> None:
53: 
54:     global _engine, AsyncSessionLocal
55: 
56:     if _engine:
57:         await _engine.dispose()
58:         _engine = None
59:         AsyncSessionLocal = None
60:         logger.info("Database connection closed")
61: 
62: 
63: async def get_async_session() -> AsyncGenerator[AsyncSession, None]:
64: 
65:     if AsyncSessionLocal is None:
66:         raise RuntimeError("Database not initialized. Call init_db() first.")
67: 
68:     async with AsyncSessionLocal() as session:
69:         try:
70:             yield session
71:             await session.commit()
72:         except Exception:
73:             await session.rollback()
74:             raise
75: 
76: 
77: @asynccontextmanager
78: async def get_db() -> AsyncGenerator[AsyncSession, None]:
79: 
80:     if AsyncSessionLocal is None:
81:         raise RuntimeError("Database not initialized. Call init_db() first.")
82: 
83:     async with AsyncSessionLocal() as session:
84:         try:
85:             yield session
86:             await session.commit()
87:         except Exception:
88:             await session.rollback()
89:             raise
````

## File: application/backend/src/app/email/__init__.py
````python
1: from app.email.client import EmailClient
2: 
3: __all__ = ["EmailClient"]
````

## File: application/backend/src/app/ldap/__init__.py
````python
1: from app.ldap.client import LDAPClient
2: 
3: __all__ = ["LDAPClient"]
````

## File: application/backend/src/app/mfa/__init__.py
````python
1: from app.mfa.totp import TOTPManager
2: 
3: __all__ = ["TOTPManager"]
````

## File: application/backend/src/app/mfa/totp.py
````python
  1: import base64
  2: import hashlib
  3: import hmac
  4: import logging
  5: import secrets
  6: import struct
  7: import time
  8: from typing import Optional
  9: from urllib.parse import quote
 10: 
 11: from app.config import Settings, get_settings
 12: 
 13: logger = logging.getLogger(__name__)
 14: 
 15: 
 16: class TOTPManager:
 17: 
 18: 
 19:     def __init__(self, settings: Optional[Settings] = None):
 20: 
 21:         self.settings = settings or get_settings()
 22: 
 23:     def generate_secret(self) -> str:
 24: 
 25: 
 26: 
 27: 
 28: 
 29: 
 30: 
 31:         secret_bytes = secrets.token_bytes(20)
 32: 
 33:         secret = base64.b32encode(secret_bytes).decode("utf-8")
 34:         logger.debug("Generated new TOTP secret")
 35:         return secret
 36: 
 37:     def generate_otpauth_uri(
 38:         self,
 39:         secret: str,
 40:         username: str,
 41:         issuer: Optional[str] = None,
 42:     ) -> str:
 43: 
 44: 
 45: 
 46: 
 47: 
 48: 
 49: 
 50: 
 51: 
 52: 
 53: 
 54:         issuer = issuer or self.settings.totp_issuer
 55: 
 56:         encoded_issuer = quote(issuer, safe="")
 57:         encoded_username = quote(username, safe="")
 58: 
 59:         # Build the otpauth URI
 60:         uri = (
 61:             f"otpauth://totp/{encoded_issuer}:{encoded_username}"
 62:             f"?secret={secret}"
 63:             f"&issuer={encoded_issuer}"
 64:             f"&algorithm={self.settings.totp_algorithm}"
 65:             f"&digits={self.settings.totp_digits}"
 66:             f"&period={self.settings.totp_interval}"
 67:         )
 68: 
 69:         logger.debug(f"Generated otpauth URI for user: {username}")
 70:         return uri
 71: 
 72:     def _get_algorithm(self) -> str:
 73:         """Get the hash algorithm name for hashlib."""
 74:         algorithm_map = {
 75:             "SHA1": "sha1",
 76:             "SHA256": "sha256",
 77:             "SHA512": "sha512",
 78:         }
 79:         return algorithm_map.get(self.settings.totp_algorithm, "sha1")
 80: 
 81:     def _generate_hotp(self, secret: str, counter: int) -> str:
 82: 
 83: 
 84: 
 85: 
 86: 
 87: 
 88: 
 89: 
 90: 
 91: 
 92: 
 93:         key = base64.b32decode(secret.upper())
 94: 
 95: 
 96:         counter_bytes = struct.pack(">Q", counter)
 97: 
 98: 
 99:         algorithm = self._get_algorithm()
100:         hmac_result = hmac.new(key, counter_bytes, algorithm).digest()
101: 
102: 
103:         offset = hmac_result[-1] & 0x0F
104:         truncated = struct.unpack(">I", hmac_result[offset : offset + 4])[0]
105:         truncated &= 0x7FFFFFFF
106: 
107: 
108:         otp = truncated % (10 ** self.settings.totp_digits)
109:         return str(otp).zfill(self.settings.totp_digits)
110: 
111:     def generate_totp(self, secret: str, timestamp: Optional[int] = None) -> str:
112: 
113: 
114: 
115: 
116: 
117: 
118: 
119: 
120: 
121: 
122:         if timestamp is None:
123:             timestamp = int(time.time())
124: 
125:         counter = timestamp // self.settings.totp_interval
126:         return self._generate_hotp(secret, counter)
127: 
128:     def verify_totp(
129:         self,
130:         secret: str,
131:         code: str,
132:         window: int = 1,
133:     ) -> bool:
134: 
135: 
136: 
137: 
138: 
139: 
140: 
141: 
142: 
143: 
144: 
145:         if not code or not code.isdigit():
146:             logger.warning("Invalid TOTP code format")
147:             return False
148: 
149: 
150:         code = code.zfill(self.settings.totp_digits)
151: 
152:         current_time = int(time.time())
153:         current_counter = current_time // self.settings.totp_interval
154: 
155: 
156:         for offset in range(-window, window + 1):
157:             counter = current_counter + offset
158:             expected_code = self._generate_hotp(secret, counter)
159:             if hmac.compare_digest(code, expected_code):
160:                 logger.debug(f"TOTP verification successful (offset: {offset})")
161:                 return True
162: 
163:         logger.debug("TOTP verification failed")
164:         return False
````

## File: application/backend/src/app/redis/__init__.py
````python
1: from app.redis.client import RedisOTPClient, get_otp_client
2: 
3: __all__ = ["RedisOTPClient", "get_otp_client"]
````

## File: application/backend/src/app/redis/client.py
````python
  1: import json
  2: import logging
  3: from functools import lru_cache
  4: from typing import Optional
  5: 
  6: import redis
  7: 
  8: from app.config import get_settings
  9: 
 10: logger = logging.getLogger(__name__)
 11: 
 12: 
 13: class RedisOTPClient:
 14: 
 15: 
 16: 
 17: 
 18: 
 19: 
 20:     def __init__(self) -> None:
 21: 
 22:         self._settings = get_settings()
 23:         self._client: Optional[redis.Redis] = None
 24:         self._connected = False
 25: 
 26:         if self._settings.redis_enabled:
 27:             self._initialize_client()
 28: 
 29:     def _initialize_client(self) -> None:
 30: 
 31:         try:
 32:             self._client = redis.Redis(
 33:                 host=self._settings.redis_host,
 34:                 port=self._settings.redis_port,
 35:                 password=self._settings.redis_password or None,
 36:                 db=self._settings.redis_db,
 37:                 ssl=self._settings.redis_ssl,
 38:                 decode_responses=True,
 39:                 socket_connect_timeout=5,
 40:                 socket_timeout=5,
 41:                 retry_on_timeout=True,
 42:             )
 43: 
 44:             self._client.ping()
 45:             self._connected = True
 46:             logger.info(
 47:                 "Redis connected successfully to %s:%s",
 48:                 self._settings.redis_host,
 49:                 self._settings.redis_port,
 50:             )
 51:         except redis.ConnectionError as e:
 52:             logger.error("Failed to connect to Redis: %s", e)
 53:             self._connected = False
 54:             self._client = None
 55:         except redis.AuthenticationError as e:
 56:             logger.error("Redis authentication failed: %s", e)
 57:             self._connected = False
 58:             self._client = None
 59: 
 60:     @property
 61:     def is_enabled(self) -> bool:
 62: 
 63:         return self._settings.redis_enabled
 64: 
 65:     @property
 66:     def is_connected(self) -> bool:
 67: 
 68:         if not self._connected or not self._client:
 69:             return False
 70:         try:
 71:             self._client.ping()
 72:             return True
 73:         except (redis.ConnectionError, redis.TimeoutError):
 74:             self._connected = False
 75:             return False
 76: 
 77:     def _get_key(self, username: str) -> str:
 78: 
 79:         return f"{self._settings.redis_key_prefix}{username}"
 80: 
 81:     def store_code(
 82:         self,
 83:         username: str,
 84:         code: str,
 85:         phone_number: str,
 86:         ttl_seconds: Optional[int] = None,
 87:     ) -> bool:
 88:         """Store OTP code with automatic TTL expiration.
 89: 
 90:         Args:
 91:             username: The username to store the code for
 92:             code: The verification code
 93:             phone_number: The phone number (for reference)
 94:             ttl_seconds: Time-to-live in seconds (defaults to settings value)
 95: 
 96:         Returns:
 97:             True if successful, False otherwise
 98:         """
 99:         if not self.is_enabled:
100:             logger.debug("Redis not enabled, skipping store_code")
101:             return False
102: 
103:         if not self.is_connected:
104:             logger.error("Redis not connected, cannot store code")
105:             return False
106: 
107:         try:
108:             key = self._get_key(username)
109:             value = json.dumps({
110:                 "code": code,
111:                 "phone_number": phone_number,
112:             })
113:             ttl = ttl_seconds or self._settings.sms_code_expiry_seconds
114: 
115:             self._client.setex(key, ttl, value)
116:             logger.debug("Stored OTP code for %s with TTL %ss", username, ttl)
117:             return True
118:         except redis.RedisError as e:
119:             logger.error("Failed to store OTP code: %s", e)
120:             return False
121: 
122:     def get_code(self, username: str) -> Optional[dict]:
123: 
124: 
125: 
126: 
127: 
128: 
129: 
130: 
131:         if not self.is_enabled:
132:             logger.debug("Redis not enabled, skipping get_code")
133:             return None
134: 
135:         if not self.is_connected:
136:             logger.error("Redis not connected, cannot get code")
137:             return None
138: 
139:         try:
140:             key = self._get_key(username)
141:             value = self._client.get(key)
142: 
143:             if value is None:
144:                 logger.debug("No OTP code found for %s", username)
145:                 return None
146: 
147:             data = json.loads(value)
148:             logger.debug("Retrieved OTP code for %s", username)
149:             return data
150:         except redis.RedisError as e:
151:             logger.error("Failed to retrieve OTP code: %s", e)
152:             return None
153:         except json.JSONDecodeError as e:
154:             logger.error("Failed to decode OTP data: %s", e)
155:             return None
156: 
157:     def delete_code(self, username: str) -> bool:
158: 
159: 
160: 
161: 
162: 
163: 
164: 
165: 
166:         if not self.is_enabled:
167:             logger.debug("Redis not enabled, skipping delete_code")
168:             return False
169: 
170:         if not self.is_connected:
171:             logger.error("Redis not connected, cannot delete code")
172:             return False
173: 
174:         try:
175:             key = self._get_key(username)
176:             deleted = self._client.delete(key)
177:             logger.debug("Deleted OTP code for %s: %s", username, deleted > 0)
178:             return deleted > 0
179:         except redis.RedisError as e:
180:             logger.error("Failed to delete OTP code: %s", e)
181:             return False
182: 
183:     def code_exists(self, username: str) -> bool:
184: 
185: 
186: 
187: 
188: 
189: 
190: 
191: 
192:         if not self.is_enabled:
193:             return False
194: 
195:         if not self.is_connected:
196:             return False
197: 
198:         try:
199:             key = self._get_key(username)
200:             return self._client.exists(key) > 0
201:         except redis.RedisError as e:
202:             logger.error("Failed to check OTP code existence: %s", e)
203:             return False
204: 
205:     def get_ttl(self, username: str) -> int:
206: 
207: 
208: 
209: 
210: 
211: 
212: 
213: 
214:         if not self.is_enabled or not self.is_connected:
215:             return -2
216: 
217:         try:
218:             key = self._get_key(username)
219:             return self._client.ttl(key)
220:         except redis.RedisError as e:
221:             logger.error("Failed to get TTL: %s", e)
222:             return -2
223: 
224:     def health_check(self) -> dict:
225: 
226: 
227: 
228: 
229: 
230:         if not self.is_enabled:
231:             return {
232:                 "enabled": False,
233:                 "connected": False,
234:                 "status": "disabled",
235:             }
236: 
237:         try:
238:             if self._client and self._client.ping():
239:                 info = self._client.info("server")
240:                 return {
241:                     "enabled": True,
242:                     "connected": True,
243:                     "status": "healthy",
244:                     "redis_version": info.get("redis_version", "unknown"),
245:                 }
246:         except redis.RedisError as e:
247:             return {
248:                 "enabled": True,
249:                 "connected": False,
250:                 "status": "unhealthy",
251:                 "error": str(e),
252:             }
253: 
254:         return {
255:             "enabled": True,
256:             "connected": False,
257:             "status": "disconnected",
258:         }
259: 
260: 
261: 
262: _inmemory_sms_codes: dict[str, dict] = {}
263: 
264: 
265: class InMemoryOTPStorage:
266: 
267: 
268: 
269: 
270: 
271:     @staticmethod
272:     def store_code(
273:         username: str,
274:         code: str,
275:         phone_number: str,
276:         expires_at: float,
277:     ) -> bool:
278: 
279:         _inmemory_sms_codes[username] = {
280:             "code": code,
281:             "phone_number": phone_number,
282:             "expires_at": expires_at,
283:         }
284:         return True
285: 
286:     @staticmethod
287:     def get_code(username: str) -> Optional[dict]:
288: 
289:         return _inmemory_sms_codes.get(username)
290: 
291:     @staticmethod
292:     def delete_code(username: str) -> bool:
293: 
294:         if username in _inmemory_sms_codes:
295:             del _inmemory_sms_codes[username]
296:             return True
297:         return False
298: 
299:     @staticmethod
300:     def code_exists(username: str) -> bool:
301: 
302:         return username in _inmemory_sms_codes
303: 
304: 
305: @lru_cache
306: def get_otp_client() -> RedisOTPClient:
307: 
308:     return RedisOTPClient()
````

## File: application/backend/src/app/sms/__init__.py
````python
1: from app.sms.client import SMSClient
2: 
3: __all__ = ["SMSClient"]
````

## File: application/backend/Dockerfile
````
 1: # Stage 1: Build stage
 2: FROM python:3.12-slim AS builder
 3: 
 4: WORKDIR /app
 5: 
 6: # Install build dependencies
 7: RUN apt-get update && apt-get install -y --no-install-recommends \
 8:     gcc \
 9:     libldap2-dev \
10:     libsasl2-dev \
11:     && rm -rf /var/lib/apt/lists/*
12: 
13: # Copy requirements and install dependencies
14: COPY src/requirements.txt .
15: RUN pip install --no-cache-dir --user -r requirements.txt
16: 
17: # Stage 2: Runtime stage
18: FROM python:3.12-slim
19: 
20: # Create non-root user for security
21: RUN groupadd -r appgroup && useradd -r -g appgroup appuser
22: 
23: WORKDIR /app
24: 
25: # Install runtime dependencies only
26: RUN apt-get update && apt-get install -y --no-install-recommends \
27:     libldap-2.5-0 \
28:     libsasl2-2 \
29:     && rm -rf /var/lib/apt/lists/* \
30:     && apt-get clean
31: 
32: # Copy installed packages from builder
33: COPY --from=builder /root/.local /home/appuser/.local
34: 
35: # Copy application code
36: COPY src/app ./app
37: 
38: # Set environment variables
39: ENV PATH=/home/appuser/.local/bin:$PATH \
40:     PYTHONDONTWRITEBYTECODE=1 \
41:     PYTHONUNBUFFERED=1 \
42:     PYTHONPATH=/app
43: 
44: # Default environment variables (can be overridden)
45: ENV LDAP_HOST=openldap-stack-ha.ldap.svc.cluster.local \
46:     LDAP_PORT=389 \
47:     LDAP_USE_SSL=false \
48:     LDAP_BASE_DN=dc=ldap,dc=talorlik,dc=internal \
49:     LDAP_USER_SEARCH_BASE=ou=users \
50:     TOTP_ISSUER=LDAP-2FA-App \
51:     TOTP_DIGITS=6 \
52:     TOTP_INTERVAL=30 \
53:     TOTP_ALGORITHM=SHA1 \
54:     APP_NAME="LDAP 2FA Backend API" \
55:     DEBUG=false \
56:     LOG_LEVEL=INFO
57: 
58: # Switch to non-root user
59: USER appuser
60: 
61: # Expose port
62: EXPOSE 8000
63: 
64: # Health check
65: HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
66:     CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/healthz')" || exit 1
67: 
68: # Run the application with gunicorn for production
69: CMD ["gunicorn", "app.main:app", \
70:     "--bind", "0.0.0.0:8000", \
71:     "--workers", "2", \
72:     "--worker-class", "uvicorn.workers.UvicornWorker", \
73:     "--access-logfile", "-", \
74:     "--error-logfile", "-"]
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/tests/test-connection.yaml
````yaml
 1: apiVersion: v1
 2: kind: Pod
 3: metadata:
 4:   name: "{{ include "ldap-2fa-frontend.fullname" . }}-test-connection"
 5:   labels:
 6:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 7:   annotations:
 8:     "helm.sh/hook": test
 9: spec:
10:   containers:
11:     - name: wget
12:       image: busybox
13:       command: ['wget']
14:       args: ['{{ include "ldap-2fa-frontend.fullname" . }}:{{ .Values.service.port }}']
15:   restartPolicy: Never
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/_helpers.tpl
````
 1: {{/*
 2: Expand the name of the chart.
 3: */}}
 4: {{- define "ldap-2fa-frontend.name" -}}
 5: {{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
 6: {{- end }}
 7: 
 8: {{/*
 9: Create a default fully qualified app name.
10: We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec).
11: If release name contains chart name it will be used as a full name.
12: */}}
13: {{- define "ldap-2fa-frontend.fullname" -}}
14: {{- if .Values.fullnameOverride }}
15: {{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
16: {{- else }}
17: {{- $name := default .Chart.Name .Values.nameOverride }}
18: {{- if contains $name .Release.Name }}
19: {{- .Release.Name | trunc 63 | trimSuffix "-" }}
20: {{- else }}
21: {{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
22: {{- end }}
23: {{- end }}
24: {{- end }}
25: 
26: {{/*
27: Create chart name and version as used by the chart label.
28: */}}
29: {{- define "ldap-2fa-frontend.chart" -}}
30: {{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
31: {{- end }}
32: 
33: {{/*
34: Common labels
35: */}}
36: {{- define "ldap-2fa-frontend.labels" -}}
37: helm.sh/chart: {{ include "ldap-2fa-frontend.chart" . }}
38: {{ include "ldap-2fa-frontend.selectorLabels" . }}
39: {{- if .Chart.AppVersion }}
40: app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
41: {{- end }}
42: app.kubernetes.io/managed-by: {{ .Release.Service }}
43: {{- end }}
44: 
45: {{/*
46: Selector labels
47: */}}
48: {{- define "ldap-2fa-frontend.selectorLabels" -}}
49: app.kubernetes.io/name: {{ include "ldap-2fa-frontend.name" . }}
50: app.kubernetes.io/instance: {{ .Release.Name }}
51: {{- end }}
52: 
53: {{/*
54: Create the name of the service account to use
55: */}}
56: {{- define "ldap-2fa-frontend.serviceAccountName" -}}
57: {{- if .Values.serviceAccount.create }}
58: {{- default (include "ldap-2fa-frontend.fullname" .) .Values.serviceAccount.name }}
59: {{- else }}
60: {{- default "default" .Values.serviceAccount.name }}
61: {{- end }}
62: {{- end }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/deployment.yaml
````yaml
 1: apiVersion: apps/v1
 2: kind: Deployment
 3: metadata:
 4:   name: {{ include "ldap-2fa-frontend.fullname" . }}
 5:   labels:
 6:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 7: spec:
 8:   {{- if not .Values.autoscaling.enabled }}
 9:   replicas: {{ .Values.replicaCount }}
10:   {{- end }}
11:   selector:
12:     matchLabels:
13:       {{- include "ldap-2fa-frontend.selectorLabels" . | nindent 6 }}
14:   template:
15:     metadata:
16:       {{- with .Values.podAnnotations }}
17:       annotations:
18:         {{- toYaml . | nindent 8 }}
19:       {{- end }}
20:       labels:
21:         {{- include "ldap-2fa-frontend.labels" . | nindent 8 }}
22:         {{- with .Values.podLabels }}
23:         {{- toYaml . | nindent 8 }}
24:         {{- end }}
25:     spec:
26:       {{- with .Values.imagePullSecrets }}
27:       imagePullSecrets:
28:         {{- toYaml . | nindent 8 }}
29:       {{- end }}
30:       serviceAccountName: {{ include "ldap-2fa-frontend.serviceAccountName" . }}
31:       {{- with .Values.podSecurityContext }}
32:       securityContext:
33:         {{- toYaml . | nindent 8 }}
34:       {{- end }}
35:       containers:
36:         - name: {{ .Chart.Name }}
37:           {{- with .Values.securityContext }}
38:           securityContext:
39:             {{- toYaml . | nindent 12 }}
40:           {{- end }}
41:           image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
42:           imagePullPolicy: {{ .Values.image.pullPolicy }}
43:           ports:
44:             - name: http
45:               containerPort: {{ .Values.service.port }}
46:               protocol: TCP
47:           {{- with .Values.livenessProbe }}
48:           livenessProbe:
49:             {{- toYaml . | nindent 12 }}
50:           {{- end }}
51:           {{- with .Values.readinessProbe }}
52:           readinessProbe:
53:             {{- toYaml . | nindent 12 }}
54:           {{- end }}
55:           {{- with .Values.resources }}
56:           resources:
57:             {{- toYaml . | nindent 12 }}
58:           {{- end }}
59:           {{- with .Values.volumeMounts }}
60:           volumeMounts:
61:             {{- toYaml . | nindent 12 }}
62:           {{- end }}
63:       {{- with .Values.volumes }}
64:       volumes:
65:         {{- toYaml . | nindent 8 }}
66:       {{- end }}
67:       {{- with .Values.nodeSelector }}
68:       nodeSelector:
69:         {{- toYaml . | nindent 8 }}
70:       {{- end }}
71:       {{- with .Values.affinity }}
72:       affinity:
73:         {{- toYaml . | nindent 8 }}
74:       {{- end }}
75:       {{- with .Values.tolerations }}
76:       tolerations:
77:         {{- toYaml . | nindent 8 }}
78:       {{- end }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/hpa.yaml
````yaml
 1: {{- if .Values.autoscaling.enabled }}
 2: apiVersion: autoscaling/v2
 3: kind: HorizontalPodAutoscaler
 4: metadata:
 5:   name: {{ include "ldap-2fa-frontend.fullname" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 8: spec:
 9:   scaleTargetRef:
10:     apiVersion: apps/v1
11:     kind: Deployment
12:     name: {{ include "ldap-2fa-frontend.fullname" . }}
13:   minReplicas: {{ .Values.autoscaling.minReplicas }}
14:   maxReplicas: {{ .Values.autoscaling.maxReplicas }}
15:   metrics:
16:     {{- if .Values.autoscaling.targetCPUUtilizationPercentage }}
17:     - type: Resource
18:       resource:
19:         name: cpu
20:         target:
21:           type: Utilization
22:           averageUtilization: {{ .Values.autoscaling.targetCPUUtilizationPercentage }}
23:     {{- end }}
24:     {{- if .Values.autoscaling.targetMemoryUtilizationPercentage }}
25:     - type: Resource
26:       resource:
27:         name: memory
28:         target:
29:           type: Utilization
30:           averageUtilization: {{ .Values.autoscaling.targetMemoryUtilizationPercentage }}
31:     {{- end }}
32: {{- end }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/ingress.yaml
````yaml
 1: {{- if .Values.ingress.enabled -}}
 2: apiVersion: networking.k8s.io/v1
 3: kind: Ingress
 4: metadata:
 5:   name: {{ include "ldap-2fa-frontend.fullname" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 8:   {{- with .Values.ingress.annotations }}
 9:   annotations:
10:     {{- toYaml . | nindent 4 }}
11:   {{- end }}
12: spec:
13:   {{- with .Values.ingress.className }}
14:   ingressClassName: {{ . }}
15:   {{- end }}
16:   {{- if .Values.ingress.tls }}
17:   tls:
18:     {{- range .Values.ingress.tls }}
19:     - hosts:
20:         {{- range .hosts }}
21:         - {{ . | quote }}
22:         {{- end }}
23:       secretName: {{ .secretName }}
24:     {{- end }}
25:   {{- end }}
26:   rules:
27:     {{- range .Values.ingress.hosts }}
28:     - host: {{ .host | quote }}
29:       http:
30:         paths:
31:           {{- range .paths }}
32:           - path: {{ .path }}
33:             {{- with .pathType }}
34:             pathType: {{ . }}
35:             {{- end }}
36:             backend:
37:               service:
38:                 name: {{ include "ldap-2fa-frontend.fullname" $ }}
39:                 port:
40:                   number: {{ $.Values.service.port }}
41:           {{- end }}
42:     {{- end }}
43: {{- end }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/NOTES.txt
````
 1: LDAP 2FA Frontend has been deployed!
 2: 
 3: 1. Get the application URL:
 4: {{- if .Values.ingress.enabled }}
 5: {{- range $host := .Values.ingress.hosts }}
 6:   {{- range .paths }}
 7:   https://{{ $host.host }}{{ .path }}
 8:   {{- end }}
 9: {{- end }}
10: {{- else if contains "NodePort" .Values.service.type }}
11:   export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "ldap-2fa-frontend.fullname" . }})
12:   export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
13:   echo http://$NODE_IP:$NODE_PORT
14: {{- else if contains "LoadBalancer" .Values.service.type }}
15:   NOTE: It may take a few minutes for the LoadBalancer IP to be available.
16:         You can watch the status by running:
17:         kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "ldap-2fa-frontend.fullname" . }}
18:   export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "ldap-2fa-frontend.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
19:   echo http://$SERVICE_IP:{{ .Values.service.port }}
20: {{- else if contains "ClusterIP" .Values.service.type }}
21:   kubectl --namespace {{ .Release.Namespace }} port-forward svc/{{ include "ldap-2fa-frontend.fullname" . }} 8080:{{ .Values.service.port }}
22:   echo "Visit http://127.0.0.1:8080"
23: {{- end }}
24: 
25: 2. Features:
26:    - User enrollment for MFA (generates QR code for authenticator apps)
27:    - Login with LDAP credentials + TOTP code
28:    - Responsive design with dark mode support
29: 
30: 3. The frontend communicates with the backend via relative URLs:
31:    - /api/healthz - Health check
32:    - /api/auth/enroll - MFA enrollment
33:    - /api/auth/login - Login with 2FA
34: 
35: 4. Ensure the backend is deployed and accessible at the same host:
36:    kubectl get ingress -n {{ .Release.Namespace }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/service.yaml
````yaml
 1: apiVersion: v1
 2: kind: Service
 3: metadata:
 4:   name: {{ include "ldap-2fa-frontend.fullname" . }}
 5:   labels:
 6:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 7: spec:
 8:   type: {{ .Values.service.type }}
 9:   ports:
10:     - port: {{ .Values.service.port }}
11:       targetPort: http
12:       protocol: TCP
13:       name: http
14:   selector:
15:     {{- include "ldap-2fa-frontend.selectorLabels" . | nindent 4 }}
````

## File: application/frontend/helm/ldap-2fa-frontend/templates/serviceaccount.yaml
````yaml
 1: {{- if .Values.serviceAccount.create -}}
 2: apiVersion: v1
 3: kind: ServiceAccount
 4: metadata:
 5:   name: {{ include "ldap-2fa-frontend.serviceAccountName" . }}
 6:   labels:
 7:     {{- include "ldap-2fa-frontend.labels" . | nindent 4 }}
 8:   {{- with .Values.serviceAccount.annotations }}
 9:   annotations:
10:     {{- toYaml . | nindent 4 }}
11:   {{- end }}
12: automountServiceAccountToken: {{ .Values.serviceAccount.automount }}
13: {{- end }}
````

## File: application/frontend/helm/ldap-2fa-frontend/.helmignore
````
 1: # Patterns to ignore when building packages.
 2: # This supports shell glob matching, relative path matching, and
 3: # negation (prefixed with !). Only one pattern per line.
 4: .DS_Store
 5: # Common VCS dirs
 6: .git/
 7: .gitignore
 8: .bzr/
 9: .bzrignore
10: .hg/
11: .hgignore
12: .svn/
13: # Common backup files
14: *.swp
15: *.bak
16: *.tmp
17: *.orig
18: *~
19: # Various IDEs
20: .project
21: .idea/
22: *.tmproj
23: .vscode/
````

## File: application/frontend/helm/ldap-2fa-frontend/Chart.yaml
````yaml
 1: apiVersion: v2
 2: name: ldap-2fa-frontend
 3: description: Frontend UI for LDAP 2FA authentication application
 4: 
 5: type: application
 6: 
 7: 
 8: version: 0.1.0
 9: 
10: 
11: appVersion: "1.0.0"
12: 
13: keywords:
14:   - ldap
15:   - 2fa
16:   - mfa
17:   - authentication
18:   - frontend
19:   - nginx
20: 
21: maintainers:
22:   - name: Talo
23:     url: https://github.com/talorlik
24: 
25: home: https://github.com/talorlik/ldap-2fa-on-k8s
26: sources:
27:   - https://github.com/talorlik/ldap-2fa-on-k8s
````

## File: application/frontend/Dockerfile
````
 1: # Stage 1: Build stage (for any potential future build steps like minification)
 2: FROM node:20-alpine AS builder
 3: 
 4: WORKDIR /app
 5: 
 6: # Copy source files
 7: COPY src/ ./src/
 8: 
 9: # In a real-world scenario, you might add build steps here:
10: # - npm install
11: # - npm run build (minify, bundle, etc.)
12: 
13: # For now, we just copy the files as-is since we're using vanilla HTML/CSS/JS
14: 
15: # Stage 2: Production stage with nginx
16: FROM nginx:1.27-alpine
17: 
18: # Remove default nginx configuration
19: RUN rm -rf /etc/nginx/conf.d/default.conf
20: 
21: # Copy custom nginx configuration
22: COPY nginx.conf /etc/nginx/conf.d/default.conf
23: 
24: # Copy static files from builder
25: COPY --from=builder /app/src/ /usr/share/nginx/html/
26: 
27: # Create non-root user and set permissions
28: RUN addgroup -g 1000 -S appgroup && \
29:     adduser -u 1000 -S appuser -G appgroup && \
30:     chown -R appuser:appgroup /usr/share/nginx/html && \
31:     chown -R appuser:appgroup /var/cache/nginx && \
32:     chown -R appuser:appgroup /var/log/nginx && \
33:     chown -R appuser:appgroup /etc/nginx/conf.d && \
34:     touch /var/run/nginx.pid && \
35:     chown -R appuser:appgroup /var/run/nginx.pid
36: 
37: # Switch to non-root user
38: USER appuser
39: 
40: # Expose port
41: EXPOSE 80
42: 
43: # Health check
44: HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
45:     CMD wget --no-verbose --tries=1 --spider http://localhost/health || exit 1
46: 
47: # Start nginx
48: CMD ["nginx", "-g", "daemon off;"]
````

## File: application/frontend/nginx.conf
````ini
 1: server {
 2:     listen 80;
 3:     listen [::]:80;
 4:     server_name _;
 5: 
 6:     # Root directory for static files
 7:     root /usr/share/nginx/html;
 8:     index index.html;
 9: 
10:     # Security headers
11:     add_header X-Frame-Options "SAMEORIGIN" always;
12:     add_header X-Content-Type-Options "nosniff" always;
13:     add_header X-XSS-Protection "1; mode=block" always;
14:     add_header Referrer-Policy "strict-origin-when-cross-origin" always;
15: 
16:     # Gzip compression
17:     gzip on;
18:     gzip_vary on;
19:     gzip_min_length 1024;
20:     gzip_proxied any;
21:     gzip_types
22:         text/plain
23:         text/css
24:         text/javascript
25:         application/javascript
26:         application/json
27:         application/xml
28:         image/svg+xml;
29: 
30:     # Serve static files
31:     location / {
32:         try_files $uri $uri/ /index.html;
33: 
34:         # Cache static assets
35:         location ~* \.(css|js|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
36:             expires 1y;
37:             add_header Cache-Control "public, immutable";
38:             access_log off;
39:         }
40:     }
41: 
42:     # Health check endpoint
43:     location /health {
44:         access_log off;
45:         return 200 "healthy\n";
46:         add_header Content-Type text/plain;
47:     }
48: 
49:     # Deny access to hidden files
50:     location ~ /\. {
51:         deny all;
52:         access_log off;
53:         log_not_found off;
54:     }
55: 
56:     # Custom error pages
57:     error_page 404 /index.html;
58:     error_page 500 502 503 504 /50x.html;
59:     location = /50x.html {
60:         root /usr/share/nginx/html;
61:     }
62: }
````

## File: application/helm/postgresql-values.tpl.yaml
````yaml
 1: global:
 2:   security:
 3:     allowInsecureImages: true
 4: 
 5: 
 6: image:
 7:   registry: "${ecr_registry}"
 8:   repository: "${ecr_repository}"
 9:   tag: "${image_tag}"
10:   pullPolicy: IfNotPresent
11: 
12: 
13: architecture: standalone
14: 
15: 
16: auth:
17:   database: "${database_name}"
18:   username: "${database_username}"
19:   enablePostgresUser: false
20: 
21: 
22:   existingSecret: "${secret_name}"
23:   existingSecretPasswordKey: "password"
24: 
25: 
26: primary:
27: 
28:   persistence:
29:     enabled: true
30: %{ if storage_class != "" ~}
31:     storageClass: "${storage_class}"
32: %{ endif ~}
33:     size: "${storage_size}"
34: 
35:   # Resource limits
36:   resources:
37:     requests:
38:       cpu: "${resources_requests_cpu}"
39:       memory: "${resources_requests_memory}"
40:     limits:
41:       cpu: "${resources_limits_cpu}"
42:       memory: "${resources_limits_memory}"
43: 
44: 
45:   service:
46:     type: ClusterIP
47: 
48: 
49: metrics:
50:   enabled: false
````

## File: application/modules/alb/outputs.tf
````hcl
 1: # output "alb_dns_name" {
 2: #   description = "Application Load Balancer DNS Name"
 3: #   value = (
 4: #     length(kubernetes_ingress_v1.ingress_alb.status) > 0 &&
 5: #     length(kubernetes_ingress_v1.ingress_alb.status[0].load_balancer) > 0 &&
 6: #     length(kubernetes_ingress_v1.ingress_alb.status[0].load_balancer[0].ingress) > 0
 7: #   ) ? kubernetes_ingress_v1.ingress_alb.status[0].load_balancer[0].ingress[0].hostname : "ALB is still provisioning"
 8: # }
 9: 
10: output "ingress_class_name" {
11:   description = "Name of the IngressClass for shared ALB"
12:   value       = kubernetes_ingress_class_v1.ingressclass_alb.metadata[0].name
13: }
14: 
15: output "ingress_class_params_name" {
16:   description = "Name of the IngressClassParams for ALB configuration"
17:   value       = local.ingressclassparams_alb_name
18: }
19: 
20: output "alb_scheme" {
21:   description = "ALB scheme configured in IngressClassParams"
22:   value       = var.alb_scheme
23: }
24: 
25: output "alb_ip_address_type" {
26:   description = "ALB IP address type configured in IngressClassParams"
27:   value       = var.alb_ip_address_type
28: }
````

## File: application/modules/argocd/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name added to all resources"
 13:   type        = string
 14: }
 15: 
 16: variable "cluster_name" {
 17:   description = "Name of the EKS cluster"
 18:   type        = string
 19: }
 20: 
 21: variable "argocd_role_name_component" {
 22:   description = "Name component for ArgoCD IAM role (between prefix and env)"
 23:   type        = string
 24:   default     = "argocd-role"
 25: }
 26: 
 27: variable "argocd_capability_name_component" {
 28:   description = "Name component for ArgoCD capability (between prefix and env)"
 29:   type        = string
 30:   default     = "argocd"
 31: }
 32: 
 33: variable "argocd_namespace" {
 34:   description = "Kubernetes namespace for ArgoCD resources"
 35:   type        = string
 36:   default     = "argocd"
 37: }
 38: 
 39: variable "argocd_project_name" {
 40:   description = "ArgoCD project name for cluster registration"
 41:   type        = string
 42:   default     = "default"
 43: }
 44: 
 45: variable "local_cluster_secret_name" {
 46:   description = "Name of the Kubernetes secret for local cluster registration"
 47:   type        = string
 48:   default     = "local-cluster"
 49: }
 50: 
 51: variable "idc_instance_arn" {
 52:   description = "ARN of the AWS Identity Center instance used for Argo CD auth"
 53:   type        = string
 54: }
 55: 
 56: variable "idc_region" {
 57:   description = "Region of the Identity Center instance"
 58:   type        = string
 59: }
 60: 
 61: variable "rbac_role_mappings" {
 62:   description = "List of RBAC role mappings for Identity Center groups/users"
 63:   type = list(object({
 64:     role = string
 65:     identities = list(object({
 66:       id   = string
 67:       type = string # SSO_GROUP or SSO_USER
 68:     }))
 69:   }))
 70:   default = []
 71: }
 72: 
 73: variable "argocd_vpce_ids" {
 74:   description = "Optional list of VPC endpoint IDs for private access to Argo CD"
 75:   type        = list(string)
 76:   default     = []
 77: }
 78: 
 79: variable "delete_propagation_policy" {
 80:   description = "Delete propagation policy for ArgoCD capability (RETAIN or DELETE)"
 81:   type        = string
 82:   default     = "RETAIN"
 83:   validation {
 84:     condition     = contains(["RETAIN", "DELETE"], var.delete_propagation_policy)
 85:     error_message = "Delete propagation policy must be either 'RETAIN' or 'DELETE'"
 86:   }
 87: }
 88: 
 89: # IAM Policy Resources
 90: variable "iam_policy_eks_resources" {
 91:   description = "List of EKS resource ARNs for IAM policy (use ['*'] for all clusters)"
 92:   type        = list(string)
 93:   default     = ["*"]
 94: }
 95: 
 96: variable "iam_policy_secrets_manager_resources" {
 97:   description = "List of Secrets Manager secret ARNs for IAM policy (use ['*'] for all secrets)"
 98:   type        = list(string)
 99:   default     = ["*"]
100: }
101: 
102: variable "iam_policy_code_connections_resources" {
103:   description = "List of CodeConnections connection ARNs for IAM policy (use ['*'] for all connections)"
104:   type        = list(string)
105:   default     = ["*"]
106: }
107: 
108: variable "enable_ecr_access" {
109:   description = "Whether to enable ECR access in IAM policy (for pulling container images)"
110:   type        = bool
111:   default     = false
112: }
113: 
114: variable "iam_policy_ecr_resources" {
115:   description = "List of ECR repository ARNs for IAM policy (use ['*'] for all repositories)"
116:   type        = list(string)
117:   default     = ["*"]
118: }
119: 
120: variable "enable_codecommit_access" {
121:   description = "Whether to enable CodeCommit access in IAM policy (for Git repository access)"
122:   type        = bool
123:   default     = false
124: }
125: 
126: variable "iam_policy_codecommit_resources" {
127:   description = "List of CodeCommit repository ARNs for IAM policy (use ['*'] for all repositories)"
128:   type        = list(string)
129:   default     = ["*"]
130: }
````

## File: application/modules/argocd_app/outputs.tf
````hcl
 1: output "app_name" {
 2:   description = "Name of the ArgoCD Application"
 3:   value       = kubernetes_manifest.argocd_app.manifest.metadata.name
 4: }
 5: 
 6: output "app_namespace" {
 7:   description = "Namespace where the ArgoCD Application is deployed"
 8:   value       = kubernetes_manifest.argocd_app.manifest.metadata.namespace
 9: }
10: 
11: output "app_uid" {
12:   description = "UID of the ArgoCD Application resource"
13:   value       = kubernetes_manifest.argocd_app.manifest.metadata.uid
14: }
15: 
16: output "destination_namespace" {
17:   description = "Target Kubernetes namespace for the application"
18:   value       = var.destination_namespace
19: }
20: 
21: output "repo_url" {
22:   description = "Git repository URL for the Application"
23:   value       = var.repo_url
24: }
25: 
26: output "repo_path" {
27:   description = "Path within the repository"
28:   value       = var.repo_path
29: }
30: 
31: output "target_revision" {
32:   description = "Git branch/tag/commit being synced"
33:   value       = var.target_revision
34: }
````

## File: application/modules/cert-manager/outputs.tf
````hcl
1: output "certificate_secret_name" {
2:   description = "Name of the Kubernetes secret containing the TLS certificate"
3:   value       = "openldap-tls"
4: }
````

## File: application/modules/cert-manager/variables.tf
````hcl
 1: variable "cluster_name" {
 2:   description = "Name of the EKS cluster"
 3:   type        = string
 4: }
 5: 
 6: variable "namespace" {
 7:   description = "Kubernetes namespace where OpenLDAP is deployed"
 8:   type        = string
 9: }
10: 
11: variable "domain_name" {
12:   description = "Domain name for certificate DNS names"
13:   type        = string
14: }
````

## File: application/modules/network-policies/outputs.tf
````hcl
 1: output "network_policy_name" {
 2:   description = "Name of the network policy for secure namespace communication"
 3:   value       = kubernetes_network_policy_v1.namespace_secure_communication.metadata[0].name
 4: }
 5: 
 6: output "network_policy_namespace" {
 7:   description = "Namespace where the network policy is applied"
 8:   value       = kubernetes_network_policy_v1.namespace_secure_communication.metadata[0].namespace
 9: }
10: 
11: output "network_policy_uid" {
12:   description = "UID of the network policy resource"
13:   value       = kubernetes_network_policy_v1.namespace_secure_communication.metadata[0].uid
14: }
````

## File: application/modules/network-policies/variables.tf
````hcl
1: variable "namespace" {
2:   description = "Kubernetes namespace where network policies will be applied"
3:   type        = string
4:   default     = "ldap"
5: }
````

## File: application/modules/postgresql/outputs.tf
````hcl
 1: output "host" {
 2:   description = "PostgreSQL service hostname"
 3:   value       = "postgresql.${var.namespace}.svc.cluster.local"
 4: }
 5: 
 6: output "port" {
 7:   description = "PostgreSQL service port"
 8:   value       = 5432
 9: }
10: 
11: output "database" {
12:   description = "Database name"
13:   value       = var.database_name
14: }
15: 
16: output "username" {
17:   description = "Database username"
18:   value       = var.database_username
19: }
20: 
21: output "connection_url" {
22:   description = "PostgreSQL connection URL (without password)"
23:   value       = "postgresql+asyncpg://${var.database_username}@postgresql.${var.namespace}.svc.cluster.local:5432/${var.database_name}"
24: }
25: 
26: output "namespace" {
27:   description = "Kubernetes namespace where PostgreSQL is deployed"
28:   value       = var.namespace
29: }
````

## File: application/modules/redis/outputs.tf
````hcl
 1: output "redis_enabled" {
 2:   description = "Whether Redis is enabled"
 3:   value       = var.enable_redis
 4: }
 5: 
 6: output "redis_host" {
 7:   description = "Redis service hostname"
 8:   value       = var.enable_redis ? "redis-master.${var.namespace}.svc.cluster.local" : ""
 9: }
10: 
11: output "redis_port" {
12:   description = "Redis service port"
13:   value       = 6379
14: }
15: 
16: output "redis_namespace" {
17:   description = "Kubernetes namespace where Redis is deployed"
18:   value       = var.enable_redis ? var.namespace : ""
19: }
20: 
21: output "redis_password_secret_name" {
22:   description = "Name of the Kubernetes secret containing Redis password"
23:   value       = var.enable_redis ? var.secret_name : ""
24: }
25: 
26: output "redis_password_secret_key" {
27:   description = "Key in the secret for Redis password"
28:   value       = "redis-password"
29: }
30: 
31: output "redis_connection_url" {
32:   description = "Redis connection URL (without password)"
33:   value       = var.enable_redis ? "redis://redis-master.${var.namespace}.svc.cluster.local:6379/0" : ""
34: }
````

## File: application/modules/route53/outputs.tf
````hcl
 1: output "acm_cert_arn" {
 2:   description = "ACM certificate ARN (validated and ready for use)"
 3:   value       = module.acm.acm_certificate_arn
 4: }
 5: 
 6: output "domain_name" {
 7:   description = "Root domain name"
 8:   value       = local.domain_name
 9: }
10: 
11: output "zone_id" {
12:   description = "Route53 hosted zone ID"
13:   value       = local.zone_id
14: }
15: 
16: output "name_servers" {
17:   description = "Route53 name servers for the hosted zone (for registrar configuration)"
18:   value       = try(data.aws_route53_zone.this[0].name_servers, aws_route53_zone.this[0].name_servers)
19: }
````

## File: application/modules/route53/README.md
````markdown
  1: # Route53 Module
  2: 
  3: This module creates a Route53 hosted zone and an ACM certificate with DNS validation for a domain.
  4: 
  5: ## Purpose
  6: 
  7: The Route53 module:
  8: - Creates a Route53 hosted zone for domain management
  9: - Optionally uses an existing Route53 hosted zone
 10: - Creates an ACM certificate with DNS validation
 11: - Automatically validates the certificate using Route53 DNS records
 12: 
 13: ## What it Creates
 14: 
 15: 1. **Route53 Hosted Zone** (`aws_route53_zone.this`)
 16:    - Public hosted zone for the domain
 17:    - Only created if `use_existing_route53_zone` is `false`
 18:    - Includes name servers output for registrar configuration
 19: 
 20: 2. **ACM Certificate** (via `terraform-aws-modules/acm/aws`)
 21:    - Certificate for the domain
 22:    - DNS validation method
 23:    - Automatic validation via Route53 DNS records
 24:    - Supports subject alternative names (SANs)
 25:    - Waits for validation to complete (30 minute timeout)
 26: 
 27: ## Usage
 28: 
 29: ### Create New Route53 Zone
 30: 
 31: ```hcl
 32: module "route53" {
 33:   source = "./modules/route53"
 34: 
 35:   env        = "prod"
 36:   region     = "us-east-1"
 37:   prefix     = "myorg"
 38:   domain_name = "example.com"
 39: 
 40:   subject_alternative_names = ["*.example.com"]
 41: }
 42: ```
 43: 
 44: ### Use Existing Route53 Zone
 45: 
 46: ```hcl
 47: module "route53" {
 48:   source = "./modules/route53"
 49: 
 50:   env        = "prod"
 51:   region     = "us-east-1"
 52:   prefix     = "myorg"
 53:   domain_name = "example.com"
 54: 
 55:   use_existing_route53_zone = true
 56:   subject_alternative_names = ["*.example.com"]
 57: }
 58: ```
 59: 
 60: ## Inputs
 61: 
 62: | Name | Description | Type | Default | Required |
 63: | ------ | ------------- | ------ | --------- | :--------: |
 64: | env | Deployment environment (for tagging) | `string` | n/a | yes |
 65: | region | Deployment region | `string` | n/a | yes |
 66: | prefix | Prefix for the resources | `string` | n/a | yes |
 67: | domain_name | Root domain name (e.g., talorlik.com) | `string` | n/a | yes |
 68: | subject_alternative_names | List of subject alternative names for the ACM certificate | `list(string)` | `[]` | no |
 69: | use_existing_route53_zone | Whether to use an existing Route53 zone | `bool` | `false` | no |
 70: | tags | Tags to apply to the resources | `map(string)` | `{}` | no |
 71: 
 72: ## Outputs
 73: 
 74: | Name | Description |
 75: | ------ | ------------- |
 76: | acm_cert_arn | ACM certificate ARN (validated and ready for use) |
 77: | domain_name | Root domain name |
 78: | zone_id | Route53 hosted zone ID |
 79: | name_servers | Route53 name servers for the hosted zone (for registrar configuration) |
 80: 
 81: ## Certificate Validation
 82: 
 83: The module automatically validates the ACM certificate using DNS validation:
 84: 
 85: 1. ACM creates validation records
 86: 2. The module creates Route53 records for validation
 87: 3. ACM validates the certificate
 88: 4. Certificate becomes ready for use
 89: 
 90: The module waits up to 30 minutes for validation to complete. If validation fails, Terraform will show an error.
 91: 
 92: ## Name Server Configuration
 93: 
 94: When creating a new Route53 hosted zone, you must configure your domain registrar to use the name servers from the `name_servers` output:
 95: 
 96: 1. Get the name servers from the module output
 97: 2. Update your domain registrar's DNS settings
 98: 3. Wait for DNS propagation (can take up to 48 hours)
 99: 
100: ## Subject Alternative Names
101: 
102: You can include multiple domain names in a single certificate using `subject_alternative_names`:
103: 
104: ```hcl
105: subject_alternative_names = [
106:   "*.example.com",
107:   "www.example.com",
108:   "api.example.com"
109: ]
110: ```
111: 
112: ## Using Existing Route53 Zone
113: 
114: If you already have a Route53 hosted zone for your domain:
115: 
116: 1. Set `use_existing_route53_zone = true`
117: 2. The module will look up the existing zone by domain name
118: 3. The ACM certificate will use the existing zone for validation
119: 
120: ## Dependencies
121: 
122: - AWS Route53 service
123: - AWS Certificate Manager (ACM)
124: - Terraform AWS provider
125: - `terraform-aws-modules/acm/aws` module (version 6.2.0)
126: 
127: ## Notes
128: 
129: - The module automatically trims trailing dots from domain names
130: - Certificate validation uses DNS method (not email)
131: - The certificate is validated automatically via Route53
132: - Name servers are only available when creating a new zone
133: - For existing zones, name servers must be configured separately
````

## File: application/modules/route53/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment (for tagging)"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Prefix for the resources"
13:   type        = string
14: }
15: 
16: variable "domain_name" {
17:   description = "Root domain name (e.g., talorlik.com)"
18:   type        = string
19: }
20: 
21: variable "subject_alternative_names" {
22:   description = "List of subject alternative names for the ACM certificate (e.g., [\"*.talorlik.com\"])"
23:   type        = list(string)
24:   default     = []
25: }
26: 
27: variable "use_existing_route53_zone" {
28:   description = "Whether to use an existing Route53 zone"
29:   type        = bool
30:   default     = false
31: }
32: 
33: variable "tags" {
34:   description = "Tags to apply to the resources"
35:   type        = map(string)
36:   default     = {}
37: }
````

## File: application/modules/route53_record/main.tf
````hcl
 1: # Route53 A (alias) record pointing to an ALB
 2: resource "aws_route53_record" "this" {
 3:   provider = aws.state_account
 4: 
 5:   zone_id = var.zone_id
 6:   name    = var.name
 7:   type    = "A"
 8: 
 9:   alias {
10:     name                   = var.alb_dns_name
11:     zone_id                = var.alb_zone_id
12:     evaluate_target_health = var.evaluate_target_health
13:   }
14: 
15:   lifecycle {
16:     create_before_destroy = true
17: 
18:     # Precondition: Ensure ALB DNS name is never null or empty
19:     precondition {
20:       condition     = var.alb_dns_name != null && var.alb_dns_name != ""
21:       error_message = "ALB DNS name must be available before creating Route53 record. Ensure the ALB has been provisioned."
22:     }
23:   }
24: }
````

## File: application/modules/route53_record/outputs.tf
````hcl
 1: output "record_name" {
 2:   description = "Route53 record name"
 3:   value       = aws_route53_record.this.name
 4: }
 5: 
 6: output "record_fqdn" {
 7:   description = "Fully qualified domain name (FQDN) of the Route53 record"
 8:   value       = aws_route53_record.this.fqdn
 9: }
10: 
11: output "record_id" {
12:   description = "Route53 record ID"
13:   value       = aws_route53_record.this.id
14: }
````

## File: application/modules/route53_record/README.md
````markdown
  1: # Route53 Record Module
  2: 
  3: This module creates a Route53 A (alias) record pointing to an Application Load
  4: Balancer (ALB). It is designed to support cross-account deployments where the
  5: Route53 hosted zone is in a different AWS account (State Account) than the ALB
  6: (Deployment Account).
  7: 
  8: ## Overview
  9: 
 10: The Route53 record module creates a single A (alias) record that points a
 11: subdomain to an ALB DNS name. This module is called multiple times in
 12: `application/main.tf` to create separate records for each service:
 13: 
 14: - `phpldapadmin.<domain>`  ALB
 15: - `passwd.<domain>`  ALB
 16: - `app.<domain>`  ALB
 17: 
 18: ## Features
 19: 
 20: - **Cross-Account Support**: Uses state account provider to create records in
 21:   State Account while ALB is in Deployment Account
 22: - **ALB Alias Records**: Creates A (alias) records for optimal performance and
 23:   cost efficiency
 24: - **Health Check Integration**: Supports target health evaluation for alias
 25:   records
 26: - **Precondition Validation**: Ensures ALB DNS name is available before record
 27:   creation
 28: - **Safe Updates**: Uses `create_before_destroy` lifecycle to prevent DNS
 29:   downtime
 30: 
 31: ## Architecture
 32: 
 33: ```ascii
 34: 
 35:                     State Account                          
 36:                                                            
 37:     
 38:            Route53 Hosted Zone                           
 39:                                                          
 40:          
 41:       A Record: phpldapadmin.<domain>                  
 42:        ALB DNS (Deployment Account)                   
 43:          
 44:                                                          
 45:          
 46:       A Record: passwd.<domain>                        
 47:        ALB DNS (Deployment Account)                   
 48:          
 49:                                                          
 50:          
 51:       A Record: app.<domain>                           
 52:        ALB DNS (Deployment Account)                   
 53:          
 54:     
 55: 
 56:                           
 57:                            DNS Resolution
 58:                           
 59: 
 60:                  Deployment Account                         
 61:                                                             
 62:     
 63:                 Application Load Balancer                 
 64:                 (Internet-Facing ALB)                     
 65:     
 66: 
 67: ```
 68: 
 69: ## Cross-Account Access
 70: 
 71: This module uses the `aws.state_account` provider alias to create Route53
 72: records in the State Account, even when the ALB is deployed in a different
 73: account (Deployment Account). This enables:
 74: 
 75: - Route53 hosted zones managed in a centralized State Account
 76: - ALB resources deployed in separate Deployment Accounts
 77: - Proper separation of concerns and account isolation
 78: 
 79: The provider configuration is inherited from the parent module
 80: (`application/providers.tf`), which configures the state account provider when
 81: `state_account_role_arn` is provided.
 82: 
 83: ## Usage
 84: 
 85: ### Basic Example
 86: 
 87: ```hcl
 88: module "route53_record_example" {
 89:   source = "./modules/route53_record"
 90: 
 91:   zone_id       = "Z1234567890ABC"
 92:   name          = "app.example.com"
 93:   alb_dns_name  = "my-alb-123456789.us-east-1.elb.amazonaws.com"
 94:   alb_zone_id   = "Z35SXDOTRQ7X7K"  # us-east-1 ALB zone ID
 95: 
 96:   providers = {
 97:     aws.state_account = aws.state_account
 98:   }
 99: }
100: ```
101: 
102: ### Integration in main.tf
103: 
104: The module is called three times in `application/main.tf`:
105: 
106: ```hcl
107: # Route53 record for phpLDAPadmin
108: module "route53_record_phpldapadmin" {
109:   source = "./modules/route53_record"
110: 
111:   count = var.use_alb && local.phpldapadmin_host != "" ? 1 : 0
112: 
113:   zone_id      = data.aws_route53_zone.this.zone_id
114:   name         = local.phpldapadmin_host
115:   alb_dns_name = data.aws_lb.alb[0].dns_name
116:   alb_zone_id  = local.alb_zone_id
117: 
118:   depends_on = [
119:     module.openldap,  # Ensures Ingress is created (which triggers ALB creation)
120:     data.aws_lb.alb,  # Ensures ALB exists before creating record
121:   ]
122: 
123:   providers = {
124:     aws.state_account = aws.state_account
125:   }
126: }
127: ```
128: 
129: ## Input Variables
130: 
131: | Variable | Description | Type | Required | Default |
132: | ---------- | ------------- | ------ | ---------- | --------- |
133: | `zone_id` | Route53 hosted zone ID for creating DNS records | `string` | Yes | - |
134: | `name` | DNS record name (e.g., `phpldapadmin.talorlik.com`) | `string` | Yes | - |
135: | `alb_dns_name` | DNS name of the ALB to point the record to | `string` | Yes | - |
136: | `alb_zone_id` | ALB canonical hosted zone ID for Route53 alias records. This should be computed from the region mapping (see ALB Zone ID Mapping section) | `string` | Yes | - |
137: | `evaluate_target_health` | Whether to evaluate target health for the alias record | `bool` | No | `true` |
138: 
139: ## Outputs
140: 
141: | Output | Description |
142: | -------- | ------------- |
143: | `record_name` | Route53 record name |
144: | `record_fqdn` | Fully qualified domain name (FQDN) of the Route53 record |
145: | `record_id` | Route53 record ID |
146: 
147: ## Dependencies
148: 
149: ### Prerequisites
150: 
151: 1. **Route53 Hosted Zone**: Must exist in the State Account (or same account)
152: 2. **ALB**: Must be provisioned and have a DNS name available
153: 3. **State Account Provider**: Must be configured in parent module when using
154:    cross-account access
155: 
156: ### Dependency Chain
157: 
158: The module has explicit dependencies to ensure proper ordering:
159: 
160: ```hcl
161: depends_on = [
162:   module.openldap,  # Ensures Ingress is created (which triggers ALB creation)
163:   data.aws_lb.alb,  # Ensures ALB exists before creating record
164: ]
165: ```
166: 
167: This ensures:
168: 
169: 1. OpenLDAP module creates Ingress resources
170: 2. Ingress resources trigger ALB creation (via EKS Auto Mode)
171: 3. ALB data source can query the ALB DNS name
172: 4. Route53 record can be created with valid ALB DNS name
173: 
174: ### Preconditions
175: 
176: The module includes a precondition that validates the ALB DNS name is available:
177: 
178: ```hcl
179: precondition {
180:   condition     = var.alb_dns_name != null && var.alb_dns_name != ""
181:   error_message = "ALB DNS name must be available before creating Route53 record. Ensure the ALB has been provisioned."
182: }
183: ```
184: 
185: This prevents creating Route53 records with invalid ALB DNS names.
186: 
187: ## ALB Zone ID Mapping
188: 
189: Application Load Balancers have region-specific canonical hosted zone IDs that
190: must be used when creating Route53 alias records. The parent module
191: (`application/main.tf`) includes a comprehensive mapping:
192: 
193: | Region | ALB Zone ID |
194: | -------- | ------------- |
195: | us-east-1 (N. Virginia) | `Z35SXDOTRQ7X7K` |
196: | us-east-2 (Ohio) | `Z3AADJGX6KTTL2` |
197: | us-west-1 (N. California) | `Z1M58G0W56PQJA` |
198: | us-west-2 (Oregon) | `Z33MTJ483K6KNU` |
199: | eu-west-1 (Ireland) | `Z3DZXE0Q2N3XK0` |
200: | eu-west-2 (London) | `Z3GKZC51ZF0DB4` |
201: | eu-west-3 (Paris) | `Z3Q77PNBUNY4FR` |
202: | eu-central-1 (Frankfurt) | `Z215JYRZR1TBD5` |
203: | ap-southeast-1 (Singapore) | `Z1LMS91P8CMLE5` |
204: | ap-southeast-2 (Sydney) | `Z1GM3OXH4ZPM65` |
205: | ap-northeast-1 (Tokyo) | `Z14GRHDCWA56QT` |
206: | ap-northeast-2 (Seoul) | `Z1W9GUF3Q8Z8BZ` |
207: | sa-east-1 (So Paulo) | `Z2P70J7HTTTPLU` |
208: 
209: The parent module automatically selects the correct zone ID based on the region
210: variable using a lookup function.
211: 
212: ## Provider Configuration
213: 
214: ### State Account Provider
215: 
216: The module requires the `aws.state_account` provider alias to be configured in
217: the parent module. This is done in `application/providers.tf`:
218: 
219: ```hcl
220: provider "aws" {
221:   alias = "state_account"
222: 
223:   # Configuration when state_account_role_arn is provided
224:   # ...
225: }
226: ```
227: 
228: When `state_account_role_arn` is provided, the provider assumes the State
229: Account role for Route53 operations. When not provided, it uses default
230: credentials.
231: 
232: ### Provider Passing
233: 
234: The parent module must pass the state account provider to this module:
235: 
236: ```hcl
237: module "route53_record_example" {
238:   # ...
239: 
240:   providers = {
241:     aws.state_account = aws.state_account
242:   }
243: }
244: ```
245: 
246: ## Lifecycle Management
247: 
248: The module uses `create_before_destroy` lifecycle to ensure DNS records are
249: updated without downtime:
250: 
251: ```hcl
252: lifecycle {
253:   create_before_destroy = true
254: }
255: ```
256: 
257: This ensures that when updating a record, Terraform creates the new record
258: before destroying the old one, preventing DNS resolution gaps.
259: 
260: ## Target Health Evaluation
261: 
262: By default, the module enables target health evaluation for alias records
263: (`evaluate_target_health = true`). This allows Route53 to:
264: 
265: - Route traffic only to healthy ALB targets
266: - Automatically fail over to healthy targets if some become unhealthy
267: - Improve overall service availability
268: 
269: You can disable this by setting `evaluate_target_health = false`, but it's
270: recommended to keep it enabled for production deployments.
271: 
272: ## Troubleshooting
273: 
274: ### Record Creation Fails with "ALB DNS name must be available"
275: 
276: **Cause**: The ALB has not been provisioned yet, or the ALB data source cannot
277: find the ALB.
278: 
279: **Solution**:
280: 
281: 1. Ensure the OpenLDAP module has been deployed (creates Ingress resources)
282: 2. Verify the ALB exists: `aws elbv2 describe-load-balancers --region <region>`
283: 3. Check the ALB data source in `main.tf` is correctly configured
284: 4. Verify the ALB name matches `local.alb_load_balancer_name`
285: 
286: ### Record Points to Wrong ALB
287: 
288: **Cause**: The `alb_dns_name` variable is incorrect or points to a different ALB.
289: 
290: **Solution**:
291: 
292: 1. Verify the ALB data source is querying the correct ALB
293: 2. Check the ALB name in `main.tf` matches the actual ALB name
294: 3. Ensure the ALB zone_id matches the region where the ALB is deployed
295: 
296: ### Cross-Account Access Issues
297: 
298: **Cause**: The state account provider is not configured correctly, or the role
299: cannot be assumed.
300: 
301: **Solution**:
302: 
303: 1. Verify `state_account_role_arn` is set in `variables.tfvars`
304: 2. Check the state account role trust relationship allows the current identity
305: 3. Ensure the state account provider is correctly configured in `providers.tf`
306: 4. Verify the provider is passed to the module in `main.tf`
307: 
308: ## Related Documentation
309: 
310: - [AWS Route53 Alias Records](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html)
311: - [Application Load Balancer Zone IDs](https://docs.aws.amazon.com/general/latest/gr/elb.html)
312: - [Cross-Account Access Documentation](../CROSS-ACCOUNT-ACCESS.md)
313: - [Application Infrastructure README](../README.md)
314: 
315: ## Examples
316: 
317: ### Single Record Creation
318: 
319: ```hcl
320: module "route53_record_app" {
321:   source = "./modules/route53_record"
322: 
323:   zone_id       = "Z1234567890ABC"
324:   name          = "app.example.com"
325:   alb_dns_name  = "my-alb-123456789.us-east-1.elb.amazonaws.com"
326:   alb_zone_id   = "Z35SXDOTRQ7X7K"
327: 
328:   providers = {
329:     aws.state_account = aws.state_account
330:   }
331: }
332: ```
333: 
334: ### Multiple Records (as in main.tf)
335: 
336: ```hcl
337: # phpLDAPadmin record
338: module "route53_record_phpldapadmin" {
339:   source = "./modules/route53_record"
340: 
341:   zone_id      = data.aws_route53_zone.this.zone_id
342:   name         = "phpldapadmin.example.com"
343:   alb_dns_name = data.aws_lb.alb[0].dns_name
344:   alb_zone_id  = local.alb_zone_id
345: 
346:   providers = {
347:     aws.state_account = aws.state_account
348:   }
349: }
350: 
351: # ltb-passwd record
352: module "route53_record_ltb_passwd" {
353:   source = "./modules/route53_record"
354: 
355:   zone_id      = data.aws_route53_zone.this.zone_id
356:   name         = "passwd.example.com"
357:   alb_dns_name = data.aws_lb.alb[0].dns_name
358:   alb_zone_id  = local.alb_zone_id
359: 
360:   providers = {
361:     aws.state_account = aws.state_account
362:   }
363: }
364: 
365: # 2FA application record
366: module "route53_record_twofa_app" {
367:   source = "./modules/route53_record"
368: 
369:   zone_id      = data.aws_route53_zone.this.zone_id
370:   name         = "app.example.com"
371:   alb_dns_name = data.aws_lb.alb[0].dns_name
372:   alb_zone_id  = local.alb_zone_id
373: 
374:   providers = {
375:     aws.state_account = aws.state_account
376:   }
377: }
378: ```
379: 
380: ## Notes
381: 
382: - **ALB Zone ID**: The ALB zone ID is region-specific and must match the region
383:   where the ALB is deployed. The parent module automatically selects the correct
384:   zone ID based on the region variable.
385: 
386: - **DNS Propagation**: After creating Route53 records, DNS changes typically
387:   propagate within a few minutes, but can take up to 48 hours in rare cases.
388: 
389: - **Cost**: Route53 alias records pointing to ALBs are free (no charges for
390:   queries or records).
391: 
392: - **Health Checks**: When `evaluate_target_health = true`, Route53 uses the
393:   ALB's target health status to determine routing. This requires the ALB to
394:   have healthy targets.
395: 
396: - **Cross-Account**: This module supports cross-account deployments where
397:   Route53 is in a different account than the ALB. Ensure proper IAM roles and
398:   trust relationships are configured.
````

## File: application/modules/route53_record/variables.tf
````hcl
 1: variable "zone_id" {
 2:   description = "Route53 hosted zone ID for creating DNS records"
 3:   type        = string
 4: }
 5: 
 6: variable "name" {
 7:   description = "DNS record name (e.g., phpldapadmin.talorlik.com)"
 8:   type        = string
 9: }
10: 
11: variable "alb_dns_name" {
12:   description = "DNS name of the ALB to point the record to"
13:   type        = string
14: }
15: 
16: variable "alb_zone_id" {
17:   description = "ALB canonical hosted zone ID for Route53 alias records. This should be computed from the region mapping."
18:   type        = string
19: }
20: 
21: variable "evaluate_target_health" {
22:   description = "Whether to evaluate target health for the alias record"
23:   type        = bool
24:   default     = true
25: }
````

## File: application/modules/ses/outputs.tf
````hcl
 1: output "sender_email" {
 2:   description = "Verified sender email address"
 3:   value       = var.sender_email
 4: }
 5: 
 6: output "sender_domain" {
 7:   description = "Verified sender domain (if configured)"
 8:   value       = var.sender_domain
 9: }
10: 
11: output "iam_role_arn" {
12:   description = "ARN of the IAM role for SES access"
13:   value       = aws_iam_role.ses_sender.arn
14: }
15: 
16: output "iam_role_name" {
17:   description = "Name of the IAM role for SES access"
18:   value       = aws_iam_role.ses_sender.name
19: }
20: 
21: output "email_identity_arn" {
22:   description = "ARN of the SES email identity"
23:   value       = var.sender_domain != null ? aws_ses_domain_identity.sender[0].arn : aws_ses_email_identity.sender[0].arn
24: }
25: 
26: output "verification_status" {
27:   description = "Instructions for email verification"
28:   value       = var.sender_domain == null ? "Check inbox of ${var.sender_email} and click verification link from AWS" : "Domain verification via DNS records"
29: }
````

## File: application/modules/ses/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Name prefix for resources"
13:   type        = string
14: }
15: 
16: variable "cluster_name" {
17:   description = "EKS cluster name for IRSA"
18:   type        = string
19: }
20: 
21: variable "sender_email" {
22:   description = "Email address to send verification emails from (must be verified in SES)"
23:   type        = string
24: }
25: 
26: variable "sender_domain" {
27:   description = "Domain to verify in SES for sending emails. If null, will verify sender_email as individual address."
28:   type        = string
29:   default     = null
30: }
31: 
32: variable "iam_role_name" {
33:   description = "Name component for the SES IAM role"
34:   type        = string
35:   default     = "ses-sender"
36: }
37: 
38: variable "service_account_namespace" {
39:   description = "Kubernetes namespace for the service account"
40:   type        = string
41:   default     = "ldap-2fa"
42: }
43: 
44: variable "service_account_name" {
45:   description = "Name of the Kubernetes service account"
46:   type        = string
47:   default     = "ldap-2fa-backend"
48: }
49: 
50: variable "route53_zone_id" {
51:   description = "Route53 zone ID for domain verification records (optional, for domain verification)"
52:   type        = string
53:   default     = null
54: }
55: 
56: variable "tags" {
57:   description = "Tags to apply to resources"
58:   type        = map(string)
59:   default     = {}
60: }
````

## File: application/modules/sns/main.tf
````hcl
  1: # SNS Module for SMS-based 2FA Verification
  2: #
  3: # This module creates:
  4: # - SNS Topic for SMS notifications
  5: # - IAM Role for EKS Service Account (IRSA) to publish to SNS
  6: # - IAM Policy for SNS SMS publishing
  7: 
  8: locals {
  9:   sns_topic_name = "${var.prefix}-${var.region}-${var.sns_topic_name}-${var.env}"
 10:   iam_role_name  = "${var.prefix}-${var.region}-${var.iam_role_name}-${var.env}"
 11: }
 12: 
 13: # Data source to get AWS account ID
 14: data "aws_caller_identity" "current" {}
 15: 
 16: # Data source to get EKS cluster OIDC provider
 17: data "aws_eks_cluster" "cluster" {
 18:   name = var.cluster_name
 19: }
 20: 
 21: # SNS Topic for SMS messages
 22: resource "aws_sns_topic" "sms" {
 23:   name         = local.sns_topic_name
 24:   display_name = var.sns_display_name
 25: 
 26:   tags = var.tags
 27: }
 28: 
 29: # SNS Topic Policy - allows the IAM role to publish
 30: resource "aws_sns_topic_policy" "sms" {
 31:   arn = aws_sns_topic.sms.arn
 32: 
 33:   policy = jsonencode({
 34:     Version = "2012-10-17"
 35:     Id      = "SNSTopicPolicy"
 36:     Statement = [
 37:       {
 38:         Sid    = "AllowPublishFromIAMRole"
 39:         Effect = "Allow"
 40:         Principal = {
 41:           AWS = aws_iam_role.sns_publisher.arn
 42:         }
 43:         Action   = "sns:Publish"
 44:         Resource = aws_sns_topic.sms.arn
 45:       }
 46:     ]
 47:   })
 48: }
 49: 
 50: # IAM Role for EKS Service Account (IRSA)
 51: resource "aws_iam_role" "sns_publisher" {
 52:   name = local.iam_role_name
 53: 
 54:   assume_role_policy = jsonencode({
 55:     Version = "2012-10-17"
 56:     Statement = [
 57:       {
 58:         Effect = "Allow"
 59:         Principal = {
 60:           Federated = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:oidc-provider/${replace(data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer, "https://", "")}"
 61:         }
 62:         Action = "sts:AssumeRoleWithWebIdentity"
 63:         Condition = {
 64:           StringEquals = {
 65:             "${replace(data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer, "https://", "")}:sub" = "system:serviceaccount:${var.service_account_namespace}:${var.service_account_name}"
 66:             "${replace(data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer, "https://", "")}:aud" = "sts.amazonaws.com"
 67:           }
 68:         }
 69:       }
 70:     ]
 71:   })
 72: 
 73:   tags = var.tags
 74: }
 75: 
 76: # IAM Policy for SNS SMS publishing
 77: resource "aws_iam_role_policy" "sns_publish" {
 78:   name = "${local.iam_role_name}-policy"
 79:   role = aws_iam_role.sns_publisher.id
 80: 
 81:   policy = jsonencode({
 82:     Version = "2012-10-17"
 83:     Statement = [
 84:       {
 85:         Sid    = "AllowSNSPublish"
 86:         Effect = "Allow"
 87:         Action = [
 88:           "sns:Publish"
 89:         ]
 90:         Resource = aws_sns_topic.sms.arn
 91:       },
 92:       {
 93:         Sid    = "AllowDirectSMSPublish"
 94:         Effect = "Allow"
 95:         Action = [
 96:           "sns:Publish"
 97:         ]
 98:         Resource = "*"
 99:         Condition = {
100:           StringEquals = {
101:             "sns:Protocol" = "sms"
102:           }
103:         }
104:       },
105:       {
106:         Sid    = "AllowSNSSubscribe"
107:         Effect = "Allow"
108:         Action = [
109:           "sns:Subscribe",
110:           "sns:ConfirmSubscription",
111:           "sns:Unsubscribe",
112:           "sns:ListSubscriptionsByTopic"
113:         ]
114:         Resource = aws_sns_topic.sms.arn
115:       },
116:       {
117:         Sid    = "AllowSNSCheckOptOut"
118:         Effect = "Allow"
119:         Action = [
120:           "sns:CheckIfPhoneNumberIsOptedOut",
121:           "sns:OptInPhoneNumber"
122:         ]
123:         Resource = "*"
124:       }
125:     ]
126:   })
127: }
128: 
129: # Set SMS attributes for the account (optional - for production use)
130: resource "aws_sns_sms_preferences" "sms_preferences" {
131:   count = var.configure_sms_preferences ? 1 : 0
132: 
133:   default_sender_id   = var.sms_sender_id
134:   default_sms_type    = var.sms_type
135:   monthly_spend_limit = var.sms_monthly_spend_limit
136: 
137:   # Note: delivery_status_iam_role_arn and delivery_status_success_sampling_rate
138:   # can be configured for SMS delivery status logging
139: }
````

## File: application/modules/sns/outputs.tf
````hcl
 1: output "sns_topic_arn" {
 2:   description = "ARN of the SNS topic for SMS"
 3:   value       = aws_sns_topic.sms.arn
 4: }
 5: 
 6: output "sns_topic_name" {
 7:   description = "Name of the SNS topic"
 8:   value       = aws_sns_topic.sms.name
 9: }
10: 
11: output "iam_role_arn" {
12:   description = "ARN of the IAM role for SNS publishing"
13:   value       = aws_iam_role.sns_publisher.arn
14: }
15: 
16: output "iam_role_name" {
17:   description = "Name of the IAM role"
18:   value       = aws_iam_role.sns_publisher.name
19: }
20: 
21: output "service_account_annotation" {
22:   description = "Annotation to add to Kubernetes service account for IRSA"
23:   value = {
24:     "eks.amazonaws.com/role-arn" = aws_iam_role.sns_publisher.arn
25:   }
26: }
````

## File: application/modules/sns/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "AWS region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Prefix for resource names"
13:   type        = string
14: }
15: 
16: variable "cluster_name" {
17:   description = "Name of the EKS cluster"
18:   type        = string
19: }
20: 
21: variable "sns_topic_name" {
22:   description = "Name component for the SNS topic"
23:   type        = string
24:   default     = "2fa-sms"
25: }
26: 
27: variable "sns_display_name" {
28:   description = "Display name for the SNS topic (appears in SMS sender)"
29:   type        = string
30:   default     = "2FA Verification"
31: }
32: 
33: variable "iam_role_name" {
34:   description = "Name component for the IAM role"
35:   type        = string
36:   default     = "2fa-sns-publisher"
37: }
38: 
39: variable "service_account_namespace" {
40:   description = "Kubernetes namespace for the service account"
41:   type        = string
42:   default     = "2fa-app"
43: }
44: 
45: variable "service_account_name" {
46:   description = "Name of the Kubernetes service account"
47:   type        = string
48:   default     = "ldap-2fa-backend"
49: }
50: 
51: variable "configure_sms_preferences" {
52:   description = "Whether to configure account-level SMS preferences"
53:   type        = bool
54:   default     = false
55: }
56: 
57: variable "sms_sender_id" {
58:   description = "Default sender ID for SMS messages (max 11 alphanumeric characters)"
59:   type        = string
60:   default     = "2FA"
61: }
62: 
63: variable "sms_type" {
64:   description = "Default SMS type: Promotional or Transactional"
65:   type        = string
66:   default     = "Transactional"
67:   validation {
68:     condition     = contains(["Promotional", "Transactional"], var.sms_type)
69:     error_message = "SMS type must be either 'Promotional' or 'Transactional'"
70:   }
71: }
72: 
73: variable "sms_monthly_spend_limit" {
74:   description = "Monthly spend limit for SMS in USD"
75:   type        = number
76:   default     = 10
77: }
78: 
79: variable "tags" {
80:   description = "Tags to apply to resources"
81:   type        = map(string)
82:   default     = {}
83: }
````

## File: application/PRD-ArgoCD.md
````markdown
  1: # ArgoCD Capability Requirements
  2: 
  3: ## 1. Overview
  4: 
  5: ### 1.1 What is EKS Argo CD Capability
  6: 
  7: The EKS Argo CD capability is a fully managed Argo CD service that:
  8: 
  9: - Runs in the EKS control plane (managed by AWS)
 10: - Connects to your cluster via an IAM role and cluster registration Secret
 11: - Reconciles workloads defined in Argo CD Applications
 12: - Is enabled and configured via Terraform
 13: 
 14: ### 1.2 GitOps Operational Flow
 15: 
 16: 1. Create IAM role for the capability
 17: 2. Create `aws_eks_capability` resource (Argo CD)
 18: 3. Register local cluster via Kubernetes Secret
 19: 4. Define Argo CD `Application` resources pointing to Git repositories/paths
 20: 5. Argo CD automatically deploys and continuously reconciles applications from Git
 21: 
 22: ### 1.3 Terraform Deployment Considerations
 23: 
 24: - **Existing workloads**: It's perfectly fine if the EKS cluster already has workloads
 25: - **Resource naming**: Ensure resource naming and namespaces avoid collisions
 26: - **Deployment order**: Deploy Argo CD capability first, then applications through Argo CD
 27: - **Application behavior**:
 28:   - If resources don't exist  Argo CD creates them on first sync
 29:   - If resources already exist  Argo CD brings them into desired state per Git repo
 30: 
 31: ## 2. Prerequisites
 32: 
 33: ### 2.1 Infrastructure Prerequisites
 34: 
 35: #### 2.1.1 EKS Cluster
 36: 
 37: - Existing EKS cluster (Auto Mode or provisioned) on a supported Kubernetes version
 38: - Must know `cluster_name` and `region`
 39: 
 40: #### 2.1.2 AWS Identity Center (IdC)
 41: 
 42: - Identity Center instance set up in a region
 43: - One or more users or groups created
 44: - Must know:
 45:   - `idc_instance_arn`
 46:   - `idc_region`
 47:   - IDs for at least one user or group (for RBAC mapping)
 48: 
 49: #### 2.1.3 Git Repository
 50: 
 51: - Repository containing Kubernetes manifests, Helm charts, or Kustomize directories
 52: - For initial setup: public HTTPS repository (no credentials required)
 53: - For production: may require private repository access (see Section 7)
 54: 
 55: ### 2.2 Terraform Prerequisites
 56: 
 57: #### 2.2.1 Required Providers
 58: 
 59: - `hashicorp/aws` provider version `>= 5.60.0` (includes `aws_eks_capability` resource)
 60:   - Used to manage EKS capability and IAM resources
 61: - `hashicorp/kubernetes` provider version `>= 2.30.0` (includes `kubernetes_manifest` for CRD support)
 62:   - Used to create Argo CD cluster secret and Application CRDs
 63: 
 64: ## 3. Architecture & Design
 65: 
 66: ### 3.1 High-Level Terraform Components
 67: 
 68: The Terraform implementation requires:
 69: 
 70: 1. **Providers**: AWS and Kubernetes providers configured against the EKS cluster
 71: 2. **IAM**: `aws_iam_role` for the Argo CD capability
 72: 3. **Capability**: `aws_eks_capability` resource creating the managed Argo CD
 73: 4. **Cluster Registration**: `kubernetes_secret` registering the EKS cluster with Argo CD
 74: 5. **Applications**: `kubernetes_manifest` resources defining Argo CD Applications
 75: 
 76: ### 3.2 Dependency Chain & Resource Relationships
 77: 
 78: The following dependency chain must be respected:
 79: 
 80: ```ascii
 81: aws_iam_role  aws_eks_capability  kubernetes_secret (cluster registration)  kubernetes_manifest (Application)
 82: ```
 83: 
 84: Key relationships:
 85: 
 86: - IAM role must exist before capability creation
 87: - Capability must be ACTIVE before cluster registration
 88: - Cluster must be registered before Applications can target it
 89: - Applications reference the registered cluster by name (`local-cluster`)
 90: 
 91: ## 4. Implementation Requirements
 92: 
 93: ### 4.1 Provider Configuration
 94: 
 95: #### 4.1.1 Terraform Provider Block
 96: 
 97: ```hcl
 98: terraform {
 99:   required_providers {
100:     aws = {
101:       source  = "hashicorp/aws"
102:       version = ">= 5.60.0"
103:     }
104:     kubernetes = {
105:       source  = "hashicorp/kubernetes"
106:       version = ">= 2.30.0"
107:     }
108:   }
109: }
110: 
111: provider "aws" {
112:   region = var.region
113: }
114: ```
115: 
116: #### 4.1.2 EKS Data Sources
117: 
118: ```hcl
119: # Existing cluster (Auto Mode)
120: data "aws_eks_cluster" "this" {
121:   name = var.cluster_name
122: }
123: 
124: data "aws_eks_cluster_auth" "this" {
125:   name = var.cluster_name
126: }
127: 
128: provider "kubernetes" {
129:   host                   = data.aws_eks_cluster.this.endpoint
130:   cluster_ca_certificate = base64decode(data.aws_eks_cluster.this.certificate_authority[0].data)
131:   token                  = data.aws_eks_cluster_auth.this.token
132: }
133: ```
134: 
135: #### 4.1.3 Required Variables
136: 
137: ```hcl
138: variable "region" {
139:   type = string
140: }
141: 
142: variable "cluster_name" {
143:   type = string
144: }
145: ```
146: 
147: ### 4.2 IAM Requirements
148: 
149: #### 4.2.1 Capability IAM Role
150: 
151: **REQ-4.2.1.1**: Create IAM role trusted by `capabilities.eks.amazonaws.com`
152: 
153: ```hcl
154: resource "aws_iam_role" "argocd_capability" {
155:   name = "ArgoCDCapabilityRole"
156: 
157:   assume_role_policy = jsonencode({
158:     Version = "2012-10-17"
159:     Statement = [
160:       {
161:         Effect = "Allow"
162:         Principal = {
163:           Service = "capabilities.eks.amazonaws.com"
164:         }
165:         Action = [
166:           "sts:AssumeRole",
167:           "sts:TagSession"
168:         ]
169:       }
170:     ]
171:   })
172: }
173: ```
174: 
175: #### 4.2.2 IAM Policy Requirements
176: 
177: **REQ-4.2.2.1**: Capability role must have permissions for:
178: 
179: - EKS API calls (describe cluster, list clusters, etc.)
180: - Access to Git repositories and AWS services used by Argo CD:
181:   - Secrets Manager (for repository credentials)
182:   - CodeConnections (for AWS CodeCommit/CodePipeline integration)
183:   - CodeCommit (if using AWS Git repositories)
184:   - ECR (if pulling images)
185: 
186: **REQ-4.2.2.2**: Example policy document (tighten for production):
187: 
188: ```hcl
189: data "aws_iam_policy_document" "argocd_capability" {
190:   statement {
191:     sid    = "EKSDescribe"
192:     effect = "Allow"
193: 
194:     actions = [
195:       "eks:DescribeCluster",
196:       "eks:ListClusters",
197:       "eks:DescribeUpdate",
198:       "eks:ListUpdates"
199:     ]
200: 
201:     resources = ["*"]
202:   }
203: 
204:   statement {
205:     sid    = "SecretsManager"
206:     effect = "Allow"
207: 
208:     actions = [
209:       "secretsmanager:GetSecretValue",
210:       "secretsmanager:DescribeSecret",
211:       "secretsmanager:ListSecrets"
212:     ]
213: 
214:     resources = ["*"]
215:   }
216: 
217:   statement {
218:     sid    = "CodeConnections"
219:     effect = "Allow"
220: 
221:     actions = [
222:       "codeconnections:ListConnections",
223:       "codeconnections:GetConnection"
224:     ]
225: 
226:     resources = ["*"]
227:   }
228: }
229: 
230: resource "aws_iam_role_policy" "argocd_capability" {
231:   role   = aws_iam_role.argocd_capability.id
232:   policy = data.aws_iam_policy_document.argocd_capability.json
233: }
234: ```
235: 
236: **REQ-4.2.2.3**: In production, replace `resources = ["*"]` with specific ARNs
237: for secrets, connections, and clusters.
238: 
239: ### 4.3 Argo CD Capability Configuration
240: 
241: #### 4.3.1 Required Variables
242: 
243: ```hcl
244: variable "idc_instance_arn" {
245:   type        = string
246:   description = "ARN of the AWS Identity Center instance used for Argo CD auth"
247: }
248: 
249: variable "idc_region" {
250:   type        = string
251:   description = "Region of the Identity Center instance"
252: }
253: 
254: variable "idc_admin_group_id" {
255:   type        = string
256:   description = "Identity Center group ID to map to Argo CD ADMIN"
257: }
258: 
259: variable "argocd_namespace" {
260:   type    = string
261:   default = "argocd"
262: }
263: 
264: variable "argocd_vpce_ids" {
265:   type        = list(string)
266:   default     = []
267:   description = "Optional list of VPC endpoint IDs for private access to Argo CD"
268: }
269: ```
270: 
271: #### 4.3.2 Capability Resource
272: 
273: **REQ-4.3.2.1**: Create `aws_eks_capability` resource with type `ARGOCD`
274: 
275: ```hcl
276: resource "aws_eks_capability" "argocd" {
277:   cluster_name = var.cluster_name
278:   name         = "argocd-main"
279:   type         = "ARGOCD"
280: 
281:   role_arn                 = aws_iam_role.argocd_capability.arn
282:   delete_propagation_policy = "RETAIN"
283: 
284:   configuration {
285:     argo_cd {
286:       # Namespace for any in-cluster Argo CRs; the control-plane service itself is managed by EKS
287:       namespace = var.argocd_namespace
288: 
289:       aws_idc {
290:         idc_instance_arn = var.idc_instance_arn
291:         idc_region       = var.idc_region
292:       }
293: 
294:       # Map an Identity Center group to Argo CD ADMIN role
295:       rbac_role_mappings {
296:         role = "ADMIN"
297: 
298:         identities {
299:           id   = var.idc_admin_group_id
300:           type = "SSO_GROUP"  # or SSO_USER
301:         }
302:       }
303: 
304:       # Optional  if specified, Argo CD endpoint is private and accessible only via these VPC endpoints
305:       dynamic "network_access" {
306:         for_each = length(var.argocd_vpce_ids) > 0 ? [1] : []
307:         content {
308:           vpce_ids = var.argocd_vpce_ids
309:         }
310:       }
311:     }
312:   }
313: 
314:   tags = {
315:     "Name"               = "argocd-main"
316:     "eks:cluster"        = var.cluster_name
317:     "eks:capabilityType" = "ARGOCD"
318:   }
319: }
320: ```
321: 
322: **REQ-4.3.2.2**: Output the Argo CD server URL
323: 
324: ```hcl
325: output "argocd_server_url" {
326:   value       = aws_eks_capability.argocd.server_url
327:   description = "Managed Argo CD UI/API endpoint"
328: }
329: ```
330: 
331: **REQ-4.3.2.3**: Terraform provider waits until capability is ACTIVE before proceeding
332: to dependent resources.
333: 
334: ### 4.4 Cluster Registration Requirements
335: 
336: #### 4.4.1 Local Cluster Registration
337: 
338: **REQ-4.4.1.1**: The managed capability does NOT automatically register the "local"
339: cluster. You must register it manually so Applications can target it.
340: 
341: **REQ-4.4.1.2**: Create Kubernetes Secret with cluster registration information:
342: 
343: ```hcl
344: resource "kubernetes_secret" "argocd_local_cluster" {
345:   metadata {
346:     name      = "local-cluster"
347:     namespace = var.argocd_namespace
348:     labels = {
349:       "argocd.argoproj.io/secret-type" = "cluster"
350:     }
351:   }
352: 
353:   string_data = {
354:     name    = "local-cluster"
355:     # Important: use cluster ARN, not API server URL
356:     server  = data.aws_eks_cluster.this.arn
357:     project = "default"
358:   }
359: 
360:   depends_on = [
361:     aws_eks_capability.argocd
362:   ]
363: }
364: ```
365: 
366: **REQ-4.4.1.3**: Applications must use the cluster name from the Secret (`local-cluster`)
367: in `spec.destination.name`, NOT `kubernetes.default.svc`.
368: 
369: ### 4.5 Argo CD Application Requirements
370: 
371: #### 4.5.1 Application Variables
372: 
373: ```hcl
374: variable "app_name" {
375:   type    = string
376:   default = "example-app"
377: }
378: 
379: variable "app_namespace" {
380:   type    = string
381:   default = "example"
382: }
383: 
384: variable "app_repo_url" {
385:   type        = string
386:   description = "Git repo URL containing app manifests or Helm chart"
387: }
388: 
389: variable "app_repo_path" {
390:   type        = string
391:   description = "Path within the repo (e.g. k8s/overlays/prod)"
392: }
393: 
394: variable "app_target_revision" {
395:   type    = string
396:   default = "HEAD"
397: }
398: ```
399: 
400: #### 4.5.2 Application Resource
401: 
402: **REQ-4.5.2.1**: Create Argo CD Application using `kubernetes_manifest`:
403: 
404: ```hcl
405: resource "kubernetes_manifest" "argocd_app" {
406:   manifest = {
407:     apiVersion = "argoproj.io/v1alpha1"
408:     kind       = "Application"
409:     metadata = {
410:       name      = var.app_name
411:       namespace = var.argocd_namespace
412:     }
413:     spec = {
414:       project = "default"
415: 
416:       source = {
417:         repoURL        = var.app_repo_url
418:         targetRevision = var.app_target_revision
419:         path           = var.app_repo_path
420:       }
421: 
422:       # Use the cluster name used in the cluster Secret
423:       destination = {
424:         name      = kubernetes_secret.argocd_local_cluster.metadata[0].name
425:         namespace = var.app_namespace
426:       }
427: 
428:       syncPolicy = {
429:         automated = {
430:           prune    = true
431:           selfHeal = true
432:         }
433:         syncOptions = [
434:           "CreateNamespace=true"
435:         ]
436:       }
437:     }
438:   }
439: 
440:   depends_on = [
441:     aws_eks_capability.argocd,
442:     kubernetes_secret.argocd_local_cluster
443:   ]
444: }
445: ```
446: 
447: **REQ-4.5.2.2**: Application spec must include:
448: 
449: - `project`: Argo CD project name (default: "default")
450: - `source.repoURL`: Git repository URL
451: - `source.targetRevision`: Git branch/tag/commit (default: "HEAD")
452: - `source.path`: Path within repository
453: - `destination.name`: Cluster name from registered cluster Secret (see REQ-4.4.1.3)
454: - `destination.namespace`: Target Kubernetes namespace
455: - `syncPolicy`: Sync behavior configuration
456: 
457: ## 5. Multi-Application Support
458: 
459: ### 5.1 Requirements
460: 
461: **REQ-5.1.1**: Support multiple Argo CD Applications from the same Git repository,
462: each targeting different paths and namespaces.
463: 
464: **REQ-5.1.2**: Each Application must:
465: 
466: - Use the same `repoURL` and `targetRevision`
467: - Use different `path` values
468: - Use different destination namespaces
469: - Reference the same cluster (`local-cluster`)
470: 
471: ### 5.2 Implementation Options
472: 
473: #### 5.2.1 Option A: Explicit Application Resources
474: 
475: **REQ-5.2.1.1**: Create separate `kubernetes_manifest` resources for each application:
476: 
477: ```hcl
478: # Application 1 - service A
479: resource "kubernetes_manifest" "argocd_app_service_a" {
480:   manifest = {
481:     apiVersion = "argoproj.io/v1alpha1"
482:     kind       = "Application"
483:     metadata = {
484:       name      = "service-a-app"
485:       namespace = var.argocd_namespace
486:     }
487:     spec = {
488:       project = "default"
489: 
490:       source = {
491:         repoURL        = "https://github.com/you/your-repo.git"
492:         targetRevision = "main"
493:         path           = "apps/service-a"
494:       }
495: 
496:       destination = {
497:         name      = kubernetes_secret.argocd_local_cluster.metadata[0].name
498:         namespace = "service-a"
499:       }
500: 
501:       syncPolicy = {
502:         automated = {
503:           prune    = true
504:           selfHeal = true
505:         }
506:         syncOptions = [
507:           "CreateNamespace=true"
508:         ]
509:       }
510:     }
511:   }
512: 
513:   depends_on = [
514:     aws_eks_capability.argocd,
515:     kubernetes_secret.argocd_local_cluster
516:   ]
517: }
518: 
519: # Application 2 - service B
520: resource "kubernetes_manifest" "argocd_app_service_b" {
521:   manifest = {
522:     apiVersion = "argoproj.io/v1alpha1"
523:     kind       = "Application"
524:     metadata = {
525:       name      = "service-b-app"
526:       namespace = var.argocd_namespace
527:     }
528:     spec = {
529:       project = "default"
530: 
531:       source = {
532:         repoURL        = "https://github.com/you/your-repo.git"
533:         targetRevision = "main"
534:         path           = "apps/service-b"
535:       }
536: 
537:       destination = {
538:         name      = kubernetes_secret.argocd_local_cluster.metadata[0].name
539:         namespace = "service-b"
540:       }
541: 
542:       syncPolicy = {
543:         automated = {
544:           prune    = true
545:           selfHeal = true
546:         }
547:         syncOptions = [
548:           "CreateNamespace=true"
549:         ]
550:       }
551:     }
552:   }
553: 
554:   depends_on = [
555:     aws_eks_capability.argocd,
556:     kubernetes_secret.argocd_local_cluster
557:   ]
558: }
559: ```
560: 
561: #### 5.2.2 Option B: Reusable Module (Recommended)
562: 
563: **REQ-5.2.2.1**: Create reusable module `modules/argocd_app`:
564: 
565: ```hcl
566: # modules/argocd_app/main.tf
567: variable "app_name" {}
568: variable "argocd_namespace" {}
569: variable "cluster_name_in_argo" {}
570: variable "repo_url" {}
571: variable "target_revision" {}
572: variable "path" {}
573: variable "destination_namespace" {}
574: 
575: resource "kubernetes_manifest" "this" {
576:   manifest = {
577:     apiVersion = "argoproj.io/v1alpha1"
578:     kind       = "Application"
579:     metadata = {
580:       name      = var.app_name
581:       namespace = var.argocd_namespace
582:     }
583:     spec = {
584:       project = "default"
585:       source = {
586:         repoURL        = var.repo_url
587:         targetRevision = var.target_revision
588:         path           = var.path
589:       }
590:       destination = {
591:         name      = var.cluster_name_in_argo
592:         namespace = var.destination_namespace
593:       }
594:       syncPolicy = {
595:         automated = {
596:           prune    = true
597:           selfHeal = true
598:         }
599:         syncOptions = [
600:           "CreateNamespace=true"
601:         ]
602:       }
603:     }
604:   }
605: }
606: ```
607: 
608: **REQ-5.2.2.2**: Use module multiple times in root module:
609: 
610: ```hcl
611: module "argocd_app_service_a" {
612:   source                = "./modules/argocd_app"
613:   app_name              = "service-a-app"
614:   argocd_namespace      = var.argocd_namespace
615:   cluster_name_in_argo  = kubernetes_secret.argocd_local_cluster.metadata[0].name
616:   repo_url              = "https://github.com/you/your-repo.git"
617:   target_revision       = "main"
618:   path                  = "apps/service-a"
619:   destination_namespace = "service-a"
620: }
621: 
622: module "argocd_app_service_b" {
623:   source                = "./modules/argocd_app"
624:   app_name              = "service-b-app"
625:   argocd_namespace      = var.argocd_namespace
626:   cluster_name_in_argo  = kubernetes_secret.argocd_local_cluster.metadata[0].name
627:   repo_url              = "https://github.com/you/your-repo.git"
628:   target_revision       = "main"
629:   path                  = "apps/service-b"
630:   destination_namespace = "service-b"
631: }
632: ```
633: 
634: **REQ-5.2.2.3**: Module approach scales better for adding additional applications.
635: 
636: ### 5.3 Multi-Application Behavior
637: 
638: **REQ-5.3.1**: Each Application appears independently in Argo CD UI with:
639: 
640: - Individual sync status
641: - Separate sync history
642: - Independent health status
643: - Independent sync policies (can be automated for one, manual for another)
644: 
645: **REQ-5.3.2**: Applications can be synced independently and may use different
646: Projects for multi-tenancy or isolation.
647: 
648: ## 6. Execution Order & Deployment
649: 
650: ### 6.1 Terraform Execution Sequence
651: 
652: **REQ-6.1.1**: Ensure EKS cluster exists and is reachable before applying Terraform.
653: 
654: **REQ-6.1.2**: Terraform apply must execute in this order:
655: 
656: 1. Configure AWS and Kubernetes providers against the cluster
657: 2. Create `aws_iam_role.argocd_capability` and policies
658: 3. Create `aws_eks_capability.argocd` with Identity Center config and RBAC mappings
659: 4. Create `kubernetes_secret.argocd_local_cluster` to register the EKS cluster ARN
660: 5. Create `kubernetes_manifest.argocd_app` resources pointing to Git repositories,
661: paths, and namespaces
662: 
663: ### 6.2 Post-Deployment Behavior
664: 
665: **REQ-6.2.1**: After Terraform apply completes:
666: 
667: - Argo CD runs in the EKS control plane (no extra pods on nodes)
668: - Argo CD communicates with cluster and Git repo as configured
669: - Applications are managed continuously from Git without further Terraform involvement
670: 
671: **REQ-6.2.2**: Applications automatically sync and reconcile based on Git
672: repository state.
673: 
674: ## 7. Optional Features
675: 
676: ### 7.1 Private Git Repository Access
677: 
678: **REQ-7.1.1**: Support private Git repositories using one of:
679: 
680: - Kubernetes Secrets with label `argocd.argoproj.io/secret-type: repository`
681: - AWS Secrets Manager secrets (with IAM permissions in capability role)
682: - AWS CodeConnections connection ARNs (referenced in Application `spec.source`)
683: 
684: **REQ-7.1.2**: For Kubernetes Secret approach:
685: 
686: - Create Secret with `argocd.argoproj.io/secret-type: repository` label
687: - Include `stringData` fields: `url`, `type`, `username`, `password` (or SSH keys)
688: 
689: **REQ-7.1.3**: For Secrets Manager approach:
690: 
691: - Reference secrets in Application or Project policy
692: - Configure IAM permissions in capability role to access Secrets Manager
693: 
694: **REQ-7.1.4**: For CodeConnections approach:
695: 
696: - Reference connection ARN in Application `spec.source` instead of direct Git URL
697: - Capability role must have permissions to use the connection
698: 
699: ### 7.2 Network Access Control
700: 
701: **REQ-7.2.1**: Optionally restrict Argo CD endpoint access via VPC endpoints:
702: 
703: - Specify `argocd_vpce_ids` variable with list of VPC endpoint IDs
704: - When specified, Argo CD endpoint is private and accessible only via these VPC endpoints
705: 
706: ### 7.3 Additional RBAC Mappings
707: 
708: **REQ-7.3.1**: Support multiple RBAC role mappings:
709: 
710: - Map Identity Center groups/users to different Argo CD roles (ADMIN, READ_ONLY, etc.)
711: - Configure multiple `rbac_role_mappings` blocks in capability configuration
712: 
713: ## 8. References
714: 
715: - [Create an Argo CD capability](https://docs.aws.amazon.com/eks/latest/userguide/create-argocd-capability.html)
716: - [create-capability  AWS CLI Command Reference](https://docs.aws.amazon.com/cli/latest/reference/eks/create-capability.html)
717: - [aws_eks_capability | Terraform Registry](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/eks_capability)
718: - [Register target clusters - Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/argocd-register-clusters.html)
719: - [Argo CD concepts - Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/argocd-concepts.html)
720: - [Create an Argo CD capability using the AWS CLI](https://docs.aws.amazon.com/eks/latest/userguide/argocd-create-cli.html)
721: - [Working with Argo CD - Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/working-with-argocd.html)
722: - [Continuous Deployment with Argo CD](https://docs.aws.amazon.com/eks/latest/userguide/argocd.html)
````

## File: application/tfstate-backend-values-template.hcl
````hcl
1: bucket         = "<BACKEND_BUCKET_NAME>"
2: key            = "<APPLICATION_PREFIX>"
3: region         = "<AWS_REGION>"
````

## File: backend_infra/modules/ebs/main.tf
````hcl
 1: # Resources in the Kubernetes Cluster such as StorageClass
 2: # *** EKS Auto mode has its own EBS CSI driver ***
 3: # There is no need to install one
 4: 
 5: # *** EKS Auto Mode takes care of IAM permissions ***
 6: # There is no need to attach AmazonEBSCSIDriverPolicy to the EKS Node IAM Role
 7: 
 8: # EBS Storage Class
 9: resource "kubernetes_storage_class" "ebs" {
10:   metadata {
11:     name = "${var.prefix}-${var.region}-${var.ebs_name}-${var.env}"
12:     annotations = {
13:       "storageclass.kubernetes.io/is-default-class" = "true"
14:     }
15:   }
16: 
17:   # *** This setting specifies the EKS Auto Mode provisioner ***
18:   storage_provisioner = "ebs.csi.eks.amazonaws.com"
19: 
20:   # The reclaim policy for a PersistentVolume tells the cluster
21:   # what to do with the volume after it has been released of its claim
22:   reclaim_policy = "Delete"
23: 
24:   # Delay the binding and provisioning of a PersistentVolume until a Pod
25:   # using the PersistentVolumeClaim is created
26:   volume_binding_mode = "WaitForFirstConsumer"
27: 
28:   # see StorageClass Parameters Reference here:
29:   # https://docs.aws.amazon.com/eks/latest/userguide/create-storage-class.html
30:   parameters = {
31:     type      = "gp3"
32:     encrypted = "true"
33:   }
34: }
35: 
36: # EBS Persistent Volume Claim
37: resource "kubernetes_persistent_volume_claim_v1" "ebs_pvc" {
38:   metadata {
39:     name = "${var.prefix}-${var.region}-${var.ebs_claim_name}-${var.env}"
40:   }
41: 
42:   spec {
43:     # Volume can be mounted as read-write by a single node
44:     #
45:     # ReadWriteOnce access mode should enable multiple pods to
46:     # access it when the pods are running on the same node.
47:     #
48:     # Using EKS Auto Mode it appears to only allow one pod to access it
49:     access_modes = ["ReadWriteOnce"]
50: 
51:     resources {
52:       requests = {
53:         storage = "1Gi"
54:       }
55:     }
56: 
57:     storage_class_name = kubernetes_storage_class.ebs.metadata[0].name
58:   }
59: 
60:   # Setting this allows `Terraform apply` to continue
61:   # Otherwise it would hang here waiting for claim to bind to a pod
62:   wait_until_bound = false
63: }
64: 
65: # This will create the PVC, which will wait until a pod needs it, and then create a PersistentVolume
````

## File: backend_infra/modules/ebs/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Name added to all resources"
13:   type        = string
14: }
15: 
16: variable "ebs_name" {
17:   description = "The name of the EBS"
18:   type        = string
19: }
20: 
21: variable "ebs_claim_name" {
22:   description = "The name of the EBS claim"
23:   type        = string
24: }
````

## File: backend_infra/modules/ecr/main.tf
````hcl
 1: locals {
 2:   ecr_name = "${var.prefix}-${var.region}-${var.ecr_name}-${var.env}"
 3: }
 4: 
 5: resource "aws_ecr_repository" "ecr" {
 6:   name                 = local.ecr_name
 7:   image_tag_mutability = var.image_tag_mutability
 8:   force_delete         = true
 9: 
10:   tags = merge(
11:     {
12:       Name = "${local.ecr_name}"
13:     },
14:     var.tags
15:   )
16: }
17: 
18: resource "aws_ecr_lifecycle_policy" "ecr_policy" {
19:   repository = aws_ecr_repository.ecr.name
20:   policy     = var.policy
21: }
````

## File: backend_infra/modules/ecr/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9:   default     = "us-east-1"
10: }
11: 
12: variable "prefix" {
13:   description = "Name added to all resources"
14:   type        = string
15: }
16: 
17: variable "ecr_name" {
18:   description = "The name of the ECR"
19:   type        = string
20: }
21: 
22: variable "image_tag_mutability" {
23:   description = "The value that determines if the image is overridable"
24:   type        = string
25: }
26: 
27: variable "policy" {
28:   type = string
29: }
30: 
31: variable "tags" {
32:   type = map(string)
33: }
````

## File: backend_infra/tfstate-backend-values-template.hcl
````hcl
1: bucket         = "<BACKEND_BUCKET_NAME>"
2: key            = "<BACKEND_PREFIX>"
3: region         = "<AWS_REGION>"
````

## File: tf_backend_state/providers.tf
````hcl
 1: terraform {
 2:   required_providers {
 3:     aws = {
 4:       source  = "hashicorp/aws"
 5:       version = "= 6.21.0"
 6:     }
 7:   }
 8: 
 9:   required_version = "~> 1.14.0"
10: }
11: 
12: provider "aws" {
13:   region = var.region
14: }
````

## File: application/backend/helm/ldap-2fa-backend/templates/configmap.yaml
````yaml
 1: apiVersion: v1
 2: kind: ConfigMap
 3: metadata:
 4:   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 5:   labels:
 6:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
 7: data:
 8: 
 9:   LDAP_HOST: {{ .Values.ldap.host | quote }}
10:   LDAP_PORT: {{ .Values.ldap.port | quote }}
11:   LDAP_USE_SSL: {{ .Values.ldap.useSsl | quote }}
12:   LDAP_BASE_DN: {{ .Values.ldap.baseDn | quote }}
13:   LDAP_ADMIN_DN: {{ .Values.ldap.adminDn | quote }}
14:   LDAP_USER_SEARCH_BASE: {{ .Values.ldap.userSearchBase | quote }}
15:   LDAP_USER_SEARCH_FILTER: {{ .Values.ldap.userSearchFilter | quote }}
16:   LDAP_ADMIN_GROUP_DN: {{ .Values.ldapAdmin.groupDn | quote }}
17:   LDAP_USERS_GID: {{ .Values.ldapAdmin.usersGid | quote }}
18:   LDAP_UID_START: {{ .Values.ldapAdmin.uidStart | quote }}
19: 
20: 
21:   {{- if not .Values.database.externalSecret.enabled }}
22:   DATABASE_URL: {{ .Values.database.url | quote }}
23:   {{- end }}
24: 
25: 
26:   ENABLE_EMAIL_VERIFICATION: {{ .Values.email.enabled | quote }}
27:   SES_SENDER_EMAIL: {{ .Values.email.senderEmail | quote }}
28:   EMAIL_VERIFICATION_EXPIRY_HOURS: {{ .Values.email.verificationExpiryHours | quote }}
29:   APP_URL: {{ .Values.email.appUrl | quote }}
30: 
31: 
32:   TOTP_ISSUER: {{ .Values.mfa.issuer | quote }}
33:   TOTP_DIGITS: {{ .Values.mfa.digits | quote }}
34:   TOTP_INTERVAL: {{ .Values.mfa.interval | quote }}
35:   TOTP_ALGORITHM: {{ .Values.mfa.algorithm | quote }}
36: 
37: 
38:   ENABLE_SMS_2FA: {{ .Values.sms.enabled | quote }}
39:   AWS_REGION: {{ .Values.sms.awsRegion | quote }}
40:   SNS_TOPIC_ARN: {{ .Values.sms.snsTopicArn | quote }}
41:   SMS_SENDER_ID: {{ .Values.sms.senderId | quote }}
42:   SMS_TYPE: {{ .Values.sms.smsType | quote }}
43:   SMS_CODE_LENGTH: {{ .Values.sms.codeLength | quote }}
44:   SMS_CODE_EXPIRY_SECONDS: {{ .Values.sms.codeExpirySeconds | quote }}
45:   SMS_MESSAGE_TEMPLATE: {{ .Values.sms.messageTemplate | quote }}
46: 
47: 
48:   APP_NAME: {{ .Values.app.name | quote }}
49:   DEBUG: {{ .Values.app.debug | quote }}
50:   LOG_LEVEL: {{ .Values.app.logLevel | quote }}
51:   CORS_ORIGINS: {{ .Values.app.corsOrigins | quote }}
52: 
53: 
54:   REDIS_ENABLED: {{ .Values.redis.enabled | quote }}
55:   REDIS_HOST: {{ .Values.redis.host | quote }}
56:   REDIS_PORT: {{ .Values.redis.port | quote }}
57:   REDIS_DB: {{ .Values.redis.db | quote }}
58:   REDIS_SSL: {{ .Values.redis.ssl | quote }}
59:   REDIS_KEY_PREFIX: {{ .Values.redis.keyPrefix | quote }}
````

## File: application/backend/helm/ldap-2fa-backend/templates/deployment.yaml
````yaml
  1: apiVersion: apps/v1
  2: kind: Deployment
  3: metadata:
  4:   name: {{ include "ldap-2fa-backend.fullname" . }}
  5:   labels:
  6:     {{- include "ldap-2fa-backend.labels" . | nindent 4 }}
  7: spec:
  8:   {{- if not .Values.autoscaling.enabled }}
  9:   replicas: {{ .Values.replicaCount }}
 10:   {{- end }}
 11:   selector:
 12:     matchLabels:
 13:       {{- include "ldap-2fa-backend.selectorLabels" . | nindent 6 }}
 14:   template:
 15:     metadata:
 16:       annotations:
 17: 
 18:         checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
 19:         {{- with .Values.podAnnotations }}
 20:         {{- toYaml . | nindent 8 }}
 21:         {{- end }}
 22:       labels:
 23:         {{- include "ldap-2fa-backend.labels" . | nindent 8 }}
 24:         {{- with .Values.podLabels }}
 25:         {{- toYaml . | nindent 8 }}
 26:         {{- end }}
 27:     spec:
 28:       {{- with .Values.imagePullSecrets }}
 29:       imagePullSecrets:
 30:         {{- toYaml . | nindent 8 }}
 31:       {{- end }}
 32:       serviceAccountName: {{ include "ldap-2fa-backend.serviceAccountName" . }}
 33:       {{- with .Values.podSecurityContext }}
 34:       securityContext:
 35:         {{- toYaml . | nindent 8 }}
 36:       {{- end }}
 37:       containers:
 38:         - name: {{ .Chart.Name }}
 39:           {{- with .Values.securityContext }}
 40:           securityContext:
 41:             {{- toYaml . | nindent 12 }}
 42:           {{- end }}
 43:           image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
 44:           imagePullPolicy: {{ .Values.image.pullPolicy }}
 45:           ports:
 46:             - name: http
 47:               containerPort: {{ .Values.service.port }}
 48:               protocol: TCP
 49:           env:
 50: 
 51:             - name: LDAP_HOST
 52:               valueFrom:
 53:                 configMapKeyRef:
 54:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 55:                   key: LDAP_HOST
 56:             - name: LDAP_PORT
 57:               valueFrom:
 58:                 configMapKeyRef:
 59:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 60:                   key: LDAP_PORT
 61:             - name: LDAP_USE_SSL
 62:               valueFrom:
 63:                 configMapKeyRef:
 64:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 65:                   key: LDAP_USE_SSL
 66:             - name: LDAP_BASE_DN
 67:               valueFrom:
 68:                 configMapKeyRef:
 69:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 70:                   key: LDAP_BASE_DN
 71:             - name: LDAP_ADMIN_DN
 72:               valueFrom:
 73:                 configMapKeyRef:
 74:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 75:                   key: LDAP_ADMIN_DN
 76:             - name: LDAP_USER_SEARCH_BASE
 77:               valueFrom:
 78:                 configMapKeyRef:
 79:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 80:                   key: LDAP_USER_SEARCH_BASE
 81:             - name: LDAP_USER_SEARCH_FILTER
 82:               valueFrom:
 83:                 configMapKeyRef:
 84:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 85:                   key: LDAP_USER_SEARCH_FILTER
 86:             - name: LDAP_ADMIN_GROUP_DN
 87:               valueFrom:
 88:                 configMapKeyRef:
 89:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 90:                   key: LDAP_ADMIN_GROUP_DN
 91:             - name: LDAP_USERS_GID
 92:               valueFrom:
 93:                 configMapKeyRef:
 94:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
 95:                   key: LDAP_USERS_GID
 96:             - name: LDAP_UID_START
 97:               valueFrom:
 98:                 configMapKeyRef:
 99:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
100:                   key: LDAP_UID_START
101: 
102:             {{- if .Values.externalSecret.enabled }}
103:             - name: LDAP_ADMIN_PASSWORD
104:               valueFrom:
105:                 secretKeyRef:
106:                   name: {{ .Values.externalSecret.secretName }}
107:                   key: {{ .Values.externalSecret.adminPasswordKey }}
108:             {{- end }}
109: 
110:             {{- if .Values.database.externalSecret.enabled }}
111:             - name: DATABASE_URL
112:               valueFrom:
113:                 secretKeyRef:
114:                   name: {{ .Values.database.externalSecret.secretName }}
115:                   key: {{ .Values.database.externalSecret.passwordKey }}
116:             {{- else }}
117:             - name: DATABASE_URL
118:               valueFrom:
119:                 configMapKeyRef:
120:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
121:                   key: DATABASE_URL
122:             {{- end }}
123: 
124:             - name: ENABLE_EMAIL_VERIFICATION
125:               valueFrom:
126:                 configMapKeyRef:
127:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
128:                   key: ENABLE_EMAIL_VERIFICATION
129:             - name: SES_SENDER_EMAIL
130:               valueFrom:
131:                 configMapKeyRef:
132:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
133:                   key: SES_SENDER_EMAIL
134:             - name: EMAIL_VERIFICATION_EXPIRY_HOURS
135:               valueFrom:
136:                 configMapKeyRef:
137:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
138:                   key: EMAIL_VERIFICATION_EXPIRY_HOURS
139:             - name: APP_URL
140:               valueFrom:
141:                 configMapKeyRef:
142:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
143:                   key: APP_URL
144: 
145:             - name: TOTP_ISSUER
146:               valueFrom:
147:                 configMapKeyRef:
148:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
149:                   key: TOTP_ISSUER
150:             - name: TOTP_DIGITS
151:               valueFrom:
152:                 configMapKeyRef:
153:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
154:                   key: TOTP_DIGITS
155:             - name: TOTP_INTERVAL
156:               valueFrom:
157:                 configMapKeyRef:
158:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
159:                   key: TOTP_INTERVAL
160:             - name: TOTP_ALGORITHM
161:               valueFrom:
162:                 configMapKeyRef:
163:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
164:                   key: TOTP_ALGORITHM
165: 
166:             - name: ENABLE_SMS_2FA
167:               valueFrom:
168:                 configMapKeyRef:
169:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
170:                   key: ENABLE_SMS_2FA
171:             - name: AWS_REGION
172:               valueFrom:
173:                 configMapKeyRef:
174:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
175:                   key: AWS_REGION
176:             - name: SNS_TOPIC_ARN
177:               valueFrom:
178:                 configMapKeyRef:
179:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
180:                   key: SNS_TOPIC_ARN
181:             - name: SMS_SENDER_ID
182:               valueFrom:
183:                 configMapKeyRef:
184:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
185:                   key: SMS_SENDER_ID
186:             - name: SMS_TYPE
187:               valueFrom:
188:                 configMapKeyRef:
189:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
190:                   key: SMS_TYPE
191:             - name: SMS_CODE_LENGTH
192:               valueFrom:
193:                 configMapKeyRef:
194:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
195:                   key: SMS_CODE_LENGTH
196:             - name: SMS_CODE_EXPIRY_SECONDS
197:               valueFrom:
198:                 configMapKeyRef:
199:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
200:                   key: SMS_CODE_EXPIRY_SECONDS
201:             - name: SMS_MESSAGE_TEMPLATE
202:               valueFrom:
203:                 configMapKeyRef:
204:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
205:                   key: SMS_MESSAGE_TEMPLATE
206: 
207:             - name: APP_NAME
208:               valueFrom:
209:                 configMapKeyRef:
210:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
211:                   key: APP_NAME
212:             - name: DEBUG
213:               valueFrom:
214:                 configMapKeyRef:
215:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
216:                   key: DEBUG
217:             - name: LOG_LEVEL
218:               valueFrom:
219:                 configMapKeyRef:
220:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
221:                   key: LOG_LEVEL
222:             - name: CORS_ORIGINS
223:               valueFrom:
224:                 configMapKeyRef:
225:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
226:                   key: CORS_ORIGINS
227: 
228:             - name: REDIS_ENABLED
229:               valueFrom:
230:                 configMapKeyRef:
231:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
232:                   key: REDIS_ENABLED
233:             - name: REDIS_HOST
234:               valueFrom:
235:                 configMapKeyRef:
236:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
237:                   key: REDIS_HOST
238:             - name: REDIS_PORT
239:               valueFrom:
240:                 configMapKeyRef:
241:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
242:                   key: REDIS_PORT
243:             - name: REDIS_DB
244:               valueFrom:
245:                 configMapKeyRef:
246:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
247:                   key: REDIS_DB
248:             - name: REDIS_SSL
249:               valueFrom:
250:                 configMapKeyRef:
251:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
252:                   key: REDIS_SSL
253:             - name: REDIS_KEY_PREFIX
254:               valueFrom:
255:                 configMapKeyRef:
256:                   name: {{ include "ldap-2fa-backend.fullname" . }}-config
257:                   key: REDIS_KEY_PREFIX
258: 
259:             {{- if .Values.redis.existingSecret.enabled }}
260:             - name: REDIS_PASSWORD
261:               valueFrom:
262:                 secretKeyRef:
263:                   name: {{ .Values.redis.existingSecret.name }}
264:                   key: {{ .Values.redis.existingSecret.key }}
265:             {{- end }}
266:           {{- with .Values.livenessProbe }}
267:           livenessProbe:
268:             {{- toYaml . | nindent 12 }}
269:           {{- end }}
270:           {{- with .Values.readinessProbe }}
271:           readinessProbe:
272:             {{- toYaml . | nindent 12 }}
273:           {{- end }}
274:           {{- with .Values.resources }}
275:           resources:
276:             {{- toYaml . | nindent 12 }}
277:           {{- end }}
278:           {{- with .Values.volumeMounts }}
279:           volumeMounts:
280:             {{- toYaml . | nindent 12 }}
281:           {{- end }}
282:       {{- with .Values.volumes }}
283:       volumes:
284:         {{- toYaml . | nindent 8 }}
285:       {{- end }}
286:       {{- with .Values.nodeSelector }}
287:       nodeSelector:
288:         {{- toYaml . | nindent 8 }}
289:       {{- end }}
290:       {{- with .Values.affinity }}
291:       affinity:
292:         {{- toYaml . | nindent 8 }}
293:       {{- end }}
294:       {{- with .Values.tolerations }}
295:       tolerations:
296:         {{- toYaml . | nindent 8 }}
297:       {{- end }}
````

## File: application/backend/src/app/database/__init__.py
````python
 1: from app.database.connection import (
 2:     get_db,
 3:     init_db,
 4:     close_db,
 5:     get_async_session,
 6:     AsyncSessionLocal,
 7: )
 8: from app.database.models import (
 9:     Base,
10:     User,
11:     VerificationToken,
12:     ProfileStatus,
13:     Group,
14:     UserGroup,
15: )
16: 
17: __all__ = [
18:     "get_db",
19:     "init_db",
20:     "close_db",
21:     "get_async_session",
22:     "AsyncSessionLocal",
23:     "Base",
24:     "User",
25:     "VerificationToken",
26:     "ProfileStatus",
27:     "Group",
28:     "UserGroup",
29: ]
````

## File: application/backend/src/app/database/models.py
````python
  1: import uuid
  2: from datetime import datetime
  3: from enum import Enum
  4: from typing import Optional
  5: 
  6: from sqlalchemy import (
  7:     Boolean,
  8:     DateTime,
  9:     String,
 10:     Text,
 11:     ForeignKey,
 12:     Index,
 13:     func,
 14: )
 15: from sqlalchemy.dialects.postgresql import UUID
 16: from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship
 17: 
 18: 
 19: class Base(DeclarativeBase):
 20: 
 21: 
 22:     pass
 23: 
 24: 
 25: class ProfileStatus(str, Enum):
 26: 
 27: 
 28:     PENDING = "pending"
 29:     COMPLETE = "complete"
 30:     ACTIVE = "active"
 31:     REVOKED = "revoked"
 32: 
 33: 
 34: class MFAMethodType(str, Enum):
 35: 
 36: 
 37:     TOTP = "totp"
 38:     SMS = "sms"
 39: 
 40: 
 41: class User(Base):
 42: 
 43: 
 44:     __tablename__ = "users"
 45: 
 46: 
 47:     id: Mapped[uuid.UUID] = mapped_column(
 48:         UUID(as_uuid=True),
 49:         primary_key=True,
 50:         default=uuid.uuid4,
 51:     )
 52: 
 53: 
 54:     username: Mapped[str] = mapped_column(
 55:         String(64),
 56:         unique=True,
 57:         nullable=False,
 58:         index=True,
 59:     )
 60:     email: Mapped[str] = mapped_column(
 61:         String(255),
 62:         unique=True,
 63:         nullable=False,
 64:         index=True,
 65:     )
 66:     first_name: Mapped[str] = mapped_column(String(100), nullable=False)
 67:     last_name: Mapped[str] = mapped_column(String(100), nullable=False)
 68: 
 69: 
 70:     phone_country_code: Mapped[str] = mapped_column(
 71:         String(5),
 72:         nullable=False,
 73:     )
 74:     phone_number: Mapped[str] = mapped_column(
 75:         String(20),
 76:         nullable=False,
 77:     )
 78: 
 79: 
 80:     password_hash: Mapped[str] = mapped_column(Text, nullable=False)
 81: 
 82: 
 83:     email_verified: Mapped[bool] = mapped_column(Boolean, default=False)
 84:     phone_verified: Mapped[bool] = mapped_column(Boolean, default=False)
 85: 
 86: 
 87:     status: Mapped[str] = mapped_column(
 88:         String(20),
 89:         default=ProfileStatus.PENDING.value,
 90:         index=True,
 91:     )
 92: 
 93: 
 94:     mfa_method: Mapped[str] = mapped_column(
 95:         String(10),
 96:         default=MFAMethodType.TOTP.value,
 97:     )
 98:     totp_secret: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 99: 
100: 
101:     created_at: Mapped[datetime] = mapped_column(
102:         DateTime(timezone=True),
103:         server_default=func.now(),
104:     )
105:     updated_at: Mapped[datetime] = mapped_column(
106:         DateTime(timezone=True),
107:         server_default=func.now(),
108:         onupdate=func.now(),
109:     )
110: 
111: 
112:     activated_at: Mapped[Optional[datetime]] = mapped_column(
113:         DateTime(timezone=True),
114:         nullable=True,
115:     )
116:     activated_by: Mapped[Optional[str]] = mapped_column(
117:         String(64),
118:         nullable=True,
119:     )
120: 
121: 
122:     verification_tokens: Mapped[list["VerificationToken"]] = relationship(
123:         "VerificationToken",
124:         back_populates="user",
125:         cascade="all, delete-orphan",
126:     )
127:     user_groups: Mapped[list["UserGroup"]] = relationship(
128:         "UserGroup",
129:         back_populates="user",
130:         cascade="all, delete-orphan",
131:     )
132: 
133: 
134:     __table_args__ = (
135:         Index("ix_users_status_created", "status", "created_at"),
136:         Index("ix_users_phone", "phone_country_code", "phone_number"),
137:     )
138: 
139:     @property
140:     def full_name(self) -> str:
141: 
142:         return f"{self.first_name} {self.last_name}"
143: 
144:     @property
145:     def full_phone_number(self) -> str:
146:         """Get full phone number with country code."""
147:         return f"{self.phone_country_code}{self.phone_number}"
148: 
149:     @property
150:     def masked_phone(self) -> str:
151:         """Get masked phone number for display."""
152:         full = self.full_phone_number
153:         if len(full) > 4:
154:             return "*" * (len(full) - 4) + full[-4:]
155:         return full
156: 
157:     @property
158:     def masked_email(self) -> str:
159:         """Get masked email for display."""
160:         if "@" not in self.email:
161:             return self.email
162:         local, domain = self.email.split("@", 1)
163:         if len(local) > 2:
164:             masked_local = local[0] + "*" * (len(local) - 2) + local[-1]
165:         else:
166:             masked_local = "*" * len(local)
167:         return f"{masked_local}@{domain}"
168: 
169:     def is_verification_complete(self) -> bool:
170:         """Check if all verifications are complete."""
171:         return self.email_verified and self.phone_verified
172: 
173:     def update_status_if_complete(self) -> bool:
174:         """Update status to COMPLETE if all verifications done."""
175:         if self.is_verification_complete() and self.status == ProfileStatus.PENDING.value:
176:             self.status = ProfileStatus.COMPLETE.value
177:             return True
178:         return False
179: 
180: 
181: class VerificationTokenType(str, Enum):
182:     """Types of verification tokens."""
183: 
184:     EMAIL = "email"
185:     PHONE = "phone"
186: 
187: 
188: class VerificationToken(Base):
189: 
190: 
191:     __tablename__ = "verification_tokens"
192: 
193:     id: Mapped[uuid.UUID] = mapped_column(
194:         UUID(as_uuid=True),
195:         primary_key=True,
196:         default=uuid.uuid4,
197:     )
198: 
199:     user_id: Mapped[uuid.UUID] = mapped_column(
200:         UUID(as_uuid=True),
201:         ForeignKey("users.id", ondelete="CASCADE"),
202:         nullable=False,
203:         index=True,
204:     )
205: 
206:     token_type: Mapped[str] = mapped_column(
207:         String(10),
208:         nullable=False,
209:     )
210: 
211:     token: Mapped[str] = mapped_column(
212:         String(255),
213:         nullable=False,
214:         index=True,
215:     )
216: 
217:     expires_at: Mapped[datetime] = mapped_column(
218:         DateTime(timezone=True),
219:         nullable=False,
220:     )
221: 
222:     used: Mapped[bool] = mapped_column(Boolean, default=False)
223: 
224:     created_at: Mapped[datetime] = mapped_column(
225:         DateTime(timezone=True),
226:         server_default=func.now(),
227:     )
228: 
229: 
230:     user: Mapped["User"] = relationship("User", back_populates="verification_tokens")
231: 
232:     def is_expired(self) -> bool:
233: 
234:         return datetime.now(self.expires_at.tzinfo) > self.expires_at
235: 
236:     def is_valid(self) -> bool:
237: 
238:         return not self.used and not self.is_expired()
239: 
240: 
241: class Group(Base):
242: 
243: 
244:     __tablename__ = "groups"
245: 
246:     id: Mapped[uuid.UUID] = mapped_column(
247:         UUID(as_uuid=True),
248:         primary_key=True,
249:         default=uuid.uuid4,
250:     )
251: 
252:     name: Mapped[str] = mapped_column(
253:         String(100),
254:         unique=True,
255:         nullable=False,
256:         index=True,
257:     )
258: 
259:     description: Mapped[Optional[str]] = mapped_column(
260:         Text,
261:         nullable=True,
262:     )
263: 
264: 
265:     ldap_dn: Mapped[str] = mapped_column(
266:         String(500),
267:         nullable=False,
268:         unique=True,
269:     )
270: 
271: 
272:     created_at: Mapped[datetime] = mapped_column(
273:         DateTime(timezone=True),
274:         server_default=func.now(),
275:     )
276:     updated_at: Mapped[datetime] = mapped_column(
277:         DateTime(timezone=True),
278:         server_default=func.now(),
279:         onupdate=func.now(),
280:     )
281: 
282: 
283:     user_groups: Mapped[list["UserGroup"]] = relationship(
284:         "UserGroup",
285:         back_populates="group",
286:         cascade="all, delete-orphan",
287:     )
288: 
289:     @property
290:     def member_count(self) -> int:
291: 
292:         return len(self.user_groups) if self.user_groups else 0
293: 
294: 
295: class UserGroup(Base):
296: 
297: 
298:     __tablename__ = "user_groups"
299: 
300:     user_id: Mapped[uuid.UUID] = mapped_column(
301:         UUID(as_uuid=True),
302:         ForeignKey("users.id", ondelete="CASCADE"),
303:         primary_key=True,
304:     )
305: 
306:     group_id: Mapped[uuid.UUID] = mapped_column(
307:         UUID(as_uuid=True),
308:         ForeignKey("groups.id", ondelete="CASCADE"),
309:         primary_key=True,
310:     )
311: 
312: 
313:     assigned_at: Mapped[datetime] = mapped_column(
314:         DateTime(timezone=True),
315:         server_default=func.now(),
316:     )
317:     assigned_by: Mapped[str] = mapped_column(
318:         String(64),
319:         nullable=False,
320:     )
321: 
322: 
323:     user: Mapped["User"] = relationship("User", back_populates="user_groups")
324:     group: Mapped["Group"] = relationship("Group", back_populates="user_groups")
325: 
326: 
327:     __table_args__ = (
328:         Index("ix_user_groups_user", "user_id"),
329:         Index("ix_user_groups_group", "group_id"),
330:     )
````

## File: application/backend/src/app/email/client.py
````python
  1: import logging
  2: from typing import Optional
  3: 
  4: import boto3
  5: from botocore.exceptions import ClientError
  6: 
  7: from app.config import Settings, get_settings
  8: 
  9: logger = logging.getLogger(__name__)
 10: 
 11: 
 12: class EmailClient:
 13: 
 14: 
 15:     def __init__(self, settings: Optional[Settings] = None):
 16: 
 17:         self.settings = settings or get_settings()
 18:         self._client = None
 19: 
 20:     @property
 21:     def client(self):
 22: 
 23:         if self._client is None:
 24:             self._client = boto3.client(
 25:                 "ses",
 26:                 region_name=self.settings.aws_region,
 27:             )
 28:         return self._client
 29: 
 30:     def send_verification_email(
 31:         self,
 32:         to_email: str,
 33:         token: str,
 34:         username: str,
 35:         first_name: str,
 36:     ) -> tuple[bool, str]:
 37: 
 38: 
 39: 
 40: 
 41: 
 42: 
 43: 
 44: 
 45: 
 46: 
 47: 
 48: 
 49:         verification_link = (
 50:             f"{self.settings.app_url}/verify-email?token={token}&username={username}"
 51:         )
 52: 
 53:         subject = f"Verify your email - {self.settings.totp_issuer}"
 54: 
 55:         html_body = f"""
 56: <!DOCTYPE html>
 57: <html>
 58: <head>
 59:     <meta charset="UTF-8">
 60:     <meta name="viewport" content="width=device-width, initial-scale=1.0">
 61: </head>
 62: <body style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #333; max-width: 600px; margin: 0 auto; padding: 20px;">
 63:     <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px 10px 0 0; text-align: center;">
 64:         <h1 style="color: white; margin: 0; font-size: 28px;">Email Verification</h1>
 65:     </div>
 66:     <div style="background: #f9f9f9; padding: 30px; border-radius: 0 0 10px 10px; border: 1px solid #e0e0e0; border-top: none;">
 67:         <p style="font-size: 16px;">Hello <strong>{first_name}</strong>,</p>
 68:         <p style="font-size: 16px;">Thank you for signing up! Please verify your email address by clicking the button below:</p>
 69:         <div style="text-align: center; margin: 30px 0;">
 70:             <a href="{verification_link}" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 40px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block;">
 71:                 Verify Email Address
 72:             </a>
 73:         </div>
 74:         <p style="font-size: 14px; color: #666;">Or copy and paste this link into your browser:</p>
 75:         <p style="font-size: 12px; color: #888; word-break: break-all; background: #fff; padding: 10px; border-radius: 5px; border: 1px solid #e0e0e0;">
 76:             {verification_link}
 77:         </p>
 78:         <p style="font-size: 14px; color: #666; margin-top: 30px;">
 79:             This link will expire in <strong>{self.settings.email_verification_expiry_hours} hours</strong>.
 80:         </p>
 81:         <hr style="border: none; border-top: 1px solid #e0e0e0; margin: 30px 0;">
 82:         <p style="font-size: 12px; color: #999; text-align: center;">
 83:             If you didn't create an account, you can safely ignore this email.
 84:         </p>
 85:     </div>
 86: </body>
 87: </html>
 88: 
 89: 
 90: 
 91: Hello {first_name},
 92: 
 93: Thank you for signing up! Please verify your email address by visiting the link below:
 94: 
 95: {verification_link}
 96: 
 97: This link will expire in {self.settings.email_verification_expiry_hours} hours.
 98: 
 99: If you didn't create an account, you can safely ignore this email.
100: 
101: 
102: 
103: 
104: 
105: 
106: 
107: 
108: 
109: 
110: 
111: 
112: 
113: 
114: 
115: 
116: 
117: 
118: 
119: 
120: 
121: 
122: 
123: 
124: 
125: 
126: 
127: 
128: 
129: 
130: 
131: 
132: 
133: 
134: 
135:         Send welcome email after admin activation.
136: 
137:         Args:
138:             to_email: Recipient email address
139:             username: User's username
140:             first_name: User's first name
141: 
142:         Returns:
143:             Tuple of (success: bool, message: str)
144: 
145: 
146: 
147: 
148: 
149: 
150: <!DOCTYPE html>
151: <html>
152: <head>
153:     <meta charset="UTF-8">
154:     <meta name="viewport" content="width=device-width, initial-scale=1.0">
155: </head>
156: <body style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #333; max-width: 600px; margin: 0 auto; padding: 20px;">
157:     <div style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); padding: 30px; border-radius: 10px 10px 0 0; text-align: center;">
158:         <h1 style="color: white; margin: 0; font-size: 28px;">Account Activated!</h1>
159:     </div>
160:     <div style="background: #f9f9f9; padding: 30px; border-radius: 0 0 10px 10px; border: 1px solid #e0e0e0; border-top: none;">
161:         <p style="font-size: 16px;">Hello <strong>{first_name}</strong>,</p>
162:         <p style="font-size: 16px;">Great news! Your account has been approved and activated by an administrator.</p>
163:         <p style="font-size: 16px;">You can now log in using your username <strong>{username}</strong> and the password you created during signup.</p>
164:         <div style="text-align: center; margin: 30px 0;">
165:             <a href="{login_link}" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); color: white; padding: 15px 40px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block;">
166:                 Login Now
167:             </a>
168:         </div>
169:         <p style="font-size: 14px; color: #666;">
170:             Remember to have your authenticator app ready for two-factor authentication.
171:         </p>
172:         <hr style="border: none; border-top: 1px solid #e0e0e0; margin: 30px 0;">
173:         <p style="font-size: 12px; color: #999; text-align: center;">
174:             If you have any questions, please contact your system administrator.
175:         </p>
176:     </div>
177: </body>
178: </html>
179: 
180: 
181: 
182: Hello {first_name},
183: 
184: Great news! Your account has been approved and activated by an administrator.
185: 
186: You can now log in using your username ({username}) and the password you created during signup.
187: 
188: Login here: {login_link}
189: 
190: Remember to have your authenticator app ready for two-factor authentication.
191: 
192: If you have any questions, please contact your system administrator.
193: 
194: 
195: 
196: 
197: 
198: 
199: 
200: 
201: 
202: 
203: 
204: 
205: 
206: 
207: 
208: 
209: 
210: 
211: 
212: 
213: 
214: 
215: 
216: 
217: 
218: 
219: 
220: 
221: 
222: 
223: 
224: 
225: 
226: 
227:         Send notification email to admins when a new user signs up.
228: 
229:         Args:
230:             admin_emails: List of admin email addresses
231:             new_user: Dictionary with new user details:
232:                 - username: str
233:                 - full_name: str
234:                 - email: str
235:                 - phone: str
236:                 - signup_time: str (ISO format)
237: 
238:         Returns:
239:             Tuple of (success: bool, message: str)
240: 
241: 
242: 
243: 
244: 
245: 
246: 
247: 
248: 
249: 
250: <!DOCTYPE html>
251: <html>
252: <head>
253:     <meta charset="UTF-8">
254:     <meta name="viewport" content="width=device-width, initial-scale=1.0">
255: </head>
256: <body style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #333; max-width: 600px; margin: 0 auto; padding: 20px;">
257:     <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 30px; border-radius: 10px 10px 0 0; text-align: center;">
258:         <h1 style="color: white; margin: 0; font-size: 28px;">New User Registration</h1>
259:     </div>
260:     <div style="background: #f9f9f9; padding: 30px; border-radius: 0 0 10px 10px; border: 1px solid #e0e0e0; border-top: none;">
261:         <p style="font-size: 16px;">A new user has registered and is awaiting approval.</p>
262: 
263:         <div style="background: #fff; padding: 20px; border-radius: 8px; border: 1px solid #e0e0e0; margin: 20px 0;">
264:             <h3 style="margin: 0 0 15px 0; color: #333; font-size: 18px;">User Details</h3>
265:             <table style="width: 100%; border-collapse: collapse;">
266:                 <tr>
267:                     <td style="padding: 8px 0; color: #666; width: 120px;">Username:</td>
268:                     <td style="padding: 8px 0; font-weight: bold;">{new_user.get('username', 'N/A')}</td>
269:                 </tr>
270:                 <tr>
271:                     <td style="padding: 8px 0; color: #666;">Full Name:</td>
272:                     <td style="padding: 8px 0; font-weight: bold;">{new_user.get('full_name', 'N/A')}</td>
273:                 </tr>
274:                 <tr>
275:                     <td style="padding: 8px 0; color: #666;">Email:</td>
276:                     <td style="padding: 8px 0; font-weight: bold;">{new_user.get('email', 'N/A')}</td>
277:                 </tr>
278:                 <tr>
279:                     <td style="padding: 8px 0; color: #666;">Phone:</td>
280:                     <td style="padding: 8px 0; font-weight: bold;">{new_user.get('phone', 'N/A')}</td>
281:                 </tr>
282:                 <tr>
283:                     <td style="padding: 8px 0; color: #666;">Signup Time:</td>
284:                     <td style="padding: 8px 0; font-weight: bold;">{new_user.get('signup_time', 'N/A')}</td>
285:                 </tr>
286:             </table>
287:         </div>
288: 
289:         <p style="font-size: 14px; color: #666;">
290:             Once the user completes email and phone verification, you can approve or reject their account from the admin dashboard.
291:         </p>
292: 
293:         <div style="text-align: center; margin: 30px 0;">
294:             <a href="{admin_dashboard_link}" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; padding: 15px 40px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block;">
295:                 Review in Admin Dashboard
296:             </a>
297:         </div>
298: 
299:         <hr style="border: none; border-top: 1px solid #e0e0e0; margin: 30px 0;">
300:         <p style="font-size: 12px; color: #999; text-align: center;">
301:             This is an automated notification from {self.settings.totp_issuer}.
302:         </p>
303:     </div>
304: </body>
305: </html>
306: 
307: 
308: 
309: New User Registration
310: 
311: A new user has registered and is awaiting approval.
312: 
313: User Details:
314: - Username: {new_user.get('username', 'N/A')}
315: - Full Name: {new_user.get('full_name', 'N/A')}
316: - Email: {new_user.get('email', 'N/A')}
317: - Phone: {new_user.get('phone', 'N/A')}
318: - Signup Time: {new_user.get('signup_time', 'N/A')}
319: 
320: Once the user completes email and phone verification, you can approve or reject their account from the admin dashboard.
321: 
322: Review in Admin Dashboard: {admin_dashboard_link}
323: 
324: This is an automated notification from {self.settings.totp_issuer}.
````

## File: application/frontend/helm/ldap-2fa-frontend/values.yaml
````yaml
  1: replicaCount: 2
  2: 
  3: 
  4: image:
  5: 
  6:   repository: ""
  7:   pullPolicy: IfNotPresent
  8:   # Image tag - should be set via CI/CD (defaults to Chart appVersion)
  9:   tag: ""
 10: 
 11: # Secrets for pulling images from private registry
 12: imagePullSecrets: []
 13: 
 14: # Override chart name
 15: nameOverride: ""
 16: fullnameOverride: ""
 17: 
 18: # Service account configuration
 19: serviceAccount:
 20:   create: true
 21:   automount: true
 22:   annotations: {}
 23:   name: ""
 24: 
 25: # Pod annotations and labels
 26: podAnnotations: {}
 27: podLabels: {}
 28: 
 29: # Pod security context
 30: podSecurityContext:
 31:   fsGroup: 1000
 32: 
 33: # Container security context
 34: securityContext:
 35:   capabilities:
 36:     drop:
 37:       - ALL
 38:   readOnlyRootFilesystem: false
 39:   runAsNonRoot: true
 40:   runAsUser: 1000
 41:   allowPrivilegeEscalation: false
 42: 
 43: # Service configuration
 44: service:
 45:   type: ClusterIP
 46:   port: 80
 47: 
 48: # Ingress configuration for ALB
 49: ingress:
 50:   enabled: true
 51:   className: ""  # Will be set to IngressClass name
 52:   annotations:
 53:     # ALB-specific annotations
 54:     alb.ingress.kubernetes.io/load-balancer-name: ""
 55:     alb.ingress.kubernetes.io/target-type: "ip"
 56:     alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
 57:     alb.ingress.kubernetes.io/ssl-redirect: "443"
 58:     alb.ingress.kubernetes.io/ssl-policy: "ELBSecurityPolicy-TLS13-1-0-PQ-2025-09"
 59: 
 60:     alb.ingress.kubernetes.io/group.order: "20"
 61:   hosts:
 62:     - host: ""
 63:       paths:
 64:         - path: /
 65:           pathType: Prefix
 66:   tls: []
 67: 
 68: 
 69: httpRoute:
 70:   enabled: false
 71: 
 72: 
 73: resources:
 74:   limits:
 75:     cpu: 200m
 76:     memory: 128Mi
 77:   requests:
 78:     cpu: 50m
 79:     memory: 64Mi
 80: 
 81: 
 82: livenessProbe:
 83:   httpGet:
 84:     path: /health
 85:     port: http
 86:   initialDelaySeconds: 5
 87:   periodSeconds: 30
 88:   timeoutSeconds: 5
 89:   failureThreshold: 3
 90: 
 91: 
 92: readinessProbe:
 93:   httpGet:
 94:     path: /health
 95:     port: http
 96:   initialDelaySeconds: 3
 97:   periodSeconds: 10
 98:   timeoutSeconds: 5
 99:   failureThreshold: 3
100: 
101: 
102: autoscaling:
103:   enabled: false
104:   minReplicas: 2
105:   maxReplicas: 10
106:   targetCPUUtilizationPercentage: 80
107:   targetMemoryUtilizationPercentage: 80
108: 
109: 
110: volumes: []
111: 
112: 
113: volumeMounts: []
114: 
115: 
116: nodeSelector: {}
117: 
118: 
119: tolerations: []
120: 
121: 
122: affinity: {}
````

## File: application/helm/redis-values.tpl.yaml
````yaml
 1: image:
 2:   registry: "${ecr_registry}"
 3:   repository: "${ecr_repository}"
 4:   tag: "${image_tag}"
 5:   pullPolicy: IfNotPresent
 6: 
 7: 
 8: architecture: standalone
 9: 
10: 
11: auth:
12:   enabled: true
13: 
14: 
15:   existingSecret: "${secret_name}"
16:   existingSecretPasswordKey: "redis-password"
17: 
18: 
19: master:
20: 
21:   persistence:
22:     enabled: ${persistence_enabled}
23: %{ if storage_class_name != "" ~}
24:     storageClass: "${storage_class_name}"
25: %{ endif ~}
26:     size: "${storage_size}"
27: 
28:   # Resource limits
29:   resources:
30:     requests:
31:       cpu: "${resources_requests_cpu}"
32:       memory: "${resources_requests_memory}"
33:     limits:
34:       cpu: "${resources_limits_cpu}"
35:       memory: "${resources_limits_memory}"
36: 
37: 
38:   containerSecurityContext:
39:     enabled: true
40:     runAsUser: 1001
41:     runAsNonRoot: true
42:     allowPrivilegeEscalation: false
43: 
44:   podSecurityContext:
45:     enabled: true
46:     fsGroup: 1001
47: 
48: 
49:   service:
50:     type: ClusterIP
51:     ports:
52:       redis: 6379
53: 
54: 
55: replica:
56:   replicaCount: 0
57: 
58: 
59: metrics:
60:   enabled: ${metrics_enabled}
61: 
62: 
63: commonConfiguration: |-
64: 
65:   save 900 1
66:   save 300 10
67:   save 60 10000
68: 
69:   appendonly no
70: 
71:   maxmemory-policy volatile-lru
72: 
73:   timeout 300
````

## File: application/modules/argocd/outputs.tf
````hcl
 1: output "argocd_server_url" {
 2:   description = "Managed Argo CD UI/API endpoint (automatically retrieved via AWS CLI)"
 3:   value       = data.external.argocd_capability.result.server_url != "" ? data.external.argocd_capability.result.server_url : null
 4: }
 5: 
 6: output "argocd_capability_name" {
 7:   description = "Name of the ArgoCD capability"
 8:   value       = local.argocd_capability_name
 9: }
10: 
11: output "argocd_capability_status" {
12:   description = "Status of the ArgoCD capability (automatically retrieved via AWS CLI)"
13:   value       = data.external.argocd_capability.result.status != "" ? data.external.argocd_capability.result.status : null
14: }
15: 
16: output "argocd_iam_role_arn" {
17:   description = "ARN of the IAM role used by ArgoCD capability"
18:   value       = aws_iam_role.argocd_capability.arn
19: }
20: 
21: output "argocd_iam_role_name" {
22:   description = "Name of the IAM role used by ArgoCD capability"
23:   value       = aws_iam_role.argocd_capability.name
24: }
25: 
26: output "local_cluster_secret_name" {
27:   description = "Name of the Kubernetes secret for local cluster registration"
28:   value       = kubernetes_secret.argocd_local_cluster.metadata[0].name
29: }
30: 
31: output "argocd_namespace" {
32:   description = "Kubernetes namespace where ArgoCD resources are deployed"
33:   value       = var.argocd_namespace
34: }
35: 
36: output "argocd_project_name" {
37:   description = "ArgoCD project name used for cluster registration"
38:   value       = var.argocd_project_name
39: }
````

## File: application/modules/argocd/README.md
````markdown
  1: # ArgoCD Capability Module
  2: 
  3: This module deploys the AWS EKS ArgoCD Capability, which is a fully managed Argo
  4: CD service that runs in the EKS control plane.
  5: 
  6: ## Purpose
  7: 
  8: The ArgoCD Capability module:
  9: 
 10: - Creates IAM role and policies for ArgoCD capability
 11: - Deploys the managed ArgoCD service on EKS
 12: - Configures AWS Identity Center (IdC) authentication
 13: - Registers the local EKS cluster with ArgoCD
 14: - Sets up RBAC mappings for Identity Center groups/users
 15: 
 16: ## What it Creates
 17: 
 18: 1. **IAM Role** (`aws_iam_role.argocd_capability`)
 19:    - Trusted by `capabilities.eks.amazonaws.com`
 20:    - Attached with policies for EKS, Secrets Manager, CodeConnections, and
 21:    optionally ECR/CodeCommit
 22: 
 23: 2. **EKS Capability** (`aws_eks_capability.argocd`)
 24:    - Managed ArgoCD service running in EKS control plane
 25:    - Configured with Identity Center authentication
 26:    - RBAC role mappings for Identity Center groups/users
 27:    - Optional VPC endpoint configuration for private access
 28: 
 29: 3. **Cluster Registration Secret** (`kubernetes_secret.argocd_local_cluster`)
 30:    - Registers the local EKS cluster with ArgoCD
 31:    - Required for Applications to target the cluster
 32: 
 33: ## Prerequisites
 34: 
 35: - EKS cluster (Auto Mode or provisioned) must exist
 36: - AWS Identity Center instance must be set up
 37: - At least one Identity Center user or group for RBAC mapping
 38: - Terraform AWS provider version `>= 5.60.0`
 39: - Terraform Kubernetes provider version `>= 2.30.0`
 40: 
 41: ## Usage
 42: 
 43: ```hcl
 44: module "argocd" {
 45:   source = "./modules/argocd"
 46: 
 47:   env    = "prod"
 48:   region = "us-east-1"
 49:   prefix = "myorg"
 50:   cluster_name = "my-eks-cluster"
 51: 
 52:   idc_instance_arn = "arn:aws:sso:::instance/ssoins-1234567890abcdef"
 53:   idc_region       = "us-east-1"
 54: 
 55:   rbac_role_mappings = [
 56:     {
 57:       role = "ADMIN"
 58:       identities = [
 59:         {
 60:           id   = "g-1234567890abcdef"
 61:           type = "SSO_GROUP"
 62:         }
 63:       ]
 64:     }
 65:   ]
 66: 
 67:   # Optional: Enable ECR access for pulling images
 68:   enable_ecr_access = true
 69: 
 70:   # Optional: Restrict access via VPC endpoints
 71:   argocd_vpce_ids = ["vpce-1234567890abcdef0"]
 72: }
 73: ```
 74: 
 75: ## Inputs
 76: 
 77: | Name | Description | Type | Required | Default |
 78: | ------ | ------------- | ------ | ---------- | --------- |
 79: | env | Deployment environment | string | yes | - |
 80: | region | Deployment region | string | yes | - |
 81: | prefix | Name added to all resources | string | yes | - |
 82: | cluster_name | Name of the EKS cluster | string | yes | - |
 83: | argocd_role_name_component | Name component for ArgoCD IAM role | string | no | "argocd-role" |
 84: | argocd_capability_name_component | Name component for ArgoCD capability | string | no | "argocd" |
 85: | argocd_namespace | Kubernetes namespace for ArgoCD resources | string | no | "argocd" |
 86: | argocd_project_name | ArgoCD project name for cluster registration | string | no | "default" |
 87: | local_cluster_secret_name | Name of the Kubernetes secret for local cluster registration | string | no | "local-cluster" |
 88: | idc_instance_arn | ARN of the AWS Identity Center instance | string | yes | - |
 89: | idc_region | Region of the Identity Center instance | string | yes | - |
 90: | rbac_role_mappings | List of RBAC role mappings for Identity Center | list(object) | no | [] |
 91: | argocd_vpce_ids | List of VPC endpoint IDs for private access | list(string) | no | [] |
 92: | delete_propagation_policy | Delete propagation policy (RETAIN or DELETE) | string | no | "RETAIN" |
 93: | iam_policy_eks_resources | EKS resource ARNs for IAM policy | list(string) | no | ["*"] |
 94: | iam_policy_secrets_manager_resources | Secrets Manager ARNs for IAM policy | list(string) | no | ["*"] |
 95: | iam_policy_code_connections_resources | CodeConnections ARNs for IAM policy | list(string) | no | ["*"] |
 96: | enable_ecr_access | Whether to enable ECR access in IAM policy | bool | no | false |
 97: | iam_policy_ecr_resources | ECR repository ARNs for IAM policy | list(string) | no | ["*"] |
 98: | enable_codecommit_access | Whether to enable CodeCommit access in IAM policy | bool | no | false |
 99: | iam_policy_codecommit_resources | CodeCommit repository ARNs for IAM policy | list(string) | no | ["*"] |
100: 
101: ## Outputs
102: 
103: | Name | Description |
104: | ------ | ------------- |
105: | argocd_server_url | Managed Argo CD UI/API endpoint |
106: | argocd_capability_name | Name of the ArgoCD capability |
107: | argocd_capability_status | Status of the ArgoCD capability |
108: | argocd_iam_role_arn | ARN of the IAM role used by ArgoCD capability |
109: | argocd_iam_role_name | Name of the IAM role used by ArgoCD capability |
110: | local_cluster_secret_name | Name of the Kubernetes secret for local cluster registration |
111: | argocd_namespace | Kubernetes namespace where ArgoCD resources are deployed |
112: | argocd_project_name | ArgoCD project name used for cluster registration |
113: 
114: ## RBAC Role Mappings
115: 
116: RBAC role mappings connect Identity Center groups/users to ArgoCD roles:
117: 
118: ```hcl
119: rbac_role_mappings = [
120:   {
121:     role = "ADMIN"
122:     identities = [
123:       {
124:         id   = "g-1234567890abcdef"  # Identity Center group ID
125:         type = "SSO_GROUP"
126:       }
127:     ]
128:   },
129:   {
130:     role = "READ_ONLY"
131:     identities = [
132:       {
133:         id   = "u-0987654321fedcba"  # Identity Center user ID
134:         type = "SSO_USER"
135:       }
136:     ]
137:   }
138: ]
139: ```
140: 
141: Valid ArgoCD roles:
142: 
143: - `ADMIN` - Full administrative access
144: - `READ_ONLY` - Read-only access
145: - Custom roles defined in ArgoCD Projects
146: 
147: ## IAM Policy Resources
148: 
149: For production, replace wildcard resources (`["*"]`) with specific ARNs:
150: 
151: ```hcl
152: iam_policy_eks_resources = [
153:   "arn:aws:eks:us-east-1:123456789012:cluster/my-cluster"
154: ]
155: 
156: iam_policy_secrets_manager_resources = [
157:   "arn:aws:secretsmanager:us-east-1:123456789012:secret:my-git-repo-*"
158: ]
159: ```
160: 
161: ## Network Access Control
162: 
163: To restrict ArgoCD endpoint access via VPC endpoints:
164: 
165: ```hcl
166: argocd_vpce_ids = [
167:   "vpce-1234567890abcdef0",
168:   "vpce-0987654321fedcba1"
169: ]
170: ```
171: 
172: When specified, ArgoCD endpoint is private and accessible only via these VPC endpoints.
173: 
174: ## Verifying Deployment
175: 
176: ```bash
177: # Check capability status
178: aws eks describe-capability \
179:   --cluster-name my-eks-cluster \
180:   --capability-name myorg-us-east-1-argocd-prod \
181:   --capability-type ARGOCD
182: 
183: # Check cluster registration secret
184: kubectl get secret local-cluster -n argocd
185: 
186: # Access ArgoCD UI (get URL from output)
187: echo $TF_OUTPUT_argocd_server_url
188: ```
189: 
190: ## Notes
191: 
192: - The capability runs in the EKS control plane (no pods on worker nodes)
193: - Cluster registration is required before Applications can target the cluster
194: - Use the `local_cluster_secret_name` output when creating ArgoCD Applications
195: - IAM policies use wildcards by default; tighten for production use
196: - Delete propagation policy defaults to `RETAIN` to prevent accidental deletion
````

## File: application/modules/argocd_app/main.tf
````hcl
 1: resource "kubernetes_manifest" "argocd_app" {
 2:   manifest = {
 3:     apiVersion = "argoproj.io/v1alpha1"
 4:     kind       = "Application"
 5:     metadata = {
 6:       name        = var.app_name
 7:       namespace   = var.argocd_namespace
 8:       labels      = var.app_labels
 9:       annotations = var.app_annotations
10:     }
11:     spec = {
12:       project = var.argocd_project_name
13: 
14:       source = {
15:         repoURL        = var.repo_url
16:         targetRevision = var.target_revision
17:         path           = var.repo_path
18:         helm = var.helm_config != null ? {
19:           valueFiles  = var.helm_config.value_files
20:           parameters  = var.helm_config.parameters
21:           releaseName = var.helm_config.release_name
22:         } : null
23:         kustomize = var.kustomize_config != null ? {
24:           images            = var.kustomize_config.images
25:           commonLabels      = var.kustomize_config.common_labels
26:           commonAnnotations = var.kustomize_config.common_annotations
27:           patches           = var.kustomize_config.patches
28:         } : null
29:         directory = var.directory_config != null ? {
30:           recurse = var.directory_config.recurse
31:           include = var.directory_config.include
32:           exclude = var.directory_config.exclude
33:           jsonnet = var.directory_config.jsonnet != null ? {
34:             libs    = var.directory_config.jsonnet.libs
35:             tlas    = var.directory_config.jsonnet.tlas
36:             extVars = var.directory_config.jsonnet.ext_vars
37:           } : null
38:         } : null
39:       }
40: 
41:       destination = {
42:         name      = var.cluster_name_in_argo
43:         namespace = var.destination_namespace
44:         server    = var.destination_server != null ? var.destination_server : null
45:       }
46: 
47:       syncPolicy = var.sync_policy != null ? {
48:         automated = var.sync_policy.automated != null ? {
49:           prune      = var.sync_policy.automated.prune
50:           selfHeal   = var.sync_policy.automated.self_heal
51:           allowEmpty = var.sync_policy.automated.allow_empty
52:         } : null
53:         syncOptions = var.sync_policy.sync_options
54:         retry = var.sync_policy.retry != null ? {
55:           limit = var.sync_policy.retry.limit
56:           backoff = var.sync_policy.retry.backoff != null ? {
57:             duration    = var.sync_policy.retry.backoff.duration
58:             factor      = var.sync_policy.retry.backoff.factor
59:             maxDuration = var.sync_policy.retry.backoff.max_duration
60:           } : null
61:         } : null
62:       } : null
63: 
64:       ignoreDifferences    = length(var.ignore_differences) > 0 ? var.ignore_differences : null
65:       revisionHistoryLimit = var.revision_history_limit
66:     }
67:   }
68: }
````

## File: application/modules/argocd_app/variables.tf
````hcl
  1: variable "app_name" {
  2:   description = "Name of the ArgoCD Application"
  3:   type        = string
  4: }
  5: 
  6: variable "argocd_namespace" {
  7:   description = "Kubernetes namespace where ArgoCD Application will be created"
  8:   type        = string
  9:   default     = "argocd"
 10: }
 11: 
 12: variable "argocd_project_name" {
 13:   description = "ArgoCD project name for the Application"
 14:   type        = string
 15:   default     = "default"
 16: }
 17: 
 18: variable "cluster_name_in_argo" {
 19:   description = "Name of the cluster in ArgoCD (from cluster registration secret)"
 20:   type        = string
 21: }
 22: 
 23: variable "repo_url" {
 24:   description = "Git repository URL containing application manifests"
 25:   type        = string
 26: }
 27: 
 28: variable "target_revision" {
 29:   description = "Git branch, tag, or commit to sync (default: HEAD)"
 30:   type        = string
 31:   default     = "HEAD"
 32: }
 33: 
 34: variable "repo_path" {
 35:   description = "Path within the repository to the application manifests"
 36:   type        = string
 37: }
 38: 
 39: variable "destination_namespace" {
 40:   description = "Target Kubernetes namespace for the application"
 41:   type        = string
 42: }
 43: 
 44: variable "destination_server" {
 45:   description = "Optional Kubernetes server URL (defaults to cluster_name_in_argo)"
 46:   type        = string
 47:   default     = null
 48: }
 49: 
 50: variable "app_labels" {
 51:   description = "Labels to apply to the ArgoCD Application resource"
 52:   type        = map(string)
 53:   default     = {}
 54: }
 55: 
 56: variable "app_annotations" {
 57:   description = "Annotations to apply to the ArgoCD Application resource"
 58:   type        = map(string)
 59:   default     = {}
 60: }
 61: 
 62: variable "sync_policy" {
 63:   description = "Sync policy configuration for the Application"
 64:   type = object({
 65:     automated = object({
 66:       prune       = bool
 67:       self_heal   = bool
 68:       allow_empty = optional(bool, false)
 69:     })
 70:     sync_options = optional(list(string), ["CreateNamespace=true"])
 71:     retry = optional(object({
 72:       limit = number
 73:       backoff = optional(object({
 74:         duration     = string
 75:         factor       = number
 76:         max_duration = string
 77:       }))
 78:     }))
 79:   })
 80:   default = null
 81: }
 82: 
 83: variable "ignore_differences" {
 84:   description = "List of ignore differences configurations"
 85:   type = list(object({
 86:     group                 = optional(string)
 87:     kind                  = optional(string)
 88:     name                  = optional(string)
 89:     namespace             = optional(string)
 90:     jsonPointers          = optional(list(string))
 91:     jqPathExpressions     = optional(list(string))
 92:     managedFieldsManagers = optional(list(string))
 93:   }))
 94:   default = []
 95: }
 96: 
 97: variable "revision_history_limit" {
 98:   description = "Number of application revisions to keep in history"
 99:   type        = number
100:   default     = 5
101: }
102: 
103: variable "helm_config" {
104:   description = "Helm-specific configuration (for Helm charts)"
105:   type = object({
106:     value_files = optional(list(string), [])
107:     parameters = optional(list(object({
108:       name         = string
109:       value        = string
110:       force_string = optional(bool, false)
111:     })), [])
112:     release_name = optional(string)
113:   })
114:   default = null
115: }
116: 
117: variable "kustomize_config" {
118:   description = "Kustomize-specific configuration"
119:   type = object({
120:     images             = optional(list(string), [])
121:     common_labels      = optional(map(string), {})
122:     common_annotations = optional(map(string), {})
123:     patches = optional(list(object({
124:       path  = string
125:       patch = string
126:       target = optional(object({
127:         group     = string
128:         kind      = string
129:         name      = string
130:         namespace = optional(string)
131:       }))
132:     })), [])
133:   })
134:   default = null
135: }
136: 
137: variable "directory_config" {
138:   description = "Directory-specific configuration (for plain manifests)"
139:   type = object({
140:     recurse = optional(bool, true)
141:     include = optional(string)
142:     exclude = optional(string)
143:     jsonnet = optional(object({
144:       libs = optional(list(string), [])
145:       tlas = optional(list(object({
146:         name  = string
147:         value = string
148:         code  = optional(bool, false)
149:       })), [])
150:       ext_vars = optional(list(object({
151:         name  = string
152:         value = string
153:         code  = optional(bool, false)
154:       })), [])
155:     }))
156:   })
157:   default = null
158: }
````

## File: application/modules/network-policies/main.tf
````hcl
  1: # Network Policies for securing internal cluster communication
  2: # These policies enforce secure communication between all services in the namespace
  3: # Generic approach: Any service can talk to any service, but only on secure ports
  4: 
  5: # Generic Network Policy: Allow secure inter-pod communication within namespace
  6: # This policy applies to ALL pods in the namespace and allows them to communicate
  7: # with each other, but only on secure/encrypted ports
  8: resource "kubernetes_network_policy_v1" "namespace_secure_communication" {
  9:   metadata {
 10:     name      = "namespace-secure-communication"
 11:     namespace = var.namespace
 12:   }
 13: 
 14:   spec {
 15:     # Apply to all pods in the namespace
 16:     pod_selector {}
 17:     policy_types = ["Ingress", "Egress"]
 18: 
 19:     # Ingress: Allow traffic from any pod in the same namespace on secure ports
 20:     ingress {
 21:       # Allow from any pod in the same namespace
 22:       from {
 23:         pod_selector {}
 24:       }
 25:       ports {
 26:         port     = "443"
 27:         protocol = "TCP"
 28:       }
 29:     }
 30: 
 31:     ingress {
 32:       from {
 33:         pod_selector {}
 34:       }
 35:       ports {
 36:         port     = "636"
 37:         protocol = "TCP"
 38:       }
 39:     }
 40: 
 41:     # Allow HTTPS on common alternative ports if needed
 42:     ingress {
 43:       from {
 44:         pod_selector {}
 45:       }
 46:       ports {
 47:         port     = "8443"
 48:         protocol = "TCP"
 49:       }
 50:     }
 51: 
 52:     # Ingress: Allow traffic from any pod in other namespaces on secure ports
 53:     # This enables cross-namespace communication for LDAP service access
 54:     ingress {
 55:       # Allow from any pod in any namespace
 56:       from {
 57:         namespace_selector {}
 58:       }
 59:       ports {
 60:         port     = "443"
 61:         protocol = "TCP"
 62:       }
 63:     }
 64: 
 65:     ingress {
 66:       from {
 67:         namespace_selector {}
 68:       }
 69:       ports {
 70:         port     = "636"
 71:         protocol = "TCP"
 72:       }
 73:     }
 74: 
 75:     ingress {
 76:       from {
 77:         namespace_selector {}
 78:       }
 79:       ports {
 80:         port     = "8443"
 81:         protocol = "TCP"
 82:       }
 83:     }
 84: 
 85:     # Egress: Allow traffic to any pod in the same namespace on secure ports
 86:     egress {
 87:       # Allow to any pod in the same namespace
 88:       to {
 89:         pod_selector {}
 90:       }
 91:       ports {
 92:         port     = "443"
 93:         protocol = "TCP"
 94:       }
 95:     }
 96: 
 97:     egress {
 98:       to {
 99:         pod_selector {}
100:       }
101:       ports {
102:         port     = "636"
103:         protocol = "TCP"
104:       }
105:     }
106: 
107:     egress {
108:       to {
109:         pod_selector {}
110:       }
111:       ports {
112:         port     = "8443"
113:         protocol = "TCP"
114:       }
115:     }
116: 
117:     # Egress: Allow DNS resolution (required for service discovery)
118:     egress {
119:       to {
120:         namespace_selector {}
121:       }
122:       ports {
123:         port     = "53"
124:         protocol = "UDP"
125:       }
126:     }
127: 
128:     egress {
129:       to {
130:         namespace_selector {}
131:       }
132:       ports {
133:         port     = "53"
134:         protocol = "TCP"
135:       }
136:     }
137: 
138:     # Egress: Allow HTTPS for external API calls (2FA providers, etc.)
139:     egress {
140:       ports {
141:         port     = "443"
142:         protocol = "TCP"
143:       }
144:     }
145: 
146:     # Egress: Allow HTTP for external API calls if needed (though HTTPS is preferred)
147:     # Note: This is included for compatibility, but services should prefer HTTPS
148:     egress {
149:       ports {
150:         port     = "80"
151:         protocol = "TCP"
152:       }
153:     }
154:   }
155: }
156: 
157: # Note: We don't need a separate default deny policy because:
158: # 1. The namespace_secure_communication policy above applies to all pods
159: # 2. It only allows specific secure ports (443, 636, 8443)
160: # 3. All other ports are implicitly denied
161: # 4. This approach is simpler and avoids policy conflicts
````

## File: application/modules/openldap/README.md
````markdown
  1: # OpenLDAP Module
  2: 
  3: This module deploys OpenLDAP Stack HA using Helm, including phpLDAPadmin and
  4: ltb-passwd web interfaces, with ALB ingress. Route53 DNS records are created by
  5: the dedicated `route53_record` module (see [Route53 Record Module
  6: Documentation](../route53_record/README.md)).
  7: 
  8: ## Features
  9: 
 10: - **OpenLDAP Stack HA**: Deploys OpenLDAP Stack HA Helm chart with multi-master
 11: replication (3 replicas for high availability)
 12: - **PhpLdapAdmin**: Web-based LDAP administration interface accessible via ALB
 13: - **LTB-passwd**: Self-service password management UI accessible via ALB
 14: - **Internal LDAP Service**: ClusterIP service (not exposed externally) for
 15: secure cluster-internal access
 16: - **Persistent Storage**: EBS-backed persistent storage for LDAP data
 17: - **TLS Support**: TLS enabled with auto-generated self-signed certificates from
 18: the osixia/openldap image
 19: - **Network Policies**: Optionally applies network policies for secure inter-pod
 20: communication
 21: - **ECR Image Support**: Uses ECR images instead of Docker Hub
 22: (images mirrored via `mirror-images-to-ecr.sh`)
 23: 
 24: ## Usage
 25: 
 26: ```hcl
 27: module "openldap" {
 28:   source = "./modules/openldap"
 29: 
 30:   env    = var.env
 31:   region = var.region
 32:   prefix = var.prefix
 33: 
 34:   app_name              = local.app_name  # Computed in main.tf as prefix-region-app_name-env
 35:   openldap_ldap_domain  = var.openldap_ldap_domain
 36:   openldap_admin_password = var.openldap_admin_password
 37:   openldap_config_password = var.openldap_config_password
 38:   storage_class_name    = local.storage_class_name
 39: 
 40:   phpldapadmin_host = var.phpldapadmin_host
 41:   ltb_passwd_host   = var.ltb_passwd_host
 42: 
 43:   use_alb                = var.use_alb
 44:   ingress_class_name     = module.alb[0].ingress_class_name
 45:   alb_load_balancer_name = local.alb_load_balancer_name
 46:   alb_target_type        = var.alb_target_type
 47:   acm_cert_arn           = data.aws_acm_certificate.this.arn
 48: 
 49:   # ECR image configuration
 50:   ecr_registry       = local.ecr_registry
 51:   ecr_repository     = local.ecr_repository
 52:   openldap_image_tag = "openldap-1.5.0"  # Default, corresponds to osixia/openldap:1.5.0
 53: 
 54:   tags = local.tags
 55: 
 56:   depends_on = [
 57:     kubernetes_storage_class_v1.this,
 58:     module.alb,
 59:   ]
 60: }
 61: ```
 62: 
 63: ## Requirements
 64: 
 65: - Kubernetes cluster with Helm provider configured
 66: - ALB Ingress Controller installed (if using ALB)
 67: - ACM certificate
 68: - StorageClass for PVCs
 69: - ECR repository (for container images)
 70: 
 71: ## Inputs
 72: 
 73: | Name | Description | Type | Default | Required |
 74: | ------ | ------------- | ------ | --------- | :--------: |
 75: | env | Deployment environment | `string` | n/a | yes |
 76: | region | Deployment region | `string` | n/a | yes |
 77: | prefix | Name prefix for resources | `string` | n/a | yes |
 78: | app_name | Full application name (computed in parent module as prefix-region-app_name-env) | `string` | n/a | yes |
 79: | openldap_ldap_domain | OpenLDAP domain (e.g., ldap.talorlik.internal) | `string` | n/a | yes |
 80: | openldap_admin_password | OpenLDAP admin password | `string` | n/a | yes |
 81: | openldap_config_password | OpenLDAP config password | `string` | n/a | yes |
 82: | storage_class_name | Name of the Kubernetes StorageClass to use for OpenLDAP PVC | `string` | n/a | yes |
 83: | phpldapadmin_host | Hostname for phpLDAPadmin ingress | `string` | n/a | yes |
 84: | ltb_passwd_host | Hostname for ltb-passwd ingress | `string` | n/a | yes |
 85: | acm_cert_arn | ARN of the ACM certificate for HTTPS | `string` | n/a | yes |
 86: | alb_load_balancer_name | Custom name for the AWS ALB | `string` | n/a | yes |
 87: | ecr_registry | ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com) | `string` | n/a | yes |
 88: | ecr_repository | ECR repository name | `string` | n/a | yes |
 89: | openldap_image_tag | OpenLDAP image tag in ECR | `string` | `"openldap-1.5.0"` | no |
 90: | openldap_secret_name | Name of the Kubernetes secret for OpenLDAP passwords | `string` | `"openldap-secret"` | no |
 91: | namespace | Kubernetes namespace for OpenLDAP | `string` | `"ldap"` | no |
 92: | use_alb | Whether to use ALB for ingress | `bool` | `true` | no |
 93: | ingress_class_name | Name of the IngressClass for ALB | `string` | `null` | no |
 94: | alb_target_type | ALB target type: ip or instance | `string` | `"ip"` | no |
 95: | helm_chart_version | OpenLDAP Helm chart version | `string` | `"4.0.1"` | no |
 96: | helm_chart_repository | Helm chart repository URL | `string` | `"https://jp-gouin.github.io/helm-openldap"` | no |
 97: | helm_chart_name | Helm chart name | `string` | `"openldap-stack-ha"` | no |
 98: | helm_release_name | Helm release name | `string` | `"openldap-stack-ha"` | no |
 99: | values_template_path | Path to the OpenLDAP values template file | `string` | `null` | no |
100: | enable_network_policies | Whether to enable network policies for the OpenLDAP namespace | `bool` | `true` | no |
101: | tags | Tags to apply to resources | `map(string)` | `{}` | no |
102: 
103: ## Outputs
104: 
105: | Name | Description |
106: | ------ | ------------- |
107: | namespace | Kubernetes namespace for OpenLDAP |
108: | secret_name | Name of the Kubernetes secret for OpenLDAP passwords |
109: | helm_release_name | Name of the Helm release |
110: | phpldapadmin_ingress_hostname | Hostname from phpLDAPadmin ingress (ALB DNS name) |
111: | ltb_passwd_ingress_hostname | Hostname from ltb-passwd ingress (ALB DNS name) |
112: | alb_dns_name | ALB DNS name (from either ingress) |
113: 
114: ## Dependencies
115: 
116: - `kubernetes_storage_class_v1` - StorageClass for PVCs
117: - `module.alb` - ALB module for ingress (if using ALB)
118: - `data.aws_acm_certificate` - ACM certificate
119: - ECR repository (for container images, created by `backend_infra`)
120: 
121: > [!NOTE]
122: >
123: > Route53 DNS records are created by the dedicated `route53_record` module in
124: > `application/main.tf`. See [Route53 Record Module
125: > Documentation](../route53_record/README.md) for details.
126: 
127: ## High Availability Configuration
128: 
129: The OpenLDAP Stack HA deployment includes:
130: 
131: - **Multi-Master Replication**: 3 replicas configured for high availability
132: - **StatefulSet**: Each replica has its own persistent volume for data durability
133: - **Automatic Failover**: If one replica fails, others continue serving requests
134: - **Data Consistency**: Multi-master replication ensures data consistency across
135: replicas
136: 
137: ## TLS Configuration
138: 
139: TLS is enabled for secure LDAP communication:
140: 
141: - **Certificate Source**: Auto-generated self-signed certificates by the
142: osixia/openldap image
143: - **Certificate Location**: Certificates are stored in `/container/service/slapd/assets/certs/`
144: within the container
145: - **Certificate Files**: `ldap.crt`, `ldap.key`, and `ca.crt` (auto-generated on
146: first startup if they don't exist)
147: - **LDAP Ports**:
148:   - Port 389: LDAP (unencrypted, for internal use)
149:   - Port 636: LDAPS (encrypted, preferred for secure communication)
150: - **TLS Enforcement**: Configurable via Helm values (`LDAP_TLS_ENFORCE`,
151: default: `false` to allow both LDAP and LDAPS)
152: 
153: ## Storage Configuration
154: 
155: - **StorageClass**: Uses the StorageClass created by the application infrastructure
156: - **Storage Size**: 8Gi per replica (configurable in Helm values)
157: - **Access Mode**: ReadWriteOnce (each replica has its own volume)
158: - **Volume Binding**: WaitForFirstConsumer (volume created when pod is scheduled)
159: 
160: ## ECR Image Configuration
161: 
162: This module uses ECR images instead of Docker Hub to eliminate Docker Hub rate
163: limiting and external dependencies. Images are automatically mirrored from Docker
164: Hub to ECR by the `mirror-images-to-ecr.sh` script before Terraform operations.
165: 
166: **Image Details:**
167: 
168: - **Source Image**: `osixia/openldap:1.5.0` (from Docker Hub)
169: - **ECR Tag**: `openldap-1.5.0` (default)
170: - **ECR Registry/Repository**: Computed from `backend_infra` Terraform state
171:   (`ecr_url`)
172: 
173: **Image Mirroring:**
174: 
175: The `mirror-images-to-ecr.sh` script automatically:
176: 
177: 1. Checks if the image exists in ECR (skips if already present)
178: 2. Pulls the image from Docker Hub
179: 3. Tags and pushes the image to ECR with the standardized tag
180: 4. Cleans up local images after pushing
181: 
182: **Configuration:**
183: 
184: The ECR registry and repository are automatically computed from the `backend_infra`
185: Terraform state in the parent module (`application/main.tf`). You only need to
186: specify the `openldap_image_tag` if you want to use a different tag than the
187: default.
188: 
189: The Helm values template (`helm/openldap-values.tpl.yaml`) uses these ECR
190: variables to configure the image:
191: 
192: ```yaml
193: image:
194:   registry: "${ecr_registry}"
195:   repository: "${ecr_repository}"
196:   tag: "${openldap_image_tag}"
197:   pullPolicy: IfNotPresent
198: ```
199: 
200: For more information about image mirroring, see the [Application Infrastructure
201: README](../README.md#ecr-image-mirroring-automatic).
202: 
203: ## Internal LDAP Service
204: 
205: The LDAP service uses ClusterIP (not LoadBalancer or NodePort) to:
206: 
207: - Keep LDAP ports strictly internal to the cluster
208: - Prevent external access to LDAP
209: - Only allow access from pods within the cluster
210: - Follow security best practices for sensitive services
211: 
212: Services in other namespaces can access the LDAP service using:
213: 
214: - Service DNS: `openldap-stack-ha.ldap.svc.cluster.local`
215: - Port 636 (LDAPS) for encrypted communication
216: 
217: ## Notes
218: 
219: - The module uses ECR images (tag: `openldap-1.5.0`, corresponds to
220:   `osixia/openldap:1.5.0` from Docker Hub) instead of Docker Hub directly
221: - TLS is enabled with auto-generated self-signed certificates from the
222:   osixia/openldap image (generated on first startup)
223: - Network policies are applied by default to secure inter-pod communication
224: - Route53 DNS records are created by the dedicated `route53_record` module (see
225:   [Route53 Record Module Documentation](../route53_record/README.md))
226: - Chart version: 4.0.1 from `https://jp-gouin.github.io/helm-openldap`
227: - Helm release name: `openldap-stack-ha` (configurable)
````

## File: application/modules/route53/main.tf
````hcl
 1: locals {
 2:   domain = var.domain_name
 3:   # Removing trailing dot from domain
 4:   domain_name = trimsuffix(local.domain, ".")
 5:   zone_id     = try(data.aws_route53_zone.this[0].zone_id, aws_route53_zone.this[0].zone_id)
 6: }
 7: 
 8: data "aws_route53_zone" "this" {
 9:   count = var.use_existing_route53_zone ? 1 : 0
10: 
11:   name         = local.domain_name
12:   private_zone = false
13: }
14: 
15: # Create Route53 hosted zone and ACM certificate
16: resource "aws_route53_zone" "this" {
17:   count = var.use_existing_route53_zone ? 0 : 1
18: 
19:   name = local.domain_name
20: 
21:   tags = {
22:     Name      = local.domain_name
23:     Env       = var.env
24:     Terraform = "true"
25:   }
26: }
27: 
28: module "acm" {
29:   source  = "terraform-aws-modules/acm/aws"
30:   version = "6.2.0"
31: 
32:   domain_name = local.domain_name
33:   zone_id     = local.zone_id
34: 
35:   subject_alternative_names = var.subject_alternative_names
36: 
37:   validation_method = "DNS"
38: 
39:   wait_for_validation = true
40:   validation_timeout  = "30m"
41: 
42:   tags = {
43:     Name      = local.domain_name
44:     Env       = var.env
45:     Terraform = "true"
46:   }
47: }
````

## File: application/modules/route53_record/providers.tf
````hcl
 1: terraform {
 2:   required_providers {
 3:     aws = {
 4:       source                = "hashicorp/aws"
 5:       version               = ">= 6.21.0"
 6:       configuration_aliases = [aws.state_account]
 7:     }
 8:   }
 9: }
10: 
11: # Provider alias for state account (inherited from parent module)
12: # This allows Route53 resources to be created in the state account
13: # when Route53 hosted zone is in a different account than deployment account
````

## File: application/modules/ses/main.tf
````hcl
  1: /**
  2:  * SES Module
  3:  *
  4:  * Configures AWS SES for sending verification emails in the LDAP 2FA application.
  5:  * Includes IAM role for IRSA to allow the backend pod to send emails.
  6:  */
  7: 
  8: locals {
  9:   role_name = "${var.prefix}-${var.region}-${var.iam_role_name}-${var.env}"
 10: }
 11: 
 12: # Get EKS cluster data for IRSA
 13: data "aws_eks_cluster" "cluster" {
 14:   name = var.cluster_name
 15: }
 16: 
 17: # OIDC provider for IRSA
 18: data "aws_iam_openid_connect_provider" "cluster" {
 19:   url = data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer
 20: }
 21: 
 22: # Verify sender email address (if not using domain verification)
 23: resource "aws_ses_email_identity" "sender" {
 24:   count = var.sender_domain == null ? 1 : 0
 25:   email = var.sender_email
 26: }
 27: 
 28: # Verify sender domain (if domain is provided)
 29: resource "aws_ses_domain_identity" "sender" {
 30:   count  = var.sender_domain != null ? 1 : 0
 31:   domain = var.sender_domain
 32: }
 33: 
 34: # Domain verification DNS record (if using domain verification and Route53)
 35: # Note: Provider is passed from parent module via providers block
 36: resource "aws_route53_record" "ses_verification" {
 37:   provider = aws.state_account
 38:   count    = var.sender_domain != null && var.route53_zone_id != null ? 1 : 0
 39:   zone_id  = var.route53_zone_id
 40:   name     = "_amazonses.${var.sender_domain}"
 41:   type     = "TXT"
 42:   ttl      = 600
 43:   records  = [aws_ses_domain_identity.sender[0].verification_token]
 44: }
 45: 
 46: # DKIM for domain (if using domain verification)
 47: resource "aws_ses_domain_dkim" "sender" {
 48:   count  = var.sender_domain != null ? 1 : 0
 49:   domain = aws_ses_domain_identity.sender[0].domain
 50: }
 51: 
 52: # DKIM DNS records (if using domain verification and Route53)
 53: # Note: Provider is passed from parent module via providers block
 54: resource "aws_route53_record" "ses_dkim" {
 55:   provider = aws.state_account
 56:   count    = var.sender_domain != null && var.route53_zone_id != null ? 3 : 0
 57:   zone_id  = var.route53_zone_id
 58:   name     = "${aws_ses_domain_dkim.sender[0].dkim_tokens[count.index]}._domainkey.${var.sender_domain}"
 59:   type     = "CNAME"
 60:   ttl      = 600
 61:   records  = ["${aws_ses_domain_dkim.sender[0].dkim_tokens[count.index]}.dkim.amazonses.com"]
 62: }
 63: 
 64: # IAM policy for SES send email
 65: resource "aws_iam_policy" "ses_send" {
 66:   name        = "${local.role_name}-policy"
 67:   description = "Allow sending emails via SES for LDAP 2FA verification"
 68: 
 69:   policy = jsonencode({
 70:     Version = "2012-10-17"
 71:     Statement = [
 72:       {
 73:         Effect = "Allow"
 74:         Action = [
 75:           "ses:SendEmail",
 76:           "ses:SendRawEmail",
 77:         ]
 78:         Resource = "*"
 79:         Condition = {
 80:           StringEquals = {
 81:             "ses:FromAddress" = var.sender_email
 82:           }
 83:         }
 84:       }
 85:     ]
 86:   })
 87: 
 88:   tags = var.tags
 89: }
 90: 
 91: # IAM role for IRSA
 92: resource "aws_iam_role" "ses_sender" {
 93:   name = local.role_name
 94: 
 95:   assume_role_policy = jsonencode({
 96:     Version = "2012-10-17"
 97:     Statement = [
 98:       {
 99:         Effect = "Allow"
100:         Principal = {
101:           Federated = data.aws_iam_openid_connect_provider.cluster.arn
102:         }
103:         Action = "sts:AssumeRoleWithWebIdentity"
104:         Condition = {
105:           StringEquals = {
106:             "${replace(data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer, "https://", "")}:sub" = "system:serviceaccount:${var.service_account_namespace}:${var.service_account_name}"
107:             "${replace(data.aws_eks_cluster.cluster.identity[0].oidc[0].issuer, "https://", "")}:aud" = "sts.amazonaws.com"
108:           }
109:         }
110:       }
111:     ]
112:   })
113: 
114:   tags = var.tags
115: }
116: 
117: # Attach policy to role
118: resource "aws_iam_role_policy_attachment" "ses_send" {
119:   role       = aws_iam_role.ses_sender.name
120:   policy_arn = aws_iam_policy.ses_send.arn
121: }
````

## File: application/modules/ses/providers.tf
````hcl
 1: terraform {
 2:   required_providers {
 3:     aws = {
 4:       source                = "hashicorp/aws"
 5:       version               = ">= 6.21.0"
 6:       configuration_aliases = [aws.state_account]
 7:     }
 8:   }
 9: }
10: 
11: # Provider alias for state account (inherited from parent module)
12: # This allows Route53 resources to be created in the state account
13: # when Route53 hosted zone is in a different account than deployment account
````

## File: application/modules/ses/README.md
````markdown
  1: # SES Module
  2: 
  3: Configures AWS SES for sending verification emails in the LDAP 2FA application.
  4: 
  5: ## Features
  6: 
  7: - Email identity verification (individual email or domain)
  8: - DKIM setup for domain verification
  9: - IAM role with IRSA for secure pod access
 10: - Optional Route53 integration for automatic DNS record creation
 11: 
 12: ## Usage
 13: 
 14: ### Individual Email Verification
 15: 
 16: ```hcl
 17: module "ses" {
 18:   source = "./modules/ses"
 19: 
 20:   env          = "dev"
 21:   region       = "us-east-1"
 22:   prefix       = "ldap2fa"
 23:   cluster_name = "my-eks-cluster"
 24: 
 25:   sender_email              = "noreply@example.com"
 26:   service_account_namespace = "ldap-2fa"
 27:   service_account_name      = "ldap-2fa-backend"
 28: }
 29: ```
 30: 
 31: ### Domain Verification (with Route53)
 32: 
 33: ```hcl
 34: module "ses" {
 35:   source = "./modules/ses"
 36: 
 37:   env          = "dev"
 38:   region       = "us-east-1"
 39:   prefix       = "ldap2fa"
 40:   cluster_name = "my-eks-cluster"
 41: 
 42:   sender_email    = "noreply@example.com"
 43:   sender_domain   = "example.com"
 44:   route53_zone_id = "Z1234567890ABC"
 45: 
 46:   service_account_namespace = "ldap-2fa"
 47:   service_account_name      = "ldap-2fa-backend"
 48: }
 49: ```
 50: 
 51: ## Inputs
 52: 
 53: | Name | Description | Type | Default | Required |
 54: | ------ | ------------- | ------ | --------- | :--------: |
 55: | env | Deployment environment | `string` | n/a | yes |
 56: | region | Deployment region | `string` | n/a | yes |
 57: | prefix | Name prefix for resources | `string` | n/a | yes |
 58: | cluster_name | EKS cluster name for IRSA | `string` | n/a | yes |
 59: | sender_email | Email address to send from | `string` | n/a | yes |
 60: | sender_domain | Domain to verify (optional) | `string` | `null` | no |
 61: | iam_role_name | IAM role name component | `string` | `"ses-sender"` | no |
 62: | service_account_namespace | K8s namespace | `string` | `"ldap-2fa"` | no |
 63: | service_account_name | K8s service account name | `string` | `"ldap-2fa-backend"` | no |
 64: | route53_zone_id | Route53 zone for DNS records | `string` | `null` | no |
 65: 
 66: ## Outputs
 67: 
 68: | Name | Description |
 69: | ------ | ------------- |
 70: | sender_email | Verified sender email |
 71: | sender_domain | Verified domain (if configured) |
 72: | iam_role_arn | IAM role ARN for IRSA |
 73: | iam_role_name | IAM role name |
 74: | email_identity_arn | SES identity ARN |
 75: | verification_status | Verification instructions |
 76: 
 77: ## IRSA Configuration
 78: 
 79: The IAM role is configured for IAM Roles for Service Accounts (IRSA). To use it:
 80: 
 81: 1. The module creates an IAM role with SES send permissions
 82: 2. Add the annotation to your Kubernetes service account:
 83: 
 84:     ```yaml
 85:     apiVersion: v1
 86:     kind: ServiceAccount
 87:     metadata:
 88:       name: ldap-2fa-backend
 89:       namespace: ldap-2fa
 90:       annotations:
 91:         eks.amazonaws.com/role-arn: <iam_role_arn from outputs>
 92:     ```
 93: 
 94: 3. The backend application will automatically assume this role when making
 95: AWS SDK calls to SES
 96: 
 97: ## Email Types
 98: 
 99: The SES module supports sending various email types for the 2FA application:
100: 
101: - **Verification Emails**: Token-based verification links for email verification
102:   - Contains UUID token in verification link
103:   - 24-hour token expiry (configurable)
104:   - Sent when user registers or requests resend
105: 
106: - **Welcome Emails**: Sent when admin approves user activation
107:   - Confirms user account is active
108:   - Provides login instructions
109: 
110: - **Admin Notification Emails**: Sent to all admins when new user signs up
111:   - Notifies admins of pending user approval
112:   - Includes user details for review
113: 
114: For detailed email templates and sending logic, see the application backend code
115: in `application/backend/src/app/email/client.py`.
116: 
117: ## Important Notes
118: 
119: 1. **SES Sandbox**: New SES accounts are in sandbox mode and can only send to
120: verified addresses. Request production access for unrestricted sending.
121: 
122: 2. **Email Verification**: If using individual email verification, check the
123: inbox for the verification link from AWS.
124: 
125: 3. **Domain Verification**: If using domain verification without Route53 integration,
126: manually add the DNS records shown in the AWS console.
127: 
128: 4. **Service Account**: The Kubernetes service account must have the annotation
129: `eks.amazonaws.com/role-arn` set to the IAM role ARN for IRSA to work.
130: 
131: 5. **VPC Endpoints**: For SMS 2FA, ensure SNS VPC endpoint is enabled in backend_infra.
132: SES does not require a VPC endpoint (uses internet gateway or NAT gateway).
133: 
134: 6. **Sending Limits**: SES has sending limits based on account reputation.
135: Monitor sending quotas and request limit increases if needed.
````

## File: application/modules/sns/README.md
````markdown
  1: # SNS Module for SMS-based 2FA Verification
  2: 
  3: This module creates AWS SNS resources for sending SMS verification codes as part
  4: of the 2FA application.
  5: 
  6: ## Features
  7: 
  8: - **SNS Topic**: Central topic for SMS notifications
  9: - **IAM Role (IRSA)**: Enables EKS pods to publish to SNS using service account
 10: - **Direct SMS Support**: Allows publishing SMS directly to phone numbers
 11: - **Subscription Management**: Supports subscribing/unsubscribing phone numbers
 12: 
 13: ## Architecture
 14: 
 15: ```text
 16:           
 17:   Backend Pod          SNS Topic         SMS Gateway    
 18:   (with IRSA)               (2FA Messages)                        
 19:           
 20:                                     
 21:          AssumeRoleWithWebIdentity   Direct Publish
 22:                                     
 23:      
 24:   IAM Role                  Phone Number    
 25:   (SNS Publisher)           (E.164 format)  
 26:      
 27: ```
 28: 
 29: ## Usage
 30: 
 31: ```hcl
 32: module "sns" {
 33:   source = "./modules/sns"
 34: 
 35:   env          = var.env
 36:   region       = var.region
 37:   prefix       = var.prefix
 38:   cluster_name = local.cluster_name
 39: 
 40:   sns_topic_name            = "2fa-sms"
 41:   sns_display_name          = "2FA Verification"
 42:   service_account_namespace = "2fa-app"
 43:   service_account_name      = "ldap-2fa-backend"
 44: 
 45:   tags = local.tags
 46: }
 47: ```
 48: 
 49: ## IRSA Configuration
 50: 
 51: The IAM role is configured for IAM Roles for Service Accounts (IRSA). To use it:
 52: 
 53: 1. Add the annotation to your Kubernetes service account:
 54: 
 55:     ```yaml
 56:     apiVersion: v1
 57:     kind: ServiceAccount
 58:     metadata:
 59:     name: ldap-2fa-backend
 60:     namespace: 2fa-app
 61:     annotations:
 62:         eks.amazonaws.com/role-arn: <iam_role_arn from outputs>
 63:     ```
 64: 
 65: 2. The backend application will automatically assume this role when making
 66:    AWS SDK calls.
 67: 
 68: ## SMS Sending Methods
 69: 
 70: ### 1. Direct SMS (Recommended for Verification Codes)
 71: 
 72: Send directly to a phone number without subscription:
 73: 
 74: ```python
 75: import boto3
 76: 
 77: sns = boto3.client('sns')
 78: sns.publish(
 79:     PhoneNumber='+1234567890',  # E.164 format
 80:     Message='Your verification code is: 123456',
 81:     MessageAttributes={
 82:         'AWS.SNS.SMS.SMSType': {
 83:             'DataType': 'String',
 84:             'StringValue': 'Transactional'
 85:         }
 86:     }
 87: )
 88: ```
 89: 
 90: ### 2. Topic-based SMS (For Notifications)
 91: 
 92: Subscribe phone numbers to the topic:
 93: 
 94: ```python
 95: # Subscribe
 96: sns.subscribe(
 97:     TopicArn='arn:aws:sns:region:account:topic',
 98:     Protocol='sms',
 99:     Endpoint='+1234567890'
100: )
101: 
102: # Publish to topic (all subscribers receive)
103: sns.publish(
104:     TopicArn='arn:aws:sns:region:account:topic',
105:     Message='Notification message'
106: )
107: ```
108: 
109: ## Phone Number Format
110: 
111: All phone numbers must be in E.164 format:
112: 
113: - Start with `+`
114: - Country code
115: - No spaces, dashes, or parentheses
116: - Examples: `+14155552671`, `+442071234567`
117: 
118: ## SMS Types
119: 
120: - **Transactional**: Higher delivery priority, used for verification codes
121: - **Promotional**: Lower cost, used for marketing (may be filtered)
122: 
123: ## Outputs
124: 
125: | Output | Description |
126: | -------- | ------------- |
127: | `sns_topic_arn` | ARN of the SNS topic |
128: | `sns_topic_name` | Name of the SNS topic |
129: | `iam_role_arn` | ARN of the IAM role for IRSA |
130: | `iam_role_name` | Name of the IAM role |
131: | `service_account_annotation` | Annotation map for Kubernetes service account |
132: 
133: ## Cost Considerations
134: 
135: - SMS pricing varies by destination country
136: - Set `sms_monthly_spend_limit` to control costs
137: - Transactional SMS costs slightly more than Promotional
138: - Consider implementing rate limiting in the application
139: 
140: ## Security Considerations
141: 
142: - IAM role is scoped to specific service account via IRSA
143: - Phone numbers should be validated before sending
144: - Implement rate limiting to prevent abuse
145: - Consider opt-out compliance for your region
````

## File: application/PRD-ADMIN-FUNCS.md
````markdown
  1: # PRD: Admin Functions and User Profile Management
  2: 
  3: ## Overview
  4: 
  5: This document defines the requirements for admin functionality and user profile
  6: management features in the LDAP 2FA Authentication application.
  7: 
  8: ## Table of Contents
  9: 
 10: 1. [User Profile Management](#1-user-profile-management)
 11: 2. [SMS OTP Verification Requirements](#2-sms-otp-verification-requirements)
 12: 3. [Admin Dashboard](#3-admin-dashboard)
 13: 4. [Group Management](#4-group-management)
 14: 5. [User-Group Assignment](#5-user-group-assignment)
 15: 6. [Approve/Revoke Workflow](#6-approverevoke-workflow)
 16: 7. [List Features](#7-list-features)
 17: 8. [Admin Notifications](#8-admin-notifications)
 18: 9. [Top Navigation Bar](#9-top-navigation-bar)
 19: 
 20: ## 1. User Profile Management
 21: 
 22: ### 1.1 Profile Page
 23: 
 24: Users must be able to view and edit their profile details through a dedicated
 25: profile page.
 26: 
 27: **Viewable Fields:**
 28: 
 29: - Username (read-only)
 30: - First Name
 31: - Last Name
 32: - Email Address
 33: - Phone Number (with country code)
 34: - MFA Method
 35: - Account Status
 36: - Account Creation Date
 37: 
 38: **Editable Fields:**
 39: 
 40: | Field | Editable | Condition |
 41: | ------- | ---------- | ----------- |
 42: | Username | No | Never editable |
 43: | First Name | Yes | Always |
 44: | Last Name | Yes | Always |
 45: | Email | Yes | Only before email is verified |
 46: | Phone Number | Yes | Only before phone is verified |
 47: | MFA Method | No | Must re-enroll to change |
 48: 
 49: ### 1.2 Edit Restrictions
 50: 
 51: - **Email Address**: Can only be modified if `email_verified = false`. Once verified,
 52: email becomes read-only to prevent account takeover.
 53: - **Phone Number**: Can only be modified if `phone_verified = false`. Once verified,
 54: phone becomes read-only.
 55: - Changing email or phone resets the respective verification status and triggers
 56: a new verification flow.
 57: 
 58: ## 2. SMS OTP Verification Requirements
 59: 
 60: ### 2.1 Phone Verification Requirement
 61: 
 62: Users can only use SMS OTP as their MFA method if their phone number has been verified.
 63: 
 64: **Behavior:**
 65: 
 66: - If a user selects SMS as MFA method during signup, phone verification is mandatory
 67: - SMS OTP option is disabled/hidden for users with unverified phone numbers
 68: - Login attempts with SMS MFA and unverified phone display error:
 69: "Phone verification required for SMS authentication"
 70: 
 71: ### 2.2 Implementation Rules
 72: 
 73: - During MFA enrollment: SMS option only available if `phone_verified = true`
 74: - During login: If `mfa_method = 'sms'` and `phone_verified = false`,
 75: reject with appropriate error
 76: - UI should grey out or hide SMS option for unverified users
 77: 
 78: ## 3. Admin Dashboard
 79: 
 80: ### 3.1 Access Control
 81: 
 82: The Admin tab/section is only visible and accessible to users who are members of
 83: the LDAP admin group.
 84: 
 85: **Visibility Rules:**
 86: 
 87: - Admin tab hidden for non-admin users
 88: - Admin routes protected by admin authentication
 89: - Admin status determined by LDAP admin group membership
 90: 
 91: ### 3.2 Admin Dashboard Features
 92: 
 93: **User Management Section:**
 94: 
 95: - View all users in the system
 96: - See user details:
 97:   - Full name
 98:   - Username
 99:   - Email
100:   - Phone number
101:   - Account status (pending, complete, active, revoked)
102:   - Email verification status
103:   - Phone verification status
104:   - MFA method
105:   - Group memberships
106:   - Creation date
107:   - Activation date and activating admin (if applicable)
108: 
109: **Group Management Section:**
110: 
111: - View all groups
112: - Create new groups
113: - Edit existing groups
114: - Delete groups
115: - View group members
116: 
117: ## 4. Group Management
118: 
119: ### 4.1 Group CRUD Operations
120: 
121: Admins must have full CRUD (Create, Read, Update, Delete) capabilities for groups.
122: 
123: **Create Group:**
124: 
125: - Name (required, unique)
126: - Description (optional)
127: - Automatically creates corresponding LDAP group
128: 
129: **Read Groups:**
130: 
131: - List all groups with member counts
132: - View group details including all members
133: 
134: **Update Group:**
135: 
136: - Modify group name
137: - Modify group description
138: - Changes sync to LDAP
139: 
140: **Delete Group:**
141: 
142: - Remove group from system
143: - Remove all user associations
144: - Delete corresponding LDAP group
145: - Confirmation required before deletion
146: 
147: ### 4.2 Group Data Model
148: 
149: ```text
150: Group:
151:   - id: UUID (primary key)
152:   - name: string (unique)
153:   - description: string
154:   - ldap_dn: string (LDAP distinguished name)
155:   - created_at: timestamp
156:   - updated_at: timestamp
157: ```
158: 
159: ## 5. User-Group Assignment
160: 
161: ### 5.1 Assignment Capabilities
162: 
163: Admins can manage user-group relationships with the following operations:
164: 
165: **Assign to Group(s):**
166: 
167: - Add user to one or more groups
168: - User can belong to multiple groups simultaneously
169: - Updates both database and LDAP group membership
170: 
171: **Remove from Group:**
172: 
173: - Remove user from a specific group
174: - User remains in other assigned groups
175: 
176: **Replace Groups:**
177: 
178: - Replace all user's group memberships with a new set
179: - Useful for role changes
180: 
181: ### 5.2 User-Group Data Model
182: 
183: ```text
184: UserGroup:
185:   - user_id: UUID (foreign key to users)
186:   - group_id: UUID (foreign key to groups)
187:   - assigned_at: timestamp
188:   - assigned_by: string (admin username)
189: ```
190: 
191: ## 6. Approve/Revoke Workflow
192: 
193: ### 6.1 User Approval (Activate)
194: 
195: When an admin approves a user:
196: 
197: 1. Admin selects user from "Awaiting Approval" list (status = 'complete')
198: 2. Admin clicks "Approve" button
199: 3. Modal appears with group selection (multi-select)
200: 4. Admin selects one or more groups to assign
201: 5. On confirmation:
202:    - User is created in LDAP
203:    - User is added to selected LDAP groups
204:    - User status changes to 'active'
205:    - Welcome email is sent to user
206:    - Activation timestamp and admin recorded
207: 
208: **Note:** Group assignment is required for approval - at least one group must
209: be selected.
210: 
211: ### 6.2 User Revocation
212: 
213: When an admin revokes an active user:
214: 
215: 1. Admin selects active user
216: 2. Admin clicks "Revoke" button
217: 3. Confirmation dialog appears
218: 4. On confirmation:
219:    - User is removed from all LDAP groups
220:    - User is deleted from LDAP
221:    - User status changes to 'revoked' OR user is deleted from database
222:    - Revocation is logged for audit
223: 
224: ## 7. List Features
225: 
226: ### 7.1 Requirements
227: 
228: All displayable lists (users, groups) must support:
229: 
230: **Sorting:**
231: 
232: - Click column header to sort ascending/descending
233: - Visual indicator for current sort column and direction
234: - Sortable columns for users: Name, Username, Email, Status, Created Date
235: - Sortable columns for groups: Name, Member Count, Created Date
236: 
237: **Filtering:**
238: 
239: - Users: Filter by status (pending, complete, active, revoked)
240: - Users: Filter by group membership
241: - Groups: Filter by member count range
242: 
243: **Searching:**
244: 
245: - Real-time search as user types
246: - Users: Search by username, email, first name, last name
247: - Groups: Search by name, description
248: 
249: ### 7.2 UI Components
250: 
251: - Search input field with icon
252: - Filter dropdowns/buttons
253: - Sortable column headers with sort indicators
254: - Pagination for large lists (optional, based on data volume)
255: 
256: ## 8. Admin Notifications
257: 
258: ### 8.1 New User Signup Notification
259: 
260: When a new user signs up, all admin users receive an email notification.
261: 
262: **Trigger:** Successful user signup (after user record created)
263: 
264: **Recipients:** All users in the LDAP admin group (fetched via `mail` attribute)
265: 
266: **Email Content:**
267: 
268: - Subject: "New User Signup - [Username]"
269: - Body includes:
270:   - New user's username
271:   - Full name
272:   - Email address
273:   - Phone number
274:   - Signup timestamp
275:   - Direct link to admin dashboard for review
276: 
277: **Implementation:**
278: 
279: - Use existing AWS SES email infrastructure
280: - Query LDAP admin group for member emails
281: - Send notification asynchronously (don't block signup response)
282: 
283: ## 9. Top Navigation Bar
284: 
285: ### 9.1 Requirements
286: 
287: After successful login, the UI must display a persistent top navigation bar.
288: 
289: **Components:**
290: 
291: - Application logo/name (left side)
292: - User information (right side):
293:   - Display name or username
294:   - Dropdown menu
295: 
296: ### 9.2 User Menu Items
297: 
298: **For Regular Users:**
299: 
300: - Profile - Navigate to profile page
301: - Logout - End session and return to login
302: 
303: **For Admin Users:**
304: 
305: - Profile - Navigate to profile page
306: - Admin Dashboard - Navigate to admin section
307: - User Management - Navigate to user list
308: - Group Management - Navigate to group list
309: - Logout - End session and return to login
310: 
311: ### 9.3 Visual Design
312: 
313: - Fixed position at top of viewport
314: - Consistent across all authenticated pages
315: - Dropdown menu appears on click/hover
316: - Visual distinction for admin menu items
317: 
318: ## Technical Requirements
319: 
320: ### Authentication
321: 
322: - JWT-based session management
323: - Token includes user ID, username, is_admin flag
324: - Token expiry with refresh mechanism
325: - All authenticated endpoints validate JWT
326: 
327: ### API Endpoints
328: 
329: **Profile:**
330: 
331: - `GET /api/profile/{username}` - Get profile (authenticated)
332: - `PUT /api/profile/{username}` - Update profile (authenticated, owner only)
333: 
334: **Admin - Groups:**
335: 
336: - `GET /api/admin/groups` - List groups
337: - `POST /api/admin/groups` - Create group
338: - `GET /api/admin/groups/{id}` - Get group details
339: - `PUT /api/admin/groups/{id}` - Update group
340: - `DELETE /api/admin/groups/{id}` - Delete group
341: 
342: **Admin - User Groups:**
343: 
344: - `GET /api/admin/users/{id}/groups` - Get user's groups
345: - `POST /api/admin/users/{id}/groups` - Assign groups
346: - `PUT /api/admin/users/{id}/groups` - Replace groups
347: - `DELETE /api/admin/users/{id}/groups/{group_id}` - Remove from group
348: 
349: **Admin - User Management:**
350: 
351: - `GET /api/admin/users` - List users (with sorting, filtering, search)
352: - `POST /api/admin/users/{id}/revoke` - Revoke user
353: 
354: ### Security Considerations
355: 
356: - All admin endpoints require admin authentication
357: - Profile edits require owner authentication
358: - Email/phone changes only allowed before verification
359: - Rate limiting on admin operations
360: - Audit logging for admin actions
361: 
362: ## Success Criteria
363: 
364: 1. Users can view and edit their profile with appropriate restrictions
365: 2. SMS OTP only available for users with verified phone numbers
366: 3. Admin tab only visible to admin users
367: 4. Admins can perform full CRUD on groups
368: 5. Admins can assign/remove users from groups
369: 6. Approval workflow requires group assignment
370: 7. Revoke removes user from LDAP and groups
371: 8. All lists support sorting, filtering, and searching
372: 9. Admins receive email when new users sign up
373: 10. Top bar displays logged-in user with functional menu
````

## File: backend_infra/modules/ebs/outputs.tf
````hcl
1: output "ebs_pvc_name" {
2:   value = kubernetes_persistent_volume_claim_v1.ebs_pvc.metadata[0].name
3: }
4: 
5: output "ebs_storage_class_name" {
6:   value = kubernetes_storage_class.ebs.metadata[0].name
7: }
````

## File: backend_infra/modules/ebs/README.md
````markdown
 1: # EBS Module
 2: 
 3: This module creates Kubernetes storage resources for EBS (Elastic Block Store)
 4: volumes in the EKS cluster.
 5: 
 6: ## Purpose
 7: 
 8: The EBS module provides persistent storage capabilities for Kubernetes workloads
 9: by creating:
10: 
11: - A **StorageClass** that defines how EBS volumes are provisioned
12: - A **PersistentVolumeClaim (PVC)** that can be used by pods to request storage
13: 
14: ## Key Features
15: 
16: ### EKS Auto Mode Integration
17: 
18: - **Built-in EBS CSI Driver**: EKS Auto Mode includes its own EBS CSI driver, so
19: no additional installation is required
20: - **Automatic IAM Permissions**: EKS Auto Mode handles IAM permissions
21: automatically - no need to attach `AmazonEBSCSIDriverPolicy` to the EKS Node IAM
22: Role
23: 
24: ### StorageClass Configuration
25: 
26: - **Default Storage Class**: The StorageClass is marked as the default class for
27: the cluster
28: - **Provisioner**: Uses `ebs.csi.eks.amazonaws.com` (EKS Auto Mode provisioner)
29: - **Reclaim Policy**: Set to `Delete` - volumes are automatically deleted when
30: the PVC is deleted
31: - **Volume Binding Mode**: `WaitForFirstConsumer` - delays volume creation until
32: a pod actually needs it
33: - **Volume Type**: `gp3` (General Purpose SSD)
34: - **Encryption**: Enabled by default for security
35: 
36: ### PersistentVolumeClaim
37: 
38: - **Access Mode**: `ReadWriteOnce` - allows a single node to mount the volume as
39: read-write
40: - **Storage Size**: Defaults to `1Gi` (configurable via module variables)
41: - **Wait Until Bound**: Set to `false` to prevent Terraform from hanging - the
42: PVC will bind when a pod requires it
43: 
44: ## Important Notes
45: 
46: - In EKS Auto Mode, even with `ReadWriteOnce`, only one pod can access the
47: volume at a time
48: - The PVC will remain in `Pending` state until a pod that uses it is created
49: - Storage is provisioned dynamically when needed, not at PVC creation time
50: 
51: ## Variables
52: 
53: - `env`: Deployment environment (e.g., prod, dev)
54: - `region`: AWS region
55: - `prefix`: Prefix added to all resource names
56: - `ebs_name`: Name for the EBS StorageClass
57: - `ebs_claim_name`: Name for the PersistentVolumeClaim
58: 
59: ## Usage Example
60: 
61: ```hcl
62: module "ebs" {
63:   source         = "./modules/ebs"
64:   env            = var.env
65:   region         = var.region
66:   prefix         = var.prefix
67:   ebs_name       = var.ebs_name
68:   ebs_claim_name = var.ebs_claim_name
69: 
70:   depends_on = [module.eks]
71: }
72: ```
73: 
74: ## References
75: 
76: - [AWS EKS Storage Class Parameters](https://docs.aws.amazon.com/eks/latest/userguide/create-storage-class.html)
77: - [Kubernetes Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
````

## File: backend_infra/modules/ecr/outputs.tf
````hcl
 1: output "ecr_name" {
 2:   value = aws_ecr_repository.ecr.name
 3: }
 4: 
 5: output "ecr_arn" {
 6:   value = aws_ecr_repository.ecr.arn
 7: }
 8: 
 9: output "ecr_url" {
10:   value = aws_ecr_repository.ecr.repository_url
11: }
12: 
13: output "ecr_registry" {
14:   description = "ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)"
15:   value       = split("/", aws_ecr_repository.ecr.repository_url)[0]
16: }
17: 
18: output "ecr_repository" {
19:   description = "ECR repository name (without registry prefix)"
20:   value       = split("/", aws_ecr_repository.ecr.repository_url)[1]
21: }
````

## File: backend_infra/modules/ecr/README.md
````markdown
  1: # ECR Module
  2: 
  3: This module creates an Amazon Elastic Container Registry (ECR) repository for
  4: storing Docker container images.
  5: 
  6: ## Purpose
  7: 
  8: The ECR module provides a private Docker registry where container images can be
  9: pushed, stored, and pulled for deployment to the EKS cluster.
 10: 
 11: ## Key Features
 12: 
 13: ### Repository Configuration
 14: 
 15: - **Image Tag Mutability**: Configurable to allow or prevent image tag
 16: overwrites
 17: - **Force Delete**: Enabled to allow repository deletion even when it contains
 18: images
 19: - **Lifecycle Policy**: Configurable policy for automatic image cleanup (e.g.,
 20: keeping only the last N images)
 21: 
 22: ### Resource Naming
 23: 
 24: Resources are named using the pattern: `${prefix}-${region}-${ecr_name}-${env}`
 25: 
 26: ## Important Configuration
 27: 
 28: ### Image Tag Mutability
 29: 
 30: - **MUTABLE**: Allows overwriting existing image tags (useful for development)
 31: - **IMMUTABLE**: Prevents tag overwrites (recommended for production)
 32: 
 33: ### Lifecycle Policy
 34: 
 35: The lifecycle policy is configured via the `policy` variable and should be a
 36: JSON-encoded string. This policy controls:
 37: 
 38: - How many images to retain
 39: - Which images to expire based on age or count
 40: - Image tag patterns to include/exclude
 41: 
 42: Example lifecycle policy structure:
 43: 
 44: ```json
 45: {
 46:   "rules": [
 47:     {
 48:       "rulePriority": 1,
 49:       "description": "Keep last 10 images",
 50:       "selection": {
 51:         "tagStatus": "any",
 52:         "countType": "imageCountMoreThan",
 53:         "countNumber": 10
 54:       },
 55:       "action": {
 56:         "type": "expire"
 57:       }
 58:     }
 59:   ]
 60: }
 61: ```
 62: 
 63: ## Variables
 64: 
 65: - `env`: Deployment environment (e.g., prod, dev)
 66: - `region`: AWS region
 67: - `prefix`: Prefix added to all resource names
 68: - `ecr_name`: Name for the ECR repository
 69: - `image_tag_mutability`: Either `MUTABLE` or `IMMUTABLE`
 70: - `policy`: JSON-encoded lifecycle policy string
 71: - `tags`: Map of tags to apply to resources
 72: 
 73: ## Outputs
 74: 
 75: - `ecr_name`: Name of the ECR repository
 76: - `ecr_arn`: ARN of the ECR repository
 77: - `ecr_url`: Full URL of the ECR repository (for docker push/pull commands)
 78: 
 79: ## Usage Example
 80: 
 81: ```hcl
 82: module "ecr" {
 83:   source               = "./modules/ecr"
 84:   env                  = var.env
 85:   region               = var.region
 86:   prefix               = var.prefix
 87:   ecr_name             = var.ecr_name
 88:   image_tag_mutability = var.image_tag_mutability
 89:   policy               = jsonencode(var.ecr_lifecycle_policy)
 90:   tags                 = local.tags
 91: }
 92: ```
 93: 
 94: ## Pushing Images
 95: 
 96: After the repository is created, authenticate Docker and push images:
 97: 
 98: ```bash
 99: aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <ecr_url>
100: docker tag <image>:<tag> <ecr_url>:<tag>
101: docker push <ecr_url>:<tag>
102: ```
103: 
104: ## References
105: 
106: - [Amazon ECR Documentation](https://docs.aws.amazon.com/ecr/)
107: - [ECR Lifecycle Policies](https://docs.aws.amazon.com/ecr/latest/userguide/lifecycle_policies.html)
````

## File: backend_infra/modules/endpoints/main.tf
````hcl
  1: # Create VPC endpoints (Private Links) for SSM Session Manager access to nodes
  2: # and for AWS services used by the 2FA application (SNS, STS)
  3: 
  4: resource "aws_security_group" "vpc_endpoint_sg" {
  5:   name        = "${var.prefix}-${var.region}-${var.endpoint_sg_name}-${var.env}"
  6:   description = "Security group for VPC endpoints"
  7:   vpc_id      = var.vpc_id
  8: 
  9:   tags = merge(var.tags, {
 10:     Name = "${var.prefix}-${var.region}-${var.endpoint_sg_name}-${var.env}"
 11:   })
 12: }
 13: 
 14: resource "aws_vpc_security_group_ingress_rule" "vpc_endpoint_sg_ingress" {
 15:   description                  = "Allow EKS Nodes to access VPC Endpoints"
 16:   from_port                    = 443
 17:   to_port                      = 443
 18:   ip_protocol                  = "tcp"
 19:   referenced_security_group_id = var.node_security_group_id
 20:   security_group_id            = aws_security_group.vpc_endpoint_sg.id
 21: }
 22: 
 23: # Allow ingress from VPC CIDR for pods that may not use node security group
 24: resource "aws_vpc_security_group_ingress_rule" "vpc_endpoint_sg_ingress_vpc" {
 25:   description       = "Allow VPC CIDR to access VPC Endpoints"
 26:   from_port         = 443
 27:   to_port           = 443
 28:   ip_protocol       = "tcp"
 29:   cidr_ipv4         = var.vpc_cidr
 30:   security_group_id = aws_security_group.vpc_endpoint_sg.id
 31: }
 32: 
 33: resource "aws_vpc_security_group_egress_rule" "vpc_endpoint_sg_egress" {
 34:   ip_protocol       = "-1"
 35:   cidr_ipv4         = "0.0.0.0/0"
 36:   security_group_id = aws_security_group.vpc_endpoint_sg.id
 37: }
 38: 
 39: # SSM Endpoints for Session Manager
 40: resource "aws_vpc_endpoint" "private_link_ssm" {
 41:   vpc_id              = var.vpc_id
 42:   service_name        = "com.amazonaws.${var.region}.ssm"
 43:   vpc_endpoint_type   = "Interface"
 44:   security_group_ids  = [aws_security_group.vpc_endpoint_sg.id]
 45:   subnet_ids          = var.private_subnets
 46:   private_dns_enabled = true
 47: 
 48:   tags = merge(var.tags, {
 49:     Name = "private-link-ssm"
 50:   })
 51: }
 52: 
 53: resource "aws_vpc_endpoint" "private_link_ssmmessages" {
 54:   vpc_id              = var.vpc_id
 55:   service_name        = "com.amazonaws.${var.region}.ssmmessages"
 56:   vpc_endpoint_type   = "Interface"
 57:   security_group_ids  = [aws_security_group.vpc_endpoint_sg.id]
 58:   subnet_ids          = var.private_subnets
 59:   private_dns_enabled = true
 60: 
 61:   tags = merge(var.tags, {
 62:     Name = "private-link-ssmmessages"
 63:   })
 64: }
 65: 
 66: resource "aws_vpc_endpoint" "private_link_ec2messages" {
 67:   vpc_id              = var.vpc_id
 68:   service_name        = "com.amazonaws.${var.region}.ec2messages"
 69:   vpc_endpoint_type   = "Interface"
 70:   security_group_ids  = [aws_security_group.vpc_endpoint_sg.id]
 71:   subnet_ids          = var.private_subnets
 72:   private_dns_enabled = true
 73: 
 74:   tags = merge(var.tags, {
 75:     Name = "private-link-ec2messages"
 76:   })
 77: }
 78: 
 79: # STS Endpoint - Required for IRSA (IAM Roles for Service Accounts)
 80: # Pods need to call STS to assume IAM roles via web identity
 81: resource "aws_vpc_endpoint" "private_link_sts" {
 82:   count = var.enable_sts_endpoint ? 1 : 0
 83: 
 84:   vpc_id              = var.vpc_id
 85:   service_name        = "com.amazonaws.${var.region}.sts"
 86:   vpc_endpoint_type   = "Interface"
 87:   security_group_ids  = [aws_security_group.vpc_endpoint_sg.id]
 88:   subnet_ids          = var.private_subnets
 89:   private_dns_enabled = true
 90: 
 91:   tags = merge(var.tags, {
 92:     Name = "private-link-sts"
 93:   })
 94: }
 95: 
 96: # SNS Endpoint - Required for SMS 2FA functionality
 97: # Pods need to call SNS to send SMS verification codes
 98: resource "aws_vpc_endpoint" "private_link_sns" {
 99:   count = var.enable_sns_endpoint ? 1 : 0
100: 
101:   vpc_id              = var.vpc_id
102:   service_name        = "com.amazonaws.${var.region}.sns"
103:   vpc_endpoint_type   = "Interface"
104:   security_group_ids  = [aws_security_group.vpc_endpoint_sg.id]
105:   subnet_ids          = var.private_subnets
106:   private_dns_enabled = true
107: 
108:   tags = merge(var.tags, {
109:     Name = "private-link-sns"
110:   })
111: }
````

## File: backend_infra/modules/endpoints/outputs.tf
````hcl
 1: output "vpc_endpoint_sg_id" {
 2:   description = "Security group ID for VPC endpoints"
 3:   value       = aws_security_group.vpc_endpoint_sg.id
 4: }
 5: 
 6: output "vpc_endpoint_ssm_id" {
 7:   description = "VPC endpoint ID for SSM"
 8:   value       = aws_vpc_endpoint.private_link_ssm.id
 9: }
10: 
11: output "vpc_endpoint_ssmmessages_id" {
12:   description = "VPC endpoint ID for SSM Messages"
13:   value       = aws_vpc_endpoint.private_link_ssmmessages.id
14: }
15: 
16: output "vpc_endpoint_ec2messages_id" {
17:   description = "VPC endpoint ID for EC2 Messages"
18:   value       = aws_vpc_endpoint.private_link_ec2messages.id
19: }
20: 
21: output "vpc_endpoint_sts_id" {
22:   description = "VPC endpoint ID for STS (IRSA)"
23:   value       = var.enable_sts_endpoint ? aws_vpc_endpoint.private_link_sts[0].id : null
24: }
25: 
26: output "vpc_endpoint_sns_id" {
27:   description = "VPC endpoint ID for SNS (SMS 2FA)"
28:   value       = var.enable_sns_endpoint ? aws_vpc_endpoint.private_link_sns[0].id : null
29: }
30: 
31: output "vpc_endpoint_ids" {
32:   description = "List of all VPC endpoint IDs"
33:   value = compact([
34:     aws_vpc_endpoint.private_link_ssm.id,
35:     aws_vpc_endpoint.private_link_ssmmessages.id,
36:     aws_vpc_endpoint.private_link_ec2messages.id,
37:     var.enable_sts_endpoint ? aws_vpc_endpoint.private_link_sts[0].id : null,
38:     var.enable_sns_endpoint ? aws_vpc_endpoint.private_link_sns[0].id : null,
39:   ])
40: }
````

## File: backend_infra/modules/endpoints/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Name added to all resources"
13:   type        = string
14: }
15: 
16: variable "endpoint_sg_name" {
17:   description = "The name of the endpoint security group"
18:   type        = string
19: }
20: 
21: variable "node_security_group_id" {
22:   description = "The ID of the node security group"
23:   type        = string
24: }
25: 
26: variable "vpc_id" {
27:   description = "The ID of the VPC"
28:   type        = string
29: }
30: 
31: variable "vpc_cidr" {
32:   description = "The CIDR block of the VPC (for security group rules)"
33:   type        = string
34: }
35: 
36: variable "private_subnets" {
37:   description = "The IDs of the private subnets"
38:   type        = list(string)
39: }
40: 
41: variable "enable_sts_endpoint" {
42:   description = "Whether to create STS VPC endpoint (required for IRSA)"
43:   type        = bool
44:   default     = true
45: }
46: 
47: variable "enable_sns_endpoint" {
48:   description = "Whether to create SNS VPC endpoint (required for SMS 2FA)"
49:   type        = bool
50:   default     = false
51: }
52: 
53: variable "tags" {
54:   description = "Tags to add to the resources"
55:   type        = map(string)
56: }
````

## File: backend_infra/destroy-backend.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: PLACEHOLDER_FILE="tfstate-backend-values-template.hcl"
 18: BACKEND_FILE="backend.hcl"
 19: VARIABLES_FILE="variables.tfvars"
 20: 
 21: 
 22: print_error() {
 23:     echo -e "${RED}ERROR:${NC} $1" >&2
 24: }
 25: 
 26: print_success() {
 27:     echo -e "${GREEN}SUCCESS:${NC} $1"
 28: }
 29: 
 30: print_info() {
 31:     echo -e "${YELLOW}INFO:${NC} $1"
 32: }
 33: 
 34: print_warning() {
 35:     echo -e "${YELLOW}WARNING:${NC} $1"
 36: }
 37: 
 38: 
 39: if ! command -v aws &> /dev/null; then
 40:     print_error "AWS CLI is not installed."
 41:     echo "Please install it from: https://aws.amazon.com/cli/"
 42:     exit 1
 43: fi
 44: 
 45: 
 46: if ! command -v terraform &> /dev/null; then
 47:     print_error "Terraform is not installed."
 48:     echo "Please install it from: https://www.terraform.io/downloads"
 49:     exit 1
 50: fi
 51: 
 52: 
 53: if ! command -v gh &> /dev/null; then
 54:     print_error "GitHub CLI (gh) is not installed."
 55:     echo "Please install it from: https://cli.github.com/"
 56:     exit 1
 57: fi
 58: 
 59: 
 60: if ! gh auth status &> /dev/null; then
 61:     print_error "Not authenticated with GitHub CLI."
 62:     echo "Please run: gh auth login"
 63:     exit 1
 64: fi
 65: 
 66: 
 67: if ! command -v jq &> /dev/null; then
 68:     print_error "jq is not installed."
 69:     echo "Please install it:"
 70:     echo "  macOS: brew install jq"
 71:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 72:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 73:     exit 1
 74: fi
 75: 
 76: 
 77: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 78: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 79: 
 80: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 81:     print_error "Could not determine repository information."
 82:     echo "Please ensure you're in a git repository and have proper permissions."
 83:     exit 1
 84: fi
 85: 
 86: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 87: 
 88: 
 89: get_repo_variable() {
 90:     local var_name=$1
 91:     local value
 92: 
 93:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 94: 
 95:     if [ -z "$value" ]; then
 96:         print_error "Repository variable '${var_name}' not found or not accessible."
 97:         return 1
 98:     fi
 99: 
100:     echo "$value"
101: }
102: 
103: 
104: get_aws_secret() {
105:     local secret_name=$1
106:     local secret_json
107:     local exit_code
108: 
109: 
110: 
111:     secret_json=$(aws secretsmanager get-secret-value \
112:         --secret-id "$secret_name" \
113:         --region "${AWS_REGION:-us-east-1}" \
114:         --query SecretString \
115:         --output text 2>&1)
116: 
117: 
118:     exit_code=$?
119: 
120: 
121:     if [ $exit_code -ne 0 ]; then
122:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
123:         print_error "Error: $secret_json"
124:         return 1
125:     fi
126: 
127: 
128:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
129:         print_error "Secret '${secret_name}' contains invalid JSON"
130:         return 1
131:     fi
132: 
133:     echo "$secret_json"
134: }
135: 
136: 
137: get_aws_plaintext_secret() {
138:     local secret_name=$1
139:     local secret_value
140:     local exit_code
141: 
142: 
143: 
144:     secret_value=$(aws secretsmanager get-secret-value \
145:         --secret-id "$secret_name" \
146:         --region "${AWS_REGION:-us-east-1}" \
147:         --query SecretString \
148:         --output text 2>&1)
149: 
150: 
151:     exit_code=$?
152: 
153: 
154:     if [ $exit_code -ne 0 ]; then
155:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
156:         print_error "Error: $secret_value"
157:         return 1
158:     fi
159: 
160: 
161:     if [ -z "$secret_value" ]; then
162:         print_error "Secret '${secret_name}' is empty"
163:         return 1
164:     fi
165: 
166:     echo "$secret_value"
167: }
168: 
169: 
170: get_secret_key_value() {
171:     local secret_json=$1
172:     local key_name=$2
173:     local value
174: 
175: 
176:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
177:         print_error "Invalid JSON provided to get_secret_key_value"
178:         return 1
179:     fi
180: 
181: 
182:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
183: 
184: 
185:     if [ $? -ne 0 ]; then
186:         print_error "Failed to parse JSON or extract key '${key_name}'"
187:         return 1
188:     fi
189: 
190: 
191:     if [ "$value" = "null" ] || [ -z "$value" ]; then
192:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
193:         return 1
194:     fi
195: 
196:     echo "$value"
197: }
198: 
199: 
200: echo ""
201: print_warning "=========================================="
202: print_warning "  DESTRUCTIVE OPERATION WARNING"
203: print_warning "=========================================="
204: print_warning "This script will DESTROY all infrastructure"
205: print_warning "in the selected region and environment."
206: print_warning ""
207: print_warning "This action CANNOT be undone!"
208: print_warning "=========================================="
209: echo ""
210: read -p "Are you sure you want to continue? (type 'yes' to confirm): " confirmation
211: 
212: if [ "$confirmation" != "yes" ]; then
213:     print_info "Operation cancelled."
214:     exit 0
215: fi
216: 
217: 
218: echo ""
219: print_info "Select AWS Region:"
220: echo "1) us-east-1: N. Virginia (default)"
221: echo "2) us-east-2: Ohio"
222: read -p "Enter choice [1-2] (default: 1): " region_choice
223: 
224: case ${region_choice:-1} in
225:     1)
226:         SELECTED_REGION="us-east-1: N. Virginia"
227:         ;;
228:     2)
229:         SELECTED_REGION="us-east-2: Ohio"
230:         ;;
231:     *)
232:         print_error "Invalid choice. Using default: us-east-1: N. Virginia"
233:         SELECTED_REGION="us-east-1: N. Virginia"
234:         ;;
235: esac
236: 
237: 
238: AWS_REGION="${SELECTED_REGION%%:*}"
239: print_success "Selected region: ${SELECTED_REGION} (${AWS_REGION})"
240: 
241: echo ""
242: print_info "Select Environment:"
243: echo "1) prod (default)"
244: echo "2) dev"
245: read -p "Enter choice [1-2] (default: 1): " env_choice
246: 
247: case ${env_choice:-1} in
248:     1)
249:         ENVIRONMENT="prod"
250:         ;;
251:     2)
252:         ENVIRONMENT="dev"
253:         ;;
254:     *)
255:         print_error "Invalid choice. Using default: prod"
256:         ENVIRONMENT="prod"
257:         ;;
258: esac
259: 
260: print_success "Selected environment: ${ENVIRONMENT}"
261: echo ""
262: 
263: # Final confirmation with environment details
264: print_warning "You are about to DESTROY infrastructure in:"
265: print_warning "  Region: ${AWS_REGION}"
266: print_warning "  Environment: ${ENVIRONMENT}"
267: echo ""
268: read -p "Type 'DESTROY' to confirm: " final_confirmation
269: 
270: if [ "$final_confirmation" != "DESTROY" ]; then
271:     print_info "Operation cancelled."
272:     exit 0
273: fi
274: 
275: 
276: 
277: print_info "Retrieving role ARNs from AWS Secrets Manager..."
278: SECRET_JSON=$(get_aws_secret "github-role" || echo "")
279: if [ -z "$SECRET_JSON" ]; then
280:     print_error "Failed to retrieve secret from AWS Secrets Manager"
281:     exit 1
282: fi
283: 
284: 
285: STATE_ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
286: if [ -z "$STATE_ROLE_ARN" ]; then
287:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
288:     exit 1
289: fi
290: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
291: 
292: 
293: if [ "$ENVIRONMENT" = "prod" ]; then
294:     DEPLOYMENT_ROLE_ARN_KEY="AWS_PRODUCTION_ACCOUNT_ROLE_ARN"
295: else
296:     DEPLOYMENT_ROLE_ARN_KEY="AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN"
297: fi
298: 
299: 
300: DEPLOYMENT_ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "$DEPLOYMENT_ROLE_ARN_KEY" || echo "")
301: if [ -z "$DEPLOYMENT_ROLE_ARN" ]; then
302:     print_error "Failed to retrieve ${DEPLOYMENT_ROLE_ARN_KEY} from secret"
303:     exit 1
304: fi
305: print_success "Retrieved ${DEPLOYMENT_ROLE_ARN_KEY}"
306: 
307: 
308: ROLE_ARN="$STATE_ROLE_ARN"
309: 
310: print_info "Assuming role: $ROLE_ARN"
311: print_info "Region: $AWS_REGION"
312: 
313: 
314: ROLE_SESSION_NAME="destroy-backend-$(date +%s)"
315: 
316: 
317: ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
318:     --role-arn "$ROLE_ARN" \
319:     --role-session-name "$ROLE_SESSION_NAME" \
320:     --region "$AWS_REGION" 2>&1)
321: 
322: if [ $? -ne 0 ]; then
323:     print_error "Failed to assume role: $ASSUME_ROLE_OUTPUT"
324:     exit 1
325: fi
326: 
327: 
328: 
329: if command -v jq &> /dev/null; then
330:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
331:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
332:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
333: else
334: 
335:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
336:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
337:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
338: fi
339: 
340: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
341:     print_error "Failed to extract credentials from assume-role output."
342:     print_error "Output was: $ASSUME_ROLE_OUTPUT"
343:     exit 1
344: fi
345: 
346: print_success "Successfully assumed role"
347: 
348: 
349: CALLER_ARN=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
350: if [ $? -ne 0 ]; then
351:     print_error "Failed to verify assumed role credentials: $CALLER_ARN"
352:     exit 1
353: fi
354: 
355: print_info "Assumed role identity: $CALLER_ARN"
356: echo ""
357: 
358: # Retrieve ExternalId from AWS Secrets Manager (plain text secret)
359: # Must be retrieved after assuming role to have AWS credentials
360: print_info "Retrieving ExternalId from AWS Secrets Manager..."
361: EXTERNAL_ID=$(get_aws_plaintext_secret "external-id" || echo "")
362: if [ -z "$EXTERNAL_ID" ]; then
363:     print_error "Failed to retrieve 'external-id' secret from AWS Secrets Manager"
364:     exit 1
365: fi
366: print_success "Retrieved ExternalId"
367: 
368: 
369: print_info "Retrieving repository variables..."
370: 
371: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME") || exit 1
372: print_success "Retrieved BACKEND_BUCKET_NAME"
373: 
374: BACKEND_PREFIX=$(get_repo_variable "BACKEND_PREFIX") || exit 1
375: print_success "Retrieved BACKEND_PREFIX"
376: 
377: 
378: if [ -f "$BACKEND_FILE" ]; then
379:     print_info "${BACKEND_FILE} already exists. Skipping creation."
380: else
381: 
382:     if [ ! -f "$PLACEHOLDER_FILE" ]; then
383:         print_error "Placeholder file '${PLACEHOLDER_FILE}' not found."
384:         exit 1
385:     fi
386: 
387: 
388:     print_info "Creating ${BACKEND_FILE} from ${PLACEHOLDER_FILE} with retrieved values..."
389: 
390: 
391:     cp "$PLACEHOLDER_FILE" "$BACKEND_FILE"
392: 
393: 
394:     if [[ "$OSTYPE" == "darwin"* ]]; then
395: 
396:         sed -i '' "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
397:         sed -i '' "s|<BACKEND_PREFIX>|${BACKEND_PREFIX}|g" "$BACKEND_FILE"
398:         sed -i '' "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
399:     else
400:         # Linux sed
401:         sed -i "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
402:         sed -i "s|<BACKEND_PREFIX>|${BACKEND_PREFIX}|g" "$BACKEND_FILE"
403:         sed -i "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
404:     fi
405: 
406:     print_success "Created ${BACKEND_FILE}"
407: fi
408: 
409: # Update variables.tfvars
410: print_info "Updating ${VARIABLES_FILE} with selected values..."
411: 
412: if [ ! -f "$VARIABLES_FILE" ]; then
413:     print_error "Variables file '${VARIABLES_FILE}' not found."
414:     exit 1
415: fi
416: 
417: # Update variables.tfvars (works on macOS and Linux)
418: if [[ "$OSTYPE" == "darwin"* ]]; then
419:     # macOS sed requires -i '' for in-place editing
420:     sed -i '' "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT}\"|" "$VARIABLES_FILE"
421:     sed -i '' "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
422:     # Add or update deployment_account_role_arn
423:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
424:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
425:     else
426:         sed -i '' "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
427:     fi
428:     # Add or update deployment_account_external_id
429:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
430:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
431:     else
432:         sed -i '' "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
433:     fi
434: else
435: 
436:     sed -i "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT}\"|" "$VARIABLES_FILE"
437:     sed -i "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
438: 
439:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
440:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
441:     else
442:         sed -i "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
443:     fi
444: 
445:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
446:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
447:     else
448:         sed -i "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
449:     fi
450: fi
451: 
452: print_success "Updated ${VARIABLES_FILE}"
453: echo ""
454: print_success "Configuration files updated successfully!"
455: echo ""
456: print_info "Backend file: ${BACKEND_FILE}"
457: print_info "  - bucket: ${BUCKET_NAME}"
458: print_info "  - key: ${BACKEND_PREFIX}"
459: print_info "  - region: ${AWS_REGION}"
460: echo ""
461: print_info "Variables file: ${VARIABLES_FILE}"
462: print_info "  - env: ${ENVIRONMENT}"
463: print_info "  - region: ${AWS_REGION}"
464: echo ""
465: 
466: # Terraform workspace name
467: WORKSPACE_NAME="${AWS_REGION}-${ENVIRONMENT}"
468: 
469: # Terraform init
470: print_info "Running terraform init with backend configuration..."
471: terraform init -backend-config="${BACKEND_FILE}"
472: 
473: # Terraform workspace
474: print_info "Selecting or creating workspace: ${WORKSPACE_NAME}..."
475: terraform workspace select "${WORKSPACE_NAME}" || terraform workspace new "${WORKSPACE_NAME}"
476: 
477: # Terraform validate
478: print_info "Running terraform validate..."
479: terraform validate
480: 
481: # Terraform plan destroy
482: print_info "Running terraform plan destroy..."
483: terraform plan -var-file="${VARIABLES_FILE}" -destroy -out terraform.tfplan
484: 
485: # Terraform apply (destroy)
486: print_warning "Applying destroy plan. This will DESTROY all infrastructure..."
487: terraform apply -auto-approve terraform.tfplan
488: 
489: echo ""
490: print_success "Destroy operation completed successfully!"
491: print_info "All infrastructure in ${AWS_REGION} (${ENVIRONMENT}) has been destroyed."
````

## File: tf_backend_state/outputs.tf
````hcl
1: output "bucket_name" {
2:   value = aws_s3_bucket.terraform_state.bucket
3: }
````

## File: tf_backend_state/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Deployment environment"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Name added to all resources"
13:   type        = string
14: }
````

## File: .github/workflows/backend_build_push.yaml
````yaml
  1: name: Backend Build and Push
  2: 
  3: on:
  4: 
  5: 
  6: 
  7: 
  8: 
  9: 
 10:   workflow_dispatch:
 11:     inputs:
 12:       environment:
 13:         description: 'Select Environment'
 14:         required: true
 15:         type: choice
 16:         default: prod
 17:         options:
 18:           - prod
 19:           - dev
 20: 
 21: env:
 22:   AWS_REGION: us-east-1
 23:   IMAGE_NAME: ldap-2fa-backend
 24: 
 25: jobs:
 26:   BuildAndPush:
 27:     runs-on: ubuntu-latest
 28:     permissions:
 29:       contents: write
 30:       id-token: write
 31:     outputs:
 32:       image_tag: ${{ steps.build.outputs.image_tag }}
 33: 
 34:     steps:
 35:       - name: Checkout the repo code
 36:         uses: actions/checkout@v4
 37:         with:
 38:           token: ${{ secrets.GITHUB_TOKEN }}
 39: 
 40:       - name: Configure AWS credentials
 41:         uses: aws-actions/configure-aws-credentials@v4
 42:         with:
 43:           role-to-assume: ${{ secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN }}
 44:           role-session-name: GitHubActions-BackendBuildPush
 45:           aws-region: ${{ env.AWS_REGION }}
 46: 
 47:       - name: Login to Amazon ECR
 48:         id: login-ecr
 49:         uses: aws-actions/amazon-ecr-login@v2
 50: 
 51:       - name: Get ECR Repository URL
 52:         id: ecr-info
 53:         run: |
 54: 
 55:           ECR_REPO_NAME="${{ vars.ECR_REPOSITORY_NAME }}"
 56:           if [ -z "$ECR_REPO_NAME" ]; then
 57:             ECR_REPO_NAME="${{ vars.PREFIX }}-${{ env.AWS_REGION }}-docker-images-${{ inputs.environment || 'prod' }}"
 58:           fi
 59:           ECR_REGISTRY="${{ steps.login-ecr.outputs.registry }}"
 60:           echo "ecr_registry=${ECR_REGISTRY}" >> $GITHUB_OUTPUT
 61:           echo "ecr_repo_name=${ECR_REPO_NAME}" >> $GITHUB_OUTPUT
 62:           echo "ecr_repo_url=${ECR_REGISTRY}/${ECR_REPO_NAME}" >> $GITHUB_OUTPUT
 63: 
 64:       - name: Build, tag, and push Docker image
 65:         id: build
 66:         working-directory: ./application/backend
 67:         run: |
 68: 
 69:           IMAGE_TAG="${{ env.IMAGE_NAME }}-${{ github.sha }}"
 70: 
 71: 
 72:           docker build -t ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG} .
 73: 
 74: 
 75:           docker push ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}
 76: 
 77:           echo "image_tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT
 78:           echo "full_image=${${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}}" >> $GITHUB_OUTPUT
 79: 
 80:           echo " Pushed image: ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}"
 81: 
 82:       - name: Update Helm values with new image
 83:         run: |
 84: 
 85:           VALUES_FILE="application/backend/helm/ldap-2fa-backend/values.yaml"
 86: 
 87: 
 88:           sed -i "s|^  repository:.*|  repository: \"${{ steps.ecr-info.outputs.ecr_repo_url }}\"|" ${VALUES_FILE}
 89: 
 90: 
 91:           sed -i "s|^  tag:.*|  tag: \"${{ steps.build.outputs.image_tag }}\"|" ${VALUES_FILE}
 92: 
 93:           echo " Updated ${VALUES_FILE} with new image:"
 94:           grep -A 3 "^image:" ${VALUES_FILE}
 95: 
 96:       - name: Commit and push changes
 97:         run: |
 98:           git config user.name "github-actions[bot]"
 99:           git config user.email "github-actions[bot]@users.noreply.github.com"
100: 
101: 
102:           if git diff --quiet; then
103:             echo "No changes to commit"
104:             exit 0
105:           fi
106: 
107:           git add application/backend/helm/ldap-2fa-backend/values.yaml
108:           git commit -m "chore(backend): update image tag to ${{ steps.build.outputs.image_tag }}
109: 
110:           Automated update by GitHub Actions workflow.
111:           Commit: ${{ github.sha }}
112:           "
113: 
114: 
115:           git push origin main
116: 
117:           echo " Changes committed and pushed"
118: 
119:   NotifyArgoCD:
120:     runs-on: ubuntu-latest
121:     permissions:
122:       contents: read
123:     needs: BuildAndPush
124:     if: success()
125:     steps:
126:       - name: Summary
127:         run: |
128:           echo "## Backend Build Summary" >> $GITHUB_STEP_SUMMARY
129:           echo "" >> $GITHUB_STEP_SUMMARY
130:           echo " **Image Tag:** ${{ needs.BuildAndPush.outputs.image_tag }}" >> $GITHUB_STEP_SUMMARY
131:           echo "" >> $GITHUB_STEP_SUMMARY
132:           echo "ArgoCD will automatically detect the changes and sync the deployment." >> $GITHUB_STEP_SUMMARY
````

## File: .github/workflows/frontend_build_push.yaml
````yaml
  1: name: Frontend Build and Push
  2: 
  3: on:
  4: 
  5: 
  6: 
  7: 
  8: 
  9: 
 10:   workflow_dispatch:
 11:     inputs:
 12:       environment:
 13:         description: 'Select Environment'
 14:         required: true
 15:         type: choice
 16:         default: prod
 17:         options:
 18:           - prod
 19:           - dev
 20: 
 21: env:
 22:   AWS_REGION: us-east-1
 23:   IMAGE_NAME: ldap-2fa-frontend
 24: 
 25: jobs:
 26:   BuildAndPush:
 27:     runs-on: ubuntu-latest
 28:     permissions:
 29:       contents: write
 30:       id-token: write
 31:     outputs:
 32:       image_tag: ${{ steps.build.outputs.image_tag }}
 33: 
 34:     steps:
 35:       - name: Checkout the repo code
 36:         uses: actions/checkout@v4
 37:         with:
 38:           token: ${{ secrets.GITHUB_TOKEN }}
 39: 
 40:       - name: Configure AWS credentials
 41:         uses: aws-actions/configure-aws-credentials@v4
 42:         with:
 43:           role-to-assume: ${{ secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN }}
 44:           role-session-name: GitHubActions-FrontendBuildPush
 45:           aws-region: ${{ env.AWS_REGION }}
 46: 
 47:       - name: Login to Amazon ECR
 48:         id: login-ecr
 49:         uses: aws-actions/amazon-ecr-login@v2
 50: 
 51:       - name: Get ECR Repository URL
 52:         id: ecr-info
 53:         run: |
 54: 
 55:           ECR_REPO_NAME="${{ vars.ECR_REPOSITORY_NAME }}"
 56:           if [ -z "$ECR_REPO_NAME" ]; then
 57:             ECR_REPO_NAME="${{ vars.PREFIX }}-${{ env.AWS_REGION }}-docker-images-${{ inputs.environment || 'prod' }}"
 58:           fi
 59:           ECR_REGISTRY="${{ steps.login-ecr.outputs.registry }}"
 60:           echo "ecr_registry=${ECR_REGISTRY}" >> $GITHUB_OUTPUT
 61:           echo "ecr_repo_name=${ECR_REPO_NAME}" >> $GITHUB_OUTPUT
 62:           echo "ecr_repo_url=${ECR_REGISTRY}/${ECR_REPO_NAME}" >> $GITHUB_OUTPUT
 63: 
 64:       - name: Build, tag, and push Docker image
 65:         id: build
 66:         working-directory: ./application/frontend
 67:         run: |
 68: 
 69:           IMAGE_TAG="${{ env.IMAGE_NAME }}-${{ github.sha }}"
 70: 
 71: 
 72:           docker build -t ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG} .
 73: 
 74: 
 75:           docker push ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}
 76: 
 77:           echo "image_tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT
 78:           echo "full_image=${${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}}" >> $GITHUB_OUTPUT
 79: 
 80:           echo " Pushed image: ${{ steps.ecr-info.outputs.ecr_repo_url }}:${IMAGE_TAG}"
 81: 
 82:       - name: Update Helm values with new image
 83:         run: |
 84: 
 85:           VALUES_FILE="application/frontend/helm/ldap-2fa-frontend/values.yaml"
 86: 
 87: 
 88:           sed -i "s|^  repository:.*|  repository: \"${{ steps.ecr-info.outputs.ecr_repo_url }}\"|" ${VALUES_FILE}
 89: 
 90: 
 91:           sed -i "s|^  tag:.*|  tag: \"${{ steps.build.outputs.image_tag }}\"|" ${VALUES_FILE}
 92: 
 93:           echo " Updated ${VALUES_FILE} with new image:"
 94:           grep -A 3 "^image:" ${VALUES_FILE}
 95: 
 96:       - name: Commit and push changes
 97:         run: |
 98:           git config user.name "github-actions[bot]"
 99:           git config user.email "github-actions[bot]@users.noreply.github.com"
100: 
101: 
102:           if git diff --quiet; then
103:             echo "No changes to commit"
104:             exit 0
105:           fi
106: 
107:           git add application/frontend/helm/ldap-2fa-frontend/values.yaml
108:           git commit -m "chore(frontend): update image tag to ${{ steps.build.outputs.image_tag }}
109: 
110:           Automated update by GitHub Actions workflow.
111:           Commit: ${{ github.sha }}
112:           "
113: 
114: 
115:           git push origin main
116: 
117:           echo " Changes committed and pushed"
118: 
119:   NotifyArgoCD:
120:     runs-on: ubuntu-latest
121:     needs: BuildAndPush
122:     if: success()
123:     permissions:
124:       contents: read
125:     steps:
126:       - name: Summary
127:         run: |
128:           echo "## Frontend Build Summary" >> $GITHUB_STEP_SUMMARY
129:           echo "" >> $GITHUB_STEP_SUMMARY
130:           echo " **Image Tag:** ${{ needs.BuildAndPush.outputs.image_tag }}" >> $GITHUB_STEP_SUMMARY
131:           echo "" >> $GITHUB_STEP_SUMMARY
132:           echo "ArgoCD will automatically detect the changes and sync the deployment." >> $GITHUB_STEP_SUMMARY
````

## File: application/backend/helm/ldap-2fa-backend/values.yaml
````yaml
  1: replicaCount: 2
  2: 
  3: 
  4: image:
  5: 
  6:   repository: ""
  7:   pullPolicy: IfNotPresent
  8:   # Image tag - should be set via CI/CD (defaults to Chart appVersion)
  9:   tag: ""
 10: 
 11: # Secrets for pulling images from private registry
 12: imagePullSecrets: []
 13: 
 14: # Override chart name
 15: nameOverride: ""
 16: fullnameOverride: ""
 17: 
 18: # Service account configuration
 19: serviceAccount:
 20:   create: true
 21:   automount: true
 22:   annotations: {}
 23:   name: ""
 24: 
 25: # Pod annotations and labels
 26: podAnnotations: {}
 27: podLabels: {}
 28: 
 29: # Pod security context
 30: podSecurityContext:
 31:   fsGroup: 1000
 32: 
 33: # Container security context
 34: securityContext:
 35:   capabilities:
 36:     drop:
 37:       - ALL
 38:   readOnlyRootFilesystem: false
 39:   runAsNonRoot: true
 40:   runAsUser: 1000
 41:   allowPrivilegeEscalation: false
 42: 
 43: # Service configuration
 44: service:
 45:   type: ClusterIP
 46:   port: 8000
 47: 
 48: # Ingress configuration for ALB
 49: ingress:
 50:   enabled: true
 51:   className: ""  # Will be set to IngressClass name
 52:   annotations:
 53:     # ALB-specific annotations
 54:     alb.ingress.kubernetes.io/load-balancer-name: ""
 55:     alb.ingress.kubernetes.io/target-type: "ip"
 56:     alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
 57:     alb.ingress.kubernetes.io/ssl-redirect: "443"
 58:     alb.ingress.kubernetes.io/ssl-policy: "ELBSecurityPolicy-TLS13-1-0-PQ-2025-09"
 59: 
 60:     alb.ingress.kubernetes.io/group.order: "10"
 61:   hosts:
 62:     - host: ""  # app.<domain> - set by ArgoCD/values override
 63:       paths:
 64:         - path: /api
 65:           pathType: Prefix
 66:   tls: []
 67: 
 68: # HTTPRoute (Gateway API) - not used
 69: httpRoute:
 70:   enabled: false
 71: 
 72: # Resource limits and requests
 73: resources:
 74:   limits:
 75:     cpu: 500m
 76:     memory: 256Mi
 77:   requests:
 78:     cpu: 100m
 79:     memory: 128Mi
 80: 
 81: # Liveness probe configuration
 82: livenessProbe:
 83:   httpGet:
 84:     path: /api/healthz
 85:     port: http
 86:   initialDelaySeconds: 10
 87:   periodSeconds: 30
 88:   timeoutSeconds: 5
 89:   failureThreshold: 3
 90: 
 91: # Readiness probe configuration
 92: readinessProbe:
 93:   httpGet:
 94:     path: /api/healthz
 95:     port: http
 96:   initialDelaySeconds: 5
 97:   periodSeconds: 10
 98:   timeoutSeconds: 5
 99:   failureThreshold: 3
100: 
101: # Autoscaling configuration
102: autoscaling:
103:   enabled: false
104:   minReplicas: 2
105:   maxReplicas: 10
106:   targetCPUUtilizationPercentage: 80
107:   targetMemoryUtilizationPercentage: 80
108: 
109: # Additional volumes
110: volumes: []
111: 
112: # Additional volume mounts
113: volumeMounts: []
114: 
115: # Node selector
116: nodeSelector: {}
117: 
118: # Tolerations
119: tolerations: []
120: 
121: # Affinity rules
122: affinity: {}
123: 
124: # =============================================================================
125: # Application-specific configuration
126: # =============================================================================
127: 
128: # LDAP configuration (non-sensitive values)
129: ldap:
130:   # LDAP server hostname (Kubernetes service DNS)
131:   host: "openldap-stack-ha.ldap.svc.cluster.local"
132: 
133:   port: 389
134: 
135:   useSsl: false
136: 
137:   baseDn: "dc=ldap,dc=talorlik,dc=internal"
138: 
139:   adminDn: "cn=admin,dc=ldap,dc=talorlik,dc=internal"
140: 
141:   userSearchBase: "ou=users"
142: 
143:   userSearchFilter: "(uid={0})"
144: 
145: 
146: mfa:
147: 
148:   issuer: "LDAP-2FA-App"
149: 
150:   digits: 6
151: 
152:   interval: 30
153: 
154:   algorithm: "SHA1"
155: 
156: 
157: app:
158: 
159:   name: "LDAP 2FA Backend API"
160: 
161:   debug: false
162: 
163:   logLevel: "INFO"
164: 
165:   corsOrigins: ""
166: 
167: # External secrets configuration
168: # Reference to existing Kubernetes secret for sensitive values
169: externalSecret:
170:   # Enable using external secret for LDAP admin password
171:   enabled: true
172:   # Name of the existing secret containing LDAP admin password
173:   secretName: "ldap-admin-secret"
174: 
175:   adminPasswordKey: "LDAP_ADMIN_PASSWORD"
176: 
177: 
178: 
179: 
180: 
181: database:
182: 
183: 
184:   url: "postgresql+asyncpg://ldap2fa:ldap2fa@postgresql.ldap-2fa.svc.cluster.local:5432/ldap2fa"
185: 
186:   externalSecret:
187:     enabled: true
188:     secretName: "postgresql-secret"
189:     passwordKey: "password"
190: 
191: 
192: 
193: 
194: 
195: email:
196: 
197:   enabled: true
198: 
199:   senderEmail: "noreply@example.com"
200: 
201:   verificationExpiryHours: 24
202: 
203:   appUrl: "https://app.example.com"
204: 
205: 
206: 
207: 
208: 
209: ldapAdmin:
210: 
211:   groupDn: "cn=admins,ou=groups,dc=ldap,dc=talorlik,dc=internal"
212: 
213:   usersGid: 500
214: 
215:   uidStart: 10000
216: 
217: 
218: 
219: 
220: 
221: sms:
222: 
223:   enabled: false
224: 
225:   awsRegion: "us-east-1"
226: 
227:   snsTopicArn: ""
228:   # SMS sender ID (max 11 alphanumeric chars, may not work in all countries)
229:   senderId: "2FA"
230: 
231:   smsType: "Transactional"
232: 
233:   codeLength: 6
234: 
235:   codeExpirySeconds: 300
236: 
237:   messageTemplate: "Your verification code is: {code}. It expires in 5 minutes."
238: 
239: 
240: serviceAccountIAM:
241: 
242: 
243:   roleArn: ""
244: 
245: # =============================================================================
246: # Redis Configuration (SMS OTP Storage)
247: # =============================================================================
248: 
249: redis:
250:   # Enable Redis for SMS OTP storage
251:   enabled: false
252:   # Redis service hostname
253:   host: "redis-master.redis.svc.cluster.local"
254: 
255:   port: 6379
256: 
257:   db: 0
258: 
259:   ssl: false
260: 
261:   keyPrefix: "sms_otp:"
262: 
263:   existingSecret:
264: 
265:     enabled: false
266: 
267:     name: "redis-secret"
268: 
269:     key: "redis-password"
````

## File: application/backend/src/app/api/routes.py
````python
   1: import hmac
   2: import logging
   3: import re
   4: import secrets
   5: import time
   6: import uuid
   7: from datetime import datetime, timedelta, timezone
   8: from enum import Enum
   9: from typing import Optional
  10: 
  11: import bcrypt
  12: import jwt
  13: from fastapi import APIRouter, Depends, Header, HTTPException, Query, status
  14: from pydantic import BaseModel, EmailStr, Field, field_validator
  15: from sqlalchemy import select, or_, func
  16: from sqlalchemy.ext.asyncio import AsyncSession
  17: from sqlalchemy.orm import selectinload
  18: 
  19: from app.config import get_settings
  20: from app.database import get_async_session, User, VerificationToken, ProfileStatus, Group, UserGroup
  21: from app.email import EmailClient
  22: from app.ldap import LDAPClient
  23: from app.mfa import TOTPManager
  24: from app.redis import get_otp_client, RedisOTPClient
  25: from app.redis.client import InMemoryOTPStorage
  26: 
  27: logger = logging.getLogger(__name__)
  28: 
  29: router = APIRouter(prefix="/api", tags=["authentication"])
  30: 
  31: 
  32: 
  33: 
  34: 
  35: 
  36: class MFAMethod(str, Enum):
  37: 
  38:     TOTP = "totp"
  39:     SMS = "sms"
  40: 
  41: 
  42: 
  43: 
  44: 
  45: 
  46: 
  47: 
  48: 
  49: 
  50: 
  51: class HealthResponse(BaseModel):
  52: 
  53:     status: str = Field(..., description="Health status")
  54:     service: str = Field(..., description="Service name")
  55:     sms_enabled: bool = Field(..., description="Whether SMS 2FA is enabled")
  56: 
  57: 
  58: class SignupRequest(BaseModel):
  59: 
  60:     username: str = Field(..., min_length=3, max_length=64, description="Username")
  61:     email: EmailStr = Field(..., description="Email address")
  62:     first_name: str = Field(..., min_length=1, max_length=100, description="First name")
  63:     last_name: str = Field(..., min_length=1, max_length=100, description="Last name")
  64:     phone_country_code: str = Field(..., description="Phone country code (e.g., +1)")
  65:     phone_number: str = Field(..., min_length=5, max_length=20, description="Phone number")
  66:     password: str = Field(..., min_length=8, description="Password")
  67:     mfa_method: MFAMethod = Field(default=MFAMethod.TOTP, description="MFA method")
  68: 
  69:     @field_validator("username")
  70:     @classmethod
  71:     def validate_username(cls, v):
  72: 
  73:         if not re.match(r"^[a-zA-Z][a-zA-Z0-9_-]*$", v):
  74:             raise ValueError("Username must start with a letter and contain only letters, numbers, underscores, and hyphens")
  75:         return v.lower()
  76: 
  77:     @field_validator("phone_country_code")
  78:     @classmethod
  79:     def validate_country_code(cls, v):
  80: 
  81:         if not re.match(r"^\+\d{1,4}$", v):
  82:             raise ValueError("Country code must be in format +X or +XX (e.g., +1, +44)")
  83:         return v
  84: 
  85:     @field_validator("phone_number")
  86:     @classmethod
  87:     def validate_phone_number(cls, v):
  88: 
  89: 
  90:         cleaned = re.sub(r"[\s-]", "", v)
  91:         if not re.match(r"^\d{5,15}$", cleaned):
  92:             raise ValueError("Phone number must contain 5-15 digits")
  93:         return cleaned
  94: 
  95: 
  96: class SignupResponse(BaseModel):
  97: 
  98:     success: bool = Field(..., description="Whether signup was successful")
  99:     message: str = Field(..., description="Response message")
 100:     user_id: Optional[str] = Field(None, description="User ID")
 101:     email_verification_sent: bool = Field(False, description="Whether email verification was sent")
 102:     phone_verification_sent: bool = Field(False, description="Whether phone verification was sent")
 103: 
 104: 
 105: class VerifyEmailRequest(BaseModel):
 106: 
 107:     token: str = Field(..., description="Email verification token")
 108:     username: str = Field(..., description="Username")
 109: 
 110: 
 111: class VerifyPhoneRequest(BaseModel):
 112: 
 113:     username: str = Field(..., description="Username")
 114:     code: str = Field(..., min_length=6, max_length=6, description="6-digit verification code")
 115: 
 116: 
 117: class VerificationResponse(BaseModel):
 118: 
 119:     success: bool = Field(..., description="Whether verification was successful")
 120:     message: str = Field(..., description="Response message")
 121:     profile_status: Optional[str] = Field(None, description="Updated profile status")
 122: 
 123: 
 124: class ResendVerificationRequest(BaseModel):
 125: 
 126:     username: str = Field(..., description="Username")
 127:     verification_type: str = Field(..., description="Type: 'email' or 'phone'")
 128: 
 129: 
 130: class ProfileStatusResponse(BaseModel):
 131: 
 132:     username: str = Field(..., description="Username")
 133:     email: str = Field(..., description="Masked email")
 134:     phone: str = Field(..., description="Masked phone")
 135:     status: str = Field(..., description="Profile status")
 136:     email_verified: bool = Field(..., description="Email verified")
 137:     phone_verified: bool = Field(..., description="Phone verified")
 138:     mfa_method: str = Field(..., description="MFA method")
 139:     created_at: str = Field(..., description="Account creation date")
 140: 
 141: 
 142: class EnrollRequest(BaseModel):
 143: 
 144:     username: str = Field(..., min_length=1, description="Username")
 145:     password: str = Field(..., min_length=1, description="Password")
 146:     mfa_method: MFAMethod = Field(default=MFAMethod.TOTP, description="MFA method")
 147:     phone_number: Optional[str] = Field(None, description="Phone for SMS")
 148: 
 149: 
 150: class EnrollResponse(BaseModel):
 151: 
 152:     success: bool = Field(..., description="Whether enrollment was successful")
 153:     message: str = Field(..., description="Response message")
 154:     mfa_method: MFAMethod = Field(..., description="Enrolled MFA method")
 155:     otpauth_uri: Optional[str] = Field(None, description="otpauth:// URI for QR code")
 156:     secret: Optional[str] = Field(None, description="TOTP secret for manual entry")
 157:     phone_number: Optional[str] = Field(None, description="Masked phone number")
 158: 
 159: 
 160: class LoginRequest(BaseModel):
 161: 
 162:     username: str = Field(..., min_length=1, description="Username")
 163:     password: str = Field(..., min_length=1, description="Password")
 164:     verification_code: str = Field(..., min_length=6, max_length=6, description="6-digit code")
 165: 
 166: 
 167: class LoginResponse(BaseModel):
 168: 
 169:     success: bool = Field(..., description="Whether login was successful")
 170:     message: str = Field(..., description="Response message")
 171:     is_admin: bool = Field(False, description="Whether user is admin")
 172:     token: Optional[str] = Field(None, description="JWT access token")
 173:     username: Optional[str] = Field(None, description="Logged in username")
 174: 
 175: 
 176: class SMSSendCodeRequest(BaseModel):
 177: 
 178:     username: str = Field(..., min_length=1, description="Username")
 179:     password: str = Field(..., min_length=1, description="Password")
 180: 
 181: 
 182: class SMSSendCodeResponse(BaseModel):
 183: 
 184:     success: bool = Field(..., description="Whether code was sent")
 185:     message: str = Field(..., description="Response message")
 186:     phone_number: Optional[str] = Field(None, description="Masked phone number")
 187:     expires_in_seconds: Optional[int] = Field(None, description="Seconds until expiry")
 188: 
 189: 
 190: class MFAMethodsResponse(BaseModel):
 191: 
 192:     methods: list[str] = Field(..., description="Available MFA methods")
 193:     sms_enabled: bool = Field(..., description="Whether SMS is enabled")
 194: 
 195: 
 196: class UserMFAStatusResponse(BaseModel):
 197: 
 198:     enrolled: bool = Field(..., description="Whether user is enrolled")
 199:     mfa_method: Optional[str] = Field(None, description="Enrolled MFA method")
 200:     phone_number: Optional[str] = Field(None, description="Masked phone")
 201: 
 202: 
 203: 
 204: class AdminUserListResponse(BaseModel):
 205: 
 206:     users: list[dict] = Field(..., description="List of users")
 207:     total: int = Field(..., description="Total count")
 208: 
 209: 
 210: class AdminActivateRequest(BaseModel):
 211: 
 212:     admin_username: str = Field(..., description="Admin username")
 213:     admin_password: str = Field(..., description="Admin password")
 214: 
 215: 
 216: class AdminActivateResponse(BaseModel):
 217: 
 218:     success: bool = Field(..., description="Whether activation was successful")
 219:     message: str = Field(..., description="Response message")
 220: 
 221: 
 222: 
 223: class ProfileResponse(BaseModel):
 224: 
 225:     id: str = Field(..., description="User ID")
 226:     username: str = Field(..., description="Username")
 227:     email: str = Field(..., description="Email address")
 228:     first_name: str = Field(..., description="First name")
 229:     last_name: str = Field(..., description="Last name")
 230:     phone_country_code: str = Field(..., description="Phone country code")
 231:     phone_number: str = Field(..., description="Phone number")
 232:     email_verified: bool = Field(..., description="Email verified")
 233:     phone_verified: bool = Field(..., description="Phone verified")
 234:     mfa_method: str = Field(..., description="MFA method")
 235:     status: str = Field(..., description="Profile status")
 236:     created_at: str = Field(..., description="Creation date")
 237:     groups: list[dict] = Field(default_factory=list, description="User's groups")
 238: 
 239: 
 240: class ProfileUpdateRequest(BaseModel):
 241: 
 242:     first_name: Optional[str] = Field(None, min_length=1, max_length=100)
 243:     last_name: Optional[str] = Field(None, min_length=1, max_length=100)
 244:     email: Optional[EmailStr] = Field(None)
 245:     phone_country_code: Optional[str] = Field(None)
 246:     phone_number: Optional[str] = Field(None)
 247: 
 248:     @field_validator("phone_country_code")
 249:     @classmethod
 250:     def validate_country_code(cls, v):
 251:         if v is not None and not re.match(r"^\+\d{1,4}$", v):
 252:             raise ValueError("Country code must be in format +X or +XX")
 253:         return v
 254: 
 255:     @field_validator("phone_number")
 256:     @classmethod
 257:     def validate_phone_number(cls, v):
 258:         if v is not None:
 259:             cleaned = re.sub(r"[\s-]", "", v)
 260:             if not re.match(r"^\d{5,15}$", cleaned):
 261:                 raise ValueError("Phone number must contain 5-15 digits")
 262:             return cleaned
 263:         return v
 264: 
 265: 
 266: 
 267: class GroupCreateRequest(BaseModel):
 268: 
 269:     name: str = Field(..., min_length=1, max_length=100, description="Group name")
 270:     description: Optional[str] = Field(None, max_length=500, description="Group description")
 271: 
 272: 
 273: class GroupUpdateRequest(BaseModel):
 274: 
 275:     name: Optional[str] = Field(None, min_length=1, max_length=100)
 276:     description: Optional[str] = Field(None, max_length=500)
 277: 
 278: 
 279: class GroupResponse(BaseModel):
 280: 
 281:     id: str = Field(..., description="Group ID")
 282:     name: str = Field(..., description="Group name")
 283:     description: Optional[str] = Field(None, description="Group description")
 284:     ldap_dn: str = Field(..., description="LDAP DN")
 285:     member_count: int = Field(..., description="Number of members")
 286:     created_at: str = Field(..., description="Creation date")
 287: 
 288: 
 289: class GroupListResponse(BaseModel):
 290: 
 291:     groups: list[GroupResponse] = Field(..., description="List of groups")
 292:     total: int = Field(..., description="Total count")
 293: 
 294: 
 295: class GroupDetailResponse(GroupResponse):
 296: 
 297:     members: list[dict] = Field(default_factory=list, description="Group members")
 298: 
 299: 
 300: 
 301: class UserGroupAssignRequest(BaseModel):
 302: 
 303:     group_ids: list[str] = Field(..., description="List of group IDs to assign")
 304: 
 305: 
 306: class UserGroupResponse(BaseModel):
 307: 
 308:     user_id: str = Field(..., description="User ID")
 309:     username: str = Field(..., description="Username")
 310:     groups: list[dict] = Field(..., description="Assigned groups")
 311: 
 312: 
 313: 
 314: class AdminUserListRequest(BaseModel):
 315: 
 316:     status_filter: Optional[str] = Field(None, description="Filter by status")
 317:     group_filter: Optional[str] = Field(None, description="Filter by group ID")
 318:     search: Optional[str] = Field(None, description="Search term")
 319:     sort_by: Optional[str] = Field("created_at", description="Sort field")
 320:     sort_order: Optional[str] = Field("desc", description="Sort order (asc/desc)")
 321: 
 322: 
 323: 
 324: 
 325: 
 326: 
 327: def _mask_phone_number(phone: str) -> str:
 328: 
 329:     if len(phone) > 4:
 330:         return "*" * (len(phone) - 4) + phone[-4:]
 331:     return phone
 332: 
 333: 
 334: def _mask_email(email: str) -> str:
 335: 
 336:     if "@" not in email:
 337:         return email
 338:     local, domain = email.split("@", 1)
 339:     if len(local) > 2:
 340:         masked = local[0] + "*" * (len(local) - 2) + local[-1]
 341:     else:
 342:         masked = "*" * len(local)
 343:     return f"{masked}@{domain}"
 344: 
 345: 
 346: def _hash_password(password: str) -> str:
 347:     """Hash password using bcrypt."""
 348:     return bcrypt.hashpw(password.encode(), bcrypt.gensalt()).decode()
 349: 
 350: 
 351: def _verify_password(password: str, hashed: str) -> bool:
 352:     """Verify password against hash."""
 353:     return bcrypt.checkpw(password.encode(), hashed.encode())
 354: 
 355: 
 356: def _get_sms_client():
 357:     """Get SMS client (lazy import)."""
 358:     from app.sms import SMSClient
 359:     return SMSClient()
 360: 
 361: 
 362: def _generate_verification_code(length: int = 6) -> str:
 363:     """Generate a numeric verification code."""
 364:     return "".join(secrets.choice("0123456789") for _ in range(length))
 365: 
 366: 
 367: async def _get_user_by_username(session: AsyncSession, username: str) -> Optional[User]:
 368: 
 369:     result = await session.execute(
 370:         select(User).where(User.username == username.lower())
 371:     )
 372:     return result.scalar_one_or_none()
 373: 
 374: 
 375: async def _get_user_by_email(session: AsyncSession, email: str) -> Optional[User]:
 376: 
 377:     result = await session.execute(
 378:         select(User).where(User.email == email.lower())
 379:     )
 380:     return result.scalar_one_or_none()
 381: 
 382: 
 383: async def _create_verification_token(
 384:     session: AsyncSession,
 385:     user_id: uuid.UUID,
 386:     token_type: str,
 387:     expiry_hours: int = 24,
 388: ) -> str:
 389: 
 390: 
 391:     result = await session.execute(
 392:         select(VerificationToken).where(
 393:             VerificationToken.user_id == user_id,
 394:             VerificationToken.token_type == token_type,
 395:             VerificationToken.used == False,
 396:         )
 397:     )
 398:     for old_token in result.scalars():
 399:         old_token.used = True
 400: 
 401: 
 402:     if token_type == "email":
 403:         token = str(uuid.uuid4())
 404:     else:
 405:         token = _generate_verification_code(6)
 406: 
 407:     verification_token = VerificationToken(
 408:         user_id=user_id,
 409:         token_type=token_type,
 410:         token=token,
 411:         expires_at=datetime.now(timezone.utc) + timedelta(hours=expiry_hours),
 412:     )
 413:     session.add(verification_token)
 414:     await session.flush()
 415: 
 416:     return token
 417: 
 418: 
 419: 
 420: 
 421: 
 422: 
 423: def _create_jwt_token(
 424:     user_id: str,
 425:     username: str,
 426:     is_admin: bool,
 427:     expires_delta: Optional[timedelta] = None,
 428: ) -> str:
 429: 
 430:     settings = get_settings()
 431:     if expires_delta is None:
 432:         expires_delta = timedelta(minutes=settings.jwt_expiry_minutes)
 433: 
 434:     expire = datetime.now(timezone.utc) + expires_delta
 435:     payload = {
 436:         "sub": user_id,
 437:         "username": username,
 438:         "is_admin": is_admin,
 439:         "exp": expire,
 440:         "iat": datetime.now(timezone.utc),
 441:     }
 442:     return jwt.encode(payload, settings.jwt_secret_key, algorithm=settings.jwt_algorithm)
 443: 
 444: 
 445: def _decode_jwt_token(token: str) -> dict:
 446: 
 447:     settings = get_settings()
 448:     try:
 449:         payload = jwt.decode(
 450:             token,
 451:             settings.jwt_secret_key,
 452:             algorithms=[settings.jwt_algorithm]
 453:         )
 454:         return payload
 455:     except jwt.ExpiredSignatureError:
 456:         raise HTTPException(
 457:             status_code=status.HTTP_401_UNAUTHORIZED,
 458:             detail="Token has expired",
 459:         )
 460:     except jwt.InvalidTokenError:
 461:         raise HTTPException(
 462:             status_code=status.HTTP_401_UNAUTHORIZED,
 463:             detail="Invalid token",
 464:         )
 465: 
 466: 
 467: async def _get_current_user(
 468:     authorization: Optional[str] = Header(None),
 469:     session: AsyncSession = Depends(get_async_session),
 470: ) -> dict:
 471: 
 472:     if not authorization or not authorization.startswith("Bearer "):
 473:         raise HTTPException(
 474:             status_code=status.HTTP_401_UNAUTHORIZED,
 475:             detail="Missing or invalid authorization header",
 476:         )
 477: 
 478:     token = authorization.split(" ")[1]
 479:     payload = _decode_jwt_token(token)
 480: 
 481:     user = await _get_user_by_username(session, payload["username"])
 482:     if not user:
 483:         raise HTTPException(
 484:             status_code=status.HTTP_401_UNAUTHORIZED,
 485:             detail="User not found",
 486:         )
 487: 
 488:     return {
 489:         "user": user,
 490:         "user_id": payload["sub"],
 491:         "username": payload["username"],
 492:         "is_admin": payload["is_admin"],
 493:     }
 494: 
 495: 
 496: async def _require_admin(
 497:     authorization: Optional[str] = Header(None),
 498:     session: AsyncSession = Depends(get_async_session),
 499: ) -> dict:
 500: 
 501:     current = await _get_current_user(authorization, session)
 502:     if not current["is_admin"]:
 503:         raise HTTPException(
 504:             status_code=status.HTTP_403_FORBIDDEN,
 505:             detail="Admin privileges required",
 506:         )
 507:     return current
 508: 
 509: 
 510: async def _send_admin_notification(user: User) -> None:
 511: 
 512:     try:
 513:         ldap_client = LDAPClient()
 514:         admin_emails = ldap_client.get_admin_emails()
 515: 
 516:         if not admin_emails:
 517:             logger.warning("No admin emails found for notification")
 518:             return
 519: 
 520:         email_client = EmailClient()
 521:         new_user_data = {
 522:             "username": user.username,
 523:             "full_name": user.full_name,
 524:             "email": user.email,
 525:             "phone": user.full_phone_number,
 526:             "signup_time": user.created_at.isoformat() if user.created_at else datetime.now(timezone.utc).isoformat(),
 527:         }
 528: 
 529:         success, msg = email_client.send_admin_notification_email(admin_emails, new_user_data)
 530:         if success:
 531:             logger.info(f"Admin notification sent for new user {user.username}")
 532:         else:
 533:             logger.error(f"Failed to send admin notification: {msg}")
 534:     except Exception as e:
 535:         logger.error(f"Error sending admin notification: {e}")
 536: 
 537: 
 538: # ============================================================================
 539: # Health Check
 540: # ============================================================================
 541: 
 542: @router.get("/healthz", response_model=HealthResponse)
 543: async def health_check() -> HealthResponse:
 544: 
 545:     settings = get_settings()
 546:     return HealthResponse(
 547:         status="healthy",
 548:         service=settings.app_name,
 549:         sms_enabled=settings.enable_sms_2fa,
 550:     )
 551: 
 552: 
 553: 
 554: 
 555: 
 556: 
 557: @router.post(
 558:     "/auth/signup",
 559:     response_model=SignupResponse,
 560:     responses={
 561:         400: {"description": "Validation error or user exists"},
 562:         500: {"description": "Internal server error"},
 563:     },
 564: )
 565: async def signup(
 566:     request: SignupRequest,
 567:     session: AsyncSession = Depends(get_async_session),
 568: ) -> SignupResponse:
 569: 
 570: 
 571: 
 572: 
 573: 
 574:     settings = get_settings()
 575: 
 576: 
 577:     if await _get_user_by_username(session, request.username):
 578:         raise HTTPException(
 579:             status_code=status.HTTP_400_BAD_REQUEST,
 580:             detail="Username already taken",
 581:         )
 582: 
 583: 
 584:     if await _get_user_by_email(session, request.email):
 585:         raise HTTPException(
 586:             status_code=status.HTTP_400_BAD_REQUEST,
 587:             detail="Email already registered",
 588:         )
 589: 
 590: 
 591:     if request.mfa_method == MFAMethod.SMS and not settings.enable_sms_2fa:
 592:         raise HTTPException(
 593:             status_code=status.HTTP_400_BAD_REQUEST,
 594:             detail="SMS 2FA is not enabled",
 595:         )
 596: 
 597: 
 598:     totp_secret = None
 599:     if request.mfa_method == MFAMethod.TOTP:
 600:         totp_manager = TOTPManager()
 601:         totp_secret = totp_manager.generate_secret()
 602: 
 603: 
 604:     user = User(
 605:         username=request.username.lower(),
 606:         email=request.email.lower(),
 607:         first_name=request.first_name,
 608:         last_name=request.last_name,
 609:         phone_country_code=request.phone_country_code,
 610:         phone_number=request.phone_number,
 611:         password_hash=_hash_password(request.password),
 612:         mfa_method=request.mfa_method.value,
 613:         totp_secret=totp_secret,
 614:         status=ProfileStatus.PENDING.value,
 615:     )
 616:     session.add(user)
 617:     await session.flush()
 618: 
 619:     email_sent = False
 620:     phone_sent = False
 621: 
 622: 
 623:     if settings.enable_email_verification:
 624:         try:
 625:             email_token = await _create_verification_token(
 626:                 session, user.id, "email",
 627:                 settings.email_verification_expiry_hours
 628:             )
 629:             email_client = EmailClient()
 630:             success, _ = email_client.send_verification_email(
 631:                 to_email=user.email,
 632:                 token=email_token,
 633:                 username=user.username,
 634:                 first_name=user.first_name,
 635:             )
 636:             email_sent = success
 637:         except Exception as e:
 638:             logger.error(f"Failed to send verification email: {e}")
 639: 
 640:     # Send phone verification
 641:     try:
 642:         phone_token = await _create_verification_token(
 643:             session, user.id, "phone",
 644:             expiry_hours=1,
 645:         )
 646:         sms_client = _get_sms_client()
 647:         full_phone = f"{user.phone_country_code}{user.phone_number}"
 648:         success, _, _ = sms_client.send_verification_code(full_phone, phone_token)
 649:         phone_sent = success
 650:     except Exception as e:
 651:         logger.error(f"Failed to send verification SMS: {e}")
 652: 
 653:     await session.commit()
 654: 
 655:     # Send admin notification asynchronously (don't block response)
 656:     await _send_admin_notification(user)
 657: 
 658:     logger.info(f"User {user.username} signed up successfully")
 659: 
 660:     return SignupResponse(
 661:         success=True,
 662:         message="Account created. Please verify your email and phone number.",
 663:         user_id=str(user.id),
 664:         email_verification_sent=email_sent,
 665:         phone_verification_sent=phone_sent,
 666:     )
 667: 
 668: 
 669: 
 670: 
 671: 
 672: 
 673: @router.post(
 674:     "/auth/verify-email",
 675:     response_model=VerificationResponse,
 676:     responses={
 677:         400: {"description": "Invalid or expired token"},
 678:         404: {"description": "User not found"},
 679:     },
 680: )
 681: async def verify_email(
 682:     request: VerifyEmailRequest,
 683:     session: AsyncSession = Depends(get_async_session),
 684: ) -> VerificationResponse:
 685: 
 686:     user = await _get_user_by_username(session, request.username)
 687:     if not user:
 688:         raise HTTPException(
 689:             status_code=status.HTTP_404_NOT_FOUND,
 690:             detail="User not found",
 691:         )
 692: 
 693:     if user.email_verified:
 694:         return VerificationResponse(
 695:             success=True,
 696:             message="Email already verified",
 697:             profile_status=user.status,
 698:         )
 699: 
 700: 
 701:     result = await session.execute(
 702:         select(VerificationToken).where(
 703:             VerificationToken.user_id == user.id,
 704:             VerificationToken.token_type == "email",
 705:             VerificationToken.token == request.token,
 706:             VerificationToken.used == False,
 707:         )
 708:     )
 709:     token = result.scalar_one_or_none()
 710: 
 711:     if not token:
 712:         raise HTTPException(
 713:             status_code=status.HTTP_400_BAD_REQUEST,
 714:             detail="Invalid verification token",
 715:         )
 716: 
 717:     if token.expires_at < datetime.now(timezone.utc):
 718:         raise HTTPException(
 719:             status_code=status.HTTP_400_BAD_REQUEST,
 720:             detail="Verification token has expired. Please request a new one.",
 721:         )
 722: 
 723: 
 724:     token.used = True
 725:     user.email_verified = True
 726:     user.update_status_if_complete()
 727: 
 728:     await session.commit()
 729: 
 730:     logger.info(f"User {user.username} verified email")
 731: 
 732:     return VerificationResponse(
 733:         success=True,
 734:         message="Email verified successfully",
 735:         profile_status=user.status,
 736:     )
 737: 
 738: 
 739: @router.post(
 740:     "/auth/verify-phone",
 741:     response_model=VerificationResponse,
 742:     responses={
 743:         400: {"description": "Invalid or expired code"},
 744:         404: {"description": "User not found"},
 745:     },
 746: )
 747: async def verify_phone(
 748:     request: VerifyPhoneRequest,
 749:     session: AsyncSession = Depends(get_async_session),
 750: ) -> VerificationResponse:
 751: 
 752:     user = await _get_user_by_username(session, request.username)
 753:     if not user:
 754:         raise HTTPException(
 755:             status_code=status.HTTP_404_NOT_FOUND,
 756:             detail="User not found",
 757:         )
 758: 
 759:     if user.phone_verified:
 760:         return VerificationResponse(
 761:             success=True,
 762:             message="Phone already verified",
 763:             profile_status=user.status,
 764:         )
 765: 
 766: 
 767:     result = await session.execute(
 768:         select(VerificationToken).where(
 769:             VerificationToken.user_id == user.id,
 770:             VerificationToken.token_type == "phone",
 771:             VerificationToken.used == False,
 772:         ).order_by(VerificationToken.created_at.desc())
 773:     )
 774:     token = result.scalar_one_or_none()
 775: 
 776:     if not token:
 777:         raise HTTPException(
 778:             status_code=status.HTTP_400_BAD_REQUEST,
 779:             detail="No verification code found. Please request a new one.",
 780:         )
 781: 
 782:     if token.expires_at < datetime.now(timezone.utc):
 783:         raise HTTPException(
 784:             status_code=status.HTTP_400_BAD_REQUEST,
 785:             detail="Verification code has expired. Please request a new one.",
 786:         )
 787: 
 788: 
 789:     if not hmac.compare_digest(request.code, token.token):
 790:         raise HTTPException(
 791:             status_code=status.HTTP_400_BAD_REQUEST,
 792:             detail="Invalid verification code",
 793:         )
 794: 
 795: 
 796:     token.used = True
 797:     user.phone_verified = True
 798:     user.update_status_if_complete()
 799: 
 800:     await session.commit()
 801: 
 802:     logger.info(f"User {user.username} verified phone")
 803: 
 804:     return VerificationResponse(
 805:         success=True,
 806:         message="Phone verified successfully",
 807:         profile_status=user.status,
 808:     )
 809: 
 810: 
 811: @router.post(
 812:     "/auth/resend-verification",
 813:     response_model=VerificationResponse,
 814:     responses={
 815:         400: {"description": "Invalid request"},
 816:         404: {"description": "User not found"},
 817:     },
 818: )
 819: async def resend_verification(
 820:     request: ResendVerificationRequest,
 821:     session: AsyncSession = Depends(get_async_session),
 822: ) -> VerificationResponse:
 823: 
 824:     settings = get_settings()
 825: 
 826:     user = await _get_user_by_username(session, request.username)
 827:     if not user:
 828:         raise HTTPException(
 829:             status_code=status.HTTP_404_NOT_FOUND,
 830:             detail="User not found",
 831:         )
 832: 
 833:     if request.verification_type == "email":
 834:         if user.email_verified:
 835:             return VerificationResponse(
 836:                 success=True,
 837:                 message="Email already verified",
 838:                 profile_status=user.status,
 839:             )
 840: 
 841:         token = await _create_verification_token(
 842:             session, user.id, "email",
 843:             settings.email_verification_expiry_hours
 844:         )
 845:         email_client = EmailClient()
 846:         success, msg = email_client.send_verification_email(
 847:             to_email=user.email,
 848:             token=token,
 849:             username=user.username,
 850:             first_name=user.first_name,
 851:         )
 852:         await session.commit()
 853: 
 854:         if not success:
 855:             raise HTTPException(
 856:                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
 857:                 detail=msg,
 858:             )
 859: 
 860:         return VerificationResponse(
 861:             success=True,
 862:             message="Verification email sent",
 863:             profile_status=user.status,
 864:         )
 865: 
 866:     elif request.verification_type == "phone":
 867:         if user.phone_verified:
 868:             return VerificationResponse(
 869:                 success=True,
 870:                 message="Phone already verified",
 871:                 profile_status=user.status,
 872:             )
 873: 
 874:         token = await _create_verification_token(
 875:             session, user.id, "phone", expiry_hours=1
 876:         )
 877:         sms_client = _get_sms_client()
 878:         full_phone = f"{user.phone_country_code}{user.phone_number}"
 879:         success, msg, _ = sms_client.send_verification_code(full_phone, token)
 880:         await session.commit()
 881: 
 882:         if not success:
 883:             raise HTTPException(
 884:                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
 885:                 detail=msg,
 886:             )
 887: 
 888:         return VerificationResponse(
 889:             success=True,
 890:             message="Verification code sent",
 891:             profile_status=user.status,
 892:         )
 893: 
 894:     else:
 895:         raise HTTPException(
 896:             status_code=status.HTTP_400_BAD_REQUEST,
 897:             detail="Invalid verification type. Use 'email' or 'phone'.",
 898:         )
 899: 
 900: 
 901: 
 902: 
 903: 
 904: 
 905: @router.get(
 906:     "/profile/status/{username}",
 907:     response_model=ProfileStatusResponse,
 908:     responses={404: {"description": "User not found"}},
 909: )
 910: async def get_profile_status(
 911:     username: str,
 912:     session: AsyncSession = Depends(get_async_session),
 913: ) -> ProfileStatusResponse:
 914: 
 915:     user = await _get_user_by_username(session, username)
 916:     if not user:
 917:         raise HTTPException(
 918:             status_code=status.HTTP_404_NOT_FOUND,
 919:             detail="User not found",
 920:         )
 921: 
 922:     return ProfileStatusResponse(
 923:         username=user.username,
 924:         email=_mask_email(user.email),
 925:         phone=user.masked_phone,
 926:         status=user.status,
 927:         email_verified=user.email_verified,
 928:         phone_verified=user.phone_verified,
 929:         mfa_method=user.mfa_method,
 930:         created_at=user.created_at.isoformat(),
 931:     )
 932: 
 933: 
 934: 
 935: 
 936: 
 937: 
 938: @router.get("/mfa/methods", response_model=MFAMethodsResponse)
 939: async def get_mfa_methods() -> MFAMethodsResponse:
 940: 
 941:     settings = get_settings()
 942:     methods = ["totp"]
 943:     if settings.enable_sms_2fa:
 944:         methods.append("sms")
 945:     return MFAMethodsResponse(methods=methods, sms_enabled=settings.enable_sms_2fa)
 946: 
 947: 
 948: @router.get("/mfa/status/{username}", response_model=UserMFAStatusResponse)
 949: async def get_mfa_status(
 950:     username: str,
 951:     session: AsyncSession = Depends(get_async_session),
 952: ) -> UserMFAStatusResponse:
 953: 
 954:     user = await _get_user_by_username(session, username)
 955:     if not user:
 956:         return UserMFAStatusResponse(enrolled=False)
 957: 
 958:     phone_number = None
 959:     if user.mfa_method == "sms":
 960:         phone_number = user.masked_phone
 961: 
 962:     return UserMFAStatusResponse(
 963:         enrolled=user.totp_secret is not None or user.mfa_method == "sms",
 964:         mfa_method=user.mfa_method,
 965:         phone_number=phone_number,
 966:     )
 967: 
 968: 
 969: 
 970: 
 971: 
 972: 
 973: @router.post(
 974:     "/auth/enroll",
 975:     response_model=EnrollResponse,
 976:     responses={
 977:         400: {"description": "Bad request"},
 978:         401: {"description": "Invalid credentials"},
 979:         403: {"description": "User not active"},
 980:     },
 981: )
 982: async def enroll(
 983:     request: EnrollRequest,
 984:     session: AsyncSession = Depends(get_async_session),
 985: ) -> EnrollResponse:
 986: 
 987: 
 988: 
 989:     settings = get_settings()
 990: 
 991:     user = await _get_user_by_username(session, request.username)
 992:     if not user:
 993:         raise HTTPException(
 994:             status_code=status.HTTP_404_NOT_FOUND,
 995:             detail="User not found",
 996:         )
 997: 
 998: 
 999:     if not _verify_password(request.password, user.password_hash):
1000:         raise HTTPException(
1001:             status_code=status.HTTP_401_UNAUTHORIZED,
1002:             detail="Invalid password",
1003:         )
1004: 
1005: 
1006:     if user.status != ProfileStatus.ACTIVE.value:
1007:         raise HTTPException(
1008:             status_code=status.HTTP_403_FORBIDDEN,
1009:             detail="Only active users can update MFA enrollment",
1010:         )
1011: 
1012: 
1013:     if request.mfa_method == MFAMethod.SMS and not settings.enable_sms_2fa:
1014:         raise HTTPException(
1015:             status_code=status.HTTP_400_BAD_REQUEST,
1016:             detail="SMS 2FA is not enabled",
1017:         )
1018: 
1019:     if request.mfa_method == MFAMethod.TOTP:
1020:         totp_manager = TOTPManager()
1021:         secret = totp_manager.generate_secret()
1022:         otpauth_uri = totp_manager.generate_otpauth_uri(
1023:             secret=secret,
1024:             username=user.username,
1025:         )
1026: 
1027:         user.mfa_method = "totp"
1028:         user.totp_secret = secret
1029:         await session.commit()
1030: 
1031:         logger.info(f"User {user.username} re-enrolled for TOTP MFA")
1032: 
1033:         return EnrollResponse(
1034:             success=True,
1035:             message="MFA enrollment updated. Scan the QR code.",
1036:             mfa_method=MFAMethod.TOTP,
1037:             otpauth_uri=otpauth_uri,
1038:             secret=secret,
1039:         )
1040:     else:
1041: 
1042:         if not request.phone_number:
1043:             phone = user.full_phone_number
1044:         else:
1045:             phone = request.phone_number
1046: 
1047:         sms_client = _get_sms_client()
1048:         is_valid, error = sms_client.validate_phone_number(phone)
1049:         if not is_valid:
1050:             raise HTTPException(
1051:                 status_code=status.HTTP_400_BAD_REQUEST,
1052:                 detail=error,
1053:             )
1054: 
1055:         user.mfa_method = "sms"
1056:         if request.phone_number:
1057: 
1058:             if request.phone_number.startswith("+"):
1059: 
1060:                 match = re.match(r"^(\+\d{1,4})(\d+)$", request.phone_number)
1061:                 if match:
1062:                     user.phone_country_code = match.group(1)
1063:                     user.phone_number = match.group(2)
1064: 
1065:         await session.commit()
1066: 
1067:         logger.info(f"User {user.username} re-enrolled for SMS MFA")
1068: 
1069:         return EnrollResponse(
1070:             success=True,
1071:             message="MFA enrollment updated for SMS.",
1072:             mfa_method=MFAMethod.SMS,
1073:             phone_number=user.masked_phone,
1074:         )
1075: 
1076: 
1077: 
1078: 
1079: 
1080: 
1081: @router.post(
1082:     "/auth/login",
1083:     response_model=LoginResponse,
1084:     responses={
1085:         401: {"description": "Invalid credentials"},
1086:         403: {"description": "Profile incomplete or not activated"},
1087:     },
1088: )
1089: async def login(
1090:     request: LoginRequest,
1091:     session: AsyncSession = Depends(get_async_session),
1092: ) -> LoginResponse:
1093: 
1094: 
1095: 
1096:     user = await _get_user_by_username(session, request.username)
1097: 
1098: 
1099:     if not user:
1100:         raise HTTPException(
1101:             status_code=status.HTTP_403_FORBIDDEN,
1102:             detail="User not found. Please sign up first.",
1103:         )
1104: 
1105: 
1106:     if user.status == ProfileStatus.PENDING.value:
1107:         missing = []
1108:         if not user.email_verified:
1109:             missing.append("email")
1110:         if not user.phone_verified:
1111:             missing.append("phone")
1112:         raise HTTPException(
1113:             status_code=status.HTTP_403_FORBIDDEN,
1114:             detail=f"Profile incomplete. Please verify your: {', '.join(missing)}",
1115:         )
1116: 
1117:     if user.status == ProfileStatus.COMPLETE.value:
1118:         raise HTTPException(
1119:             status_code=status.HTTP_403_FORBIDDEN,
1120:             detail="Your profile is awaiting admin approval. Please wait for activation.",
1121:         )
1122: 
1123:     # Only ACTIVE users can login - verify against LDAP
1124:     ldap_client = LDAPClient()
1125:     auth_success, auth_message = ldap_client.authenticate(
1126:         request.username, request.password
1127:     )
1128: 
1129:     if not auth_success:
1130:         logger.warning(f"Login failed for {request.username}: {auth_message}")
1131:         raise HTTPException(
1132:             status_code=status.HTTP_401_UNAUTHORIZED,
1133:             detail="Invalid username or password",
1134:         )
1135: 
1136: 
1137:     if user.mfa_method == "totp":
1138:         if not user.totp_secret:
1139:             raise HTTPException(
1140:                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
1141:                 detail="TOTP not configured",
1142:             )
1143: 
1144:         totp_manager = TOTPManager()
1145:         if not totp_manager.verify_totp(user.totp_secret, request.verification_code):
1146:             logger.warning(f"Login failed for {request.username}: Invalid TOTP")
1147:             raise HTTPException(
1148:                 status_code=status.HTTP_401_UNAUTHORIZED,
1149:                 detail="Invalid verification code",
1150:             )
1151: 
1152:     elif user.mfa_method == "sms":
1153: 
1154:         otp_client = get_otp_client()
1155:         sms_code_data = None
1156: 
1157:         if otp_client.is_enabled and otp_client.is_connected:
1158: 
1159:             sms_code_data = otp_client.get_code(request.username)
1160: 
1161:             if not sms_code_data:
1162:                 raise HTTPException(
1163:                     status_code=status.HTTP_401_UNAUTHORIZED,
1164:                     detail="No verification code sent. Please request a code first.",
1165:                 )
1166: 
1167: 
1168:             if not hmac.compare_digest(
1169:                 request.verification_code, sms_code_data["code"]
1170:             ):
1171:                 logger.warning(
1172:                     f"Login failed for {request.username}: Invalid SMS code"
1173:                 )
1174:                 raise HTTPException(
1175:                     status_code=status.HTTP_401_UNAUTHORIZED,
1176:                     detail="Invalid verification code",
1177:                 )
1178: 
1179: 
1180:             otp_client.delete_code(request.username)
1181:         else:
1182: 
1183:             sms_code_data = InMemoryOTPStorage.get_code(request.username)
1184: 
1185:             if not sms_code_data:
1186:                 raise HTTPException(
1187:                     status_code=status.HTTP_401_UNAUTHORIZED,
1188:                     detail="No verification code sent. Please request a code first.",
1189:                 )
1190: 
1191:             if time.time() > sms_code_data["expires_at"]:
1192:                 InMemoryOTPStorage.delete_code(request.username)
1193:                 raise HTTPException(
1194:                     status_code=status.HTTP_401_UNAUTHORIZED,
1195:                     detail="Verification code expired. Please request a new one.",
1196:                 )
1197: 
1198:             if not hmac.compare_digest(
1199:                 request.verification_code, sms_code_data["code"]
1200:             ):
1201:                 logger.warning(
1202:                     f"Login failed for {request.username}: Invalid SMS code"
1203:                 )
1204:                 raise HTTPException(
1205:                     status_code=status.HTTP_401_UNAUTHORIZED,
1206:                     detail="Invalid verification code",
1207:                 )
1208: 
1209:             InMemoryOTPStorage.delete_code(request.username)
1210: 
1211: 
1212:     is_admin = ldap_client.is_admin(request.username)
1213: 
1214: 
1215:     token = _create_jwt_token(
1216:         user_id=str(user.id),
1217:         username=user.username,
1218:         is_admin=is_admin,
1219:     )
1220: 
1221:     logger.info(f"User {request.username} logged in successfully")
1222: 
1223:     return LoginResponse(
1224:         success=True,
1225:         message="Login successful",
1226:         is_admin=is_admin,
1227:         token=token,
1228:         username=user.username,
1229:     )
1230: 
1231: 
1232: @router.post(
1233:     "/auth/sms/send-code",
1234:     response_model=SMSSendCodeResponse,
1235:     responses={
1236:         401: {"description": "Invalid credentials"},
1237:         403: {"description": "User not enrolled for SMS"},
1238:     },
1239: )
1240: async def send_sms_code(
1241:     request: SMSSendCodeRequest,
1242:     session: AsyncSession = Depends(get_async_session),
1243: ) -> SMSSendCodeResponse:
1244: 
1245:     settings = get_settings()
1246: 
1247:     if not settings.enable_sms_2fa:
1248:         raise HTTPException(
1249:             status_code=status.HTTP_400_BAD_REQUEST,
1250:             detail="SMS 2FA is not enabled",
1251:         )
1252: 
1253:     user = await _get_user_by_username(session, request.username)
1254:     if not user:
1255:         raise HTTPException(
1256:             status_code=status.HTTP_404_NOT_FOUND,
1257:             detail="User not found",
1258:         )
1259: 
1260: 
1261:     if user.status == ProfileStatus.ACTIVE.value:
1262:         ldap_client = LDAPClient()
1263:         auth_success, _ = ldap_client.authenticate(request.username, request.password)
1264:         if not auth_success:
1265:             raise HTTPException(
1266:                 status_code=status.HTTP_401_UNAUTHORIZED,
1267:                 detail="Invalid username or password",
1268:             )
1269:     else:
1270: 
1271:         if not _verify_password(request.password, user.password_hash):
1272:             raise HTTPException(
1273:                 status_code=status.HTTP_401_UNAUTHORIZED,
1274:                 detail="Invalid username or password",
1275:             )
1276: 
1277:     if user.mfa_method != "sms":
1278:         raise HTTPException(
1279:             status_code=status.HTTP_403_FORBIDDEN,
1280:             detail="User not enrolled for SMS MFA",
1281:         )
1282: 
1283: 
1284:     sms_client = _get_sms_client()
1285:     code = _generate_verification_code(settings.sms_code_length)
1286: 
1287:     success, message, _ = sms_client.send_verification_code(
1288:         user.full_phone_number, code
1289:     )
1290: 
1291:     if not success:
1292:         raise HTTPException(
1293:             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
1294:             detail=f"Failed to send SMS: {message}",
1295:         )
1296: 
1297:     # Store code for verification (Redis or in-memory fallback)
1298:     otp_client = get_otp_client()
1299:     if otp_client.is_enabled and otp_client.is_connected:
1300:         # Use Redis for OTP storage
1301:         stored = otp_client.store_code(
1302:             username=request.username,
1303:             code=code,
1304:             phone_number=user.full_phone_number,
1305:             ttl_seconds=settings.sms_code_expiry_seconds,
1306:         )
1307:         if not stored:
1308:             logger.error(f"Failed to store OTP code in Redis for {request.username}")
1309:             raise HTTPException(
1310:                 status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
1311:                 detail="Failed to store verification code. Please try again.",
1312:             )
1313:     else:
1314:         # Fallback to in-memory storage
1315:         InMemoryOTPStorage.store_code(
1316:             username=request.username,
1317:             code=code,
1318:             phone_number=user.full_phone_number,
1319:             expires_at=time.time() + settings.sms_code_expiry_seconds,
1320:         )
1321: 
1322:     logger.info(f"SMS code sent to user {request.username}")
1323: 
1324:     return SMSSendCodeResponse(
1325:         success=True,
1326:         message="Verification code sent",
1327:         phone_number=user.masked_phone,
1328:         expires_in_seconds=settings.sms_code_expiry_seconds,
1329:     )
1330: 
1331: 
1332: 
1333: 
1334: 
1335: 
1336: @router.post(
1337:     "/admin/login",
1338:     response_model=LoginResponse,
1339:     responses={
1340:         401: {"description": "Invalid credentials"},
1341:         403: {"description": "Not an admin"},
1342:     },
1343: )
1344: async def admin_login(
1345:     request: LoginRequest,
1346:     session: AsyncSession = Depends(get_async_session),
1347: ) -> LoginResponse:
1348: 
1349: 
1350:     response = await login(request, session)
1351: 
1352:     if not response.is_admin:
1353:         raise HTTPException(
1354:             status_code=status.HTTP_403_FORBIDDEN,
1355:             detail="Access denied. Admin privileges required.",
1356:         )
1357: 
1358:     return response
1359: 
1360: 
1361: @router.get(
1362:     "/admin/users",
1363:     response_model=AdminUserListResponse,
1364:     responses={401: {"description": "Invalid credentials"}, 403: {"description": "Not admin"}},
1365: )
1366: async def admin_list_users(
1367:     admin_username: str,
1368:     admin_password: str,
1369:     status_filter: Optional[str] = None,
1370:     session: AsyncSession = Depends(get_async_session),
1371: ) -> AdminUserListResponse:
1372: 
1373: 
1374:     ldap_client = LDAPClient()
1375:     auth_success, _ = ldap_client.authenticate(admin_username, admin_password)
1376:     if not auth_success:
1377:         raise HTTPException(
1378:             status_code=status.HTTP_401_UNAUTHORIZED,
1379:             detail="Invalid admin credentials",
1380:         )
1381: 
1382:     if not ldap_client.is_admin(admin_username):
1383:         raise HTTPException(
1384:             status_code=status.HTTP_403_FORBIDDEN,
1385:             detail="Admin privileges required",
1386:         )
1387: 
1388: 
1389:     query = select(User)
1390:     if status_filter:
1391:         query = query.where(User.status == status_filter)
1392:     query = query.order_by(User.created_at.desc())
1393: 
1394:     result = await session.execute(query)
1395:     users = result.scalars().all()
1396: 
1397:     user_list = [
1398:         {
1399:             "id": str(u.id),
1400:             "username": u.username,
1401:             "email": u.email,
1402:             "first_name": u.first_name,
1403:             "last_name": u.last_name,
1404:             "phone": u.full_phone_number,
1405:             "status": u.status,
1406:             "email_verified": u.email_verified,
1407:             "phone_verified": u.phone_verified,
1408:             "mfa_method": u.mfa_method,
1409:             "created_at": u.created_at.isoformat(),
1410:             "activated_at": u.activated_at.isoformat() if u.activated_at else None,
1411:             "activated_by": u.activated_by,
1412:         }
1413:         for u in users
1414:     ]
1415: 
1416:     return AdminUserListResponse(users=user_list, total=len(user_list))
1417: 
1418: 
1419: @router.post(
1420:     "/admin/users/{user_id}/activate",
1421:     response_model=AdminActivateResponse,
1422:     responses={
1423:         401: {"description": "Invalid credentials"},
1424:         403: {"description": "Not admin or user not ready"},
1425:         404: {"description": "User not found"},
1426:     },
1427: )
1428: async def admin_activate_user(
1429:     user_id: str,
1430:     request: AdminActivateRequest,
1431:     session: AsyncSession = Depends(get_async_session),
1432: ) -> AdminActivateResponse:
1433: 
1434: 
1435:     ldap_client = LDAPClient()
1436:     auth_success, _ = ldap_client.authenticate(
1437:         request.admin_username, request.admin_password
1438:     )
1439:     if not auth_success:
1440:         raise HTTPException(
1441:             status_code=status.HTTP_401_UNAUTHORIZED,
1442:             detail="Invalid admin credentials",
1443:         )
1444: 
1445:     if not ldap_client.is_admin(request.admin_username):
1446:         raise HTTPException(
1447:             status_code=status.HTTP_403_FORBIDDEN,
1448:             detail="Admin privileges required",
1449:         )
1450: 
1451: 
1452:     try:
1453:         user_uuid = uuid.UUID(user_id)
1454:     except ValueError:
1455:         raise HTTPException(
1456:             status_code=status.HTTP_400_BAD_REQUEST,
1457:             detail="Invalid user ID format",
1458:         )
1459: 
1460:     result = await session.execute(select(User).where(User.id == user_uuid))
1461:     user = result.scalar_one_or_none()
1462: 
1463:     if not user:
1464:         raise HTTPException(
1465:             status_code=status.HTTP_404_NOT_FOUND,
1466:             detail="User not found",
1467:         )
1468: 
1469:     if user.status != ProfileStatus.COMPLETE.value:
1470:         raise HTTPException(
1471:             status_code=status.HTTP_403_FORBIDDEN,
1472:             detail=f"User cannot be activated. Current status: {user.status}",
1473:         )
1474: 
1475:     # Create user in LDAP
1476:     # We need to get the plain password, but we only have the hash
1477:     # The admin will need to set a temporary password or we use a token-based approach
1478:     # For now, we'll generate a temporary password and require the user to reset it
1479: 
1480:     temp_password = secrets.token_urlsafe(16)
1481: 
1482:     success, message = ldap_client.create_user(
1483:         username=user.username,
1484:         password=temp_password,
1485:         first_name=user.first_name,
1486:         last_name=user.last_name,
1487:         email=user.email,
1488:     )
1489: 
1490:     if not success:
1491:         raise HTTPException(
1492:             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
1493:             detail=f"Failed to create LDAP user: {message}",
1494:         )
1495: 
1496:     # Update user status
1497:     user.status = ProfileStatus.ACTIVE.value
1498:     user.activated_at = datetime.now(timezone.utc)
1499:     user.activated_by = request.admin_username
1500:     # Update password hash to match the temp password (user will use this until LDAP password reset)
1501:     user.password_hash = _hash_password(temp_password)
1502: 
1503:     await session.commit()
1504: 
1505:     # Send welcome email
1506:     try:
1507:         email_client = EmailClient()
1508:         email_client.send_welcome_email(
1509:             to_email=user.email,
1510:             username=user.username,
1511:             first_name=user.first_name,
1512:         )
1513:     except Exception as e:
1514:         logger.error(f"Failed to send welcome email: {e}")
1515: 
1516:     logger.info(f"User {user.username} activated by {request.admin_username}")
1517: 
1518:     return AdminActivateResponse(
1519:         success=True,
1520:         message=f"User {user.username} activated successfully. A temporary password has been set.",
1521:     )
1522: 
1523: 
1524: @router.post(
1525:     "/admin/users/{user_id}/reject",
1526:     response_model=AdminActivateResponse,
1527:     responses={
1528:         401: {"description": "Invalid credentials"},
1529:         403: {"description": "Not admin"},
1530:         404: {"description": "User not found"},
1531:     },
1532: )
1533: async def admin_reject_user(
1534:     user_id: str,
1535:     request: AdminActivateRequest,
1536:     session: AsyncSession = Depends(get_async_session),
1537: ) -> AdminActivateResponse:
1538: 
1539: 
1540:     ldap_client = LDAPClient()
1541:     auth_success, _ = ldap_client.authenticate(
1542:         request.admin_username, request.admin_password
1543:     )
1544:     if not auth_success:
1545:         raise HTTPException(
1546:             status_code=status.HTTP_401_UNAUTHORIZED,
1547:             detail="Invalid admin credentials",
1548:         )
1549: 
1550:     if not ldap_client.is_admin(request.admin_username):
1551:         raise HTTPException(
1552:             status_code=status.HTTP_403_FORBIDDEN,
1553:             detail="Admin privileges required",
1554:         )
1555: 
1556: 
1557:     try:
1558:         user_uuid = uuid.UUID(user_id)
1559:     except ValueError:
1560:         raise HTTPException(
1561:             status_code=status.HTTP_400_BAD_REQUEST,
1562:             detail="Invalid user ID format",
1563:         )
1564: 
1565:     result = await session.execute(select(User).where(User.id == user_uuid))
1566:     user = result.scalar_one_or_none()
1567: 
1568:     if not user:
1569:         raise HTTPException(
1570:             status_code=status.HTTP_404_NOT_FOUND,
1571:             detail="User not found",
1572:         )
1573: 
1574:     username = user.username
1575:     await session.delete(user)
1576:     await session.commit()
1577: 
1578:     logger.info(f"User {username} rejected/deleted by {request.admin_username}")
1579: 
1580:     return AdminActivateResponse(
1581:         success=True,
1582:         message=f"User {username} has been rejected and removed.",
1583:     )
1584: 
1585: 
1586: # ============================================================================
1587: # Profile Endpoints
1588: # ============================================================================
1589: 
1590: @router.get(
1591:     "/profile/{username}",
1592:     response_model=ProfileResponse,
1593:     responses={
1594:         401: {"description": "Not authenticated"},
1595:         403: {"description": "Not authorized"},
1596:         404: {"description": "User not found"},
1597:     },
1598: )
1599: async def get_profile(
1600:     username: str,
1601:     authorization: Optional[str] = Header(None),
1602:     session: AsyncSession = Depends(get_async_session),
1603: ) -> ProfileResponse:
1604: 
1605:     current = await _get_current_user(authorization, session)
1606: 
1607: 
1608:     if current["username"] != username.lower() and not current["is_admin"]:
1609:         raise HTTPException(
1610:             status_code=status.HTTP_403_FORBIDDEN,
1611:             detail="You can only view your own profile",
1612:         )
1613: 
1614:     user = await _get_user_by_username(session, username)
1615:     if not user:
1616:         raise HTTPException(
1617:             status_code=status.HTTP_404_NOT_FOUND,
1618:             detail="User not found",
1619:         )
1620: 
1621: 
1622:     result = await session.execute(
1623:         select(UserGroup).where(UserGroup.user_id == user.id).options(
1624:             selectinload(UserGroup.group)
1625:         )
1626:     )
1627:     user_groups = result.scalars().all()
1628:     groups = [
1629:         {"id": str(ug.group_id), "name": ug.group.name}
1630:         for ug in user_groups if ug.group
1631:     ]
1632: 
1633:     return ProfileResponse(
1634:         id=str(user.id),
1635:         username=user.username,
1636:         email=user.email,
1637:         first_name=user.first_name,
1638:         last_name=user.last_name,
1639:         phone_country_code=user.phone_country_code,
1640:         phone_number=user.phone_number,
1641:         email_verified=user.email_verified,
1642:         phone_verified=user.phone_verified,
1643:         mfa_method=user.mfa_method,
1644:         status=user.status,
1645:         created_at=user.created_at.isoformat() if user.created_at else "",
1646:         groups=groups,
1647:     )
1648: 
1649: 
1650: @router.put(
1651:     "/profile/{username}",
1652:     response_model=ProfileResponse,
1653:     responses={
1654:         401: {"description": "Not authenticated"},
1655:         403: {"description": "Not authorized or field not editable"},
1656:         404: {"description": "User not found"},
1657:     },
1658: )
1659: async def update_profile(
1660:     username: str,
1661:     request: ProfileUpdateRequest,
1662:     authorization: Optional[str] = Header(None),
1663:     session: AsyncSession = Depends(get_async_session),
1664: ) -> ProfileResponse:
1665: 
1666: 
1667: 
1668: 
1669: 
1670: 
1671: 
1672:     current = await _get_current_user(authorization, session)
1673: 
1674: 
1675:     if current["username"] != username.lower():
1676:         raise HTTPException(
1677:             status_code=status.HTTP_403_FORBIDDEN,
1678:             detail="You can only update your own profile",
1679:         )
1680: 
1681:     user = await _get_user_by_username(session, username)
1682:     if not user:
1683:         raise HTTPException(
1684:             status_code=status.HTTP_404_NOT_FOUND,
1685:             detail="User not found",
1686:         )
1687: 
1688: 
1689:     if request.first_name is not None:
1690:         user.first_name = request.first_name
1691: 
1692:     if request.last_name is not None:
1693:         user.last_name = request.last_name
1694: 
1695: 
1696:     if request.email is not None:
1697:         if user.email_verified:
1698:             raise HTTPException(
1699:                 status_code=status.HTTP_403_FORBIDDEN,
1700:                 detail="Email cannot be changed after verification",
1701:             )
1702: 
1703:         existing = await _get_user_by_email(session, request.email)
1704:         if existing and existing.id != user.id:
1705:             raise HTTPException(
1706:                 status_code=status.HTTP_400_BAD_REQUEST,
1707:                 detail="Email already in use",
1708:             )
1709:         user.email = request.email.lower()
1710: 
1711: 
1712:     if request.phone_country_code is not None or request.phone_number is not None:
1713:         if user.phone_verified:
1714:             raise HTTPException(
1715:                 status_code=status.HTTP_403_FORBIDDEN,
1716:                 detail="Phone cannot be changed after verification",
1717:             )
1718:         if request.phone_country_code is not None:
1719:             user.phone_country_code = request.phone_country_code
1720:         if request.phone_number is not None:
1721:             user.phone_number = request.phone_number
1722: 
1723:     await session.commit()
1724: 
1725: 
1726:     result = await session.execute(
1727:         select(UserGroup).where(UserGroup.user_id == user.id).options(
1728:             selectinload(UserGroup.group)
1729:         )
1730:     )
1731:     user_groups = result.scalars().all()
1732:     groups = [
1733:         {"id": str(ug.group_id), "name": ug.group.name}
1734:         for ug in user_groups if ug.group
1735:     ]
1736: 
1737:     logger.info(f"Profile updated for user {username}")
1738: 
1739:     return ProfileResponse(
1740:         id=str(user.id),
1741:         username=user.username,
1742:         email=user.email,
1743:         first_name=user.first_name,
1744:         last_name=user.last_name,
1745:         phone_country_code=user.phone_country_code,
1746:         phone_number=user.phone_number,
1747:         email_verified=user.email_verified,
1748:         phone_verified=user.phone_verified,
1749:         mfa_method=user.mfa_method,
1750:         status=user.status,
1751:         created_at=user.created_at.isoformat() if user.created_at else "",
1752:         groups=groups,
1753:     )
1754: 
1755: 
1756: # ============================================================================
1757: # Group Management Endpoints (Admin)
1758: # ============================================================================
1759: 
1760: @router.get(
1761:     "/admin/groups",
1762:     response_model=GroupListResponse,
1763:     responses={401: {"description": "Not authenticated"}, 403: {"description": "Not admin"}},
1764: )
1765: async def admin_list_groups(
1766:     search: Optional[str] = Query(None, description="Search term"),
1767:     sort_by: Optional[str] = Query("name", description="Sort field"),
1768:     sort_order: Optional[str] = Query("asc", description="Sort order"),
1769:     authorization: Optional[str] = Header(None),
1770:     session: AsyncSession = Depends(get_async_session),
1771: ) -> GroupListResponse:
1772: 
1773:     await _require_admin(authorization, session)
1774: 
1775:     query = select(Group)
1776: 
1777: 
1778:     if search:
1779:         search_term = f"%{search}%"
1780:         query = query.where(
1781:             or_(
1782:                 Group.name.ilike(search_term),
1783:                 Group.description.ilike(search_term),
1784:             )
1785:         )
1786: 
1787:     # Apply sorting
1788:     if sort_by == "name":
1789:         order_col = Group.name
1790:     elif sort_by == "created_at":
1791:         order_col = Group.created_at
1792:     else:
1793:         order_col = Group.name
1794: 
1795:     if sort_order == "desc":
1796:         query = query.order_by(order_col.desc())
1797:     else:
1798:         query = query.order_by(order_col.asc())
1799: 
1800:     result = await session.execute(query.options(selectinload(Group.user_groups)))
1801:     groups = result.scalars().all()
1802: 
1803:     group_list = [
1804:         GroupResponse(
1805:             id=str(g.id),
1806:             name=g.name,
1807:             description=g.description,
1808:             ldap_dn=g.ldap_dn,
1809:             member_count=len(g.user_groups) if g.user_groups else 0,
1810:             created_at=g.created_at.isoformat() if g.created_at else "",
1811:         )
1812:         for g in groups
1813:     ]
1814: 
1815:     return GroupListResponse(groups=group_list, total=len(group_list))
1816: 
1817: 
1818: @router.post(
1819:     "/admin/groups",
1820:     response_model=GroupResponse,
1821:     responses={
1822:         401: {"description": "Not authenticated"},
1823:         403: {"description": "Not admin"},
1824:         400: {"description": "Group already exists"},
1825:     },
1826: )
1827: async def admin_create_group(
1828:     request: GroupCreateRequest,
1829:     authorization: Optional[str] = Header(None),
1830:     session: AsyncSession = Depends(get_async_session),
1831: ) -> GroupResponse:
1832: 
1833:     await _require_admin(authorization, session)
1834: 
1835: 
1836:     existing = await session.execute(
1837:         select(Group).where(Group.name == request.name)
1838:     )
1839:     if existing.scalar_one_or_none():
1840:         raise HTTPException(
1841:             status_code=status.HTTP_400_BAD_REQUEST,
1842:             detail="Group name already exists",
1843:         )
1844: 
1845: 
1846:     ldap_client = LDAPClient()
1847:     success, message, ldap_dn = ldap_client.create_group(
1848:         name=request.name,
1849:         description=request.description or "",
1850:     )
1851: 
1852:     if not success:
1853:         raise HTTPException(
1854:             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
1855:             detail=f"Failed to create LDAP group: {message}",
1856:         )
1857: 
1858:     # Create database record
1859:     group = Group(
1860:         name=request.name,
1861:         description=request.description,
1862:         ldap_dn=ldap_dn,
1863:     )
1864:     session.add(group)
1865:     await session.commit()
1866: 
1867:     logger.info(f"Group {request.name} created")
1868: 
1869:     return GroupResponse(
1870:         id=str(group.id),
1871:         name=group.name,
1872:         description=group.description,
1873:         ldap_dn=group.ldap_dn,
1874:         member_count=0,
1875:         created_at=group.created_at.isoformat() if group.created_at else "",
1876:     )
1877: 
1878: 
1879: @router.get(
1880:     "/admin/groups/{group_id}",
1881:     response_model=GroupDetailResponse,
1882:     responses={
1883:         401: {"description": "Not authenticated"},
1884:         403: {"description": "Not admin"},
1885:         404: {"description": "Group not found"},
1886:     },
1887: )
1888: async def admin_get_group(
1889:     group_id: str,
1890:     authorization: Optional[str] = Header(None),
1891:     session: AsyncSession = Depends(get_async_session),
1892: ) -> GroupDetailResponse:
1893: 
1894:     await _require_admin(authorization, session)
1895: 
1896:     try:
1897:         group_uuid = uuid.UUID(group_id)
1898:     except ValueError:
1899:         raise HTTPException(
1900:             status_code=status.HTTP_400_BAD_REQUEST,
1901:             detail="Invalid group ID format",
1902:         )
1903: 
1904:     result = await session.execute(
1905:         select(Group).where(Group.id == group_uuid).options(
1906:             selectinload(Group.user_groups).selectinload(UserGroup.user)
1907:         )
1908:     )
1909:     group = result.scalar_one_or_none()
1910: 
1911:     if not group:
1912:         raise HTTPException(
1913:             status_code=status.HTTP_404_NOT_FOUND,
1914:             detail="Group not found",
1915:         )
1916: 
1917:     members = [
1918:         {
1919:             "id": str(ug.user.id),
1920:             "username": ug.user.username,
1921:             "full_name": ug.user.full_name,
1922:             "assigned_at": ug.assigned_at.isoformat() if ug.assigned_at else "",
1923:             "assigned_by": ug.assigned_by,
1924:         }
1925:         for ug in group.user_groups if ug.user
1926:     ]
1927: 
1928:     return GroupDetailResponse(
1929:         id=str(group.id),
1930:         name=group.name,
1931:         description=group.description,
1932:         ldap_dn=group.ldap_dn,
1933:         member_count=len(members),
1934:         created_at=group.created_at.isoformat() if group.created_at else "",
1935:         members=members,
1936:     )
1937: 
1938: 
1939: @router.put(
1940:     "/admin/groups/{group_id}",
1941:     response_model=GroupResponse,
1942:     responses={
1943:         401: {"description": "Not authenticated"},
1944:         403: {"description": "Not admin"},
1945:         404: {"description": "Group not found"},
1946:     },
1947: )
1948: async def admin_update_group(
1949:     group_id: str,
1950:     request: GroupUpdateRequest,
1951:     authorization: Optional[str] = Header(None),
1952:     session: AsyncSession = Depends(get_async_session),
1953: ) -> GroupResponse:
1954: 
1955:     await _require_admin(authorization, session)
1956: 
1957:     try:
1958:         group_uuid = uuid.UUID(group_id)
1959:     except ValueError:
1960:         raise HTTPException(
1961:             status_code=status.HTTP_400_BAD_REQUEST,
1962:             detail="Invalid group ID format",
1963:         )
1964: 
1965:     result = await session.execute(
1966:         select(Group).where(Group.id == group_uuid).options(
1967:             selectinload(Group.user_groups)
1968:         )
1969:     )
1970:     group = result.scalar_one_or_none()
1971: 
1972:     if not group:
1973:         raise HTTPException(
1974:             status_code=status.HTTP_404_NOT_FOUND,
1975:             detail="Group not found",
1976:         )
1977: 
1978: 
1979:     if request.description is not None:
1980:         ldap_client = LDAPClient()
1981:         success, message = ldap_client.update_group(
1982:             group_dn=group.ldap_dn,
1983:             description=request.description,
1984:         )
1985:         if not success:
1986:             logger.warning(f"Failed to update LDAP group: {message}")
1987: 
1988:     # Update database
1989:     if request.name is not None:
1990:         # Check if name already exists
1991:         existing = await session.execute(
1992:             select(Group).where(Group.name == request.name, Group.id != group_uuid)
1993:         )
1994:         if existing.scalar_one_or_none():
1995:             raise HTTPException(
1996:                 status_code=status.HTTP_400_BAD_REQUEST,
1997:                 detail="Group name already exists",
1998:             )
1999:         group.name = request.name
2000: 
2001:     if request.description is not None:
2002:         group.description = request.description
2003: 
2004:     await session.commit()
2005: 
2006:     logger.info(f"Group {group.name} updated")
2007: 
2008:     return GroupResponse(
2009:         id=str(group.id),
2010:         name=group.name,
2011:         description=group.description,
2012:         ldap_dn=group.ldap_dn,
2013:         member_count=len(group.user_groups) if group.user_groups else 0,
2014:         created_at=group.created_at.isoformat() if group.created_at else "",
2015:     )
2016: 
2017: 
2018: @router.delete(
2019:     "/admin/groups/{group_id}",
2020:     response_model=AdminActivateResponse,
2021:     responses={
2022:         401: {"description": "Not authenticated"},
2023:         403: {"description": "Not admin"},
2024:         404: {"description": "Group not found"},
2025:     },
2026: )
2027: async def admin_delete_group(
2028:     group_id: str,
2029:     authorization: Optional[str] = Header(None),
2030:     session: AsyncSession = Depends(get_async_session),
2031: ) -> AdminActivateResponse:
2032: 
2033:     await _require_admin(authorization, session)
2034: 
2035:     try:
2036:         group_uuid = uuid.UUID(group_id)
2037:     except ValueError:
2038:         raise HTTPException(
2039:             status_code=status.HTTP_400_BAD_REQUEST,
2040:             detail="Invalid group ID format",
2041:         )
2042: 
2043:     result = await session.execute(select(Group).where(Group.id == group_uuid))
2044:     group = result.scalar_one_or_none()
2045: 
2046:     if not group:
2047:         raise HTTPException(
2048:             status_code=status.HTTP_404_NOT_FOUND,
2049:             detail="Group not found",
2050:         )
2051: 
2052:     group_name = group.name
2053:     ldap_dn = group.ldap_dn
2054: 
2055: 
2056:     ldap_client = LDAPClient()
2057:     success, message = ldap_client.delete_group(ldap_dn)
2058:     if not success:
2059:         logger.warning(f"Failed to delete LDAP group: {message}")
2060: 
2061:     # Delete from database (cascades to user_groups)
2062:     await session.delete(group)
2063:     await session.commit()
2064: 
2065:     logger.info(f"Group {group_name} deleted")
2066: 
2067:     return AdminActivateResponse(
2068:         success=True,
2069:         message=f"Group {group_name} deleted successfully",
2070:     )
2071: 
2072: 
2073: 
2074: 
2075: 
2076: 
2077: @router.get(
2078:     "/admin/users/{user_id}/groups",
2079:     response_model=UserGroupResponse,
2080:     responses={
2081:         401: {"description": "Not authenticated"},
2082:         403: {"description": "Not admin"},
2083:         404: {"description": "User not found"},
2084:     },
2085: )
2086: async def admin_get_user_groups(
2087:     user_id: str,
2088:     authorization: Optional[str] = Header(None),
2089:     session: AsyncSession = Depends(get_async_session),
2090: ) -> UserGroupResponse:
2091: 
2092:     await _require_admin(authorization, session)
2093: 
2094:     try:
2095:         user_uuid = uuid.UUID(user_id)
2096:     except ValueError:
2097:         raise HTTPException(
2098:             status_code=status.HTTP_400_BAD_REQUEST,
2099:             detail="Invalid user ID format",
2100:         )
2101: 
2102:     result = await session.execute(
2103:         select(User).where(User.id == user_uuid)
2104:     )
2105:     user = result.scalar_one_or_none()
2106: 
2107:     if not user:
2108:         raise HTTPException(
2109:             status_code=status.HTTP_404_NOT_FOUND,
2110:             detail="User not found",
2111:         )
2112: 
2113: 
2114:     result = await session.execute(
2115:         select(UserGroup).where(UserGroup.user_id == user_uuid).options(
2116:             selectinload(UserGroup.group)
2117:         )
2118:     )
2119:     user_groups = result.scalars().all()
2120: 
2121:     groups = [
2122:         {
2123:             "id": str(ug.group_id),
2124:             "name": ug.group.name if ug.group else "",
2125:             "assigned_at": ug.assigned_at.isoformat() if ug.assigned_at else "",
2126:             "assigned_by": ug.assigned_by,
2127:         }
2128:         for ug in user_groups
2129:     ]
2130: 
2131:     return UserGroupResponse(
2132:         user_id=str(user.id),
2133:         username=user.username,
2134:         groups=groups,
2135:     )
2136: 
2137: 
2138: @router.post(
2139:     "/admin/users/{user_id}/groups",
2140:     response_model=UserGroupResponse,
2141:     responses={
2142:         401: {"description": "Not authenticated"},
2143:         403: {"description": "Not admin"},
2144:         404: {"description": "User or group not found"},
2145:     },
2146: )
2147: async def admin_assign_user_groups(
2148:     user_id: str,
2149:     request: UserGroupAssignRequest,
2150:     authorization: Optional[str] = Header(None),
2151:     session: AsyncSession = Depends(get_async_session),
2152: ) -> UserGroupResponse:
2153: 
2154:     current = await _require_admin(authorization, session)
2155: 
2156:     try:
2157:         user_uuid = uuid.UUID(user_id)
2158:     except ValueError:
2159:         raise HTTPException(
2160:             status_code=status.HTTP_400_BAD_REQUEST,
2161:             detail="Invalid user ID format",
2162:         )
2163: 
2164:     result = await session.execute(select(User).where(User.id == user_uuid))
2165:     user = result.scalar_one_or_none()
2166: 
2167:     if not user:
2168:         raise HTTPException(
2169:             status_code=status.HTTP_404_NOT_FOUND,
2170:             detail="User not found",
2171:         )
2172: 
2173:     ldap_client = LDAPClient()
2174: 
2175:     for group_id in request.group_ids:
2176:         try:
2177:             group_uuid = uuid.UUID(group_id)
2178:         except ValueError:
2179:             continue
2180: 
2181: 
2182:         result = await session.execute(select(Group).where(Group.id == group_uuid))
2183:         group = result.scalar_one_or_none()
2184:         if not group:
2185:             continue
2186: 
2187: 
2188:         result = await session.execute(
2189:             select(UserGroup).where(
2190:                 UserGroup.user_id == user_uuid,
2191:                 UserGroup.group_id == group_uuid,
2192:             )
2193:         )
2194:         if result.scalar_one_or_none():
2195:             continue
2196: 
2197: 
2198:         if user.status == ProfileStatus.ACTIVE.value:
2199:             success, msg = ldap_client.add_user_to_group(user.username, group.ldap_dn)
2200:             if not success:
2201:                 logger.warning(f"Failed to add {user.username} to LDAP group: {msg}")
2202: 
2203:         # Add database assignment
2204:         user_group = UserGroup(
2205:             user_id=user_uuid,
2206:             group_id=group_uuid,
2207:             assigned_by=current["username"],
2208:         )
2209:         session.add(user_group)
2210: 
2211:     await session.commit()
2212: 
2213: 
2214:     result = await session.execute(
2215:         select(UserGroup).where(UserGroup.user_id == user_uuid).options(
2216:             selectinload(UserGroup.group)
2217:         )
2218:     )
2219:     user_groups = result.scalars().all()
2220: 
2221:     groups = [
2222:         {
2223:             "id": str(ug.group_id),
2224:             "name": ug.group.name if ug.group else "",
2225:             "assigned_at": ug.assigned_at.isoformat() if ug.assigned_at else "",
2226:             "assigned_by": ug.assigned_by,
2227:         }
2228:         for ug in user_groups
2229:     ]
2230: 
2231:     logger.info(f"Groups assigned to user {user.username}")
2232: 
2233:     return UserGroupResponse(
2234:         user_id=str(user.id),
2235:         username=user.username,
2236:         groups=groups,
2237:     )
2238: 
2239: 
2240: @router.put(
2241:     "/admin/users/{user_id}/groups",
2242:     response_model=UserGroupResponse,
2243:     responses={
2244:         401: {"description": "Not authenticated"},
2245:         403: {"description": "Not admin"},
2246:         404: {"description": "User not found"},
2247:     },
2248: )
2249: async def admin_replace_user_groups(
2250:     user_id: str,
2251:     request: UserGroupAssignRequest,
2252:     authorization: Optional[str] = Header(None),
2253:     session: AsyncSession = Depends(get_async_session),
2254: ) -> UserGroupResponse:
2255: 
2256:     current = await _require_admin(authorization, session)
2257: 
2258:     try:
2259:         user_uuid = uuid.UUID(user_id)
2260:     except ValueError:
2261:         raise HTTPException(
2262:             status_code=status.HTTP_400_BAD_REQUEST,
2263:             detail="Invalid user ID format",
2264:         )
2265: 
2266:     result = await session.execute(select(User).where(User.id == user_uuid))
2267:     user = result.scalar_one_or_none()
2268: 
2269:     if not user:
2270:         raise HTTPException(
2271:             status_code=status.HTTP_404_NOT_FOUND,
2272:             detail="User not found",
2273:         )
2274: 
2275:     ldap_client = LDAPClient()
2276: 
2277: 
2278:     result = await session.execute(
2279:         select(UserGroup).where(UserGroup.user_id == user_uuid).options(
2280:             selectinload(UserGroup.group)
2281:         )
2282:     )
2283:     current_assignments = result.scalars().all()
2284: 
2285: 
2286:     if user.status == ProfileStatus.ACTIVE.value:
2287:         for ug in current_assignments:
2288:             if ug.group:
2289:                 ldap_client.remove_user_from_group(user.username, ug.group.ldap_dn)
2290: 
2291: 
2292:     for ug in current_assignments:
2293:         await session.delete(ug)
2294: 
2295: 
2296:     for group_id in request.group_ids:
2297:         try:
2298:             group_uuid = uuid.UUID(group_id)
2299:         except ValueError:
2300:             continue
2301: 
2302:         result = await session.execute(select(Group).where(Group.id == group_uuid))
2303:         group = result.scalar_one_or_none()
2304:         if not group:
2305:             continue
2306: 
2307: 
2308:         if user.status == ProfileStatus.ACTIVE.value:
2309:             ldap_client.add_user_to_group(user.username, group.ldap_dn)
2310: 
2311:         user_group = UserGroup(
2312:             user_id=user_uuid,
2313:             group_id=group_uuid,
2314:             assigned_by=current["username"],
2315:         )
2316:         session.add(user_group)
2317: 
2318:     await session.commit()
2319: 
2320: 
2321:     result = await session.execute(
2322:         select(UserGroup).where(UserGroup.user_id == user_uuid).options(
2323:             selectinload(UserGroup.group)
2324:         )
2325:     )
2326:     user_groups = result.scalars().all()
2327: 
2328:     groups = [
2329:         {
2330:             "id": str(ug.group_id),
2331:             "name": ug.group.name if ug.group else "",
2332:             "assigned_at": ug.assigned_at.isoformat() if ug.assigned_at else "",
2333:             "assigned_by": ug.assigned_by,
2334:         }
2335:         for ug in user_groups
2336:     ]
2337: 
2338:     logger.info(f"Groups replaced for user {user.username}")
2339: 
2340:     return UserGroupResponse(
2341:         user_id=str(user.id),
2342:         username=user.username,
2343:         groups=groups,
2344:     )
2345: 
2346: 
2347: @router.delete(
2348:     "/admin/users/{user_id}/groups/{group_id}",
2349:     response_model=AdminActivateResponse,
2350:     responses={
2351:         401: {"description": "Not authenticated"},
2352:         403: {"description": "Not admin"},
2353:         404: {"description": "User or assignment not found"},
2354:     },
2355: )
2356: async def admin_remove_user_from_group(
2357:     user_id: str,
2358:     group_id: str,
2359:     authorization: Optional[str] = Header(None),
2360:     session: AsyncSession = Depends(get_async_session),
2361: ) -> AdminActivateResponse:
2362: 
2363:     await _require_admin(authorization, session)
2364: 
2365:     try:
2366:         user_uuid = uuid.UUID(user_id)
2367:         group_uuid = uuid.UUID(group_id)
2368:     except ValueError:
2369:         raise HTTPException(
2370:             status_code=status.HTTP_400_BAD_REQUEST,
2371:             detail="Invalid ID format",
2372:         )
2373: 
2374: 
2375:     result = await session.execute(select(User).where(User.id == user_uuid))
2376:     user = result.scalar_one_or_none()
2377:     if not user:
2378:         raise HTTPException(
2379:             status_code=status.HTTP_404_NOT_FOUND,
2380:             detail="User not found",
2381:         )
2382: 
2383: 
2384:     result = await session.execute(
2385:         select(UserGroup).where(
2386:             UserGroup.user_id == user_uuid,
2387:             UserGroup.group_id == group_uuid,
2388:         ).options(selectinload(UserGroup.group))
2389:     )
2390:     user_group = result.scalar_one_or_none()
2391: 
2392:     if not user_group:
2393:         raise HTTPException(
2394:             status_code=status.HTTP_404_NOT_FOUND,
2395:             detail="User is not assigned to this group",
2396:         )
2397: 
2398: 
2399:     if user.status == ProfileStatus.ACTIVE.value and user_group.group:
2400:         ldap_client = LDAPClient()
2401:         ldap_client.remove_user_from_group(user.username, user_group.group.ldap_dn)
2402: 
2403:     group_name = user_group.group.name if user_group.group else "Unknown"
2404:     await session.delete(user_group)
2405:     await session.commit()
2406: 
2407:     logger.info(f"User {user.username} removed from group {group_name}")
2408: 
2409:     return AdminActivateResponse(
2410:         success=True,
2411:         message=f"User removed from group {group_name}",
2412:     )
2413: 
2414: 
2415: # ============================================================================
2416: # User Revoke Endpoint (Admin)
2417: # ============================================================================
2418: 
2419: @router.post(
2420:     "/admin/users/{user_id}/revoke",
2421:     response_model=AdminActivateResponse,
2422:     responses={
2423:         401: {"description": "Not authenticated"},
2424:         403: {"description": "Not admin or user not active"},
2425:         404: {"description": "User not found"},
2426:     },
2427: )
2428: async def admin_revoke_user(
2429:     user_id: str,
2430:     authorization: Optional[str] = Header(None),
2431:     session: AsyncSession = Depends(get_async_session),
2432: ) -> AdminActivateResponse:
2433: 
2434: 
2435: 
2436: 
2437: 
2438: 
2439: 
2440:     current = await _require_admin(authorization, session)
2441: 
2442:     try:
2443:         user_uuid = uuid.UUID(user_id)
2444:     except ValueError:
2445:         raise HTTPException(
2446:             status_code=status.HTTP_400_BAD_REQUEST,
2447:             detail="Invalid user ID format",
2448:         )
2449: 
2450:     result = await session.execute(
2451:         select(User).where(User.id == user_uuid).options(
2452:             selectinload(User.user_groups).selectinload(UserGroup.group)
2453:         )
2454:     )
2455:     user = result.scalar_one_or_none()
2456: 
2457:     if not user:
2458:         raise HTTPException(
2459:             status_code=status.HTTP_404_NOT_FOUND,
2460:             detail="User not found",
2461:         )
2462: 
2463:     if user.status != ProfileStatus.ACTIVE.value:
2464:         raise HTTPException(
2465:             status_code=status.HTTP_403_FORBIDDEN,
2466:             detail="Only active users can be revoked",
2467:         )
2468: 
2469:     ldap_client = LDAPClient()
2470: 
2471: 
2472:     for ug in user.user_groups:
2473:         if ug.group:
2474:             success, msg = ldap_client.remove_user_from_group(
2475:                 user.username, ug.group.ldap_dn
2476:             )
2477:             if not success:
2478:                 logger.warning(f"Failed to remove {user.username} from LDAP group: {msg}")
2479: 
2480:     # Delete from LDAP
2481:     success, message = ldap_client.delete_user(user.username)
2482:     if not success:
2483:         logger.warning(f"Failed to delete LDAP user: {message}")
2484: 
2485:     # Update status to revoked
2486:     user.status = ProfileStatus.REVOKED.value
2487: 
2488:     # Remove all group assignments from database
2489:     for ug in user.user_groups:
2490:         await session.delete(ug)
2491: 
2492:     await session.commit()
2493: 
2494:     logger.info(f"User {user.username} revoked by {current['username']}")
2495: 
2496:     return AdminActivateResponse(
2497:         success=True,
2498:         message=f"User {user.username} has been revoked",
2499:     )
2500: 
2501: 
2502: 
2503: 
2504: 
2505: 
2506: @router.get(
2507:     "/admin/users/enhanced",
2508:     response_model=AdminUserListResponse,
2509:     responses={401: {"description": "Not authenticated"}, 403: {"description": "Not admin"}},
2510: )
2511: async def admin_list_users_enhanced(
2512:     status_filter: Optional[str] = Query(None, description="Filter by status"),
2513:     group_filter: Optional[str] = Query(None, description="Filter by group ID"),
2514:     search: Optional[str] = Query(None, description="Search term"),
2515:     sort_by: Optional[str] = Query("created_at", description="Sort field"),
2516:     sort_order: Optional[str] = Query("desc", description="Sort order"),
2517:     authorization: Optional[str] = Header(None),
2518:     session: AsyncSession = Depends(get_async_session),
2519: ) -> AdminUserListResponse:
2520: 
2521:     await _require_admin(authorization, session)
2522: 
2523:     query = select(User).options(
2524:         selectinload(User.user_groups).selectinload(UserGroup.group)
2525:     )
2526: 
2527: 
2528:     if status_filter:
2529:         query = query.where(User.status == status_filter)
2530: 
2531: 
2532:     if search:
2533:         search_term = f"%{search}%"
2534:         query = query.where(
2535:             or_(
2536:                 User.username.ilike(search_term),
2537:                 User.email.ilike(search_term),
2538:                 User.first_name.ilike(search_term),
2539:                 User.last_name.ilike(search_term),
2540:             )
2541:         )
2542: 
2543:     # Apply sorting
2544:     if sort_by == "username":
2545:         order_col = User.username
2546:     elif sort_by == "email":
2547:         order_col = User.email
2548:     elif sort_by == "first_name":
2549:         order_col = User.first_name
2550:     elif sort_by == "status":
2551:         order_col = User.status
2552:     else:
2553:         order_col = User.created_at
2554: 
2555:     if sort_order == "asc":
2556:         query = query.order_by(order_col.asc())
2557:     else:
2558:         query = query.order_by(order_col.desc())
2559: 
2560:     result = await session.execute(query)
2561:     users = result.scalars().all()
2562: 
2563: 
2564:     if group_filter:
2565:         try:
2566:             group_uuid = uuid.UUID(group_filter)
2567:             users = [
2568:                 u for u in users
2569:                 if any(ug.group_id == group_uuid for ug in u.user_groups)
2570:             ]
2571:         except ValueError:
2572:             pass
2573: 
2574:     user_list = [
2575:         {
2576:             "id": str(u.id),
2577:             "username": u.username,
2578:             "email": u.email,
2579:             "first_name": u.first_name,
2580:             "last_name": u.last_name,
2581:             "phone": u.full_phone_number,
2582:             "status": u.status,
2583:             "email_verified": u.email_verified,
2584:             "phone_verified": u.phone_verified,
2585:             "mfa_method": u.mfa_method,
2586:             "created_at": u.created_at.isoformat() if u.created_at else "",
2587:             "activated_at": u.activated_at.isoformat() if u.activated_at else None,
2588:             "activated_by": u.activated_by,
2589:             "groups": [
2590:                 {"id": str(ug.group_id), "name": ug.group.name if ug.group else ""}
2591:                 for ug in u.user_groups
2592:             ],
2593:         }
2594:         for u in users
2595:     ]
2596: 
2597:     return AdminUserListResponse(users=user_list, total=len(user_list))
````

## File: application/backend/src/app/config.py
````python
 1: import os
 2: from functools import lru_cache
 3: 
 4: from pydantic_settings import BaseSettings
 5: 
 6: 
 7: class Settings(BaseSettings):
 8: 
 9: 
10: 
11:     ldap_host: str = os.getenv("LDAP_HOST", "openldap-stack-ha.ldap.svc.cluster.local")
12:     ldap_port: int = int(os.getenv("LDAP_PORT", "389"))
13:     ldap_use_ssl: bool = os.getenv("LDAP_USE_SSL", "false").lower() == "true"
14:     ldap_base_dn: str = os.getenv("LDAP_BASE_DN", "dc=ldap,dc=talorlik,dc=internal")
15:     ldap_admin_dn: str = os.getenv(
16:         "LDAP_ADMIN_DN", "cn=admin,dc=ldap,dc=talorlik,dc=internal"
17:     )
18:     ldap_admin_password: str = os.getenv("LDAP_ADMIN_PASSWORD", "")
19:     ldap_user_search_base: str = os.getenv("LDAP_USER_SEARCH_BASE", "ou=users")
20:     ldap_user_search_filter: str = os.getenv("LDAP_USER_SEARCH_FILTER", "(uid={0})")
21:     ldap_admin_group_dn: str = os.getenv(
22:         "LDAP_ADMIN_GROUP_DN", "cn=admins,ou=groups,dc=ldap,dc=talorlik,dc=internal"
23:     )
24:     ldap_group_search_base: str = os.getenv("LDAP_GROUP_SEARCH_BASE", "ou=groups")
25:     ldap_users_gid: int = int(os.getenv("LDAP_USERS_GID", "500"))
26:     ldap_uid_start: int = int(os.getenv("LDAP_UID_START", "10000"))
27: 
28: 
29:     totp_issuer: str = os.getenv("TOTP_ISSUER", "LDAP-2FA-App")
30:     totp_digits: int = int(os.getenv("TOTP_DIGITS", "6"))
31:     totp_interval: int = int(os.getenv("TOTP_INTERVAL", "30"))
32:     totp_algorithm: str = os.getenv("TOTP_ALGORITHM", "SHA1")
33: 
34: 
35:     enable_sms_2fa: bool = os.getenv("ENABLE_SMS_2FA", "false").lower() == "true"
36:     aws_region: str = os.getenv("AWS_REGION", "us-east-1")
37:     sns_topic_arn: str = os.getenv("SNS_TOPIC_ARN", "")
38:     sms_sender_id: str = os.getenv("SMS_SENDER_ID", "2FA")
39:     sms_type: str = os.getenv("SMS_TYPE", "Transactional")
40:     sms_code_length: int = int(os.getenv("SMS_CODE_LENGTH", "6"))
41:     sms_code_expiry_seconds: int = int(os.getenv("SMS_CODE_EXPIRY_SECONDS", "300"))
42:     sms_message_template: str = os.getenv(
43:         "SMS_MESSAGE_TEMPLATE",
44:         "Your verification code is: {code}. It expires in 5 minutes."
45:     )
46: 
47: 
48:     redis_enabled: bool = os.getenv("REDIS_ENABLED", "false").lower() == "true"
49:     redis_host: str = os.getenv("REDIS_HOST", "redis-master.redis.svc.cluster.local")
50:     redis_port: int = int(os.getenv("REDIS_PORT", "6379"))
51:     redis_password: str = os.getenv("REDIS_PASSWORD", "")
52:     redis_db: int = int(os.getenv("REDIS_DB", "0"))
53:     redis_ssl: bool = os.getenv("REDIS_SSL", "false").lower() == "true"
54:     redis_key_prefix: str = os.getenv("REDIS_KEY_PREFIX", "sms_otp:")
55: 
56: 
57:     database_url: str = os.getenv(
58:         "DATABASE_URL",
59:         "postgresql+asyncpg://ldap2fa:ldap2fa@localhost:5432/ldap2fa"
60:     )
61: 
62: 
63:     enable_email_verification: bool = os.getenv(
64:         "ENABLE_EMAIL_VERIFICATION", "true"
65:     ).lower() == "true"
66:     ses_sender_email: str = os.getenv("SES_SENDER_EMAIL", "noreply@example.com")
67:     email_verification_expiry_hours: int = int(
68:         os.getenv("EMAIL_VERIFICATION_EXPIRY_HOURS", "24")
69:     )
70:     app_url: str = os.getenv("APP_URL", "http://localhost:8080")
71: 
72: 
73:     app_name: str = os.getenv("APP_NAME", "LDAP 2FA Backend API")
74:     debug: bool = os.getenv("DEBUG", "false").lower() == "true"
75:     log_level: str = os.getenv("LOG_LEVEL", "INFO")
76: 
77: 
78:     jwt_secret_key: str = os.getenv("JWT_SECRET_KEY", "change-me-in-production-use-secure-random-key")
79:     jwt_algorithm: str = os.getenv("JWT_ALGORITHM", "HS256")
80:     jwt_expiry_minutes: int = int(os.getenv("JWT_EXPIRY_MINUTES", "60"))
81:     jwt_refresh_expiry_days: int = int(os.getenv("JWT_REFRESH_EXPIRY_DAYS", "7"))
82: 
83: 
84:     cors_origins: list[str] = os.getenv("CORS_ORIGINS", "").split(",") if os.getenv(
85:         "CORS_ORIGINS"
86:     ) else []
87: 
88:     class Config:
89: 
90: 
91:         env_file = ".env"
92:         env_file_encoding = "utf-8"
93: 
94: 
95: @lru_cache
96: def get_settings() -> Settings:
97: 
98:     return Settings()
````

## File: application/backend/src/app/main.py
````python
 1: import logging
 2: import sys
 3: 
 4: from fastapi import FastAPI
 5: from fastapi.middleware.cors import CORSMiddleware
 6: 
 7: from app.api import router
 8: from app.config import get_settings
 9: from app.database import init_db, close_db
10: 
11: 
12: settings = get_settings()
13: logging.basicConfig(
14:     level=getattr(logging, settings.log_level.upper()),
15:     format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
16:     handlers=[logging.StreamHandler(sys.stdout)],
17: )
18: 
19: logger = logging.getLogger(__name__)
20: 
21: 
22: app = FastAPI(
23:     title=settings.app_name,
24:     description="Two-Factor Authentication API with LDAP, TOTP, and user signup support",
25:     version="2.0.0",
26:     docs_url="/api/docs",
27:     redoc_url="/api/redoc",
28:     openapi_url="/api/openapi.json",
29: )
30: 
31: 
32: if settings.cors_origins:
33:     app.add_middleware(
34:         CORSMiddleware,
35:         allow_origins=settings.cors_origins,
36:         allow_credentials=True,
37:         allow_methods=["*"],
38:         allow_headers=["*"],
39:     )
40:     logger.info(f"CORS enabled for origins: {settings.cors_origins}")
41: 
42: # Include API routes
43: app.include_router(router)
44: 
45: 
46: @app.on_event("startup")
47: async def startup_event():
48: 
49:     logger.info(f"Starting {settings.app_name}")
50: 
51:     # Initialize database
52:     try:
53:         await init_db()
54:         logger.info("Database connection established")
55:     except Exception as e:
56:         logger.error(f"Failed to initialize database: {e}")
57:         raise
58: 
59:     logger.info(f"LDAP Host: {settings.ldap_host}:{settings.ldap_port}")
60:     logger.info(f"TOTP Issuer: {settings.totp_issuer}")
61:     logger.info(f"Email verification: {'enabled' if settings.enable_email_verification else 'disabled'}")
62:     logger.info(f"SMS 2FA: {'enabled' if settings.enable_sms_2fa else 'disabled'}")
63:     logger.info(f"Debug mode: {settings.debug}")
64: 
65: 
66: @app.on_event("shutdown")
67: async def shutdown_event():
68: 
69:     logger.info(f"Shutting down {settings.app_name}")
70: 
71:     # Close database connection
72:     await close_db()
73:     logger.info("Database connection closed")
74: 
75: 
76: if __name__ == "__main__":
77:     import uvicorn
78: 
79:     uvicorn.run(
80:         "app.main:app",
81:         host="0.0.0.0",
82:         port=8000,
83:         reload=settings.debug,
84:         log_level=settings.log_level.lower(),
85:     )
````

## File: application/backend/src/requirements.txt
````
 1: # Core framework
 2: fastapi==0.115.6
 3: uvicorn[standard]==0.34.0
 4: gunicorn==23.0.0
 5: 
 6: # Settings management
 7: pydantic==2.10.4
 8: pydantic-settings==2.7.1
 9: 
10: # LDAP
11: ldap3==2.9.1
12: 
13: # AWS SDK for SNS (SMS) and SES (Email)
14: boto3==1.35.81
15: 
16: # Database (PostgreSQL)
17: sqlalchemy[asyncio]==2.0.36
18: asyncpg==0.30.0
19: alembic==1.14.0
20: 
21: # Redis for SMS OTP storage
22: redis==5.2.1
23: 
24: # Password hashing
25: bcrypt==4.2.1
26: 
27: # JWT for session management
28: PyJWT==2.10.1
29: 
30: # Email validation
31: email-validator==2.2.0
32: 
33: # Production server
34: python-multipart==0.0.20
````

## File: application/frontend/src/css/styles.css
````css
   1: :root {
   2:     --primary-color: #4f46e5;
   3:     --primary-hover: #4338ca;
   4:     --secondary-color: #64748b;
   5:     --success-color: #22c55e;
   6:     --error-color: #ef4444;
   7:     --warning-color: #f59e0b;
   8:     --info-color: #3b82f6;
   9:     --background-color: #f8fafc;
  10:     --card-background: #ffffff;
  11:     --text-primary: #1e293b;
  12:     --text-secondary: #64748b;
  13:     --border-color: #e2e8f0;
  14:     --input-background: #f1f5f9;
  15:     --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
  16:     --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
  17:     --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -4px rgba(0, 0, 0, 0.1);
  18:     --border-radius: 12px;
  19:     --transition: all 0.2s ease-in-out;
  20: }
  21: 
  22: 
  23: *, *::before, *::after {
  24:     box-sizing: border-box;
  25:     margin: 0;
  26:     padding: 0;
  27: }
  28: 
  29: body {
  30:     font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
  31:     background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  32:     min-height: 100vh;
  33:     display: flex;
  34:     align-items: center;
  35:     justify-content: center;
  36:     padding: 20px;
  37:     color: var(--text-primary);
  38:     line-height: 1.6;
  39: }
  40: 
  41: 
  42: .container {
  43:     background: var(--card-background);
  44:     border-radius: var(--border-radius);
  45:     box-shadow: var(--shadow-lg);
  46:     padding: 40px;
  47:     width: 100%;
  48:     max-width: 520px;
  49:     animation: fadeIn 0.5s ease-out;
  50: }
  51: 
  52: @keyframes fadeIn {
  53:     from {
  54:         opacity: 0;
  55:         transform: translateY(-20px);
  56:     }
  57:     to {
  58:         opacity: 1;
  59:         transform: translateY(0);
  60:     }
  61: }
  62: 
  63: 
  64: header {
  65:     text-align: center;
  66:     margin-bottom: 30px;
  67: }
  68: 
  69: header h1 {
  70:     font-size: 1.75rem;
  71:     font-weight: 700;
  72:     color: var(--text-primary);
  73:     margin-bottom: 8px;
  74: }
  75: 
  76: header .subtitle {
  77:     color: var(--text-secondary);
  78:     font-size: 0.95rem;
  79: }
  80: 
  81: 
  82: .tabs {
  83:     display: flex;
  84:     gap: 8px;
  85:     margin-bottom: 24px;
  86:     background: var(--input-background);
  87:     padding: 4px;
  88:     border-radius: 10px;
  89:     flex-wrap: wrap;
  90: }
  91: 
  92: .tab-btn {
  93:     flex: 1;
  94:     padding: 12px 12px;
  95:     border: none;
  96:     background: transparent;
  97:     color: var(--text-secondary);
  98:     font-size: 0.9rem;
  99:     font-weight: 500;
 100:     cursor: pointer;
 101:     border-radius: 8px;
 102:     transition: var(--transition);
 103:     min-width: fit-content;
 104: }
 105: 
 106: .tab-btn:hover {
 107:     color: var(--text-primary);
 108: }
 109: 
 110: .tab-btn.active {
 111:     background: var(--card-background);
 112:     color: var(--primary-color);
 113:     box-shadow: var(--shadow-sm);
 114: }
 115: 
 116: 
 117: .tab-content {
 118:     display: none;
 119: }
 120: 
 121: .tab-content.active {
 122:     display: block;
 123:     animation: fadeIn 0.3s ease-out;
 124: }
 125: 
 126: 
 127: .auth-form {
 128:     display: flex;
 129:     flex-direction: column;
 130:     gap: 20px;
 131: }
 132: 
 133: .form-row {
 134:     display: grid;
 135:     grid-template-columns: 1fr 1fr;
 136:     gap: 16px;
 137: }
 138: 
 139: .form-group {
 140:     display: flex;
 141:     flex-direction: column;
 142:     gap: 6px;
 143: }
 144: 
 145: .form-group label {
 146:     font-size: 0.9rem;
 147:     font-weight: 500;
 148:     color: var(--text-primary);
 149: }
 150: 
 151: .form-group input,
 152: .form-group select {
 153:     padding: 14px 16px;
 154:     border: 2px solid var(--border-color);
 155:     border-radius: 10px;
 156:     font-size: 1rem;
 157:     background: var(--input-background);
 158:     transition: var(--transition);
 159: }
 160: 
 161: .form-group input:focus,
 162: .form-group select:focus {
 163:     outline: none;
 164:     border-color: var(--primary-color);
 165:     background: var(--card-background);
 166:     box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1);
 167: }
 168: 
 169: .form-group input::placeholder {
 170:     color: var(--text-secondary);
 171: }
 172: 
 173: 
 174: .phone-input-group {
 175:     display: flex;
 176:     gap: 8px;
 177: }
 178: 
 179: .phone-input-group select {
 180:     width: 120px;
 181:     flex-shrink: 0;
 182: }
 183: 
 184: .phone-input-group input {
 185:     flex: 1;
 186: }
 187: 
 188: 
 189: .btn {
 190:     padding: 14px 24px;
 191:     border: none;
 192:     border-radius: 10px;
 193:     font-size: 1rem;
 194:     font-weight: 600;
 195:     cursor: pointer;
 196:     transition: var(--transition);
 197:     display: flex;
 198:     align-items: center;
 199:     justify-content: center;
 200:     gap: 8px;
 201: }
 202: 
 203: .btn-primary {
 204:     background: var(--primary-color);
 205:     color: white;
 206: }
 207: 
 208: .btn-primary:hover {
 209:     background: var(--primary-hover);
 210:     transform: translateY(-1px);
 211:     box-shadow: var(--shadow-md);
 212: }
 213: 
 214: .btn-primary:active {
 215:     transform: translateY(0);
 216: }
 217: 
 218: .btn-secondary {
 219:     background: var(--input-background);
 220:     color: var(--text-primary);
 221:     border: 2px solid var(--border-color);
 222: }
 223: 
 224: .btn-secondary:hover {
 225:     background: var(--border-color);
 226: }
 227: 
 228: .btn-small {
 229:     padding: 8px 16px;
 230:     font-size: 0.85rem;
 231: }
 232: 
 233: .btn:disabled {
 234:     opacity: 0.7;
 235:     cursor: not-allowed;
 236:     transform: none;
 237: }
 238: 
 239: .btn-loading {
 240:     display: none;
 241: }
 242: 
 243: .btn.loading .btn-text {
 244:     display: none;
 245: }
 246: 
 247: .btn.loading .btn-loading {
 248:     display: inline;
 249: }
 250: 
 251: 
 252: .result-container {
 253:     margin-top: 24px;
 254:     padding: 20px;
 255:     border-radius: 10px;
 256:     animation: fadeIn 0.3s ease-out;
 257: }
 258: 
 259: .result-container.success {
 260:     background: rgba(34, 197, 94, 0.1);
 261:     border: 2px solid var(--success-color);
 262: }
 263: 
 264: .result-container.error {
 265:     background: rgba(239, 68, 68, 0.1);
 266:     border: 2px solid var(--error-color);
 267: }
 268: 
 269: .result-container h3 {
 270:     font-size: 1.1rem;
 271:     margin-bottom: 8px;
 272: }
 273: 
 274: .result-container.success h3 {
 275:     color: var(--success-color);
 276: }
 277: 
 278: .result-container.error h3 {
 279:     color: var(--error-color);
 280: }
 281: 
 282: .result-container p {
 283:     color: var(--text-secondary);
 284:     font-size: 0.95rem;
 285: }
 286: 
 287: .admin-badge {
 288:     display: inline-block;
 289:     background: linear-gradient(135deg, #f59e0b 0%, #ef4444 100%);
 290:     color: white;
 291:     padding: 4px 12px;
 292:     border-radius: 20px;
 293:     font-size: 0.85rem;
 294:     font-weight: 600;
 295:     margin-top: 8px;
 296: }
 297: 
 298: 
 299: .qr-section {
 300:     text-align: center;
 301: }
 302: 
 303: .qr-section h3 {
 304:     color: var(--text-primary);
 305:     margin-bottom: 8px;
 306: }
 307: 
 308: .qr-section > p {
 309:     margin-bottom: 20px;
 310: }
 311: 
 312: .qr-code {
 313:     display: inline-block;
 314:     padding: 16px;
 315:     background: white;
 316:     border-radius: 12px;
 317:     box-shadow: var(--shadow-md);
 318:     margin-bottom: 20px;
 319: }
 320: 
 321: .qr-code canvas {
 322:     display: block;
 323: }
 324: 
 325: .manual-entry {
 326:     padding: 16px;
 327:     background: var(--input-background);
 328:     border-radius: 10px;
 329:     margin-top: 16px;
 330: }
 331: 
 332: .manual-entry p {
 333:     font-size: 0.85rem;
 334:     margin-bottom: 12px;
 335: }
 336: 
 337: .manual-entry code {
 338:     display: block;
 339:     padding: 12px;
 340:     background: var(--card-background);
 341:     border: 2px solid var(--border-color);
 342:     border-radius: 8px;
 343:     font-family: 'Monaco', 'Consolas', monospace;
 344:     font-size: 0.9rem;
 345:     word-break: break-all;
 346:     margin-bottom: 12px;
 347:     color: var(--primary-color);
 348: }
 349: 
 350: 
 351: .status-message {
 352:     position: fixed;
 353:     top: 20px;
 354:     left: 50%;
 355:     transform: translateX(-50%);
 356:     padding: 14px 24px;
 357:     border-radius: 10px;
 358:     font-weight: 500;
 359:     box-shadow: var(--shadow-lg);
 360:     z-index: 1000;
 361:     animation: slideDown 0.3s ease-out;
 362: }
 363: 
 364: @keyframes slideDown {
 365:     from {
 366:         opacity: 0;
 367:         transform: translateX(-50%) translateY(-20px);
 368:     }
 369:     to {
 370:         opacity: 1;
 371:         transform: translateX(-50%) translateY(0);
 372:     }
 373: }
 374: 
 375: .status-message.success {
 376:     background: var(--success-color);
 377:     color: white;
 378: }
 379: 
 380: .status-message.error {
 381:     background: var(--error-color);
 382:     color: white;
 383: }
 384: 
 385: .status-message.warning {
 386:     background: var(--warning-color);
 387:     color: white;
 388: }
 389: 
 390: 
 391: .mfa-method-selector {
 392:     display: flex;
 393:     flex-direction: column;
 394:     gap: 12px;
 395: }
 396: 
 397: .radio-option {
 398:     display: block;
 399:     cursor: pointer;
 400: }
 401: 
 402: .radio-option input[type="radio"] {
 403:     position: absolute;
 404:     opacity: 0;
 405:     width: 0;
 406:     height: 0;
 407: }
 408: 
 409: .radio-label {
 410:     display: flex;
 411:     align-items: center;
 412:     gap: 12px;
 413:     padding: 14px 16px;
 414:     border: 2px solid var(--border-color);
 415:     border-radius: 10px;
 416:     background: var(--input-background);
 417:     transition: var(--transition);
 418: }
 419: 
 420: .radio-option input[type="radio"]:checked + .radio-label {
 421:     border-color: var(--primary-color);
 422:     background: rgba(79, 70, 229, 0.05);
 423: }
 424: 
 425: .radio-option:hover .radio-label {
 426:     border-color: var(--primary-color);
 427: }
 428: 
 429: .radio-icon {
 430:     font-size: 1.5rem;
 431: }
 432: 
 433: .radio-text {
 434:     display: flex;
 435:     flex-direction: column;
 436:     gap: 2px;
 437: }
 438: 
 439: .radio-text strong {
 440:     font-size: 0.95rem;
 441:     color: var(--text-primary);
 442: }
 443: 
 444: .radio-text small {
 445:     font-size: 0.8rem;
 446:     color: var(--text-secondary);
 447: }
 448: 
 449: 
 450: .code-input-group {
 451:     display: flex;
 452:     gap: 8px;
 453: }
 454: 
 455: .code-input-group input {
 456:     flex: 1;
 457: }
 458: 
 459: .code-input-group .btn {
 460:     white-space: nowrap;
 461: }
 462: 
 463: 
 464: .form-hint {
 465:     font-size: 0.8rem;
 466:     color: var(--text-secondary);
 467:     margin-top: 4px;
 468: }
 469: 
 470: 
 471: .sms-section {
 472:     text-align: center;
 473:     padding: 20px;
 474: }
 475: 
 476: .sms-section h3 {
 477:     color: var(--success-color);
 478:     margin-bottom: 12px;
 479: }
 480: 
 481: .sms-section p {
 482:     margin-bottom: 8px;
 483: }
 484: 
 485: .sms-section .hint {
 486:     font-size: 0.85rem;
 487:     color: var(--text-secondary);
 488: }
 489: 
 490: 
 491: .radio-option.disabled {
 492:     opacity: 0.5;
 493:     cursor: not-allowed;
 494: }
 495: 
 496: .radio-option.disabled .radio-label {
 497:     pointer-events: none;
 498: }
 499: 
 500: 
 501: .verification-panel {
 502:     padding: 24px;
 503:     background: var(--input-background);
 504:     border-radius: 12px;
 505:     margin-top: 20px;
 506: }
 507: 
 508: .verification-panel h3 {
 509:     font-size: 1.2rem;
 510:     color: var(--text-primary);
 511:     margin-bottom: 8px;
 512: }
 513: 
 514: .verification-subtitle {
 515:     color: var(--text-secondary);
 516:     margin-bottom: 20px;
 517: }
 518: 
 519: .verification-items {
 520:     display: flex;
 521:     flex-direction: column;
 522:     gap: 16px;
 523:     margin-bottom: 24px;
 524: }
 525: 
 526: .verification-item {
 527:     display: flex;
 528:     align-items: center;
 529:     gap: 12px;
 530:     padding: 16px;
 531:     background: var(--card-background);
 532:     border-radius: 10px;
 533:     border: 2px solid var(--border-color);
 534: }
 535: 
 536: .verification-item .status-icon {
 537:     font-size: 1.5rem;
 538: }
 539: 
 540: .verification-details {
 541:     flex: 1;
 542: }
 543: 
 544: .verification-label {
 545:     display: block;
 546:     font-weight: 600;
 547:     color: var(--text-primary);
 548: }
 549: 
 550: .verification-hint {
 551:     display: block;
 552:     font-size: 0.85rem;
 553:     color: var(--text-secondary);
 554: }
 555: 
 556: .phone-verify-input {
 557:     margin-bottom: 20px;
 558: }
 559: 
 560: .verification-complete {
 561:     text-align: center;
 562:     padding: 24px;
 563:     background: rgba(34, 197, 94, 0.1);
 564:     border-radius: 10px;
 565:     border: 2px solid var(--success-color);
 566: }
 567: 
 568: .verification-complete .success-icon {
 569:     font-size: 3rem;
 570:     margin-bottom: 12px;
 571: }
 572: 
 573: .verification-complete h4 {
 574:     color: var(--success-color);
 575:     margin-bottom: 8px;
 576: }
 577: 
 578: .verification-complete p {
 579:     color: var(--text-secondary);
 580: }
 581: 
 582: 
 583: .admin-section {
 584:     animation: fadeIn 0.3s ease-out;
 585: }
 586: 
 587: .admin-header {
 588:     display: flex;
 589:     justify-content: space-between;
 590:     align-items: center;
 591:     margin-bottom: 20px;
 592: }
 593: 
 594: .admin-header h3 {
 595:     font-size: 1.2rem;
 596:     color: var(--text-primary);
 597: }
 598: 
 599: .admin-filters {
 600:     display: flex;
 601:     gap: 12px;
 602:     margin-bottom: 20px;
 603: }
 604: 
 605: .admin-filters select {
 606:     flex: 1;
 607:     padding: 10px 14px;
 608:     border: 2px solid var(--border-color);
 609:     border-radius: 8px;
 610:     background: var(--input-background);
 611:     font-size: 0.9rem;
 612: }
 613: 
 614: .admin-users-list {
 615:     display: flex;
 616:     flex-direction: column;
 617:     gap: 16px;
 618:     max-height: 400px;
 619:     overflow-y: auto;
 620: }
 621: 
 622: .user-card {
 623:     padding: 16px;
 624:     background: var(--input-background);
 625:     border-radius: 10px;
 626:     border: 2px solid var(--border-color);
 627:     transition: var(--transition);
 628: }
 629: 
 630: .user-card:hover {
 631:     border-color: var(--primary-color);
 632: }
 633: 
 634: .user-info {
 635:     margin-bottom: 12px;
 636: }
 637: 
 638: .user-name {
 639:     font-weight: 600;
 640:     color: var(--text-primary);
 641:     font-size: 1.05rem;
 642: }
 643: 
 644: .user-username {
 645:     color: var(--text-secondary);
 646:     font-size: 0.9rem;
 647: }
 648: 
 649: .user-details {
 650:     display: flex;
 651:     gap: 16px;
 652:     margin-top: 8px;
 653:     font-size: 0.85rem;
 654:     color: var(--text-secondary);
 655: }
 656: 
 657: .user-status {
 658:     display: flex;
 659:     align-items: center;
 660:     gap: 12px;
 661:     margin-top: 8px;
 662: }
 663: 
 664: .status-badge {
 665:     padding: 4px 10px;
 666:     border-radius: 20px;
 667:     font-size: 0.75rem;
 668:     font-weight: 600;
 669:     text-transform: uppercase;
 670: }
 671: 
 672: .status-pending {
 673:     background: rgba(245, 158, 11, 0.2);
 674:     color: #d97706;
 675: }
 676: 
 677: .status-complete {
 678:     background: rgba(59, 130, 246, 0.2);
 679:     color: #2563eb;
 680: }
 681: 
 682: .status-active {
 683:     background: rgba(34, 197, 94, 0.2);
 684:     color: #16a34a;
 685: }
 686: 
 687: .verification-badges {
 688:     font-size: 0.8rem;
 689:     color: var(--text-secondary);
 690: }
 691: 
 692: .user-meta {
 693:     font-size: 0.8rem;
 694:     color: var(--text-secondary);
 695:     margin-top: 8px;
 696: }
 697: 
 698: .user-actions {
 699:     display: flex;
 700:     gap: 8px;
 701: }
 702: 
 703: .admin-no-users {
 704:     text-align: center;
 705:     padding: 40px 20px;
 706:     color: var(--text-secondary);
 707: }
 708: 
 709: .loading-spinner {
 710:     text-align: center;
 711:     padding: 40px 20px;
 712:     color: var(--text-secondary);
 713: }
 714: 
 715: .error-message {
 716:     text-align: center;
 717:     padding: 20px;
 718:     color: var(--error-color);
 719:     background: rgba(239, 68, 68, 0.1);
 720:     border-radius: 10px;
 721: }
 722: 
 723: 
 724: .hidden {
 725:     display: none !important;
 726: }
 727: 
 728: 
 729: footer {
 730:     margin-top: 30px;
 731:     text-align: center;
 732:     padding-top: 20px;
 733:     border-top: 1px solid var(--border-color);
 734: }
 735: 
 736: footer p {
 737:     color: var(--text-secondary);
 738:     font-size: 0.85rem;
 739: }
 740: 
 741: 
 742: @media (max-width: 540px) {
 743:     body {
 744:         padding: 10px;
 745:     }
 746: 
 747:     .container {
 748:         padding: 24px;
 749:     }
 750: 
 751:     header h1 {
 752:         font-size: 1.5rem;
 753:     }
 754: 
 755:     .tabs {
 756:         flex-direction: column;
 757:     }
 758: 
 759:     .tab-btn {
 760:         padding: 14px;
 761:     }
 762: 
 763:     .form-row {
 764:         grid-template-columns: 1fr;
 765:     }
 766: 
 767:     .phone-input-group {
 768:         flex-direction: column;
 769:     }
 770: 
 771:     .phone-input-group select {
 772:         width: 100%;
 773:     }
 774: 
 775:     .admin-filters {
 776:         flex-direction: column;
 777:     }
 778: 
 779:     .user-details {
 780:         flex-direction: column;
 781:         gap: 4px;
 782:     }
 783: 
 784:     .user-status {
 785:         flex-direction: column;
 786:         align-items: flex-start;
 787:         gap: 8px;
 788:     }
 789: 
 790:     .user-actions {
 791:         flex-direction: column;
 792:     }
 793: }
 794: 
 795: 
 796: @media (prefers-color-scheme: dark) {
 797:     :root {
 798:         --background-color: #0f172a;
 799:         --card-background: #1e293b;
 800:         --text-primary: #f1f5f9;
 801:         --text-secondary: #94a3b8;
 802:         --border-color: #334155;
 803:         --input-background: #0f172a;
 804:     }
 805: 
 806:     body {
 807:         background: linear-gradient(135deg, #1e1b4b 0%, #312e81 100%);
 808:     }
 809: 
 810:     .form-group input:focus,
 811:     .form-group select:focus {
 812:         background: var(--card-background);
 813:     }
 814: 
 815:     .qr-code {
 816:         background: white;
 817:     }
 818: 
 819:     .user-card {
 820:         background: var(--card-background);
 821:     }
 822: 
 823:     .verification-panel {
 824:         background: var(--card-background);
 825:     }
 826: 
 827:     .verification-item {
 828:         background: var(--input-background);
 829:     }
 830: }
 831: 
 832: 
 833: @keyframes spin {
 834:     to {
 835:         transform: rotate(360deg);
 836:     }
 837: }
 838: 
 839: .spinner {
 840:     width: 20px;
 841:     height: 20px;
 842:     border: 2px solid transparent;
 843:     border-top-color: currentColor;
 844:     border-radius: 50%;
 845:     animation: spin 0.8s linear infinite;
 846:     display: inline-block;
 847:     margin-right: 8px;
 848: }
 849: 
 850: 
 851: .admin-users-list::-webkit-scrollbar {
 852:     width: 8px;
 853: }
 854: 
 855: .admin-users-list::-webkit-scrollbar-track {
 856:     background: var(--input-background);
 857:     border-radius: 4px;
 858: }
 859: 
 860: .admin-users-list::-webkit-scrollbar-thumb {
 861:     background: var(--border-color);
 862:     border-radius: 4px;
 863: }
 864: 
 865: .admin-users-list::-webkit-scrollbar-thumb:hover {
 866:     background: var(--text-secondary);
 867: }
 868: 
 869: 
 870: 
 871: 
 872: 
 873: .top-bar {
 874:     position: fixed;
 875:     top: 0;
 876:     left: 0;
 877:     right: 0;
 878:     height: 60px;
 879:     background: var(--card-background);
 880:     box-shadow: var(--shadow-md);
 881:     z-index: 1000;
 882: }
 883: 
 884: .top-bar-content {
 885:     max-width: 1200px;
 886:     margin: 0 auto;
 887:     height: 100%;
 888:     display: flex;
 889:     align-items: center;
 890:     justify-content: space-between;
 891:     padding: 0 24px;
 892: }
 893: 
 894: .top-bar-brand {
 895:     display: flex;
 896:     align-items: center;
 897:     gap: 10px;
 898:     font-size: 1.25rem;
 899:     font-weight: 700;
 900:     color: var(--primary-color);
 901: }
 902: 
 903: .brand-icon {
 904:     font-size: 1.5rem;
 905: }
 906: 
 907: .top-bar-user {
 908:     position: relative;
 909: }
 910: 
 911: .user-menu-btn {
 912:     display: flex;
 913:     align-items: center;
 914:     gap: 8px;
 915:     padding: 8px 16px;
 916:     border: 2px solid var(--border-color);
 917:     border-radius: 8px;
 918:     background: var(--input-background);
 919:     cursor: pointer;
 920:     font-size: 0.9rem;
 921:     font-weight: 500;
 922:     color: var(--text-primary);
 923:     transition: var(--transition);
 924: }
 925: 
 926: .user-menu-btn:hover {
 927:     border-color: var(--primary-color);
 928: }
 929: 
 930: .dropdown-arrow {
 931:     font-size: 0.7rem;
 932:     color: var(--text-secondary);
 933: }
 934: 
 935: .user-dropdown {
 936:     position: absolute;
 937:     top: calc(100% + 8px);
 938:     right: 0;
 939:     min-width: 200px;
 940:     background: var(--card-background);
 941:     border: 2px solid var(--border-color);
 942:     border-radius: 10px;
 943:     box-shadow: var(--shadow-lg);
 944:     overflow: hidden;
 945: }
 946: 
 947: .dropdown-item {
 948:     display: flex;
 949:     align-items: center;
 950:     gap: 10px;
 951:     padding: 12px 16px;
 952:     color: var(--text-primary);
 953:     text-decoration: none;
 954:     transition: var(--transition);
 955: }
 956: 
 957: .dropdown-item:hover {
 958:     background: var(--input-background);
 959: }
 960: 
 961: .dropdown-icon {
 962:     font-size: 1rem;
 963: }
 964: 
 965: .dropdown-divider {
 966:     border: none;
 967:     border-top: 1px solid var(--border-color);
 968:     margin: 0;
 969: }
 970: 
 971: 
 972: 
 973: 
 974: 
 975: .container.logged-in {
 976:     margin-top: 80px;
 977:     max-width: 1000px;
 978: }
 979: 
 980: .container.logged-in header:first-child {
 981:     display: none;
 982: }
 983: 
 984: 
 985: 
 986: 
 987: 
 988: .section-header {
 989:     display: flex;
 990:     justify-content: space-between;
 991:     align-items: center;
 992:     margin-bottom: 24px;
 993: }
 994: 
 995: .section-header h2 {
 996:     font-size: 1.5rem;
 997:     font-weight: 700;
 998:     color: var(--text-primary);
 999:     margin: 0;
1000: }
1001: 
1002: 
1003: 
1004: 
1005: 
1006: .admin-controls {
1007:     display: flex;
1008:     flex-wrap: wrap;
1009:     gap: 12px;
1010:     margin-bottom: 20px;
1011: }
1012: 
1013: .search-box {
1014:     flex: 1;
1015:     min-width: 200px;
1016: }
1017: 
1018: .search-input {
1019:     width: 100%;
1020:     padding: 10px 14px;
1021:     border: 2px solid var(--border-color);
1022:     border-radius: 8px;
1023:     background: var(--input-background);
1024:     font-size: 0.9rem;
1025:     color: var(--text-primary);
1026: }
1027: 
1028: .search-input:focus {
1029:     outline: none;
1030:     border-color: var(--primary-color);
1031: }
1032: 
1033: .filter-controls {
1034:     display: flex;
1035:     gap: 8px;
1036:     flex-wrap: wrap;
1037: }
1038: 
1039: .filter-select {
1040:     padding: 10px 14px;
1041:     border: 2px solid var(--border-color);
1042:     border-radius: 8px;
1043:     background: var(--input-background);
1044:     font-size: 0.9rem;
1045:     color: var(--text-primary);
1046:     min-width: 150px;
1047: }
1048: 
1049: 
1050: 
1051: 
1052: 
1053: .data-table-container {
1054:     overflow-x: auto;
1055:     margin-bottom: 20px;
1056: }
1057: 
1058: .data-table {
1059:     width: 100%;
1060:     border-collapse: collapse;
1061:     font-size: 0.9rem;
1062: }
1063: 
1064: .data-table th,
1065: .data-table td {
1066:     padding: 12px 16px;
1067:     text-align: left;
1068:     border-bottom: 1px solid var(--border-color);
1069: }
1070: 
1071: .data-table th {
1072:     background: var(--input-background);
1073:     font-weight: 600;
1074:     color: var(--text-secondary);
1075:     white-space: nowrap;
1076: }
1077: 
1078: .data-table th.sortable {
1079:     cursor: pointer;
1080:     user-select: none;
1081: }
1082: 
1083: .data-table th.sortable:hover {
1084:     color: var(--primary-color);
1085: }
1086: 
1087: .data-table th.sortable::after {
1088:     content: '';
1089:     margin-left: 8px;
1090:     opacity: 0.3;
1091: }
1092: 
1093: .data-table th.sort-asc::after {
1094:     content: '';
1095:     opacity: 1;
1096: }
1097: 
1098: .data-table th.sort-desc::after {
1099:     content: '';
1100:     opacity: 1;
1101: }
1102: 
1103: .data-table tbody tr:hover {
1104:     background: var(--input-background);
1105: }
1106: 
1107: .action-buttons {
1108:     display: flex;
1109:     gap: 8px;
1110:     flex-wrap: wrap;
1111: }
1112: 
1113: .btn-xs {
1114:     padding: 4px 10px;
1115:     font-size: 0.75rem;
1116: }
1117: 
1118: .btn-danger {
1119:     background: var(--error-color);
1120:     color: white;
1121: }
1122: 
1123: .btn-danger:hover {
1124:     background: #dc2626;
1125: }
1126: 
1127: 
1128: 
1129: 
1130: 
1131: .group-badges {
1132:     display: flex;
1133:     flex-wrap: wrap;
1134:     gap: 8px;
1135: }
1136: 
1137: .group-badge {
1138:     display: inline-block;
1139:     padding: 4px 12px;
1140:     background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
1141:     color: white;
1142:     border-radius: 20px;
1143:     font-size: 0.8rem;
1144:     font-weight: 500;
1145: }
1146: 
1147: .group-badge-small {
1148:     display: inline-block;
1149:     padding: 2px 8px;
1150:     background: var(--primary-color);
1151:     color: white;
1152:     border-radius: 12px;
1153:     font-size: 0.7rem;
1154:     font-weight: 500;
1155: }
1156: 
1157: .no-groups {
1158:     color: var(--text-secondary);
1159:     font-style: italic;
1160: }
1161: 
1162: 
1163: 
1164: 
1165: 
1166: .readonly-input {
1167:     background: var(--input-background) !important;
1168:     color: var(--text-secondary) !important;
1169:     cursor: not-allowed;
1170: }
1171: 
1172: 
1173: 
1174: 
1175: 
1176: .modal-overlay {
1177:     position: fixed;
1178:     top: 0;
1179:     left: 0;
1180:     right: 0;
1181:     bottom: 0;
1182:     background: rgba(0, 0, 0, 0.5);
1183:     display: flex;
1184:     align-items: center;
1185:     justify-content: center;
1186:     z-index: 2000;
1187:     padding: 20px;
1188: }
1189: 
1190: .modal {
1191:     background: var(--card-background);
1192:     border-radius: var(--border-radius);
1193:     box-shadow: var(--shadow-lg);
1194:     width: 100%;
1195:     max-width: 500px;
1196:     max-height: 90vh;
1197:     overflow-y: auto;
1198:     animation: fadeIn 0.2s ease-out;
1199: }
1200: 
1201: .modal-header {
1202:     display: flex;
1203:     justify-content: space-between;
1204:     align-items: center;
1205:     padding: 20px 24px;
1206:     border-bottom: 1px solid var(--border-color);
1207: }
1208: 
1209: .modal-header h3 {
1210:     margin: 0;
1211:     font-size: 1.25rem;
1212:     color: var(--text-primary);
1213: }
1214: 
1215: .modal-close {
1216:     background: none;
1217:     border: none;
1218:     font-size: 1.5rem;
1219:     color: var(--text-secondary);
1220:     cursor: pointer;
1221:     padding: 0;
1222:     line-height: 1;
1223: }
1224: 
1225: .modal-close:hover {
1226:     color: var(--text-primary);
1227: }
1228: 
1229: .modal-body {
1230:     padding: 24px;
1231: }
1232: 
1233: .modal-footer {
1234:     display: flex;
1235:     justify-content: flex-end;
1236:     gap: 12px;
1237:     padding: 16px 24px;
1238:     border-top: 1px solid var(--border-color);
1239: }
1240: 
1241: 
1242: 
1243: 
1244: 
1245: .checkbox-list {
1246:     display: flex;
1247:     flex-direction: column;
1248:     gap: 8px;
1249:     max-height: 200px;
1250:     overflow-y: auto;
1251: }
1252: 
1253: .checkbox-option {
1254:     display: flex;
1255:     align-items: center;
1256:     gap: 10px;
1257:     padding: 10px 14px;
1258:     border: 2px solid var(--border-color);
1259:     border-radius: 8px;
1260:     cursor: pointer;
1261:     transition: var(--transition);
1262: }
1263: 
1264: .checkbox-option:hover {
1265:     border-color: var(--primary-color);
1266: }
1267: 
1268: .checkbox-option input[type="checkbox"] {
1269:     width: 18px;
1270:     height: 18px;
1271:     accent-color: var(--primary-color);
1272: }
1273: 
1274: 
1275: 
1276: 
1277: 
1278: .members-list {
1279:     display: flex;
1280:     flex-direction: column;
1281:     gap: 8px;
1282:     max-height: 300px;
1283:     overflow-y: auto;
1284: }
1285: 
1286: .member-item {
1287:     display: flex;
1288:     justify-content: space-between;
1289:     align-items: center;
1290:     padding: 12px 16px;
1291:     background: var(--input-background);
1292:     border-radius: 8px;
1293: }
1294: 
1295: .member-name {
1296:     font-weight: 600;
1297:     color: var(--text-primary);
1298: }
1299: 
1300: .member-username {
1301:     font-size: 0.85rem;
1302:     color: var(--text-secondary);
1303: }
1304: 
1305: 
1306: 
1307: 
1308: 
1309: .empty-state {
1310:     text-align: center;
1311:     padding: 40px 20px;
1312:     color: var(--text-secondary);
1313: }
1314: 
1315: .warning-message {
1316:     padding: 12px 16px;
1317:     background: rgba(245, 158, 11, 0.1);
1318:     border: 1px solid var(--warning-color);
1319:     border-radius: 8px;
1320:     color: var(--warning-color);
1321: }
1322: 
1323: 
1324: 
1325: 
1326: 
1327: .status-revoked {
1328:     background: rgba(107, 114, 128, 0.2);
1329:     color: #6b7280;
1330: }
1331: 
1332: 
1333: 
1334: 
1335: 
1336: textarea {
1337:     width: 100%;
1338:     padding: 14px 16px;
1339:     border: 2px solid var(--border-color);
1340:     border-radius: 10px;
1341:     font-size: 1rem;
1342:     font-family: inherit;
1343:     background: var(--input-background);
1344:     color: var(--text-primary);
1345:     resize: vertical;
1346:     transition: var(--transition);
1347: }
1348: 
1349: textarea:focus {
1350:     outline: none;
1351:     border-color: var(--primary-color);
1352:     background: var(--card-background);
1353: }
1354: 
1355: 
1356: 
1357: 
1358: 
1359: @media (prefers-color-scheme: dark) {
1360:     .top-bar {
1361:         background: var(--card-background);
1362:         border-bottom: 1px solid var(--border-color);
1363:     }
1364: 
1365:     .user-dropdown {
1366:         background: var(--card-background);
1367:     }
1368: 
1369:     .modal {
1370:         background: var(--card-background);
1371:     }
1372: 
1373:     .data-table th {
1374:         background: rgba(0, 0, 0, 0.2);
1375:     }
1376: }
1377: 
1378: 
1379: 
1380: 
1381: 
1382: @media (max-width: 768px) {
1383:     .top-bar-content {
1384:         padding: 0 16px;
1385:     }
1386: 
1387:     .brand-text {
1388:         display: none;
1389:     }
1390: 
1391:     .admin-controls {
1392:         flex-direction: column;
1393:     }
1394: 
1395:     .filter-controls {
1396:         width: 100%;
1397:     }
1398: 
1399:     .filter-select {
1400:         flex: 1;
1401:     }
1402: 
1403:     .data-table {
1404:         font-size: 0.8rem;
1405:     }
1406: 
1407:     .data-table th,
1408:     .data-table td {
1409:         padding: 8px 10px;
1410:     }
1411: 
1412:     .action-buttons {
1413:         flex-direction: column;
1414:     }
1415: }
````

## File: application/frontend/src/js/api.js
````javascript
  1: const API = {
  2: 
  3: 
  4: 
  5:     basePath: '/api',
  6: 
  7: 
  8: 
  9: 
 10:     tokenKey: 'ldap2fa_token',
 11: 
 12: 
 13: 
 14: 
 15:     getToken() {
 16:         return localStorage.getItem(this.tokenKey);
 17:     },
 18: 
 19: 
 20: 
 21: 
 22:     setToken(token) {
 23:         if (token) {
 24:             localStorage.setItem(this.tokenKey, token);
 25:         } else {
 26:             localStorage.removeItem(this.tokenKey);
 27:         }
 28:     },
 29: 
 30: 
 31: 
 32: 
 33:     clearToken() {
 34:         localStorage.removeItem(this.tokenKey);
 35:     },
 36: 
 37: 
 38: 
 39: 
 40: 
 41: 
 42: 
 43: 
 44:     async request(endpoint, options = {}, auth = false) {
 45:         const url = `${this.basePath}${endpoint}`;
 46: 
 47:         const defaultOptions = {
 48:             headers: {
 49:                 'Content-Type': 'application/json',
 50:             },
 51:         };
 52: 
 53: 
 54:         if (auth) {
 55:             const token = this.getToken();
 56:             if (token) {
 57:                 defaultOptions.headers['Authorization'] = `Bearer ${token}`;
 58:             }
 59:         }
 60: 
 61:         const mergedOptions = {
 62:             ...defaultOptions,
 63:             ...options,
 64:             headers: {
 65:                 ...defaultOptions.headers,
 66:                 ...options.headers,
 67:             },
 68:         };
 69: 
 70:         try {
 71:             const response = await fetch(url, mergedOptions);
 72:             const data = await response.json();
 73: 
 74:             if (!response.ok) {
 75:                 throw new APIError(
 76:                     data.detail || 'An error occurred',
 77:                     response.status,
 78:                     data
 79:                 );
 80:             }
 81: 
 82:             return data;
 83:         } catch (error) {
 84:             if (error instanceof APIError) {
 85:                 throw error;
 86:             }
 87: 
 88: 
 89:             throw new APIError(
 90:                 error.message || 'Network error. Please check your connection.',
 91:                 0,
 92:                 null
 93:             );
 94:         }
 95:     },
 96: 
 97: 
 98: 
 99: 
100:     async authRequest(endpoint, options = {}) {
101:         return this.request(endpoint, options, true);
102:     },
103: 
104: 
105: 
106: 
107: 
108:     async healthCheck() {
109:         return this.request('/healthz');
110:     },
111: 
112: 
113: 
114: 
115: 
116:     async getMfaMethods() {
117:         return this.request('/mfa/methods');
118:     },
119: 
120: 
121: 
122: 
123: 
124: 
125:     async getMfaStatus(username) {
126:         return this.request(`/mfa/status/${encodeURIComponent(username)}`);
127:     },
128: 
129: 
130: 
131: 
132: 
133: 
134: 
135: 
136: 
137: 
138:     async signup(userData) {
139:         return this.request('/auth/signup', {
140:             method: 'POST',
141:             body: JSON.stringify({
142:                 username: userData.username,
143:                 email: userData.email,
144:                 first_name: userData.firstName,
145:                 last_name: userData.lastName,
146:                 phone_country_code: userData.phoneCountryCode,
147:                 phone_number: userData.phoneNumber,
148:                 password: userData.password,
149:                 mfa_method: userData.mfaMethod || 'totp',
150:             }),
151:         });
152:     },
153: 
154: 
155: 
156: 
157: 
158: 
159: 
160:     async verifyEmail(username, token) {
161:         return this.request('/auth/verify-email', {
162:             method: 'POST',
163:             body: JSON.stringify({ username, token }),
164:         });
165:     },
166: 
167: 
168: 
169: 
170: 
171: 
172: 
173:     async verifyPhone(username, code) {
174:         return this.request('/auth/verify-phone', {
175:             method: 'POST',
176:             body: JSON.stringify({ username, code }),
177:         });
178:     },
179: 
180: 
181: 
182: 
183: 
184: 
185: 
186:     async resendVerification(username, type) {
187:         return this.request('/auth/resend-verification', {
188:             method: 'POST',
189:             body: JSON.stringify({
190:                 username,
191:                 verification_type: type,
192:             }),
193:         });
194:     },
195: 
196: 
197: 
198: 
199: 
200: 
201:     async getProfileStatus(username) {
202:         return this.request(`/profile/status/${encodeURIComponent(username)}`);
203:     },
204: 
205: 
206: 
207: 
208: 
209: 
210: 
211: 
212: 
213: 
214: 
215: 
216: 
217:     async enroll(username, password, mfaMethod = 'totp', phoneNumber = null) {
218:         const body = { username, password, mfa_method: mfaMethod };
219:         if (phoneNumber) {
220:             body.phone_number = phoneNumber;
221:         }
222:         return this.request('/auth/enroll', {
223:             method: 'POST',
224:             body: JSON.stringify(body),
225:         });
226:     },
227: 
228: 
229: 
230: 
231: 
232: 
233: 
234: 
235: 
236: 
237: 
238:     async sendSmsCode(username, password) {
239:         return this.request('/auth/sms/send-code', {
240:             method: 'POST',
241:             body: JSON.stringify({ username, password }),
242:         });
243:     },
244: 
245: 
246: 
247: 
248: 
249: 
250: 
251: 
252:     async login(username, password, verificationCode) {
253:         return this.request('/auth/login', {
254:             method: 'POST',
255:             body: JSON.stringify({
256:                 username,
257:                 password,
258:                 verification_code: verificationCode,
259:             }),
260:         });
261:     },
262: 
263: 
264: 
265: 
266: 
267: 
268: 
269: 
270: 
271: 
272: 
273: 
274:     async adminLogin(username, password, verificationCode) {
275:         return this.request('/admin/login', {
276:             method: 'POST',
277:             body: JSON.stringify({
278:                 username,
279:                 password,
280:                 verification_code: verificationCode,
281:             }),
282:         });
283:     },
284: 
285: 
286: 
287: 
288: 
289: 
290: 
291: 
292:     async adminListUsers(adminUsername, adminPassword, statusFilter = null) {
293:         let url = `/admin/users?admin_username=${encodeURIComponent(adminUsername)}&admin_password=${encodeURIComponent(adminPassword)}`;
294:         if (statusFilter) {
295:             url += `&status_filter=${encodeURIComponent(statusFilter)}`;
296:         }
297:         return this.request(url);
298:     },
299: 
300: 
301: 
302: 
303: 
304: 
305: 
306: 
307:     async adminActivateUser(userId, adminUsername, adminPassword) {
308:         return this.request(`/admin/users/${encodeURIComponent(userId)}/activate`, {
309:             method: 'POST',
310:             body: JSON.stringify({
311:                 admin_username: adminUsername,
312:                 admin_password: adminPassword,
313:             }),
314:         });
315:     },
316: 
317: 
318: 
319: 
320: 
321: 
322: 
323: 
324:     async adminRejectUser(userId, adminUsername, adminPassword) {
325:         return this.request(`/admin/users/${encodeURIComponent(userId)}/reject`, {
326:             method: 'POST',
327:             body: JSON.stringify({
328:                 admin_username: adminUsername,
329:                 admin_password: adminPassword,
330:             }),
331:         });
332:     },
333: 
334: 
335: 
336: 
337: 
338: 
339: 
340: 
341: 
342: 
343:     async getProfile(username) {
344:         return this.authRequest(`/profile/${encodeURIComponent(username)}`);
345:     },
346: 
347: 
348: 
349: 
350: 
351: 
352: 
353:     async updateProfile(username, updates) {
354:         return this.authRequest(`/profile/${encodeURIComponent(username)}`, {
355:             method: 'PUT',
356:             body: JSON.stringify(updates),
357:         });
358:     },
359: 
360: 
361: 
362: 
363: 
364: 
365: 
366: 
367: 
368: 
369:     async listGroups(params = {}) {
370:         const query = new URLSearchParams();
371:         if (params.search) query.set('search', params.search);
372:         if (params.sort_by) query.set('sort_by', params.sort_by);
373:         if (params.sort_order) query.set('sort_order', params.sort_order);
374: 
375:         const queryStr = query.toString();
376:         return this.authRequest(`/admin/groups${queryStr ? '?' + queryStr : ''}`);
377:     },
378: 
379: 
380: 
381: 
382: 
383: 
384: 
385:     async createGroup(name, description = '') {
386:         return this.authRequest('/admin/groups', {
387:             method: 'POST',
388:             body: JSON.stringify({ name, description }),
389:         });
390:     },
391: 
392: 
393: 
394: 
395: 
396: 
397:     async getGroup(groupId) {
398:         return this.authRequest(`/admin/groups/${encodeURIComponent(groupId)}`);
399:     },
400: 
401: 
402: 
403: 
404: 
405: 
406: 
407:     async updateGroup(groupId, updates) {
408:         return this.authRequest(`/admin/groups/${encodeURIComponent(groupId)}`, {
409:             method: 'PUT',
410:             body: JSON.stringify(updates),
411:         });
412:     },
413: 
414: 
415: 
416: 
417: 
418: 
419:     async deleteGroup(groupId) {
420:         return this.authRequest(`/admin/groups/${encodeURIComponent(groupId)}`, {
421:             method: 'DELETE',
422:         });
423:     },
424: 
425: 
426: 
427: 
428: 
429: 
430: 
431: 
432: 
433: 
434:     async getUserGroups(userId) {
435:         return this.authRequest(`/admin/users/${encodeURIComponent(userId)}/groups`);
436:     },
437: 
438: 
439: 
440: 
441: 
442: 
443: 
444:     async assignUserGroups(userId, groupIds) {
445:         return this.authRequest(`/admin/users/${encodeURIComponent(userId)}/groups`, {
446:             method: 'POST',
447:             body: JSON.stringify({ group_ids: groupIds }),
448:         });
449:     },
450: 
451: 
452: 
453: 
454: 
455: 
456: 
457:     async replaceUserGroups(userId, groupIds) {
458:         return this.authRequest(`/admin/users/${encodeURIComponent(userId)}/groups`, {
459:             method: 'PUT',
460:             body: JSON.stringify({ group_ids: groupIds }),
461:         });
462:     },
463: 
464: 
465: 
466: 
467: 
468: 
469: 
470:     async removeUserFromGroup(userId, groupId) {
471:         return this.authRequest(`/admin/users/${encodeURIComponent(userId)}/groups/${encodeURIComponent(groupId)}`, {
472:             method: 'DELETE',
473:         });
474:     },
475: 
476: 
477: 
478: 
479: 
480: 
481: 
482: 
483: 
484: 
485:     async adminListUsersEnhanced(params = {}) {
486:         const query = new URLSearchParams();
487:         if (params.status_filter) query.set('status_filter', params.status_filter);
488:         if (params.group_filter) query.set('group_filter', params.group_filter);
489:         if (params.search) query.set('search', params.search);
490:         if (params.sort_by) query.set('sort_by', params.sort_by);
491:         if (params.sort_order) query.set('sort_order', params.sort_order);
492: 
493:         const queryStr = query.toString();
494:         return this.authRequest(`/admin/users/enhanced${queryStr ? '?' + queryStr : ''}`);
495:     },
496: 
497: 
498: 
499: 
500: 
501: 
502:     async revokeUser(userId) {
503:         return this.authRequest(`/admin/users/${encodeURIComponent(userId)}/revoke`, {
504:             method: 'POST',
505:         });
506:     },
507: };
508: 
509: 
510: 
511: 
512: class APIError extends Error {
513:     constructor(message, statusCode, data) {
514:         super(message);
515:         this.name = 'APIError';
516:         this.statusCode = statusCode;
517:         this.data = data;
518:     }
519: 
520: 
521: 
522: 
523:     isAuthError() {
524:         return this.statusCode === 401;
525:     }
526: 
527: 
528: 
529: 
530:     isForbidden() {
531:         return this.statusCode === 403;
532:     }
533: 
534: 
535: 
536: 
537:     isNotEnrolled() {
538:         return this.statusCode === 403;
539:     }
540: 
541: 
542: 
543: 
544:     isNotFound() {
545:         return this.statusCode === 404;
546:     }
547: 
548: 
549: 
550: 
551:     isServerError() {
552:         return this.statusCode >= 500;
553:     }
554: 
555: 
556: 
557: 
558:     isValidationError() {
559:         return this.statusCode === 400 || this.statusCode === 422;
560:     }
561: }
562: 
563: 
564: window.API = API;
565: window.APIError = APIError;
````

## File: application/frontend/src/js/main.js
````javascript
   1: document.addEventListener('DOMContentLoaded', () => {
   2: 
   3:     App.init();
   4: });
   5: 
   6: 
   7: 
   8: 
   9: 
  10: 
  11: 
  12: function escapeHtml(str) {
  13:     if (!str) return '';
  14:     return String(str)
  15:         .replace(/&/g, '&amp;')
  16:         .replace(/</g, '&lt;')
  17:         .replace(/>/g, '&gt;')
  18:         .replace(/"/g, '&quot;')
  19:         .replace(/'/g, '&#039;');
  20: }
  21: 
  22: const App = {
  23: 
  24:     smsEnabled: false,
  25:     userMfaMethod: null,
  26:     currentUser: null,
  27:     session: null,
  28:     groups: [],
  29:     users: [],
  30:     sortState: { field: 'created_at', order: 'desc' },
  31: 
  32: 
  33: 
  34: 
  35:     async init() {
  36:         this.setupTabs();
  37:         this.setupLoginForm();
  38:         this.setupSignupForm();
  39:         this.setupEnrollForm();
  40:         this.setupCopySecret();
  41:         this.setupMfaMethodSelector();
  42:         this.setupVerification();
  43:         this.setupTopBar();
  44:         this.setupProfile();
  45:         this.setupAdminUsers();
  46:         this.setupAdminGroups();
  47:         this.setupModals();
  48: 
  49: 
  50:         await this.checkMfaMethods();
  51: 
  52: 
  53:         this.checkEmailVerificationToken();
  54: 
  55: 
  56:         this.checkSession();
  57:     },
  58: 
  59: 
  60: 
  61: 
  62:     checkSession() {
  63:         const token = API.getToken();
  64:         if (token) {
  65:             try {
  66: 
  67:                 const payload = JSON.parse(atob(token.split('.')[1]));
  68: 
  69: 
  70:                 if (payload.exp * 1000 < Date.now()) {
  71:                     API.clearToken();
  72:                     return;
  73:                 }
  74: 
  75: 
  76:                 this.session = {
  77:                     username: payload.username,
  78:                     isAdmin: payload.is_admin,
  79:                     token: token,
  80:                 };
  81: 
  82:                 this.showLoggedInState();
  83:             } catch (e) {
  84:                 API.clearToken();
  85:             }
  86:         }
  87:     },
  88: 
  89: 
  90: 
  91: 
  92:     showLoggedInState() {
  93: 
  94:         document.getElementById('top-bar').classList.remove('hidden');
  95:         document.getElementById('user-display-name').textContent = this.session.username;
  96: 
  97: 
  98:         if (this.session.isAdmin) {
  99:             document.getElementById('admin-menu-items').classList.remove('hidden');
 100:         }
 101: 
 102: 
 103:         document.getElementById('auth-header').classList.add('hidden');
 104:         document.getElementById('auth-tabs').classList.add('hidden');
 105: 
 106: 
 107:         this.showSection('profile');
 108: 
 109: 
 110:         document.getElementById('main-container').classList.add('logged-in');
 111:     },
 112: 
 113: 
 114: 
 115: 
 116:     showLoggedOutState() {
 117: 
 118:         document.getElementById('top-bar').classList.add('hidden');
 119:         document.getElementById('admin-menu-items').classList.add('hidden');
 120: 
 121: 
 122:         document.getElementById('auth-header').classList.remove('hidden');
 123:         document.getElementById('auth-tabs').classList.remove('hidden');
 124: 
 125: 
 126:         this.hideAllSections();
 127:         document.getElementById('login-tab').classList.add('active');
 128: 
 129: 
 130:         document.getElementById('main-container').classList.remove('logged-in');
 131: 
 132: 
 133:         this.session = null;
 134:         API.clearToken();
 135:     },
 136: 
 137: 
 138: 
 139: 
 140:     showSection(section) {
 141:         this.hideAllSections();
 142: 
 143:         switch (section) {
 144:             case 'profile':
 145:                 document.getElementById('profile-section').classList.remove('hidden');
 146:                 this.loadProfile();
 147:                 break;
 148:             case 'admin-users':
 149:                 document.getElementById('admin-users-section').classList.remove('hidden');
 150:                 this.loadAdminUsers();
 151:                 break;
 152:             case 'admin-groups':
 153:                 document.getElementById('admin-groups-section').classList.remove('hidden');
 154:                 this.loadAdminGroups();
 155:                 break;
 156:         }
 157:     },
 158: 
 159: 
 160: 
 161: 
 162:     hideAllSections() {
 163:         document.querySelectorAll('.tab-content').forEach(el => {
 164:             el.classList.remove('active');
 165:             el.classList.add('hidden');
 166:         });
 167:     },
 168: 
 169: 
 170: 
 171: 
 172:     setupTopBar() {
 173:         const userMenuBtn = document.getElementById('user-menu-btn');
 174:         const userDropdown = document.getElementById('user-dropdown');
 175: 
 176: 
 177:         userMenuBtn.addEventListener('click', (e) => {
 178:             e.stopPropagation();
 179:             userDropdown.classList.toggle('hidden');
 180:         });
 181: 
 182: 
 183:         document.addEventListener('click', () => {
 184:             userDropdown.classList.add('hidden');
 185:         });
 186: 
 187: 
 188:         document.getElementById('menu-profile').addEventListener('click', (e) => {
 189:             e.preventDefault();
 190:             userDropdown.classList.add('hidden');
 191:             this.showSection('profile');
 192:         });
 193: 
 194:         document.getElementById('menu-admin-users').addEventListener('click', (e) => {
 195:             e.preventDefault();
 196:             userDropdown.classList.add('hidden');
 197:             this.showSection('admin-users');
 198:         });
 199: 
 200:         document.getElementById('menu-admin-groups').addEventListener('click', (e) => {
 201:             e.preventDefault();
 202:             userDropdown.classList.add('hidden');
 203:             this.showSection('admin-groups');
 204:         });
 205: 
 206:         document.getElementById('menu-logout').addEventListener('click', (e) => {
 207:             e.preventDefault();
 208:             userDropdown.classList.add('hidden');
 209:             this.logout();
 210:         });
 211:     },
 212: 
 213: 
 214: 
 215: 
 216:     logout() {
 217:         this.showLoggedOutState();
 218:         this.showStatus('Logged out successfully', 'success');
 219:     },
 220: 
 221: 
 222: 
 223: 
 224:     async checkMfaMethods() {
 225:         try {
 226:             const response = await API.getMfaMethods();
 227:             this.smsEnabled = response.sms_enabled;
 228: 
 229: 
 230:             this.updateSmsOptions();
 231:         } catch (error) {
 232:             console.warn('Could not fetch MFA methods:', error.message);
 233:             this.smsEnabled = false;
 234:         }
 235:     },
 236: 
 237: 
 238: 
 239: 
 240:     updateSmsOptions() {
 241:         const smsOptions = document.querySelectorAll('#sms-option, #signup-sms-option');
 242:         smsOptions.forEach(option => {
 243:             if (!this.smsEnabled) {
 244:                 option.classList.add('disabled');
 245:                 option.querySelector('input').disabled = true;
 246:                 option.querySelector('small').textContent = 'SMS not available';
 247:             } else {
 248:                 option.classList.remove('disabled');
 249:                 option.querySelector('input').disabled = false;
 250:             }
 251:         });
 252:     },
 253: 
 254: 
 255: 
 256: 
 257:     async checkEmailVerificationToken() {
 258:         const urlParams = new URLSearchParams(window.location.search);
 259:         const token = urlParams.get('token');
 260:         const username = urlParams.get('username');
 261: 
 262:         if (token && username) {
 263:             try {
 264:                 const response = await API.verifyEmail(username, token);
 265:                 this.showStatus('Email verified successfully!', 'success');
 266: 
 267: 
 268:                 window.history.replaceState({}, document.title, window.location.pathname);
 269: 
 270: 
 271:                 if (this.currentUser && this.currentUser.username === username) {
 272:                     this.updateVerificationStatus(response.profile_status);
 273:                 }
 274:             } catch (error) {
 275:                 this.showStatus(error.message, 'error');
 276:             }
 277:         }
 278:     },
 279: 
 280: 
 281: 
 282: 
 283:     setupTabs() {
 284:         const tabButtons = document.querySelectorAll('.tab-btn');
 285:         const tabContents = document.querySelectorAll('.tab-content');
 286: 
 287:         tabButtons.forEach(button => {
 288:             button.addEventListener('click', () => {
 289:                 const targetTab = button.dataset.tab;
 290: 
 291: 
 292:                 tabButtons.forEach(btn => btn.classList.remove('active'));
 293:                 button.classList.add('active');
 294: 
 295: 
 296:                 tabContents.forEach(content => {
 297:                     content.classList.remove('active');
 298:                     content.classList.add('hidden');
 299:                     if (content.id === `${targetTab}-tab`) {
 300:                         content.classList.add('active');
 301:                         content.classList.remove('hidden');
 302:                     }
 303:                 });
 304: 
 305: 
 306:                 this.clearResults();
 307:             });
 308:         });
 309:     },
 310: 
 311: 
 312: 
 313: 
 314:     setupMfaMethodSelector() {
 315: 
 316:         const enrollMethodRadios = document.querySelectorAll('input[name="mfa_method"]');
 317:         const phoneGroup = document.getElementById('phone-group');
 318:         const phoneInput = document.getElementById('enroll-phone');
 319: 
 320:         enrollMethodRadios.forEach(radio => {
 321:             radio.addEventListener('change', () => {
 322:                 if (radio.value === 'sms') {
 323:                     phoneGroup.classList.remove('hidden');
 324:                     phoneInput.required = true;
 325:                 } else {
 326:                     phoneGroup.classList.add('hidden');
 327:                     phoneInput.required = false;
 328:                     phoneInput.value = '';
 329:                 }
 330:             });
 331:         });
 332:     },
 333: 
 334:     /**
 335:      * Setup login form handling
 336:      */
 337:     setupLoginForm() {
 338:         const form = document.getElementById('login-form');
 339:         const resultContainer = document.getElementById('login-result');
 340:         const sendSmsBtn = document.getElementById('send-sms-btn');
 341:         const smsStatus = document.getElementById('sms-status');
 342: 
 343: 
 344:         sendSmsBtn.addEventListener('click', async () => {
 345:             const username = form.querySelector('#login-username').value.trim();
 346:             const password = form.querySelector('#login-password').value;
 347: 
 348:             if (!username || !password) {
 349:                 this.showStatus('Please enter username and password first', 'warning');
 350:                 return;
 351:             }
 352: 
 353:             sendSmsBtn.disabled = true;
 354:             sendSmsBtn.textContent = 'Sending...';
 355: 
 356:             try {
 357:                 const response = await API.sendSmsCode(username, password);
 358: 
 359:                 smsStatus.textContent = `Code sent to ${response.phone_number}. Expires in ${response.expires_in_seconds}s`;
 360:                 smsStatus.classList.remove('hidden');
 361: 
 362:                 this.showStatus('Verification code sent!', 'success');
 363:                 this.startSmsCountdown(sendSmsBtn, response.expires_in_seconds);
 364: 
 365:             } catch (error) {
 366:                 this.showStatus(error.message, 'error');
 367:                 sendSmsBtn.disabled = false;
 368:                 sendSmsBtn.textContent = 'Send SMS';
 369:             }
 370:         });
 371: 
 372: 
 373:         let mfaCheckTimeout;
 374:         form.querySelector('#login-username').addEventListener('blur', async (e) => {
 375:             const username = e.target.value.trim();
 376:             if (!username) return;
 377: 
 378:             clearTimeout(mfaCheckTimeout);
 379:             mfaCheckTimeout = setTimeout(async () => {
 380:                 try {
 381:                     const status = await API.getMfaStatus(username);
 382:                     this.userMfaMethod = status.mfa_method;
 383: 
 384: 
 385:                     if (status.enrolled && status.mfa_method === 'sms') {
 386:                         sendSmsBtn.classList.remove('hidden');
 387:                         smsStatus.textContent = `SMS will be sent to ${status.phone_number}`;
 388:                         smsStatus.classList.remove('hidden');
 389:                     } else {
 390:                         sendSmsBtn.classList.add('hidden');
 391:                         smsStatus.classList.add('hidden');
 392:                     }
 393:                 } catch (error) {
 394:                     sendSmsBtn.classList.add('hidden');
 395:                     smsStatus.classList.add('hidden');
 396:                 }
 397:             }, 500);
 398:         });
 399: 
 400:         form.addEventListener('submit', async (e) => {
 401:             e.preventDefault();
 402: 
 403:             const submitBtn = form.querySelector('button[type="submit"]');
 404:             const username = form.querySelector('#login-username').value.trim();
 405:             const password = form.querySelector('#login-password').value;
 406:             const verificationCode = form.querySelector('#login-code').value.trim();
 407: 
 408:             if (!/^\d{6}$/.test(verificationCode)) {
 409:                 this.showStatus('Please enter a valid 6-digit code', 'error');
 410:                 return;
 411:             }
 412: 
 413:             submitBtn.classList.add('loading');
 414:             submitBtn.disabled = true;
 415:             resultContainer.classList.add('hidden');
 416: 
 417:             try {
 418:                 const response = await API.login(username, password, verificationCode);
 419: 
 420: 
 421:                 if (response.token) {
 422:                     API.setToken(response.token);
 423:                     this.session = {
 424:                         username: response.username || username,
 425:                         isAdmin: response.is_admin,
 426:                         token: response.token,
 427:                     };
 428: 
 429:                     this.showStatus('Login successful!', 'success');
 430:                     form.reset();
 431:                     sendSmsBtn.classList.add('hidden');
 432:                     smsStatus.classList.add('hidden');
 433: 
 434: 
 435:                     this.showLoggedInState();
 436:                 } else {
 437:                     resultContainer.innerHTML = `
 438:                         <h3> Login Successful!</h3>
 439:                         <p>${response.message}</p>
 440:                     `;
 441:                     resultContainer.className = 'result-container success';
 442:                     resultContainer.classList.remove('hidden');
 443:                 }
 444: 
 445:             } catch (error) {
 446:                 resultContainer.innerHTML = `
 447:                     <h3> Login Failed</h3>
 448:                     <p>${escapeHtml(error.message)}</p>
 449:                 `;
 450:                 resultContainer.className = 'result-container error';
 451:                 resultContainer.classList.remove('hidden');
 452: 
 453:                 this.showStatus(error.message, 'error');
 454:             } finally {
 455:                 submitBtn.classList.remove('loading');
 456:                 submitBtn.disabled = false;
 457:             }
 458:         });
 459:     },
 460: 
 461: 
 462: 
 463: 
 464:     setupSignupForm() {
 465:         const form = document.getElementById('signup-form');
 466:         const resultContainer = document.getElementById('signup-result');
 467:         const verificationPanel = document.getElementById('verification-status');
 468: 
 469:         form.addEventListener('submit', async (e) => {
 470:             e.preventDefault();
 471: 
 472:             const submitBtn = form.querySelector('button[type="submit"]');
 473:             const password = form.querySelector('#signup-password').value;
 474:             const confirmPassword = form.querySelector('#signup-confirm-password').value;
 475: 
 476: 
 477:             if (password !== confirmPassword) {
 478:                 this.showStatus('Passwords do not match', 'error');
 479:                 return;
 480:             }
 481: 
 482:             const userData = {
 483:                 username: form.querySelector('#signup-username').value.trim().toLowerCase(),
 484:                 email: form.querySelector('#signup-email').value.trim().toLowerCase(),
 485:                 firstName: form.querySelector('#signup-firstname').value.trim(),
 486:                 lastName: form.querySelector('#signup-lastname').value.trim(),
 487:                 phoneCountryCode: form.querySelector('#signup-country-code').value,
 488:                 phoneNumber: form.querySelector('#signup-phone').value.trim(),
 489:                 password: password,
 490:                 mfaMethod: form.querySelector('input[name="signup_mfa_method"]:checked').value,
 491:             };
 492: 
 493:             submitBtn.classList.add('loading');
 494:             submitBtn.disabled = true;
 495:             resultContainer.classList.add('hidden');
 496:             verificationPanel.classList.add('hidden');
 497: 
 498:             try {
 499:                 const response = await API.signup(userData);
 500: 
 501:                 this.currentUser = {
 502:                     username: userData.username,
 503:                     email: userData.email,
 504:                 };
 505: 
 506: 
 507:                 form.classList.add('hidden');
 508:                 verificationPanel.classList.remove('hidden');
 509: 
 510: 
 511:                 if (response.email_verification_sent) {
 512:                     document.getElementById('email-verify-hint').textContent =
 513:                         `Check ${userData.email} for verification link`;
 514:                 }
 515:                 if (response.phone_verification_sent) {
 516:                     document.getElementById('phone-verify-hint').textContent =
 517:                         `Enter code sent to ${userData.phoneCountryCode}${userData.phoneNumber}`;
 518:                 }
 519: 
 520:                 this.showStatus('Account created! Please verify your email and phone.', 'success');
 521: 
 522:             } catch (error) {
 523:                 resultContainer.innerHTML = `
 524:                     <h3> Signup Failed</h3>
 525:                     <p>${escapeHtml(error.message)}</p>
 526:                 `;
 527:                 resultContainer.className = 'result-container error';
 528:                 resultContainer.classList.remove('hidden');
 529: 
 530:                 this.showStatus(error.message, 'error');
 531:             } finally {
 532:                 submitBtn.classList.remove('loading');
 533:                 submitBtn.disabled = false;
 534:             }
 535:         });
 536:     },
 537: 
 538: 
 539: 
 540: 
 541:     setupVerification() {
 542:         const resendEmailBtn = document.getElementById('resend-email-btn');
 543:         const resendPhoneBtn = document.getElementById('resend-phone-btn');
 544:         const verifyPhoneBtn = document.getElementById('verify-phone-btn');
 545:         const phoneCodeInput = document.getElementById('phone-verify-code');
 546: 
 547: 
 548:         resendEmailBtn.addEventListener('click', async () => {
 549:             if (!this.currentUser) return;
 550: 
 551:             resendEmailBtn.disabled = true;
 552:             resendEmailBtn.textContent = 'Sending...';
 553: 
 554:             try {
 555:                 await API.resendVerification(this.currentUser.username, 'email');
 556:                 this.showStatus('Verification email sent!', 'success');
 557: 
 558: 
 559:                 this.startResendCountdown(resendEmailBtn, 60);
 560:             } catch (error) {
 561:                 this.showStatus(error.message, 'error');
 562:                 resendEmailBtn.disabled = false;
 563:                 resendEmailBtn.textContent = 'Resend';
 564:             }
 565:         });
 566: 
 567: 
 568:         resendPhoneBtn.addEventListener('click', async () => {
 569:             if (!this.currentUser) return;
 570: 
 571:             resendPhoneBtn.disabled = true;
 572:             resendPhoneBtn.textContent = 'Sending...';
 573: 
 574:             try {
 575:                 await API.resendVerification(this.currentUser.username, 'phone');
 576:                 this.showStatus('Verification code sent!', 'success');
 577: 
 578:                 this.startResendCountdown(resendPhoneBtn, 60);
 579:             } catch (error) {
 580:                 this.showStatus(error.message, 'error');
 581:                 resendPhoneBtn.disabled = false;
 582:                 resendPhoneBtn.textContent = 'Resend';
 583:             }
 584:         });
 585: 
 586: 
 587:         verifyPhoneBtn.addEventListener('click', async () => {
 588:             if (!this.currentUser) return;
 589: 
 590:             const code = phoneCodeInput.value.trim();
 591:             if (!/^\d{6}$/.test(code)) {
 592:                 this.showStatus('Please enter a valid 6-digit code', 'error');
 593:                 return;
 594:             }
 595: 
 596:             verifyPhoneBtn.disabled = true;
 597:             verifyPhoneBtn.textContent = 'Verifying...';
 598: 
 599:             try {
 600:                 const response = await API.verifyPhone(this.currentUser.username, code);
 601: 
 602:                 document.getElementById('phone-verify-status').textContent = '';
 603:                 document.getElementById('phone-verify-hint').textContent = 'Verified!';
 604:                 phoneCodeInput.disabled = true;
 605:                 verifyPhoneBtn.classList.add('hidden');
 606: 
 607:                 this.showStatus('Phone verified successfully!', 'success');
 608:                 this.updateVerificationStatus(response.profile_status);
 609: 
 610:             } catch (error) {
 611:                 this.showStatus(error.message, 'error');
 612:                 verifyPhoneBtn.disabled = false;
 613:                 verifyPhoneBtn.textContent = 'Verify';
 614:             }
 615:         });
 616:     },
 617: 
 618: 
 619: 
 620: 
 621:     updateVerificationStatus(status) {
 622:         if (status === 'complete') {
 623: 
 624:             document.getElementById('email-verify-status').textContent = '';
 625:             document.getElementById('phone-verify-status').textContent = '';
 626:             document.getElementById('verification-complete').classList.remove('hidden');
 627:             document.querySelector('.phone-verify-input').classList.add('hidden');
 628:             document.querySelectorAll('.verification-item button').forEach(btn => {
 629:                 btn.classList.add('hidden');
 630:             });
 631:         }
 632:     },
 633: 
 634: 
 635: 
 636: 
 637:     startResendCountdown(button, seconds) {
 638:         let remaining = seconds;
 639:         button.disabled = true;
 640: 
 641:         const interval = setInterval(() => {
 642:             remaining--;
 643:             button.textContent = `Resend (${remaining}s)`;
 644: 
 645:             if (remaining <= 0) {
 646:                 clearInterval(interval);
 647:                 button.textContent = 'Resend';
 648:                 button.disabled = false;
 649:             }
 650:         }, 1000);
 651:     },
 652: 
 653: 
 654: 
 655: 
 656:     startSmsCountdown(button, seconds) {
 657:         let remaining = seconds;
 658:         button.disabled = true;
 659: 
 660:         const interval = setInterval(() => {
 661:             remaining--;
 662:             button.textContent = `Resend (${remaining}s)`;
 663: 
 664:             if (remaining <= 0) {
 665:                 clearInterval(interval);
 666:                 button.textContent = 'Send SMS';
 667:                 button.disabled = false;
 668:             }
 669:         }, 1000);
 670:     },
 671: 
 672: 
 673: 
 674: 
 675:     setupEnrollForm() {
 676:         const form = document.getElementById('enroll-form');
 677:         const resultContainer = document.getElementById('enroll-result');
 678:         const qrSection = document.getElementById('qr-section');
 679:         const smsSection = document.getElementById('sms-enroll-section');
 680:         const qrCodeDiv = document.getElementById('qr-code');
 681:         const secretCode = document.getElementById('secret-code');
 682:         const enrolledPhone = document.getElementById('enrolled-phone');
 683: 
 684:         form.addEventListener('submit', async (e) => {
 685:             e.preventDefault();
 686: 
 687:             const submitBtn = form.querySelector('button[type="submit"]');
 688:             const username = form.querySelector('#enroll-username').value.trim();
 689:             const password = form.querySelector('#enroll-password').value;
 690:             const mfaMethod = form.querySelector('input[name="mfa_method"]:checked').value;
 691:             const phoneNumber = form.querySelector('#enroll-phone').value.trim();
 692: 
 693:             if (mfaMethod === 'sms' && !phoneNumber) {
 694:                 this.showStatus('Please enter a phone number for SMS verification', 'error');
 695:                 return;
 696:             }
 697: 
 698:             submitBtn.classList.add('loading');
 699:             submitBtn.disabled = true;
 700:             resultContainer.classList.add('hidden');
 701:             qrSection.classList.add('hidden');
 702:             smsSection.classList.add('hidden');
 703: 
 704:             try {
 705:                 const response = await API.enroll(username, password, mfaMethod, phoneNumber);
 706: 
 707:                 if (response.success) {
 708:                     resultContainer.classList.remove('hidden');
 709: 
 710:                     if (response.mfa_method === 'totp' && response.otpauth_uri) {
 711:                         qrCodeDiv.innerHTML = '';
 712: 
 713:                         await QRCode.toCanvas(qrCodeDiv, response.otpauth_uri, {
 714:                             width: 200,
 715:                             margin: 2,
 716:                             color: {
 717:                                 dark: '#1e293b',
 718:                                 light: '#ffffff'
 719:                             }
 720:                         });
 721: 
 722:                         secretCode.textContent = response.secret;
 723:                         qrSection.classList.remove('hidden');
 724: 
 725:                         this.showStatus('MFA enrollment successful! Scan the QR code.', 'success');
 726:                     } else if (response.mfa_method === 'sms') {
 727:                         enrolledPhone.textContent = response.phone_number;
 728:                         smsSection.classList.remove('hidden');
 729: 
 730:                         this.showStatus('SMS verification setup complete!', 'success');
 731:                     }
 732: 
 733:                     form.querySelector('#enroll-password').value = '';
 734:                 } else {
 735:                     throw new Error(response.message || 'Enrollment failed');
 736:                 }
 737: 
 738:             } catch (error) {
 739:                 resultContainer.innerHTML = `
 740:                     <div class="result-container error">
 741:                         <h3> Enrollment Failed</h3>
 742:                         <p>${escapeHtml(error.message)}</p>
 743:                     </div>
 744:                 `;
 745:                 resultContainer.classList.remove('hidden');
 746:                 qrSection.classList.add('hidden');
 747:                 smsSection.classList.add('hidden');
 748: 
 749:                 this.showStatus(error.message, 'error');
 750:             } finally {
 751:                 submitBtn.classList.remove('loading');
 752:                 submitBtn.disabled = false;
 753:             }
 754:         });
 755:     },
 756: 
 757: 
 758: 
 759: 
 760:     setupCopySecret() {
 761:         const copyBtn = document.getElementById('copy-secret');
 762:         const secretCode = document.getElementById('secret-code');
 763: 
 764:         copyBtn.addEventListener('click', async () => {
 765:             const secret = secretCode.textContent;
 766: 
 767:             try {
 768:                 await navigator.clipboard.writeText(secret);
 769:                 this.showStatus('Secret copied to clipboard!', 'success');
 770: 
 771:                 const originalText = copyBtn.textContent;
 772:                 copyBtn.textContent = 'Copied!';
 773:                 setTimeout(() => {
 774:                     copyBtn.textContent = originalText;
 775:                 }, 2000);
 776:             } catch (err) {
 777: 
 778:                 const textArea = document.createElement('textarea');
 779:                 textArea.value = secret;
 780:                 document.body.appendChild(textArea);
 781:                 textArea.select();
 782:                 document.execCommand('copy');
 783:                 document.body.removeChild(textArea);
 784: 
 785:                 this.showStatus('Secret copied to clipboard!', 'success');
 786:             }
 787:         });
 788:     },
 789: 
 790: 
 791: 
 792: 
 793:     setupProfile() {
 794:         const form = document.getElementById('profile-form');
 795: 
 796:         form.addEventListener('submit', async (e) => {
 797:             e.preventDefault();
 798: 
 799:             if (!this.session) return;
 800: 
 801:             const submitBtn = form.querySelector('button[type="submit"]');
 802:             submitBtn.classList.add('loading');
 803:             submitBtn.disabled = true;
 804: 
 805:             const updates = {};
 806:             const firstName = document.getElementById('profile-firstname').value.trim();
 807:             const lastName = document.getElementById('profile-lastname').value.trim();
 808:             const email = document.getElementById('profile-email').value.trim();
 809:             const phoneCountryCode = document.getElementById('profile-country-code').value;
 810:             const phoneNumber = document.getElementById('profile-phone').value.trim();
 811: 
 812:             if (firstName) updates.first_name = firstName;
 813:             if (lastName) updates.last_name = lastName;
 814:             if (email && !document.getElementById('profile-email').readOnly) {
 815:                 updates.email = email;
 816:             }
 817:             if (!document.getElementById('profile-phone').readOnly) {
 818:                 updates.phone_country_code = phoneCountryCode;
 819:                 updates.phone_number = phoneNumber;
 820:             }
 821: 
 822:             try {
 823:                 await API.updateProfile(this.session.username, updates);
 824:                 this.showStatus('Profile updated successfully', 'success');
 825:             } catch (error) {
 826:                 this.showStatus(error.message, 'error');
 827:             } finally {
 828:                 submitBtn.classList.remove('loading');
 829:                 submitBtn.disabled = false;
 830:             }
 831:         });
 832:     },
 833: 
 834: 
 835: 
 836: 
 837:     async loadProfile() {
 838:         if (!this.session) return;
 839: 
 840:         try {
 841:             const profile = await API.getProfile(this.session.username);
 842: 
 843:             document.getElementById('profile-username').value = profile.username;
 844:             document.getElementById('profile-firstname').value = profile.first_name;
 845:             document.getElementById('profile-lastname').value = profile.last_name;
 846:             document.getElementById('profile-email').value = profile.email;
 847:             document.getElementById('profile-country-code').value = profile.phone_country_code;
 848:             document.getElementById('profile-phone').value = profile.phone_number;
 849:             document.getElementById('profile-mfa').value = profile.mfa_method.toUpperCase();
 850:             document.getElementById('profile-status').value = profile.status.toUpperCase();
 851: 
 852: 
 853:             const emailInput = document.getElementById('profile-email');
 854:             const phoneInput = document.getElementById('profile-phone');
 855:             const countryCodeSelect = document.getElementById('profile-country-code');
 856: 
 857:             if (profile.email_verified) {
 858:                 emailInput.readOnly = true;
 859:                 emailInput.classList.add('readonly-input');
 860:                 document.getElementById('profile-email-hint').textContent = 'Email cannot be changed after verification';
 861:             } else {
 862:                 emailInput.readOnly = false;
 863:                 emailInput.classList.remove('readonly-input');
 864:                 document.getElementById('profile-email-hint').textContent = '';
 865:             }
 866: 
 867:             if (profile.phone_verified) {
 868:                 phoneInput.readOnly = true;
 869:                 phoneInput.classList.add('readonly-input');
 870:                 countryCodeSelect.disabled = true;
 871:                 document.getElementById('profile-phone-hint').textContent = 'Phone cannot be changed after verification';
 872:             } else {
 873:                 phoneInput.readOnly = false;
 874:                 phoneInput.classList.remove('readonly-input');
 875:                 countryCodeSelect.disabled = false;
 876:                 document.getElementById('profile-phone-hint').textContent = '';
 877:             }
 878: 
 879:             // Display groups
 880:             const groupsContainer = document.getElementById('profile-groups');
 881:             if (profile.groups && profile.groups.length > 0) {
 882:                 groupsContainer.innerHTML = profile.groups.map(g =>
 883:                     `<span class="group-badge">${g.name}</span>`
 884:                 ).join('');
 885:             } else {
 886:                 groupsContainer.innerHTML = '<span class="no-groups">No groups assigned</span>';
 887:             }
 888: 
 889:         } catch (error) {
 890:             this.showStatus('Failed to load profile', 'error');
 891:         }
 892:     },
 893: 
 894: 
 895: 
 896: 
 897:     setupAdminUsers() {
 898:         const searchInput = document.getElementById('users-search');
 899:         const statusFilter = document.getElementById('users-status-filter');
 900:         const groupFilter = document.getElementById('users-group-filter');
 901:         const refreshBtn = document.getElementById('users-refresh-btn');
 902: 
 903: 
 904:         let searchTimeout;
 905:         searchInput.addEventListener('input', () => {
 906:             clearTimeout(searchTimeout);
 907:             searchTimeout = setTimeout(() => this.loadAdminUsers(), 300);
 908:         });
 909: 
 910: 
 911:         statusFilter.addEventListener('change', () => this.loadAdminUsers());
 912:         groupFilter.addEventListener('change', () => this.loadAdminUsers());
 913: 
 914: 
 915:         refreshBtn.addEventListener('click', () => this.loadAdminUsers());
 916: 
 917: 
 918:         document.querySelectorAll('#users-table th.sortable').forEach(th => {
 919:             th.addEventListener('click', () => {
 920:                 const field = th.dataset.sort;
 921:                 if (this.sortState.field === field) {
 922:                     this.sortState.order = this.sortState.order === 'asc' ? 'desc' : 'asc';
 923:                 } else {
 924:                     this.sortState.field = field;
 925:                     this.sortState.order = 'asc';
 926:                 }
 927:                 this.updateSortIndicators('users-table');
 928:                 this.loadAdminUsers();
 929:             });
 930:         });
 931:     },
 932: 
 933: 
 934: 
 935: 
 936:     async loadAdminUsers() {
 937:         if (!this.session || !this.session.isAdmin) return;
 938: 
 939:         const tableBody = document.getElementById('users-table-body');
 940:         const loading = document.getElementById('users-loading');
 941:         const empty = document.getElementById('users-empty');
 942: 
 943:         loading.classList.remove('hidden');
 944:         empty.classList.add('hidden');
 945:         tableBody.innerHTML = '';
 946: 
 947:         try {
 948:             const params = {
 949:                 status_filter: document.getElementById('users-status-filter').value || undefined,
 950:                 group_filter: document.getElementById('users-group-filter').value || undefined,
 951:                 search: document.getElementById('users-search').value || undefined,
 952:                 sort_by: this.sortState.field,
 953:                 sort_order: this.sortState.order,
 954:             };
 955: 
 956:             const response = await API.adminListUsersEnhanced(params);
 957:             this.users = response.users;
 958: 
 959: 
 960:             await this.loadGroupsForFilter();
 961: 
 962:             if (response.users.length === 0) {
 963:                 empty.classList.remove('hidden');
 964:             } else {
 965:                 tableBody.innerHTML = response.users.map(user => `
 966:                     <tr>
 967:                         <td>${user.first_name} ${user.last_name}</td>
 968:                         <td>${user.username}</td>
 969:                         <td>${user.email}</td>
 970:                         <td><span class="status-badge status-${user.status}">${user.status.toUpperCase()}</span></td>
 971:                         <td>${user.groups.map(g => `<span class="group-badge-small">${g.name}</span>`).join(' ') || '-'}</td>
 972:                         <td>${new Date(user.created_at).toLocaleDateString()}</td>
 973:                         <td class="action-buttons">
 974:                             ${user.status === 'complete' ? `
 975:                                 <button class="btn btn-primary btn-xs" onclick="App.showApproveModal('${user.id}', '${user.username}')">Approve</button>
 976:                                 <button class="btn btn-danger btn-xs" onclick="App.confirmAction('Reject this user?', () => App.rejectUser('${user.id}'))">Reject</button>
 977:                             ` : ''}
 978:                             ${user.status === 'active' ? `
 979:                                 <button class="btn btn-danger btn-xs" onclick="App.confirmAction('Revoke this user?', () => App.revokeUser('${user.id}'))">Revoke</button>
 980:                             ` : ''}
 981:                         </td>
 982:                     </tr>
 983:                 `).join('');
 984:             }
 985: 
 986:         } catch (error) {
 987:             this.showStatus(error.message, 'error');
 988:         } finally {
 989:             loading.classList.add('hidden');
 990:         }
 991:     },
 992: 
 993: 
 994: 
 995: 
 996:     async loadGroupsForFilter() {
 997:         try {
 998:             const response = await API.listGroups();
 999:             this.groups = response.groups;
1000: 
1001:             const filterSelect = document.getElementById('users-group-filter');
1002:             const currentValue = filterSelect.value;
1003: 
1004: 
1005:             filterSelect.innerHTML = '<option value="">All Groups</option>' +
1006:                 response.groups.map(g => `<option value="${g.id}">${g.name}</option>`).join('');
1007: 
1008:             filterSelect.value = currentValue;
1009:         } catch (error) {
1010:             console.warn('Could not load groups for filter', error);
1011:         }
1012:     },
1013: 
1014: 
1015: 
1016: 
1017:     setupAdminGroups() {
1018:         const searchInput = document.getElementById('groups-search');
1019:         const createBtn = document.getElementById('create-group-btn');
1020: 
1021: 
1022:         let searchTimeout;
1023:         searchInput.addEventListener('input', () => {
1024:             clearTimeout(searchTimeout);
1025:             searchTimeout = setTimeout(() => this.loadAdminGroups(), 300);
1026:         });
1027: 
1028: 
1029:         createBtn.addEventListener('click', () => this.showGroupModal());
1030: 
1031: 
1032:         document.querySelectorAll('#groups-table th.sortable').forEach(th => {
1033:             th.addEventListener('click', () => {
1034:                 const field = th.dataset.sort;
1035:                 if (this.sortState.field === field) {
1036:                     this.sortState.order = this.sortState.order === 'asc' ? 'desc' : 'asc';
1037:                 } else {
1038:                     this.sortState.field = field;
1039:                     this.sortState.order = 'asc';
1040:                 }
1041:                 this.updateSortIndicators('groups-table');
1042:                 this.loadAdminGroups();
1043:             });
1044:         });
1045:     },
1046: 
1047: 
1048: 
1049: 
1050:     async loadAdminGroups() {
1051:         if (!this.session || !this.session.isAdmin) return;
1052: 
1053:         const tableBody = document.getElementById('groups-table-body');
1054:         const loading = document.getElementById('groups-loading');
1055:         const empty = document.getElementById('groups-empty');
1056: 
1057:         loading.classList.remove('hidden');
1058:         empty.classList.add('hidden');
1059:         tableBody.innerHTML = '';
1060: 
1061:         try {
1062:             const params = {
1063:                 search: document.getElementById('groups-search').value || undefined,
1064:                 sort_by: this.sortState.field,
1065:                 sort_order: this.sortState.order,
1066:             };
1067: 
1068:             const response = await API.listGroups(params);
1069:             this.groups = response.groups;
1070: 
1071:             if (response.groups.length === 0) {
1072:                 empty.classList.remove('hidden');
1073:             } else {
1074:                 tableBody.innerHTML = response.groups.map(group => `
1075:                     <tr>
1076:                         <td><strong>${group.name}</strong></td>
1077:                         <td>${group.description || '-'}</td>
1078:                         <td>
1079:                             <a href="#" onclick="App.showGroupMembers('${group.id}', '${group.name}'); return false;">
1080:                                 ${group.member_count} members
1081:                             </a>
1082:                         </td>
1083:                         <td>${new Date(group.created_at).toLocaleDateString()}</td>
1084:                         <td class="action-buttons">
1085:                             <button class="btn btn-secondary btn-xs" onclick="App.showGroupModal('${group.id}')">Edit</button>
1086:                             <button class="btn btn-danger btn-xs" onclick="App.confirmAction('Delete this group?', () => App.deleteGroup('${group.id}'))">Delete</button>
1087:                         </td>
1088:                     </tr>
1089:                 `).join('');
1090:             }
1091: 
1092:         } catch (error) {
1093:             this.showStatus(error.message, 'error');
1094:         } finally {
1095:             loading.classList.add('hidden');
1096:         }
1097:     },
1098: 
1099: 
1100: 
1101: 
1102:     updateSortIndicators(tableId) {
1103:         document.querySelectorAll(`#${tableId} th.sortable`).forEach(th => {
1104:             th.classList.remove('sort-asc', 'sort-desc');
1105:             if (th.dataset.sort === this.sortState.field) {
1106:                 th.classList.add(`sort-${this.sortState.order}`);
1107:             }
1108:         });
1109:     },
1110: 
1111: 
1112: 
1113: 
1114:     setupModals() {
1115:         const overlay = document.getElementById('modal-overlay');
1116: 
1117: 
1118:         document.querySelectorAll('[data-close-modal]').forEach(btn => {
1119:             btn.addEventListener('click', () => this.closeModals());
1120:         });
1121: 
1122: 
1123:         overlay.addEventListener('click', (e) => {
1124:             if (e.target === overlay) {
1125:                 this.closeModals();
1126:             }
1127:         });
1128: 
1129: 
1130:         document.getElementById('group-modal-form').addEventListener('submit', async (e) => {
1131:             e.preventDefault();
1132:             await this.saveGroup();
1133:         });
1134: 
1135: 
1136:         document.getElementById('approve-modal-form').addEventListener('submit', async (e) => {
1137:             e.preventDefault();
1138:             await this.approveUser();
1139:         });
1140:     },
1141: 
1142: 
1143: 
1144: 
1145:     closeModals() {
1146:         document.getElementById('modal-overlay').classList.add('hidden');
1147:         document.querySelectorAll('.modal').forEach(m => m.classList.add('hidden'));
1148:     },
1149: 
1150: 
1151: 
1152: 
1153:     async showGroupModal(groupId = null) {
1154:         const modal = document.getElementById('group-modal');
1155:         const title = document.getElementById('group-modal-title');
1156:         const nameInput = document.getElementById('group-name');
1157:         const descInput = document.getElementById('group-description');
1158: 
1159:         if (groupId) {
1160:             title.textContent = 'Edit Group';
1161:             try {
1162:                 const group = await API.getGroup(groupId);
1163:                 nameInput.value = group.name;
1164:                 descInput.value = group.description || '';
1165:                 modal.dataset.groupId = groupId;
1166:             } catch (error) {
1167:                 this.showStatus(error.message, 'error');
1168:                 return;
1169:             }
1170:         } else {
1171:             title.textContent = 'Create Group';
1172:             nameInput.value = '';
1173:             descInput.value = '';
1174:             delete modal.dataset.groupId;
1175:         }
1176: 
1177:         document.getElementById('modal-overlay').classList.remove('hidden');
1178:         modal.classList.remove('hidden');
1179:         nameInput.focus();
1180:     },
1181: 
1182: 
1183: 
1184: 
1185:     async saveGroup() {
1186:         const modal = document.getElementById('group-modal');
1187:         const groupId = modal.dataset.groupId;
1188:         const name = document.getElementById('group-name').value.trim();
1189:         const description = document.getElementById('group-description').value.trim();
1190: 
1191:         if (!name) {
1192:             this.showStatus('Group name is required', 'error');
1193:             return;
1194:         }
1195: 
1196:         try {
1197:             if (groupId) {
1198:                 await API.updateGroup(groupId, { name, description });
1199:                 this.showStatus('Group updated successfully', 'success');
1200:             } else {
1201:                 await API.createGroup(name, description);
1202:                 this.showStatus('Group created successfully', 'success');
1203:             }
1204: 
1205:             this.closeModals();
1206:             this.loadAdminGroups();
1207:         } catch (error) {
1208:             this.showStatus(error.message, 'error');
1209:         }
1210:     },
1211: 
1212: 
1213: 
1214: 
1215:     async deleteGroup(groupId) {
1216:         try {
1217:             await API.deleteGroup(groupId);
1218:             this.showStatus('Group deleted successfully', 'success');
1219:             this.loadAdminGroups();
1220:         } catch (error) {
1221:             this.showStatus(error.message, 'error');
1222:         }
1223:     },
1224: 
1225: 
1226: 
1227: 
1228:     async showGroupMembers(groupId, groupName) {
1229:         const modal = document.getElementById('members-modal');
1230:         const title = document.getElementById('members-modal-title');
1231:         const membersList = document.getElementById('members-list');
1232: 
1233:         title.textContent = `Members of ${groupName}`;
1234:         membersList.innerHTML = '<div class="loading-spinner">Loading...</div>';
1235: 
1236:         document.getElementById('modal-overlay').classList.remove('hidden');
1237:         modal.classList.remove('hidden');
1238: 
1239:         try {
1240:             const group = await API.getGroup(groupId);
1241: 
1242:             if (group.members.length === 0) {
1243:                 membersList.innerHTML = '<div class="empty-state">No members in this group</div>';
1244:             } else {
1245:                 membersList.innerHTML = group.members.map(m => `
1246:                     <div class="member-item">
1247:                         <span class="member-name">${m.full_name}</span>
1248:                         <span class="member-username">@${m.username}</span>
1249:                     </div>
1250:                 `).join('');
1251:             }
1252:         } catch (error) {
1253:             membersList.innerHTML = `<div class="error-message">${escapeHtml(error.message)}</div>`;
1254:         }
1255:     },
1256: 
1257:     /**
1258:      * Show approve user modal with group selection
1259:      */
1260:     async showApproveModal(userId, username) {
1261:         const modal = document.getElementById('approve-modal');
1262:         const userNameEl = document.getElementById('approve-user-name');
1263:         const groupsList = document.getElementById('approve-groups-list');
1264: 
1265:         userNameEl.textContent = username;
1266:         modal.dataset.userId = userId;
1267: 
1268: 
1269:         groupsList.innerHTML = '<div class="loading-spinner">Loading groups...</div>';
1270: 
1271:         document.getElementById('modal-overlay').classList.remove('hidden');
1272:         modal.classList.remove('hidden');
1273: 
1274:         try {
1275:             const response = await API.listGroups();
1276: 
1277:             if (response.groups.length === 0) {
1278:                 groupsList.innerHTML = '<div class="warning-message">No groups available. Please create a group first.</div>';
1279:             } else {
1280:                 groupsList.innerHTML = response.groups.map(g => `
1281:                     <label class="checkbox-option">
1282:                         <input type="checkbox" name="approve_group" value="${g.id}">
1283:                         <span>${g.name}</span>
1284:                     </label>
1285:                 `).join('');
1286:             }
1287:         } catch (error) {
1288:             groupsList.innerHTML = `<div class="error-message">${escapeHtml(error.message)}</div>`;
1289:         }
1290:     },
1291: 
1292:     /**
1293:      * Approve user (from modal)
1294:      */
1295:     async approveUser() {
1296:         const modal = document.getElementById('approve-modal');
1297:         const userId = modal.dataset.userId;
1298:         const selectedGroups = Array.from(
1299:             document.querySelectorAll('input[name="approve_group"]:checked')
1300:         ).map(cb => cb.value);
1301: 
1302:         if (selectedGroups.length === 0) {
1303:             this.showStatus('Please select at least one group', 'error');
1304:             return;
1305:         }
1306: 
1307:         try {
1308: 
1309:             await API.assignUserGroups(userId, selectedGroups);
1310: 
1311: 
1312: 
1313: 
1314:             this.showStatus('User approved and assigned to groups. Please complete activation via legacy admin panel.', 'warning');
1315: 
1316:             this.closeModals();
1317:             this.loadAdminUsers();
1318:         } catch (error) {
1319:             this.showStatus(error.message, 'error');
1320:         }
1321:     },
1322: 
1323: 
1324: 
1325: 
1326:     async rejectUser(userId) {
1327:         try {
1328: 
1329:             this.showStatus('Please use legacy admin panel to reject users for now.', 'warning');
1330:         } catch (error) {
1331:             this.showStatus(error.message, 'error');
1332:         }
1333:     },
1334: 
1335: 
1336: 
1337: 
1338:     async revokeUser(userId) {
1339:         try {
1340:             await API.revokeUser(userId);
1341:             this.showStatus('User revoked successfully', 'success');
1342:             this.loadAdminUsers();
1343:         } catch (error) {
1344:             this.showStatus(error.message, 'error');
1345:         }
1346:     },
1347: 
1348: 
1349: 
1350: 
1351:     confirmAction(message, callback) {
1352:         const modal = document.getElementById('confirm-modal');
1353:         const messageEl = document.getElementById('confirm-modal-message');
1354:         const okBtn = document.getElementById('confirm-modal-ok');
1355: 
1356:         messageEl.textContent = message;
1357: 
1358: 
1359:         const newOkBtn = okBtn.cloneNode(true);
1360:         okBtn.parentNode.replaceChild(newOkBtn, okBtn);
1361: 
1362:         newOkBtn.addEventListener('click', () => {
1363:             this.closeModals();
1364:             callback();
1365:         });
1366: 
1367:         document.getElementById('modal-overlay').classList.remove('hidden');
1368:         modal.classList.remove('hidden');
1369:     },
1370: 
1371: 
1372: 
1373: 
1374: 
1375: 
1376:     showStatus(message, type = 'success') {
1377:         const statusEl = document.getElementById('status-message');
1378: 
1379:         statusEl.textContent = message;
1380:         statusEl.className = `status-message ${type}`;
1381:         statusEl.classList.remove('hidden');
1382: 
1383:         setTimeout(() => {
1384:             statusEl.classList.add('hidden');
1385:         }, 4000);
1386:     },
1387: 
1388: 
1389: 
1390: 
1391:     clearResults() {
1392:         document.getElementById('login-result').classList.add('hidden');
1393:         document.getElementById('signup-result').classList.add('hidden');
1394:         document.getElementById('enroll-result').classList.add('hidden');
1395:         document.getElementById('qr-section').classList.add('hidden');
1396:         document.getElementById('sms-enroll-section').classList.add('hidden');
1397: 
1398: 
1399:         const sendSmsBtn = document.getElementById('send-sms-btn');
1400:         const smsStatus = document.getElementById('sms-status');
1401:         sendSmsBtn.classList.add('hidden');
1402:         smsStatus.classList.add('hidden');
1403:     }
1404: };
1405: 
1406: 
1407: window.App = App;
````

## File: application/frontend/src/index.html
````html
  1: <!DOCTYPE html>
  2: <html lang="en">
  3: <head>
  4:     <meta charset="UTF-8">
  5:     <meta name="viewport" content="width=device-width, initial-scale=1.0">
  6:     <meta name="description" content="LDAP 2FA Authentication Application">
  7:     <title>LDAP 2FA Authentication</title>
  8:     <link rel="stylesheet" href="/css/styles.css">
  9: 
 10:     <script src="https://cdn.jsdelivr.net/npm/qrcode@1.5.3/build/qrcode.min.js"></script>
 11: </head>
 12: <body>
 13: 
 14:     <header id="top-bar" class="top-bar hidden">
 15:         <div class="top-bar-content">
 16:             <div class="top-bar-brand">
 17:                 <span class="brand-icon"></span>
 18:                 <span class="brand-text">LDAP 2FA</span>
 19:             </div>
 20:             <div class="top-bar-user">
 21:                 <button id="user-menu-btn" class="user-menu-btn">
 22:                     <span id="user-display-name" class="user-name">User</span>
 23:                     <span class="dropdown-arrow"></span>
 24:                 </button>
 25:                 <div id="user-dropdown" class="user-dropdown hidden">
 26:                     <a href="#" id="menu-profile" class="dropdown-item">
 27:                         <span class="dropdown-icon"></span> Profile
 28:                     </a>
 29:                     <div id="admin-menu-items" class="hidden">
 30:                         <hr class="dropdown-divider">
 31:                         <a href="#" id="menu-admin-users" class="dropdown-item">
 32:                             <span class="dropdown-icon"></span> User Management
 33:                         </a>
 34:                         <a href="#" id="menu-admin-groups" class="dropdown-item">
 35:                             <span class="dropdown-icon"></span> Group Management
 36:                         </a>
 37:                     </div>
 38:                     <hr class="dropdown-divider">
 39:                     <a href="#" id="menu-logout" class="dropdown-item">
 40:                         <span class="dropdown-icon"></span> Logout
 41:                     </a>
 42:                 </div>
 43:             </div>
 44:         </div>
 45:     </header>
 46: 
 47: 
 48:     <div id="main-container" class="container">
 49:         <header id="auth-header">
 50:             <h1> LDAP 2FA Authentication</h1>
 51:             <p class="subtitle">Secure two-factor authentication for your LDAP account</p>
 52:         </header>
 53: 
 54: 
 55:         <nav id="auth-tabs" class="tabs">
 56:             <button class="tab-btn active" data-tab="login">Login</button>
 57:             <button class="tab-btn" data-tab="signup">Sign Up</button>
 58:             <button class="tab-btn" data-tab="enroll">Enroll MFA</button>
 59:         </nav>
 60: 
 61: 
 62:         <section id="login-tab" class="tab-content active">
 63:             <form id="login-form" class="auth-form">
 64:                 <div class="form-group">
 65:                     <label for="login-username">Username</label>
 66:                     <input type="text" id="login-username" name="username" required
 67:                            placeholder="Enter your username" autocomplete="username">
 68:                 </div>
 69: 
 70:                 <div class="form-group">
 71:                     <label for="login-password">Password</label>
 72:                     <input type="password" id="login-password" name="password" required
 73:                            placeholder="Enter your password" autocomplete="current-password">
 74:                 </div>
 75: 
 76:                 <div class="form-group">
 77:                     <label for="login-code">Verification Code</label>
 78:                     <div class="code-input-group">
 79:                         <input type="text" id="login-code" name="verification_code" required
 80:                                placeholder="Enter 6-digit code" maxlength="6" pattern="[0-9]{6}"
 81:                                autocomplete="one-time-code" inputmode="numeric">
 82:                         <button type="button" id="send-sms-btn" class="btn btn-secondary btn-small hidden">
 83:                             Send SMS
 84:                         </button>
 85:                     </div>
 86:                     <small id="sms-status" class="form-hint hidden"></small>
 87:                 </div>
 88: 
 89:                 <button type="submit" class="btn btn-primary">
 90:                     <span class="btn-text">Login</span>
 91:                     <span class="btn-loading hidden">Authenticating...</span>
 92:                 </button>
 93:             </form>
 94: 
 95:             <div id="login-result" class="result-container hidden"></div>
 96:         </section>
 97: 
 98: 
 99:         <section id="signup-tab" class="tab-content">
100:             <form id="signup-form" class="auth-form">
101:                 <div class="form-row">
102:                     <div class="form-group">
103:                         <label for="signup-firstname">First Name</label>
104:                         <input type="text" id="signup-firstname" name="first_name" required
105:                                placeholder="First name" autocomplete="given-name">
106:                     </div>
107:                     <div class="form-group">
108:                         <label for="signup-lastname">Last Name</label>
109:                         <input type="text" id="signup-lastname" name="last_name" required
110:                                placeholder="Last name" autocomplete="family-name">
111:                     </div>
112:                 </div>
113: 
114:                 <div class="form-group">
115:                     <label for="signup-username">Username</label>
116:                     <input type="text" id="signup-username" name="username" required
117:                            placeholder="Choose a username" autocomplete="username"
118:                            pattern="[a-zA-Z][a-zA-Z0-9_-]*" minlength="3" maxlength="64">
119:                     <small class="form-hint">Letters, numbers, underscores, and hyphens only</small>
120:                 </div>
121: 
122:                 <div class="form-group">
123:                     <label for="signup-email">Email</label>
124:                     <input type="email" id="signup-email" name="email" required
125:                            placeholder="your@email.com" autocomplete="email">
126:                 </div>
127: 
128:                 <div class="form-group">
129:                     <label for="signup-phone">Phone Number</label>
130:                     <div class="phone-input-group">
131:                         <select id="signup-country-code" name="phone_country_code" required>
132:                             <option value="+1"> +1</option>
133:                             <option value="+44"> +44</option>
134:                             <option value="+49"> +49</option>
135:                             <option value="+33"> +33</option>
136:                             <option value="+39"> +39</option>
137:                             <option value="+34"> +34</option>
138:                             <option value="+31"> +31</option>
139:                             <option value="+32"> +32</option>
140:                             <option value="+41"> +41</option>
141:                             <option value="+43"> +43</option>
142:                             <option value="+46"> +46</option>
143:                             <option value="+47"> +47</option>
144:                             <option value="+45"> +45</option>
145:                             <option value="+358"> +358</option>
146:                             <option value="+48"> +48</option>
147:                             <option value="+351"> +351</option>
148:                             <option value="+353"> +353</option>
149:                             <option value="+972"> +972</option>
150:                             <option value="+971"> +971</option>
151:                             <option value="+966"> +966</option>
152:                             <option value="+91"> +91</option>
153:                             <option value="+86"> +86</option>
154:                             <option value="+81"> +81</option>
155:                             <option value="+82"> +82</option>
156:                             <option value="+65"> +65</option>
157:                             <option value="+61"> +61</option>
158:                             <option value="+64"> +64</option>
159:                             <option value="+55"> +55</option>
160:                             <option value="+52"> +52</option>
161:                             <option value="+54"> +54</option>
162:                             <option value="+27"> +27</option>
163:                             <option value="+234"> +234</option>
164:                             <option value="+254"> +254</option>
165:                             <option value="+20"> +20</option>
166:                         </select>
167:                         <input type="tel" id="signup-phone" name="phone_number" required
168:                                placeholder="Phone number" autocomplete="tel-national"
169:                                pattern="[0-9]{5,15}" minlength="5" maxlength="15">
170:                     </div>
171:                     <small class="form-hint">Enter your phone number without the country code</small>
172:                 </div>
173: 
174:                 <div class="form-group">
175:                     <label for="signup-password">Password</label>
176:                     <input type="password" id="signup-password" name="password" required
177:                            placeholder="Create a password" autocomplete="new-password"
178:                            minlength="8">
179:                     <small class="form-hint">Minimum 8 characters</small>
180:                 </div>
181: 
182:                 <div class="form-group">
183:                     <label for="signup-confirm-password">Confirm Password</label>
184:                     <input type="password" id="signup-confirm-password" name="confirm_password" required
185:                            placeholder="Confirm your password" autocomplete="new-password">
186:                 </div>
187: 
188: 
189:                 <div class="form-group">
190:                     <label>MFA Method</label>
191:                     <div class="mfa-method-selector">
192:                         <label class="radio-option">
193:                             <input type="radio" name="signup_mfa_method" value="totp" checked>
194:                             <span class="radio-label">
195:                                 <span class="radio-icon"></span>
196:                                 <span class="radio-text">
197:                                     <strong>Authenticator App</strong>
198:                                     <small>Google Authenticator, Authy, etc.</small>
199:                                 </span>
200:                             </span>
201:                         </label>
202:                         <label class="radio-option" id="signup-sms-option">
203:                             <input type="radio" name="signup_mfa_method" value="sms">
204:                             <span class="radio-label">
205:                                 <span class="radio-icon"></span>
206:                                 <span class="radio-text">
207:                                     <strong>SMS</strong>
208:                                     <small>Receive codes via text message</small>
209:                                 </span>
210:                             </span>
211:                         </label>
212:                     </div>
213:                 </div>
214: 
215:                 <button type="submit" class="btn btn-primary">
216:                     <span class="btn-text">Create Account</span>
217:                     <span class="btn-loading hidden">Creating Account...</span>
218:                 </button>
219:             </form>
220: 
221: 
222:             <div id="verification-status" class="verification-panel hidden">
223:                 <h3> Complete Your Registration</h3>
224:                 <p class="verification-subtitle">Please verify your email and phone to continue</p>
225: 
226:                 <div class="verification-items">
227:                     <div class="verification-item">
228:                         <span class="status-icon" id="email-verify-status"></span>
229:                         <div class="verification-details">
230:                             <span class="verification-label">Email Verification</span>
231:                             <span class="verification-hint" id="email-verify-hint">Check your inbox</span>
232:                         </div>
233:                         <button type="button" id="resend-email-btn" class="btn btn-secondary btn-small">
234:                             Resend
235:                         </button>
236:                     </div>
237:                     <div class="verification-item">
238:                         <span class="status-icon" id="phone-verify-status"></span>
239:                         <div class="verification-details">
240:                             <span class="verification-label">Phone Verification</span>
241:                             <span class="verification-hint" id="phone-verify-hint">Enter code sent to your phone</span>
242:                         </div>
243:                         <button type="button" id="resend-phone-btn" class="btn btn-secondary btn-small">
244:                             Resend
245:                         </button>
246:                     </div>
247:                 </div>
248: 
249: 
250:                 <div class="phone-verify-input">
251:                     <div class="form-group">
252:                         <label for="phone-verify-code">Phone Verification Code</label>
253:                         <div class="code-input-group">
254:                             <input type="text" id="phone-verify-code"
255:                                    placeholder="Enter 6-digit code" maxlength="6"
256:                                    pattern="[0-9]{6}" inputmode="numeric">
257:                             <button type="button" id="verify-phone-btn" class="btn btn-primary btn-small">
258:                                 Verify
259:                             </button>
260:                         </div>
261:                     </div>
262:                 </div>
263: 
264:                 <div id="verification-complete" class="verification-complete hidden">
265:                     <div class="success-icon"></div>
266:                     <h4>Verification Complete!</h4>
267:                     <p>Your account is now awaiting admin approval. You will receive an email once activated.</p>
268:                 </div>
269:             </div>
270: 
271:             <div id="signup-result" class="result-container hidden"></div>
272:         </section>
273: 
274: 
275:         <section id="enroll-tab" class="tab-content">
276:             <form id="enroll-form" class="auth-form">
277:                 <div class="form-group">
278:                     <label for="enroll-username">Username</label>
279:                     <input type="text" id="enroll-username" name="username" required
280:                            placeholder="Enter your username" autocomplete="username">
281:                 </div>
282: 
283:                 <div class="form-group">
284:                     <label for="enroll-password">Password</label>
285:                     <input type="password" id="enroll-password" name="password" required
286:                            placeholder="Enter your password" autocomplete="current-password">
287:                 </div>
288: 
289: 
290:                 <div class="form-group">
291:                     <label>MFA Method</label>
292:                     <div class="mfa-method-selector">
293:                         <label class="radio-option">
294:                             <input type="radio" name="mfa_method" value="totp" checked>
295:                             <span class="radio-label">
296:                                 <span class="radio-icon"></span>
297:                                 <span class="radio-text">
298:                                     <strong>Authenticator App</strong>
299:                                     <small>Google Authenticator, Authy, etc.</small>
300:                                 </span>
301:                             </span>
302:                         </label>
303:                         <label class="radio-option" id="sms-option">
304:                             <input type="radio" name="mfa_method" value="sms">
305:                             <span class="radio-label">
306:                                 <span class="radio-icon"></span>
307:                                 <span class="radio-text">
308:                                     <strong>SMS</strong>
309:                                     <small>Receive codes via text message</small>
310:                                 </span>
311:                             </span>
312:                         </label>
313:                     </div>
314:                 </div>
315: 
316: 
317:                 <div class="form-group hidden" id="phone-group">
318:                     <label for="enroll-phone">Phone Number</label>
319:                     <input type="tel" id="enroll-phone" name="phone_number"
320:                            placeholder="+1234567890 (E.164 format)"
321:                            pattern="\+[1-9]\d{1,14}">
322:                     <small class="form-hint">
323:                         Enter phone number with country code (e.g., +1 for US)
324:                     </small>
325:                 </div>
326: 
327:                 <button type="submit" class="btn btn-primary">
328:                     <span class="btn-text">Enroll for MFA</span>
329:                     <span class="btn-loading hidden">Enrolling...</span>
330:                 </button>
331:             </form>
332: 
333:             <div id="enroll-result" class="result-container hidden">
334: 
335:                 <div id="qr-section" class="qr-section hidden">
336:                     <h3>Scan QR Code</h3>
337:                     <p>Scan this QR code with your authenticator app (Google Authenticator, Authy, etc.)</p>
338:                     <div id="qr-code" class="qr-code"></div>
339:                     <div class="manual-entry">
340:                         <p>Or manually enter this secret:</p>
341:                         <code id="secret-code"></code>
342:                         <button id="copy-secret" class="btn btn-secondary btn-small">Copy Secret</button>
343:                     </div>
344:                 </div>
345: 
346: 
347:                 <div id="sms-enroll-section" class="sms-section hidden">
348:                     <h3> SMS Verification Setup</h3>
349:                     <p>A verification code has been sent to <strong id="enrolled-phone"></strong></p>
350:                     <p class="hint">You can now use SMS codes to log in. Each code expires in 5 minutes.</p>
351:                 </div>
352:             </div>
353:         </section>
354: 
355: 
356:         <section id="profile-section" class="tab-content hidden">
357:             <div class="section-header">
358:                 <h2> My Profile</h2>
359:             </div>
360:             <form id="profile-form" class="auth-form">
361:                 <div class="form-group">
362:                     <label>Username</label>
363:                     <input type="text" id="profile-username" readonly class="readonly-input">
364:                 </div>
365: 
366:                 <div class="form-row">
367:                     <div class="form-group">
368:                         <label for="profile-firstname">First Name</label>
369:                         <input type="text" id="profile-firstname" name="first_name">
370:                     </div>
371:                     <div class="form-group">
372:                         <label for="profile-lastname">Last Name</label>
373:                         <input type="text" id="profile-lastname" name="last_name">
374:                     </div>
375:                 </div>
376: 
377:                 <div class="form-group">
378:                     <label for="profile-email">Email</label>
379:                     <input type="email" id="profile-email" name="email">
380:                     <small id="profile-email-hint" class="form-hint"></small>
381:                 </div>
382: 
383:                 <div class="form-group">
384:                     <label for="profile-phone">Phone Number</label>
385:                     <div class="phone-input-group">
386:                         <select id="profile-country-code" name="phone_country_code">
387:                             <option value="+1"> +1</option>
388:                             <option value="+44"> +44</option>
389:                             <option value="+49"> +49</option>
390:                             <option value="+33"> +33</option>
391:                             <option value="+91"> +91</option>
392:                         </select>
393:                         <input type="tel" id="profile-phone" name="phone_number">
394:                     </div>
395:                     <small id="profile-phone-hint" class="form-hint"></small>
396:                 </div>
397: 
398:                 <div class="form-group">
399:                     <label>MFA Method</label>
400:                     <input type="text" id="profile-mfa" readonly class="readonly-input">
401:                 </div>
402: 
403:                 <div class="form-group">
404:                     <label>Account Status</label>
405:                     <input type="text" id="profile-status" readonly class="readonly-input">
406:                 </div>
407: 
408:                 <div class="form-group">
409:                     <label>Groups</label>
410:                     <div id="profile-groups" class="group-badges"></div>
411:                 </div>
412: 
413:                 <button type="submit" class="btn btn-primary">
414:                     <span class="btn-text">Save Changes</span>
415:                     <span class="btn-loading hidden">Saving...</span>
416:                 </button>
417:             </form>
418:         </section>
419: 
420: 
421:         <section id="admin-users-section" class="tab-content hidden">
422:             <div class="section-header">
423:                 <h2> User Management</h2>
424:             </div>
425: 
426:             <div class="admin-controls">
427:                 <div class="search-box">
428:                     <input type="text" id="users-search" placeholder="Search users..." class="search-input">
429:                 </div>
430:                 <div class="filter-controls">
431:                     <select id="users-status-filter" class="filter-select">
432:                         <option value="">All Statuses</option>
433:                         <option value="pending">Pending</option>
434:                         <option value="complete">Awaiting Approval</option>
435:                         <option value="active">Active</option>
436:                         <option value="revoked">Revoked</option>
437:                     </select>
438:                     <select id="users-group-filter" class="filter-select">
439:                         <option value="">All Groups</option>
440:                     </select>
441:                     <button type="button" id="users-refresh-btn" class="btn btn-secondary btn-small">
442:                          Refresh
443:                     </button>
444:                 </div>
445:             </div>
446: 
447:             <div class="data-table-container">
448:                 <table class="data-table" id="users-table">
449:                     <thead>
450:                         <tr>
451:                             <th class="sortable" data-sort="first_name">Name</th>
452:                             <th class="sortable" data-sort="username">Username</th>
453:                             <th class="sortable" data-sort="email">Email</th>
454:                             <th class="sortable" data-sort="status">Status</th>
455:                             <th>Groups</th>
456:                             <th class="sortable" data-sort="created_at">Created</th>
457:                             <th>Actions</th>
458:                         </tr>
459:                     </thead>
460:                     <tbody id="users-table-body">
461: 
462:                     </tbody>
463:                 </table>
464:             </div>
465: 
466:             <div id="users-loading" class="loading-spinner hidden">Loading...</div>
467:             <div id="users-empty" class="empty-state hidden">No users found</div>
468:         </section>
469: 
470: 
471:         <section id="admin-groups-section" class="tab-content hidden">
472:             <div class="section-header">
473:                 <h2> Group Management</h2>
474:                 <button type="button" id="create-group-btn" class="btn btn-primary btn-small">
475:                     + Create Group
476:                 </button>
477:             </div>
478: 
479:             <div class="admin-controls">
480:                 <div class="search-box">
481:                     <input type="text" id="groups-search" placeholder="Search groups..." class="search-input">
482:                 </div>
483:             </div>
484: 
485:             <div class="data-table-container">
486:                 <table class="data-table" id="groups-table">
487:                     <thead>
488:                         <tr>
489:                             <th class="sortable" data-sort="name">Name</th>
490:                             <th>Description</th>
491:                             <th>Members</th>
492:                             <th class="sortable" data-sort="created_at">Created</th>
493:                             <th>Actions</th>
494:                         </tr>
495:                     </thead>
496:                     <tbody id="groups-table-body">
497: 
498:                     </tbody>
499:                 </table>
500:             </div>
501: 
502:             <div id="groups-loading" class="loading-spinner hidden">Loading...</div>
503:             <div id="groups-empty" class="empty-state hidden">No groups found</div>
504:         </section>
505: 
506: 
507:         <div id="status-message" class="status-message hidden"></div>
508: 
509:         <footer>
510:             <p> Need help? Contact your system administrator.</p>
511:         </footer>
512:     </div>
513: 
514: 
515:     <div id="modal-overlay" class="modal-overlay hidden">
516: 
517:         <div id="group-modal" class="modal hidden">
518:             <div class="modal-header">
519:                 <h3 id="group-modal-title">Create Group</h3>
520:                 <button type="button" class="modal-close" data-close-modal>&times;</button>
521:             </div>
522:             <form id="group-modal-form">
523:                 <div class="modal-body">
524:                     <div class="form-group">
525:                         <label for="group-name">Group Name</label>
526:                         <input type="text" id="group-name" required placeholder="Enter group name">
527:                     </div>
528:                     <div class="form-group">
529:                         <label for="group-description">Description</label>
530:                         <textarea id="group-description" rows="3" placeholder="Enter description"></textarea>
531:                     </div>
532:                 </div>
533:                 <div class="modal-footer">
534:                     <button type="button" class="btn btn-secondary" data-close-modal>Cancel</button>
535:                     <button type="submit" class="btn btn-primary">Save</button>
536:                 </div>
537:             </form>
538:         </div>
539: 
540: 
541:         <div id="approve-modal" class="modal hidden">
542:             <div class="modal-header">
543:                 <h3>Approve User</h3>
544:                 <button type="button" class="modal-close" data-close-modal>&times;</button>
545:             </div>
546:             <form id="approve-modal-form">
547:                 <div class="modal-body">
548:                     <p>Approve user <strong id="approve-user-name"></strong> and assign to groups:</p>
549:                     <div class="form-group">
550:                         <label>Select Groups (at least one required)</label>
551:                         <div id="approve-groups-list" class="checkbox-list">
552: 
553:                         </div>
554:                     </div>
555:                 </div>
556:                 <div class="modal-footer">
557:                     <button type="button" class="btn btn-secondary" data-close-modal>Cancel</button>
558:                     <button type="submit" class="btn btn-primary">Approve</button>
559:                 </div>
560:             </form>
561:         </div>
562: 
563: 
564:         <div id="members-modal" class="modal hidden">
565:             <div class="modal-header">
566:                 <h3 id="members-modal-title">Group Members</h3>
567:                 <button type="button" class="modal-close" data-close-modal>&times;</button>
568:             </div>
569:             <div class="modal-body">
570:                 <div id="members-list" class="members-list">
571: 
572:                 </div>
573:             </div>
574:             <div class="modal-footer">
575:                 <button type="button" class="btn btn-secondary" data-close-modal>Close</button>
576:             </div>
577:         </div>
578: 
579: 
580:         <div id="confirm-modal" class="modal hidden">
581:             <div class="modal-header">
582:                 <h3 id="confirm-modal-title">Confirm</h3>
583:                 <button type="button" class="modal-close" data-close-modal>&times;</button>
584:             </div>
585:             <div class="modal-body">
586:                 <p id="confirm-modal-message"></p>
587:             </div>
588:             <div class="modal-footer">
589:                 <button type="button" class="btn btn-secondary" data-close-modal>Cancel</button>
590:                 <button type="button" id="confirm-modal-ok" class="btn btn-danger">Confirm</button>
591:             </div>
592:         </div>
593:     </div>
594: 
595:     <script src="/js/api.js"></script>
596:     <script src="/js/main.js"></script>
597: </body>
598: </html>
````

## File: application/modules/alb/variables.tf
````hcl
 1: variable "env" {
 2:   description = "Environment suffix used to name resources"
 3:   type        = string
 4: }
 5: 
 6: variable "region" {
 7:   description = "Deployment region"
 8:   type        = string
 9: }
10: 
11: variable "prefix" {
12:   description = "Prefix used to name resources"
13:   type        = string
14: }
15: 
16: variable "app_name" {
17:   description = "Application name"
18:   type        = string
19: }
20: 
21: variable "cluster_name" {
22:   description = "Name of EKS Cluster where ALB is to be deployed"
23:   type        = string
24: }
25: 
26: # variable "ingress_alb_name" {
27: #   description = "Name component for ingress ALB resource (between prefix and env)"
28: #   type        = string
29: # }
30: 
31: # variable "service_alb_name" {
32: #   description = "Name component for service ALB resource (between prefix and env)"
33: #   type        = string
34: # }
35: 
36: variable "ingressclass_alb_name" {
37:   description = "Name component for ingressclass ALB resource (between prefix and env)"
38:   type        = string
39: }
40: 
41: variable "ingressclassparams_alb_name" {
42:   description = "Name component for ingressclassparams ALB resource (between prefix and env)"
43:   type        = string
44: }
45: 
46: variable "acm_certificate_arn" {
47:   description = "ACM certificate ARN for HTTPS/TLS termination at ALB"
48:   type        = string
49:   default     = null
50: }
51: 
52: variable "alb_scheme" {
53:   description = "ALB scheme: internet-facing or internal"
54:   type        = string
55:   default     = "internet-facing"
56:   validation {
57:     condition     = contains(["internet-facing", "internal"], var.alb_scheme)
58:     error_message = "ALB scheme must be either 'internet-facing' or 'internal'"
59:   }
60: }
61: 
62: variable "alb_ip_address_type" {
63:   description = "ALB IP address type: ipv4 or dualstack"
64:   type        = string
65:   default     = "ipv4"
66:   validation {
67:     condition     = contains(["ipv4", "dualstack"], var.alb_ip_address_type)
68:     error_message = "ALB IP address type must be either 'ipv4' or 'dualstack'"
69:   }
70: }
71: 
72: variable "alb_group_name" {
73:   description = "ALB group name for grouping multiple Ingress resources to share a single ALB. This is an internal Kubernetes identifier (max 63 characters)."
74:   type        = string
75:   default     = null # If null, will be derived from app_name
76: }
77: 
78: variable "kubernetes_master" {
79:   description = "Kubernetes API server endpoint (KUBERNETES_MASTER environment variable). Set by set-k8s-env.sh or GitHub workflow."
80:   type        = string
81:   default     = null
82:   nullable    = true
83: }
84: 
85: variable "kube_config_path" {
86:   description = "Path to kubeconfig file (KUBE_CONFIG_PATH environment variable). Set by set-k8s-env.sh or GitHub workflow."
87:   type        = string
88:   default     = null
89:   nullable    = true
90: }
91: 
92: variable "wait_for_crd" {
93:   description = "Whether to wait for EKS Auto Mode CRD to be available before creating IngressClassParams. Set to true for initial cluster deployments, false after cluster is established."
94:   type        = bool
95:   default     = false
96: }
````

## File: application/modules/argocd_app/README.md
````markdown
  1: # ArgoCD Application Module
  2: 
  3: This module creates an ArgoCD Application resource that subscribes a Kubernetes
  4: application to ArgoCD for GitOps deployment.
  5: 
  6: ## Purpose
  7: 
  8: The ArgoCD Application module:
  9: 
 10: - Creates a Kubernetes Application CRD that ArgoCD uses to manage application deployments
 11: - Configures source (Git repository, path, revision) and destination (cluster, namespace)
 12: - Sets up sync policies for automated or manual deployments
 13: - Supports Helm charts, Kustomize, and plain Kubernetes manifests
 14: 
 15: ## What it Creates
 16: 
 17: 1. **ArgoCD Application** (`kubernetes_manifest.argocd_app`)
 18:    - Kubernetes Custom Resource of type `Application` from `argoproj.io/v1alpha1`
 19:    - Defines source repository, path, and target cluster/namespace
 20:    - Configures sync behavior (automated, manual, retry policies)
 21:    - Supports Helm, Kustomize, and directory-based deployments
 22: 
 23: ## Prerequisites
 24: 
 25: - ArgoCD Capability must be deployed and active
 26: - Local cluster must be registered with ArgoCD (via cluster secret)
 27: - Git repository must be accessible from ArgoCD
 28: - Kubernetes provider must be configured with access to the EKS cluster
 29: 
 30: ## Usage
 31: 
 32: ### Basic Application (Plain Manifests)
 33: 
 34: ```hcl
 35: module "argocd_app_example" {
 36:   source = "./modules/argocd_app"
 37: 
 38:   app_name              = "example-app"
 39:   argocd_namespace      = "argocd"
 40:   cluster_name_in_argo  = "local-cluster"
 41:   repo_url              = "https://github.com/you/your-repo.git"
 42:   target_revision       = "main"
 43:   repo_path             = "apps/example-app"
 44:   destination_namespace = "example"
 45: 
 46:   sync_policy = {
 47:     automated = {
 48:       prune      = true
 49:       self_heal   = true
 50:       allow_empty = false
 51:     }
 52:     sync_options = ["CreateNamespace=true"]
 53:   }
 54: 
 55:   depends_on = [
 56:     module.argocd
 57:   ]
 58: }
 59: ```
 60: 
 61: ### Helm Chart Application
 62: 
 63: ```hcl
 64: module "argocd_app_helm" {
 65:   source = "./modules/argocd_app"
 66: 
 67:   app_name              = "nginx-app"
 68:   argocd_namespace      = "argocd"
 69:   cluster_name_in_argo  = "local-cluster"
 70:   repo_url              = "https://github.com/you/helm-charts.git"
 71:   target_revision       = "main"
 72:   repo_path             = "charts/nginx"
 73:   destination_namespace = "nginx"
 74: 
 75:   helm_config = {
 76:     value_files = ["values.yaml", "values-prod.yaml"]
 77:     parameters = [
 78:       {
 79:         name  = "replicaCount"
 80:         value = "3"
 81:       },
 82:       {
 83:         name         = "image.tag"
 84:         value        = "1.21.0"
 85:         force_string = false
 86:       }
 87:     ]
 88:     release_name = "nginx"
 89:   }
 90: 
 91:   sync_policy = {
 92:     automated = {
 93:       prune     = true
 94:       self_heal = true
 95:     }
 96:     sync_options = ["CreateNamespace=true"]
 97:   }
 98: 
 99:   depends_on = [
100:     module.argocd
101:   ]
102: }
103: ```
104: 
105: ### Kustomize Application
106: 
107: ```hcl
108: module "argocd_app_kustomize" {
109:   source = "./modules/argocd_app"
110: 
111:   app_name              = "kustomize-app"
112:   argocd_namespace      = "argocd"
113:   cluster_name_in_argo  = "local-cluster"
114:   repo_url              = "https://github.com/you/kustomize-apps.git"
115:   target_revision       = "main"
116:   repo_path             = "overlays/production"
117:   destination_namespace = "production"
118: 
119:   kustomize_config = {
120:     images = ["nginx:1.21.0"]
121:     common_labels = {
122:       environment = "production"
123:       managed-by  = "argocd"
124:     }
125:   }
126: 
127:   sync_policy = {
128:     automated = {
129:       prune     = true
130:       self_heal = true
131:     }
132:   }
133: 
134:   depends_on = [
135:     module.argocd
136:   ]
137: }
138: ```
139: 
140: ### Manual Sync Application
141: 
142: ```hcl
143: module "argocd_app_manual" {
144:   source = "./modules/argocd_app"
145: 
146:   app_name              = "manual-app"
147:   argocd_namespace      = "argocd"
148:   cluster_name_in_argo  = "local-cluster"
149:   repo_url              = "https://github.com/you/your-repo.git"
150:   target_revision       = "main"
151:   repo_path             = "apps/manual-app"
152:   destination_namespace = "manual"
153: 
154:   # No sync_policy = manual sync only
155:   sync_policy = null
156: 
157:   depends_on = [
158:     module.argocd
159:   ]
160: }
161: ```
162: 
163: ## Inputs
164: 
165: | Name | Description | Type | Required | Default |
166: | ------ | ------------- | ------ | ---------- | --------- |
167: | app_name | Name of the ArgoCD Application | string | yes | - |
168: | argocd_namespace | Kubernetes namespace for ArgoCD Application | string | no | "argocd" |
169: | argocd_project_name | ArgoCD project name | string | no | "default" |
170: | cluster_name_in_argo | Name of the cluster in ArgoCD | string | yes | - |
171: | repo_url | Git repository URL | string | yes | - |
172: | target_revision | Git branch/tag/commit | string | no | "HEAD" |
173: | repo_path | Path within repository | string | yes | - |
174: | destination_namespace | Target Kubernetes namespace | string | yes | - |
175: | destination_server | Optional Kubernetes server URL | string | no | null |
176: | app_labels | Labels for Application resource | map(string) | no | {} |
177: | app_annotations | Annotations for Application resource | map(string) | no | {} |
178: | sync_policy | Sync policy configuration | object | no | null |
179: | ignore_differences | List of ignore differences configs | list(object) | no | [] |
180: | revision_history_limit | Number of revisions to keep | number | no | 10 |
181: | helm_config | Helm-specific configuration | object | no | null |
182: | kustomize_config | Kustomize-specific configuration | object | no | null |
183: | directory_config | Directory-specific configuration | object | no | null |
184: 
185: ## Outputs
186: 
187: | Name | Description |
188: | ------ | ------------- |
189: | app_name | Name of the ArgoCD Application |
190: | app_namespace | Namespace where Application is deployed |
191: | app_uid | UID of the Application resource |
192: | destination_namespace | Target Kubernetes namespace |
193: | repo_url | Git repository URL |
194: | repo_path | Path within repository |
195: | target_revision | Git branch/tag/commit being synced |
196: 
197: ## Sync Policy Options
198: 
199: ### Automated Sync
200: 
201: ```hcl
202: sync_policy = {
203:   automated = {
204:     prune      = true   # Delete resources not in Git
205:     self_heal   = true   # Auto-sync on drift detection
206:     allow_empty = false # Allow empty application
207:   }
208:   sync_options = [
209:     "CreateNamespace=true",  # Create namespace if missing
210:     "PrunePropagationPolicy=foreground",
211:     "PruneLast=true"
212:   ]
213: }
214: ```
215: 
216: ### Retry Policy
217: 
218: ```hcl
219: sync_policy = {
220:   automated = {
221:     prune     = true
222:     self_heal = true
223:   }
224:   retry = {
225:     limit = 5
226:     backoff = {
227:       duration    = "5s"
228:       factor      = 2
229:       max_duration = "3m"
230:     }
231:   }
232: }
233: ```
234: 
235: ## Ignore Differences
236: 
237: To ignore specific fields that are managed outside of Git:
238: 
239: ```hcl
240: ignore_differences = [
241:   {
242:     group = "apps"
243:     kind  = "Deployment"
244:     jsonPointers = ["/spec/replicas"]
245:   },
246:   {
247:     kind              = "Service"
248:     jsonPointers      = ["/spec/clusterIP"]
249:     managedFieldsManagers = ["kubectl"]
250:   }
251: ]
252: ```
253: 
254: ## Multi-Application Pattern
255: 
256: Deploy multiple applications from the same repository:
257: 
258: ```hcl
259: module "argocd_app_service_a" {
260:   source = "./modules/argocd_app"
261: 
262:   app_name              = "service-a-app"
263:   cluster_name_in_argo  = module.argocd.local_cluster_secret_name
264:   repo_url              = "https://github.com/you/your-repo.git"
265:   target_revision       = "main"
266:   repo_path             = "apps/service-a"
267:   destination_namespace = "service-a"
268: 
269:   sync_policy = {
270:     automated = {
271:       prune     = true
272:       self_heal  = true
273:     }
274:   }
275: 
276:   depends_on = [module.argocd]
277: }
278: 
279: module "argocd_app_service_b" {
280:   source = "./modules/argocd_app"
281: 
282:   app_name              = "service-b-app"
283:   cluster_name_in_argo  = module.argocd.local_cluster_secret_name
284:   repo_url              = "https://github.com/you/your-repo.git"
285:   target_revision       = "main"
286:   repo_path             = "apps/service-b"
287:   destination_namespace = "service-b"
288: 
289:   sync_policy = {
290:     automated = {
291:       prune     = true
292:       self_heal  = true
293:     }
294:   }
295: 
296:   depends_on = [module.argocd]
297: }
298: ```
299: 
300: ## Verifying Application
301: 
302: ```bash
303: # Check Application status
304: kubectl get application -n argocd example-app
305: 
306: # View Application details
307: kubectl describe application -n argocd example-app
308: 
309: # Check sync status
310: kubectl get application -n argocd example-app -o jsonpath='{.status.sync.status}'
311: 
312: # View Application in ArgoCD UI
313: # Navigate to: https://<argocd-server-url>/applications/example-app
314: ```
315: 
316: ## Notes
317: 
318: - Applications must reference the cluster name from the cluster registration secret
319: - Use `cluster_name_in_argo` from the ArgoCD module output
320: - Sync policies can be automated or manual
321: - Supports Helm, Kustomize, and plain Kubernetes manifests
322: - Applications are continuously reconciled by ArgoCD based on Git state
323: - Use `depends_on` in the module block to ensure ArgoCD capability is ready before creating Applications
````

## File: application/modules/network-policies/README.md
````markdown
  1: # Network Policies Module
  2: 
  3: This module creates Kubernetes Network Policies to secure internal cluster
  4: communication using a **generic, service-agnostic approach**.
  5: 
  6: ## Purpose
  7: 
  8: Network Policies enforce secure pod-to-pod communication rules within the
  9: Kubernetes cluster, ensuring:
 10: 
 11: - **Encrypted Internal Communication**: Only secure ports (HTTPS 443, LDAPS 636,
 12: etc.) are allowed between services
 13: - **Generic Approach**: Any service can communicate with any service, as long as
 14: it uses secure protocols
 15: - **Future-Proof**: Works with any service you add later (2FA website, APIs,
 16: etc.) without policy changes
 17: - **Default Deny**: All traffic is denied by default, with explicit allow rules
 18: for secure communication
 19: 
 20: ## Design Philosophy
 21: 
 22: This module uses a **generic, service-agnostic approach** rather than
 23: service-specific policies:
 24: 
 25: -  **Any service can talk to any service** - No need to create new policies
 26: when adding services
 27: -  **Only secure ports allowed** - Enforces encryption (HTTPS, LDAPS, etc.)
 28: -  **Works with future services** - Your 2FA website, APIs, or any other
 29: service will work automatically
 30: -  **Simpler to maintain** - One policy instead of many service-specific
 31: policies
 32: 
 33: ## Network Policies Created
 34: 
 35: ### 1. Namespace Secure Communication Policy
 36: 
 37: A single, generic policy that applies to **ALL pods** in the namespace:
 38: 
 39: **Allowed Ingress (from any pod in namespace):**
 40: 
 41: - HTTPS (port 443)
 42: - LDAPS (port 636)
 43: - Alternative HTTPS (port 8443)
 44: 
 45: **Allowed Ingress (from any pod in other namespaces):**
 46: 
 47: - HTTPS (port 443)
 48: - LDAPS (port 636)
 49: - Alternative HTTPS (port 8443)
 50: 
 51: > [!NOTE]
 52: >
 53: > Cross-namespace communication is enabled to allow services in other
 54: > namespaces to access the LDAP service. All communication must still use secure
 55: > ports (HTTPS, LDAPS).
 56: 
 57: **Allowed Egress (to any pod in namespace):**
 58: 
 59: - HTTPS (port 443)
 60: - LDAPS (port 636)
 61: - Alternative HTTPS (port 8443)
 62: 
 63: **Allowed External Egress:**
 64: 
 65: - DNS resolution (port 53 UDP/TCP)
 66: - HTTPS (port 443) for external API calls
 67: - HTTP (port 80) for external API calls (though HTTPS is preferred)
 68: 
 69: **Key Features:**
 70: 
 71: - Applies to all pods in the namespace (no label selectors)
 72: - Only secure/encrypted ports are allowed
 73: - Works with any service you add (PhpLdapAdmin, LTB-passwd, 2FA website, etc.)
 74: 
 75: ### 2. Default Deny Policy
 76: 
 77: > [!NOTE]
 78: >
 79: > A separate default deny policy is **not created** in the current
 80: > implementation. The `namespace_secure_communication` policy achieves default
 81: > deny behavior by only allowing specific secure ports (443, 636, 8443). All other
 82: > ports are implicitly denied. This approach is simpler and avoids policy
 83: > conflicts while maintaining the same security posture.
 84: 
 85: The implementation achieves default deny behavior through:
 86: 
 87: - Only specific secure ports are explicitly allowed (443, 636, 8443)
 88: - All other ports are implicitly denied by Kubernetes Network Policy behavior
 89: - No separate default deny policy is needed
 90: 
 91: ## Security Benefits
 92: 
 93: 1. **Encrypted Internal Communication**: Forces all inter-service communication
 94: to use secure ports (HTTPS, LDAPS)
 95: 2. **Generic and Flexible**: Works with any service without policy changes
 96: 3. **Future-Proof**: Your 2FA website and any future services will work
 97: automatically
 98: 4. **Network Segmentation**: Services can only communicate on secure ports
 99: 5. **Default Deny**: All traffic is denied by default, with explicit allow rules
100: for secure communication
101: 6. **External API Access**: Services can make HTTPS calls to external APIs (2FA
102: providers, etc.)
103: 
104: ## Usage
105: 
106: The network policies are automatically applied when the module is included in
107: your Terraform configuration:
108: 
109: ```hcl
110: module "network_policies" {
111:   source = "./modules/network-policies"
112: 
113:   namespace = "ldap"
114: }
115: ```
116: 
117: ## How It Works for Your 2FA Website
118: 
119: When you add your 2FA website:
120: 
121: 1. **User Access**: Users navigate to your website via ALB (HTTPS on port 443)
122: 
123:    - ALB traffic comes from outside the cluster, so it's not restricted by
124:    Network Policies
125:    - Your website receives traffic normally
126: 
127: 2. **LDAP Authentication**: Your website connects to OpenLDAP
128: 
129:    -  **Allowed**: LDAPS (port 636) - encrypted communication
130:    -  **Blocked**: LDAP (port 389) - unencrypted communication
131: 
132: 3. **2FA Provider APIs**: Your website calls external 2FA provider APIs
133: 
134:    -  **Allowed**: HTTPS (port 443) - encrypted communication
135:    -  **Allowed**: HTTP (port 80) - for compatibility (though HTTPS is
136:    preferred)
137: 
138: 4. **Service Discovery**: Your website resolves service names
139: 
140:    -  **Allowed**: DNS (port 53) - required for Kubernetes service discovery
141: 
142: **No policy changes needed!** The generic policy already allows all of this.
143: 
144: ## Important Notes
145: 
146: ### Secure Ports
147: 
148: The policies allow these secure ports:
149: 
150: - **443**: HTTPS (for web services, APIs)
151: - **636**: LDAPS (for LDAP communication)
152: - **8443**: Alternative HTTPS port (for services that use non-standard HTTPS)
153: 
154: ### Unencrypted Ports Are Blocked
155: 
156: These ports are **explicitly blocked**:
157: 
158: - **389**: LDAP (unencrypted) - Use LDAPS (636) instead
159: - **80**: HTTP (unencrypted) - Use HTTPS (443) instead
160: - **8080, 3000, etc.**: Unencrypted application ports - Use HTTPS (443) instead
161: 
162: ### Service Configuration
163: 
164: Your services must be configured to:
165: 
166: - **Use HTTPS** for web services (not HTTP)
167: - **Use LDAPS** for LDAP communication (not LDAP)
168: - **Use secure ports** for inter-service communication
169: 
170: ### ALB Traffic
171: 
172: > [!IMPORTANT]
173: >
174: > Traffic from the ALB comes from outside the cluster (from AWS
175: > infrastructure), so it's **not subject to Network Policies**. The ALB
176: > communicates with pods via the Kubernetes Service, and the Network Policies
177: > control pod-to-pod communication within the cluster.
178: 
179: ### Cross-Namespace Communication
180: 
181: The network policies **allow cross-namespace communication** to enable services
182: in other namespaces to access the LDAP service:
183: 
184: -  **Allowed**: Services in any namespace can connect to LDAP service on secure
185: ports (443, 636, 8443)
186: -  **Secure**: All cross-namespace communication must use encrypted ports
187: (HTTPS, LDAPS)
188: -  **Generic**: Works with any service in any namespace without policy changes
189: 
190: **Example**: A service in the `production` namespace can connect to the LDAP
191: service in the `ldap` namespace using LDAPS (port 636):
192: 
193: ```bash
194: Service Pod (production namespace)
195:      LDAPS (636)  Allowed by Network Policy
196: LDAP Service (ldap namespace)
197: ```
198: 
199: This enables microservices architectures where different services in different
200: namespaces can securely access the centralized LDAP service.
201: 
202: ### DNS Requirements
203: 
204: The policies allow DNS resolution (port 53) which is required for:
205: 
206: - Service discovery within the cluster
207: - External DNS lookups if needed
208: 
209: ## Example: 2FA Website Flow
210: 
211: ```bash
212: User (Internet)
213:      HTTPS (443)
214: ALB (External - not restricted by Network Policies)
215:      HTTPS (443)
216: 2FA Website Pod
217:      LDAPS (636)  Allowed by Network Policy
218: OpenLDAP Pod
219:      HTTPS (443)  Allowed by Network Policy
220: External 2FA Provider API
221: ```
222: 
223: All communication uses secure ports, so everything works automatically!
224: 
225: ## Troubleshooting
226: 
227: If services cannot communicate after applying network policies:
228: 
229: 1. **Check Policy Status**:
230: 
231:    ```bash
232:    kubectl get networkpolicies -n ldap
233:    ```
234: 
235: 2. **Verify Service Ports**:
236: 
237:    ```bash
238:    # Check what ports your services are using
239:    kubectl get services -n ldap
240:    kubectl describe service <service-name> -n ldap
241:    ```
242: 
243:    Ensure services use secure ports (443, 636, 8443).
244: 
245: 3. **Test Connectivity**:
246: 
247:    ```bash
248:    # Test HTTPS connectivity
249:    kubectl exec -n ldap <pod-name> -- nc -zv <service-name> 443
250: 
251:    # Test LDAPS connectivity
252:    kubectl exec -n ldap <pod-name> -- nc -zv <service-name> 636
253:    ```
254: 
255: 4. **Check Service Configuration**:
256:    - Ensure services are configured to use HTTPS (not HTTP)
257:    - Ensure LDAP services use LDAPS (not LDAP)
258:    - Verify service ports match allowed ports (443, 636, 8443)
259: 
260: 5. **Check Policy Logs**:
261:    Network policies are enforced by the CNI plugin. Check CNI logs if policies
262:    aren't working.
263: 
264: ## Adding New Secure Ports
265: 
266: If you need to allow additional secure ports, update the
267: `namespace_secure_communication` policy in `main.tf`:
268: 
269: ```hcl
270: ingress {
271:   from {
272:     pod_selector {}
273:   }
274:   ports {
275:     port     = "YOUR_SECURE_PORT"
276:     protocol = "TCP"
277:   }
278: }
279: ```
280: 
281: ## References
282: 
283: - [Kubernetes Network Policies Documentation](https://kubernetes.io/docs/concepts/services-networking/network-policies/)
284: - [AWS EKS Network Policies](https://docs.aws.amazon.com/eks/latest/userguide/network-policy.html)
````

## File: application/.terraform.lock.hcl
````hcl
  1: # This file is maintained automatically by "terraform init".
  2: # Manual edits may be lost in future updates.
  3: 
  4: provider "registry.terraform.io/hashicorp/aws" {
  5:   version     = "6.27.0"
  6:   constraints = ">= 6.21.0"
  7:   hashes = [
  8:     "h1:emgTfB1LXSFYh9uAwgsRMoMIN5Wz7jNNKq3rqC0EHWk=",
  9:     "zh:177a24b806c72e8484b5cabc93b2b38e3d770ae6f745a998b54d6619fd0e8129",
 10:     "zh:4ac4a85c14fb868a3306b542e6a56c10bd6c6d5a67bc0c9b8f6a9060cf5f3be7",
 11:     "zh:552652185bc85c8ba1da1d65dea47c454728a5c6839c458b6dcd3ce71c19ccfc",
 12:     "zh:60284b8172d09aee91eae0856f09855eaf040ce3a58d6933602ae17c53f8ed04",
 13:     "zh:6be38d156756ca61fb8e7c752cc5d769cd709686700ac4b230f40a6e95b5dbc9",
 14:     "zh:7a409138fae4ef42e3a637e37cb9efedf96459e28a3c764fc4e855e8db9a7485",
 15:     "zh:8070cf5224ed1ed3a3e9a59f7c30ff88bf071c7567165275d477c1738a56c064",
 16:     "zh:894439ef340a9a79f69cd759e27ad11c7826adeca27be1b1ca82b3c9702fa300",
 17:     "zh:89d035eebf08a97c89374ff06040955ddc09f275ecca609d0c9d58d149bef5cf",
 18:     "zh:985b1145d724fc1f38369099e4a5087141885740fd6c0b1dbc492171e73c2e49",
 19:     "zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425",
 20:     "zh:a80b47ae8d1475201c86bd94a5dcb9dd4da5e8b73102a90820b68b66b76d50fd",
 21:     "zh:d3395be1556210f82199b9166a6b2e677cee9c4b67e96e63f6c3a98325ad7ab0",
 22:     "zh:db0b869d09657f6f1e4110b56093c5fcdf9dbdd97c020db1e577b239c0adcbce",
 23:     "zh:ffc72e680370ae7c21f9bd3082c6317730df805c6797427839a6b6b7e9a26a01",
 24:   ]
 25: }
 26: 
 27: provider "registry.terraform.io/hashicorp/external" {
 28:   version = "2.3.5"
 29:   hashes = [
 30:     "h1:FnUk98MI5nOh3VJ16cHf8mchQLewLfN1qZG/MqNgPrI=",
 31:     "zh:6e89509d056091266532fa64de8c06950010498adf9070bf6ff85bc485a82562",
 32:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
 33:     "zh:86868aec05b58dc0aa1904646a2c26b9367d69b890c9ad70c33c0d3aa7b1485a",
 34:     "zh:a2ce38fda83a62fa5fb5a70e6ca8453b168575feb3459fa39803f6f40bd42154",
 35:     "zh:a6c72798f4a9a36d1d1433c0372006cc9b904e8cfd60a2ae03ac5b7d2abd2398",
 36:     "zh:a8a3141d2fc71c86bf7f3c13b0b3be8a1b0f0144a47572a15af4dfafc051e28a",
 37:     "zh:aa20a1242eb97445ad26ebcfb9babf2cd675bdb81cac5f989268ebefa4ef278c",
 38:     "zh:b58a22445fb8804e933dcf835ab06c29a0f33148dce61316814783ee7f4e4332",
 39:     "zh:cb5626a661ee761e0576defb2a2d75230a3244799d380864f3089c66e99d0dcc",
 40:     "zh:d1acb00d20445f682c4e705c965e5220530209c95609194c2dc39324f3d4fcce",
 41:     "zh:d91a254ba77b69a29d8eae8ed0e9367cbf0ea6ac1a85b58e190f8cb096a40871",
 42:     "zh:f6592327673c9f85cdb6f20336faef240abae7621b834f189c4a62276ea5db41",
 43:   ]
 44: }
 45: 
 46: provider "registry.terraform.io/hashicorp/helm" {
 47:   version     = "2.17.0"
 48:   constraints = "~> 2.0"
 49:   hashes = [
 50:     "h1:kQMkcPVvHOguOqnxoEU2sm1ND9vCHiT8TvZ2x6v/Rsw=",
 51:     "zh:06fb4e9932f0afc1904d2279e6e99353c2ddac0d765305ce90519af410706bd4",
 52:     "zh:104eccfc781fc868da3c7fec4385ad14ed183eb985c96331a1a937ac79c2d1a7",
 53:     "zh:129345c82359837bb3f0070ce4891ec232697052f7d5ccf61d43d818912cf5f3",
 54:     "zh:3956187ec239f4045975b35e8c30741f701aa494c386aaa04ebabffe7749f81c",
 55:     "zh:66a9686d92a6b3ec43de3ca3fde60ef3d89fb76259ed3313ca4eb9bb8c13b7dd",
 56:     "zh:88644260090aa621e7e8083585c468c8dd5e09a3c01a432fb05da5c4623af940",
 57:     "zh:a248f650d174a883b32c5b94f9e725f4057e623b00f171936dcdcc840fad0b3e",
 58:     "zh:aa498c1f1ab93be5c8fbf6d48af51dc6ef0f10b2ea88d67bcb9f02d1d80d3930",
 59:     "zh:bf01e0f2ec2468c53596e027d376532a2d30feb72b0b5b810334d043109ae32f",
 60:     "zh:c46fa84cc8388e5ca87eb575a534ebcf68819c5a5724142998b487cb11246654",
 61:     "zh:d0c0f15ffc115c0965cbfe5c81f18c2e114113e7a1e6829f6bfd879ce5744fbb",
 62:     "zh:f569b65999264a9416862bca5cd2a6177d94ccb0424f3a4ef424428912b9cb3c",
 63:   ]
 64: }
 65: 
 66: provider "registry.terraform.io/hashicorp/kubernetes" {
 67:   version     = "2.38.0"
 68:   constraints = "~> 2.0"
 69:   hashes = [
 70:     "h1:soK8Lt0SZ6dB+HsypFRDzuX/npqlMU6M0fvyaR1yW0k=",
 71:     "zh:0af928d776eb269b192dc0ea0f8a3f0f5ec117224cd644bdacdc682300f84ba0",
 72:     "zh:1be998e67206f7cfc4ffe77c01a09ac91ce725de0abaec9030b22c0a832af44f",
 73:     "zh:326803fe5946023687d603f6f1bab24de7af3d426b01d20e51d4e6fbe4e7ec1b",
 74:     "zh:4a99ec8d91193af961de1abb1f824be73df07489301d62e6141a656b3ebfff12",
 75:     "zh:5136e51765d6a0b9e4dbcc3b38821e9736bd2136cf15e9aac11668f22db117d2",
 76:     "zh:63fab47349852d7802fb032e4f2b6a101ee1ce34b62557a9ad0f0f0f5b6ecfdc",
 77:     "zh:924fb0257e2d03e03e2bfe9c7b99aa73c195b1f19412ca09960001bee3c50d15",
 78:     "zh:b63a0be5e233f8f6727c56bed3b61eb9456ca7a8bb29539fba0837f1badf1396",
 79:     "zh:d39861aa21077f1bc899bc53e7233262e530ba8a3a2d737449b100daeb303e4d",
 80:     "zh:de0805e10ebe4c83ce3b728a67f6b0f9d18be32b25146aa89116634df5145ad4",
 81:     "zh:f569b65999264a9416862bca5cd2a6177d94ccb0424f3a4ef424428912b9cb3c",
 82:     "zh:faf23e45f0090eef8ba28a8aac7ec5d4fdf11a36c40a8d286304567d71c1e7db",
 83:   ]
 84: }
 85: 
 86: provider "registry.terraform.io/hashicorp/local" {
 87:   version = "2.6.1"
 88:   hashes = [
 89:     "h1:DbiR/D2CPigzCGweYIyJH0N0x04oyI5xiZ9wSW/s3kQ=",
 90:     "zh:10050d08f416de42a857e4b6f76809aae63ea4ec6f5c852a126a915dede814b4",
 91:     "zh:2df2a3ebe9830d4759c59b51702e209fe053f47453cb4688f43c063bac8746b7",
 92:     "zh:2e759568bcc38c86ca0e43701d34cf29945736fdc8e429c5b287ddc2703c7b18",
 93:     "zh:6a62a34e48500ab4aea778e355e162ebde03260b7a9eb9edc7e534c84fbca4c6",
 94:     "zh:74373728ba32a1d5450a3a88ac45624579e32755b086cd4e51e88d9aca240ef6",
 95:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
 96:     "zh:8dddae588971a996f622e7589cd8b9da7834c744ac12bfb59c97fa77ded95255",
 97:     "zh:946f82f66353bb97aefa8d95c4ca86db227f9b7c50b82415289ac47e4e74d08d",
 98:     "zh:e9a5c09e6f35e510acf15b666fd0b34a30164cecdcd81ce7cda0f4b2dade8d91",
 99:     "zh:eafe5b873ef42b32feb2f969c38ff8652507e695620cbaf03b9db714bee52249",
100:     "zh:ec146289fa27650c9d433bb5c7847379180c0b7a323b1b94e6e7ad5d2a7dbe71",
101:     "zh:fc882c35ce05631d76c0973b35adde26980778fc81d9da81a2fade2b9d73423b",
102:   ]
103: }
104: 
105: provider "registry.terraform.io/hashicorp/time" {
106:   version     = "0.13.1"
107:   constraints = "~> 0.9"
108:   hashes = [
109:     "h1:ZT5ppCNIModqk3iOkVt5my8b8yBHmDpl663JtXAIRqM=",
110:     "zh:02cb9aab1002f0f2a94a4f85acec8893297dc75915f7404c165983f720a54b74",
111:     "zh:04429b2b31a492d19e5ecf999b116d396dac0b24bba0d0fb19ecaefe193fdb8f",
112:     "zh:26f8e51bb7c275c404ba6028c1b530312066009194db721a8427a7bc5cdbc83a",
113:     "zh:772ff8dbdbef968651ab3ae76d04afd355c32f8a868d03244db3f8496e462690",
114:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
115:     "zh:898db5d2b6bd6ca5457dccb52eedbc7c5b1a71e4a4658381bcbb38cedbbda328",
116:     "zh:8de913bf09a3fa7bedc29fec18c47c571d0c7a3d0644322c46f3aa648cf30cd8",
117:     "zh:9402102c86a87bdfe7e501ffbb9c685c32bbcefcfcf897fd7d53df414c36877b",
118:     "zh:b18b9bb1726bb8cfbefc0a29cf3657c82578001f514bcf4c079839b6776c47f0",
119:     "zh:b9d31fdc4faecb909d7c5ce41d2479dd0536862a963df434be4b16e8e4edc94d",
120:     "zh:c951e9f39cca3446c060bd63933ebb89cedde9523904813973fbc3d11863ba75",
121:     "zh:e5b773c0d07e962291be0e9b413c7a22c044b8c7b58c76e8aa91d1659990dfb5",
122:   ]
123: }
````

## File: application/destroy-application.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: PLACEHOLDER_FILE="tfstate-backend-values-template.hcl"
 18: BACKEND_FILE="backend.hcl"
 19: VARIABLES_FILE="variables.tfvars"
 20: 
 21: 
 22: export BACKEND_FILE
 23: export VARIABLES_FILE
 24: 
 25: 
 26: print_error() {
 27:     echo -e "${RED}ERROR:${NC} $1" >&2
 28: }
 29: 
 30: print_success() {
 31:     echo -e "${GREEN}SUCCESS:${NC} $1"
 32: }
 33: 
 34: print_info() {
 35:     echo -e "${YELLOW}INFO:${NC} $1"
 36: }
 37: 
 38: print_warning() {
 39:     echo -e "${YELLOW}WARNING:${NC} $1"
 40: }
 41: 
 42: 
 43: if ! command -v aws &> /dev/null; then
 44:     print_error "AWS CLI is not installed."
 45:     echo "Please install it from: https://aws.amazon.com/cli/"
 46:     exit 1
 47: fi
 48: 
 49: 
 50: if ! command -v terraform &> /dev/null; then
 51:     print_error "Terraform is not installed."
 52:     echo "Please install it from: https://www.terraform.io/downloads"
 53:     exit 1
 54: fi
 55: 
 56: 
 57: if ! command -v gh &> /dev/null; then
 58:     print_error "GitHub CLI (gh) is not installed."
 59:     echo "Please install it from: https://cli.github.com/"
 60:     exit 1
 61: fi
 62: 
 63: 
 64: if ! gh auth status &> /dev/null; then
 65:     print_error "Not authenticated with GitHub CLI."
 66:     echo "Please run: gh auth login"
 67:     exit 1
 68: fi
 69: 
 70: 
 71: if ! command -v jq &> /dev/null; then
 72:     print_error "jq is not installed."
 73:     echo "Please install it:"
 74:     echo "  macOS: brew install jq"
 75:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 76:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 77:     exit 1
 78: fi
 79: 
 80: 
 81: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 82: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 83: 
 84: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 85:     print_error "Could not determine repository information."
 86:     echo "Please ensure you're in a git repository and have proper permissions."
 87:     exit 1
 88: fi
 89: 
 90: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 91: 
 92: 
 93: get_repo_variable() {
 94:     local var_name=$1
 95:     local value
 96: 
 97:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 98: 
 99:     if [ -z "$value" ]; then
100:         print_error "Repository variable '${var_name}' not found or not accessible."
101:         return 1
102:     fi
103: 
104:     echo "$value"
105: }
106: 
107: 
108: get_aws_secret() {
109:     local secret_name=$1
110:     local secret_json
111:     local exit_code
112: 
113: 
114: 
115:     secret_json=$(aws secretsmanager get-secret-value \
116:         --secret-id "$secret_name" \
117:         --region "${AWS_REGION:-us-east-1}" \
118:         --query SecretString \
119:         --output text 2>&1)
120: 
121: 
122:     exit_code=$?
123: 
124: 
125:     if [ $exit_code -ne 0 ]; then
126:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
127:         print_error "Error: $secret_json"
128:         return 1
129:     fi
130: 
131: 
132:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
133:         print_error "Secret '${secret_name}' contains invalid JSON"
134:         return 1
135:     fi
136: 
137:     echo "$secret_json"
138: }
139: 
140: 
141: get_aws_plaintext_secret() {
142:     local secret_name=$1
143:     local secret_value
144:     local exit_code
145: 
146: 
147: 
148:     secret_value=$(aws secretsmanager get-secret-value \
149:         --secret-id "$secret_name" \
150:         --region "${AWS_REGION:-us-east-1}" \
151:         --query SecretString \
152:         --output text 2>&1)
153: 
154: 
155:     exit_code=$?
156: 
157: 
158:     if [ $exit_code -ne 0 ]; then
159:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
160:         print_error "Error: $secret_value"
161:         return 1
162:     fi
163: 
164: 
165:     if [ -z "$secret_value" ]; then
166:         print_error "Secret '${secret_name}' is empty"
167:         return 1
168:     fi
169: 
170:     echo "$secret_value"
171: }
172: 
173: 
174: get_secret_key_value() {
175:     local secret_json=$1
176:     local key_name=$2
177:     local value
178: 
179: 
180:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
181:         print_error "Invalid JSON provided to get_secret_key_value"
182:         return 1
183:     fi
184: 
185: 
186:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
187: 
188: 
189:     if [ $? -ne 0 ]; then
190:         print_error "Failed to parse JSON or extract key '${key_name}'"
191:         return 1
192:     fi
193: 
194: 
195:     if [ "$value" = "null" ] || [ -z "$value" ]; then
196:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
197:         return 1
198:     fi
199: 
200:     echo "$value"
201: }
202: 
203: 
204: 
205: 
206: 
207: 
208: 
209: assume_aws_role() {
210:     local role_arn=$1
211:     local external_id=${2:-}
212:     local role_description=${3:-"role"}
213:     local session_name_suffix=${4:-"destroy-application"}
214: 
215:     if [ -z "$role_arn" ]; then
216:         print_error "Role ARN is required for assume_aws_role"
217:         return 1
218:     fi
219: 
220:     print_info "Assuming ${role_description}: $role_arn"
221:     print_info "Region: $AWS_REGION"
222: 
223: 
224:     local role_session_name="${session_name_suffix}-$(date +%s)"
225:     local assume_role_output
226: 
227: 
228: 
229:     if [ -n "$external_id" ]; then
230:         assume_role_output=$(aws sts assume-role \
231:             --role-arn "$role_arn" \
232:             --role-session-name "$role_session_name" \
233:             --external-id "$external_id" \
234:             --region "$AWS_REGION" 2>&1)
235:     else
236:         assume_role_output=$(aws sts assume-role \
237:             --role-arn "$role_arn" \
238:             --role-session-name "$role_session_name" \
239:             --region "$AWS_REGION" 2>&1)
240:     fi
241: 
242:     if [ $? -ne 0 ]; then
243:         print_error "Failed to assume ${role_description}: $assume_role_output"
244:         return 1
245:     fi
246: 
247: 
248: 
249:     local access_key_id
250:     local secret_access_key
251:     local session_token
252: 
253:     if command -v jq &> /dev/null; then
254:         access_key_id=$(echo "$assume_role_output" | jq -r '.Credentials.AccessKeyId')
255:         secret_access_key=$(echo "$assume_role_output" | jq -r '.Credentials.SecretAccessKey')
256:         session_token=$(echo "$assume_role_output" | jq -r '.Credentials.SessionToken')
257:     else
258: 
259:         access_key_id=$(echo "$assume_role_output" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
260:         secret_access_key=$(echo "$assume_role_output" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
261:         session_token=$(echo "$assume_role_output" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
262:     fi
263: 
264:     if [ -z "$access_key_id" ] || [ -z "$secret_access_key" ] || [ -z "$session_token" ]; then
265:         print_error "Failed to extract credentials from assume-role output."
266:         print_error "Output was: $assume_role_output"
267:         return 1
268:     fi
269: 
270: 
271:     export AWS_ACCESS_KEY_ID="$access_key_id"
272:     export AWS_SECRET_ACCESS_KEY="$secret_access_key"
273:     export AWS_SESSION_TOKEN="$session_token"
274: 
275:     print_success "Successfully assumed ${role_description}"
276: 
277: 
278:     local caller_arn
279:     caller_arn=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
280:     if [ $? -ne 0 ]; then
281:         print_error "Failed to verify assumed role credentials: $caller_arn"
282:         return 1
283:     fi
284: 
285:     print_info "${role_description} identity: $caller_arn"
286:     return 0
287: }
288: 
289: 
290: echo ""
291: print_warning "=========================================="
292: print_warning "  DESTRUCTIVE OPERATION WARNING"
293: print_warning "=========================================="
294: print_warning "This script will DESTROY all application"
295: print_warning "infrastructure in the selected region and environment."
296: print_warning ""
297: print_warning "This action CANNOT be undone!"
298: print_warning "=========================================="
299: echo ""
300: read -p "Are you sure you want to continue? (type 'yes' to confirm): " confirmation
301: 
302: if [ "$confirmation" != "yes" ]; then
303:     print_info "Operation cancelled."
304:     exit 0
305: fi
306: 
307: 
308: echo ""
309: print_info "Select AWS Region:"
310: echo "1) us-east-1: N. Virginia (default)"
311: echo "2) us-east-2: Ohio"
312: read -p "Enter choice [1-2] (default: 1): " region_choice
313: 
314: case ${region_choice:-1} in
315:     1)
316:         SELECTED_REGION="us-east-1: N. Virginia"
317:         ;;
318:     2)
319:         SELECTED_REGION="us-east-2: Ohio"
320:         ;;
321:     *)
322:         print_error "Invalid choice. Using default: us-east-1: N. Virginia"
323:         SELECTED_REGION="us-east-1: N. Virginia"
324:         ;;
325: esac
326: 
327: 
328: AWS_REGION="${SELECTED_REGION%%:*}"
329: export AWS_REGION
330: print_success "Selected region: ${SELECTED_REGION} (${AWS_REGION})"
331: 
332: echo ""
333: print_info "Select Environment:"
334: echo "1) prod (default)"
335: echo "2) dev"
336: read -p "Enter choice [1-2] (default: 1): " env_choice
337: 
338: case ${env_choice:-1} in
339:     1)
340:         ENVIRONMENT="prod"
341:         ;;
342:     2)
343:         ENVIRONMENT="dev"
344:         ;;
345:     *)
346:         print_error "Invalid choice. Using default: prod"
347:         ENVIRONMENT="prod"
348:         ;;
349: esac
350: 
351: print_success "Selected environment: ${ENVIRONMENT}"
352: export ENVIRONMENT
353: echo ""
354: 
355: # Final confirmation with environment details
356: print_warning "You are about to DESTROY application infrastructure in:"
357: print_warning "  Region: ${AWS_REGION}"
358: print_warning "  Environment: ${ENVIRONMENT}"
359: echo ""
360: read -p "Type 'DESTROY' to confirm: " final_confirmation
361: 
362: if [ "$final_confirmation" != "DESTROY" ]; then
363:     print_info "Operation cancelled."
364:     exit 0
365: fi
366: 
367: 
368: 
369: print_info "Retrieving role ARNs from AWS Secrets Manager..."
370: ROLE_SECRET_JSON=$(get_aws_secret "github-role" || echo "")
371: if [ -z "$ROLE_SECRET_JSON" ]; then
372:     print_error "Failed to retrieve 'github-role' secret from AWS Secrets Manager"
373:     exit 1
374: fi
375: 
376: 
377: STATE_ROLE_ARN=$(get_secret_key_value "$ROLE_SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
378: if [ -z "$STATE_ROLE_ARN" ]; then
379:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
380:     exit 1
381: fi
382: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
383: 
384: 
385: if [ "$ENVIRONMENT" = "prod" ]; then
386:     DEPLOYMENT_ROLE_ARN_KEY="AWS_PRODUCTION_ACCOUNT_ROLE_ARN"
387: else
388:     DEPLOYMENT_ROLE_ARN_KEY="AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN"
389: fi
390: 
391: 
392: DEPLOYMENT_ROLE_ARN=$(get_secret_key_value "$ROLE_SECRET_JSON" "$DEPLOYMENT_ROLE_ARN_KEY" || echo "")
393: if [ -z "$DEPLOYMENT_ROLE_ARN" ]; then
394:     print_error "Failed to retrieve ${DEPLOYMENT_ROLE_ARN_KEY} from secret"
395:     exit 1
396: fi
397: export DEPLOYMENT_ROLE_ARN
398: print_success "Retrieved ${DEPLOYMENT_ROLE_ARN_KEY}"
399: 
400: 
401: print_info "Retrieving ExternalId from AWS Secrets Manager..."
402: EXTERNAL_ID=$(get_aws_plaintext_secret "external-id" || echo "")
403: if [ -z "$EXTERNAL_ID" ]; then
404:     print_error "Failed to retrieve 'external-id' secret from AWS Secrets Manager"
405:     exit 1
406: fi
407: export EXTERNAL_ID
408: print_success "Retrieved ExternalId"
409: 
410: 
411: print_info "Retrieving Terraform variables from AWS Secrets Manager..."
412: TF_VARS_SECRET_JSON=$(get_aws_secret "tf-vars" || echo "")
413: if [ -z "$TF_VARS_SECRET_JSON" ]; then
414:     print_error "Failed to retrieve 'tf-vars' secret from AWS Secrets Manager"
415:     exit 1
416: fi
417: 
418: 
419: TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_OPENLDAP_ADMIN_PASSWORD" || echo "")
420: if [ -z "$TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE" ]; then
421:     print_error "Failed to retrieve TF_VAR_OPENLDAP_ADMIN_PASSWORD from secret"
422:     exit 1
423: fi
424: print_success "Retrieved TF_VAR_OPENLDAP_ADMIN_PASSWORD"
425: 
426: TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_OPENLDAP_CONFIG_PASSWORD" || echo "")
427: if [ -z "$TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE" ]; then
428:     print_error "Failed to retrieve TF_VAR_OPENLDAP_CONFIG_PASSWORD from secret"
429:     exit 1
430: fi
431: print_success "Retrieved TF_VAR_OPENLDAP_CONFIG_PASSWORD"
432: 
433: 
434: TF_VAR_POSTGRESQL_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_POSTGRESQL_PASSWORD" || echo "")
435: if [ -z "$TF_VAR_POSTGRESQL_PASSWORD_VALUE" ]; then
436:     print_error "Failed to retrieve TF_VAR_POSTGRESQL_PASSWORD from secret"
437:     exit 1
438: fi
439: print_success "Retrieved TF_VAR_POSTGRESQL_PASSWORD"
440: 
441: 
442: TF_VAR_REDIS_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_REDIS_PASSWORD" || echo "")
443: if [ -z "$TF_VAR_REDIS_PASSWORD_VALUE" ]; then
444:     print_error "Failed to retrieve TF_VAR_REDIS_PASSWORD from secret"
445:     exit 1
446: fi
447: print_success "Retrieved TF_VAR_REDIS_PASSWORD"
448: 
449: 
450: 
451: 
452: export TF_VAR_openldap_admin_password="$TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE"
453: export TF_VAR_openldap_config_password="$TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE"
454: export TF_VAR_postgresql_database_password="$TF_VAR_POSTGRESQL_PASSWORD_VALUE"
455: export TF_VAR_redis_password="$TF_VAR_REDIS_PASSWORD_VALUE"
456: 
457: print_success "Retrieved and exported all secrets from AWS Secrets Manager"
458: echo ""
459: 
460: # Retrieve repository variables
461: print_info "Retrieving repository variables..."
462: 
463: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME") || exit 1
464: print_success "Retrieved BACKEND_BUCKET_NAME"
465: 
466: APPLICATION_PREFIX=$(get_repo_variable "APPLICATION_PREFIX") || exit 1
467: print_success "Retrieved APPLICATION_PREFIX"
468: 
469: 
470: if [ -f "$BACKEND_FILE" ]; then
471:     print_info "${BACKEND_FILE} already exists. Skipping creation."
472: else
473: 
474:     if [ ! -f "$PLACEHOLDER_FILE" ]; then
475:         print_error "Placeholder file '${PLACEHOLDER_FILE}' not found."
476:         exit 1
477:     fi
478: 
479: 
480:     print_info "Creating ${BACKEND_FILE} from ${PLACEHOLDER_FILE} with retrieved values..."
481: 
482: 
483:     cp "$PLACEHOLDER_FILE" "$BACKEND_FILE"
484: 
485: 
486:     if [[ "$OSTYPE" == "darwin"* ]]; then
487: 
488:         sed -i '' "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
489:         sed -i '' "s|<APPLICATION_PREFIX>|${APPLICATION_PREFIX}|g" "$BACKEND_FILE"
490:         sed -i '' "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
491:     else
492: 
493:         sed -i "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
494:         sed -i "s|<APPLICATION_PREFIX>|${APPLICATION_PREFIX}|g" "$BACKEND_FILE"
495:         sed -i "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
496:     fi
497: 
498:     print_success "Created ${BACKEND_FILE}"
499: fi
500: 
501: print_success "Configuration files updated successfully!"
502: echo ""
503: print_info "Backend file: ${BACKEND_FILE}"
504: print_info "  - bucket: ${BUCKET_NAME}"
505: print_info "  - key: ${APPLICATION_PREFIX}"
506: print_info "  - region: ${AWS_REGION}"
507: echo ""
508: 
509: # Assume State Account role for backend operations
510: if ! assume_aws_role "$STATE_ROLE_ARN" "" "State Account role" "destroy-application"; then
511:     exit 1
512: fi
513: 
514: echo ""
515: 
516: # Terraform workspace name
517: WORKSPACE_NAME="${AWS_REGION}-${ENVIRONMENT}"
518: 
519: # Terraform init
520: print_info "Running terraform init with backend configuration..."
521: terraform init -backend-config="${BACKEND_FILE}"
522: 
523: # Terraform workspace
524: print_info "Selecting or creating workspace: ${WORKSPACE_NAME}..."
525: terraform workspace select "${WORKSPACE_NAME}" 2>/dev/null || terraform workspace new "${WORKSPACE_NAME}"
526: 
527: # Terraform validate
528: print_info "Running terraform validate..."
529: terraform validate
530: 
531: # Set Kubernetes environment variables
532: print_info "Setting Kubernetes environment variables..."
533: if [ ! -f "set-k8s-env.sh" ]; then
534:     print_error "set-k8s-env.sh not found."
535:     exit 1
536: fi
537: 
538: 
539: chmod +x ./set-k8s-env.sh
540: 
541: 
542: 
543: source ./set-k8s-env.sh
544: 
545: if [ -z "$KUBERNETES_MASTER" ]; then
546:     print_error "Failed to set KUBERNETES_MASTER environment variable."
547:     exit 1
548: fi
549: 
550: print_success "Kubernetes environment variables set"
551: print_info "  - KUBERNETES_MASTER: ${KUBERNETES_MASTER}"
552: print_info "  - KUBE_CONFIG_PATH: ${KUBE_CONFIG_PATH}"
553: 
554: 
555: export TF_VAR_kubernetes_master="$KUBERNETES_MASTER"
556: export TF_VAR_kube_config_path="$KUBE_CONFIG_PATH"
557: print_info "  - TF_VAR_kubernetes_master: ${TF_VAR_kubernetes_master}"
558: print_info "  - TF_VAR_kube_config_path: ${TF_VAR_kube_config_path}"
559: echo ""
560: 
561: # Assume State Account role again for Terraform operations
562: if ! assume_aws_role "$STATE_ROLE_ARN" "" "State Account role" "destroy-application"; then
563:     exit 1
564: fi
565: 
566: echo ""
567: 
568: # Terraform plan destroy
569: print_info "Running terraform plan destroy..."
570: terraform plan -var-file="${VARIABLES_FILE}" -destroy -out terraform.tfplan
571: 
572: # Terraform apply (destroy)
573: print_warning "Applying destroy plan. This will DESTROY all application infrastructure..."
574: terraform apply -auto-approve terraform.tfplan
575: 
576: echo ""
577: print_success "Destroy operation completed successfully!"
578: print_info "All application infrastructure in ${AWS_REGION} (${ENVIRONMENT}) has been destroyed."
````

## File: application/mirror-images-to-ecr.sh
````bash
  1: set -euo pipefail
  2: 
  3: cd "$(dirname "$0")"
  4: 
  5: # Colors for output (if not already defined by sourcing script)
  6: if [ -z "${RED:-}" ]; then
  7:     RED='\033[0;31m'
  8:     GREEN='\033[0;32m'
  9:     YELLOW='\033[1;33m'
 10:     BLUE='\033[0;34m'
 11:     NC='\033[0m' # No Color
 12: fi
 13: 
 14: # Function to print colored messages (if not already defined by sourcing script)
 15: if ! declare -f print_error > /dev/null; then
 16:     print_error() {
 17:         echo -e "${RED}ERROR:${NC} $1" >&2
 18:     }
 19: fi
 20: 
 21: if ! declare -f print_success > /dev/null; then
 22:     print_success() {
 23:         echo -e "${GREEN}SUCCESS:${NC} $1"
 24:     }
 25: fi
 26: 
 27: if ! declare -f print_info > /dev/null; then
 28:     print_info() {
 29:         echo -e "${YELLOW}INFO:${NC} $1"
 30:     }
 31: fi
 32: 
 33: info() { echo -e "${BLUE}[INFO]${NC} $*"; }
 34: 
 35: 
 36: for cmd in docker jq; do
 37:   if ! command -v "$cmd" &> /dev/null; then
 38:     print_error "$cmd is required but not installed."
 39:     exit 1
 40:   fi
 41: done
 42: 
 43: 
 44: if ! docker info &> /dev/null 2>&1; then
 45:   print_error "Docker daemon is not running. Please start Docker and try again."
 46:   exit 1
 47: fi
 48: 
 49: info "Starting ECR image mirroring process..."
 50: echo ""
 51: 
 52: # Get AWS account ID
 53: AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
 54: info "AWS Account ID: $AWS_ACCOUNT_ID"
 55: 
 56: 
 57: if [ -z "${AWS_REGION:-}" ]; then
 58:     print_error "AWS_REGION is not set. Run ./setup-application.sh first."
 59:     exit 1
 60: fi
 61: info "AWS Region: $AWS_REGION"
 62: 
 63: 
 64: BACKEND_FILE="${BACKEND_FILE:-backend.hcl}"
 65: 
 66: 
 67: if [ ! -f "$BACKEND_FILE" ]; then
 68:     print_error "$BACKEND_FILE not found. Run ./setup-application.sh first."
 69:     exit 1
 70: fi
 71: 
 72: 
 73: BACKEND_BUCKET=$(grep 'bucket' "$BACKEND_FILE" | sed 's/.*"\(.*\)".*/\1/')
 74: BACKEND_KEY="backend_state/terraform.tfstate"
 75: 
 76: info "Backend S3 bucket: $BACKEND_BUCKET"
 77: 
 78: 
 79: WORKSPACE=$(terraform workspace show 2>/dev/null || echo "default")
 80: info "Terraform workspace: $WORKSPACE"
 81: 
 82: 
 83: if [ "$WORKSPACE" = "default" ]; then
 84:     STATE_KEY="$BACKEND_KEY"
 85: else
 86:     STATE_KEY="env:/$WORKSPACE/$BACKEND_KEY"
 87: fi
 88: 
 89: info "Fetching ECR repository information from s3://$BACKEND_BUCKET/$STATE_KEY"
 90: 
 91: 
 92: ECR_URL=$(aws s3 cp "s3://$BACKEND_BUCKET/$STATE_KEY" - 2>/dev/null | jq -r '.outputs.ecr_url.value' || echo "")
 93: 
 94: if [ -z "$ECR_URL" ] || [ "$ECR_URL" = "null" ]; then
 95:     print_error "Could not retrieve ECR URL from backend_infra state."
 96:     print_error "Make sure backend_infra has been deployed and outputs ecr_url."
 97:     exit 1
 98: fi
 99: 
100: info "ECR Repository URL: $ECR_URL"
101: 
102: 
103: ECR_REPO_NAME=$(echo "$ECR_URL" | awk -F'/' '{print $NF}')
104: info "ECR Repository Name: $ECR_REPO_NAME"
105: echo ""
106: 
107: # ECR is in the Deployment Account, so we need to assume the Deployment Account role
108: # Check if DEPLOYMENT_ROLE_ARN and EXTERNAL_ID are set (from setup-application.sh)
109: if [ -z "${DEPLOYMENT_ROLE_ARN:-}" ]; then
110:     print_error "DEPLOYMENT_ROLE_ARN is not set. Run ./setup-application.sh first."
111:     exit 1
112: fi
113: 
114: if [ -z "${EXTERNAL_ID:-}" ]; then
115:     print_error "EXTERNAL_ID is not set. Run ./setup-application.sh first."
116:     exit 1
117: fi
118: 
119: print_info "Assuming Deployment Account role for ECR operations: $DEPLOYMENT_ROLE_ARN"
120: print_info "Region: $AWS_REGION"
121: 
122: # Assume deployment account role with ExternalId
123: DEPLOYMENT_ROLE_SESSION_NAME="mirror-images-$(date +%s)"
124: DEPLOYMENT_ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
125:     --role-arn "$DEPLOYMENT_ROLE_ARN" \
126:     --role-session-name "$DEPLOYMENT_ROLE_SESSION_NAME" \
127:     --external-id "$EXTERNAL_ID" \
128:     --region "$AWS_REGION" 2>&1)
129: 
130: if [ $? -ne 0 ]; then
131:     print_error "Failed to assume Deployment Account role: $DEPLOYMENT_ASSUME_ROLE_OUTPUT"
132:     exit 1
133: fi
134: 
135: # Extract Deployment Account credentials from JSON output
136: if command -v jq &> /dev/null; then
137:     export AWS_ACCESS_KEY_ID=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
138:     export AWS_SECRET_ACCESS_KEY=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
139:     export AWS_SESSION_TOKEN=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
140: else
141: 
142:     export AWS_ACCESS_KEY_ID=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
143:     export AWS_SECRET_ACCESS_KEY=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
144:     export AWS_SESSION_TOKEN=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
145: fi
146: 
147: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
148:     print_error "Failed to extract Deployment Account credentials from assume-role output."
149:     print_error "Output was: $DEPLOYMENT_ASSUME_ROLE_OUTPUT"
150:     exit 1
151: fi
152: 
153: 
154: DEPLOYMENT_CALLER_ARN=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
155: if [ $? -ne 0 ]; then
156:     print_error "Failed to verify Deployment Account role credentials: $DEPLOYMENT_CALLER_ARN"
157:     exit 1
158: fi
159: 
160: 
161: DEPLOYMENT_ACCOUNT_ID=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Account' --output text 2>&1)
162: if [ $? -ne 0 ]; then
163:     print_error "Failed to get Deployment Account ID: $DEPLOYMENT_ACCOUNT_ID"
164:     exit 1
165: fi
166: 
167: print_success "Successfully assumed Deployment Account role"
168: print_info "Deployment Account role identity: $DEPLOYMENT_CALLER_ARN"
169: print_info "Deployment Account ID: $DEPLOYMENT_ACCOUNT_ID"
170: echo ""
171: 
172: # Function to check if an image tag exists in ECR
173: check_ecr_image_exists() {
174:   local tag=$1
175: 
176:   # Query ECR for the specific image tag
177:   local result
178:   result=$(aws ecr describe-images \
179:     --repository-name "$ECR_REPO_NAME" \
180:     --region "$AWS_REGION" \
181:     --image-ids imageTag="$tag" \
182:     --query 'imageDetails[0].imageTags[0]' \
183:     --output text 2>/dev/null || echo "None")
184: 
185:   if [ "$result" != "None" ] && [ -n "$result" ]; then
186:     return 0
187:   else
188:     return 1
189:   fi
190: }
191: 
192: 
193: info "Authenticating Docker to ECR..."
194: if aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$DEPLOYMENT_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com" 2>/dev/null; then
195:   print_success "Docker authenticated to ECR"
196: else
197:   print_error "Failed to authenticate Docker to ECR"
198:   exit 1
199: fi
200: echo ""
201: 
202: # Define images to mirror with specific tags
203: # Format: "source_image:tag ecr_tag"
204: 
205: IMAGES=(
206:   "bitnami/redis:latest redis-latest"
207:   "bitnami/postgresql:latest postgresql-latest"
208:   "osixia/openldap:1.5.0 openldap-1.5.0"
209: )
210: 
211: info "Checking which images need to be mirrored..."
212: echo ""
213: 
214: IMAGES_TO_MIRROR=()
215: IMAGES_ALREADY_EXIST=()
216: 
217: for image_spec in "${IMAGES[@]}"; do
218:   read -r SOURCE_IMAGE ECR_TAG <<< "$image_spec"
219: 
220:   if check_ecr_image_exists "$ECR_TAG"; then
221:     info " Image already exists in ECR: $ECR_TAG"
222:     IMAGES_ALREADY_EXIST+=("$ECR_TAG")
223:   else
224:     info " Image not found in ECR: $ECR_TAG (will be mirrored)"
225:     IMAGES_TO_MIRROR+=("$image_spec")
226:   fi
227: done
228: 
229: echo ""
230: 
231: if [ ${#IMAGES_ALREADY_EXIST[@]} -gt 0 ]; then
232:   print_success "${
233: fi
234: 
235: if [ ${
236:   print_success "All required images already exist in ECR. No mirroring needed."
237:   echo ""
238:   exit 0
239: fi
240: 
241: info "${
242: echo ""
243: 
244: for image_spec in "${IMAGES_TO_MIRROR[@]}"; do
245:   read -r SOURCE_IMAGE ECR_TAG <<< "$image_spec"
246: 
247:   info "Processing: $SOURCE_IMAGE -> $ECR_TAG"
248: 
249: 
250:   info "  Pulling $SOURCE_IMAGE from Docker Hub..."
251:   if ! docker pull --platform linux/amd64 "$SOURCE_IMAGE"; then
252:     print_error "  Failed to pull $SOURCE_IMAGE"
253:     exit 1
254:   fi
255:   print_success "  Successfully pulled $SOURCE_IMAGE"
256: 
257: 
258:   ECR_IMAGE="$ECR_URL:$ECR_TAG"
259:   info "  Tagging as $ECR_IMAGE..."
260:   docker tag "$SOURCE_IMAGE" "$ECR_IMAGE"
261: 
262: 
263:   info "  Pushing to ECR..."
264:   if ! docker push "$ECR_IMAGE"; then
265:     print_error "  Failed to push $ECR_IMAGE"
266:     exit 1
267:   fi
268:   print_success "  Successfully pushed $ECR_IMAGE"
269: 
270: 
271:   info "  Cleaning up local images..."
272:   docker rmi "$SOURCE_IMAGE" "$ECR_IMAGE" 2>/dev/null || true
273: 
274:   echo ""
275: done
276: 
277: print_success "Image mirroring complete!"
278: echo ""
279: 
280: # List all images in ECR repository
281: info "Current images in ECR repository '$ECR_REPO_NAME':"
282: aws ecr describe-images --repository-name "$ECR_REPO_NAME" --region "$AWS_REGION" \
283:   --query 'sort_by(imageDetails,& imagePushedAt)[*].[imageTags[0],imagePushedAt,imageSizeInBytes]' \
284:   --output table 2>/dev/null || print_info "Could not list ECR images"
285: 
286: echo ""
287: print_success "ECR images are ready for deployment"
````

## File: application/PRD-SIGNUP-MAN.md
````markdown
  1: # PRD: User Signup Management System
  2: 
  3: ## Document Information
  4: 
  5: | Field | Value |
  6: | ------- | ------- |
  7: | Document ID | PRD-SIGNUP-MAN |
  8: | Version | 1.0 |
  9: | Status | Implemented |
 10: | Last Updated | December 2024 |
 11: 
 12: ## 1. Overview
 13: 
 14: ### 1.1 Purpose
 15: 
 16: This document defines the requirements for a self-service user signup system that
 17: allows users to register their own accounts, verify their identity through email
 18: and phone verification, and be activated by an administrator before gaining access
 19: to LDAP-authenticated resources.
 20: 
 21: ### 1.2 Background
 22: 
 23: The existing LDAP 2FA application requires administrators to manually create users
 24: in LDAP. This creates a bottleneck and doesn't scale well for organizations with
 25: frequent user onboarding. A self-service signup system reduces administrative overhead
 26: while maintaining security through multi-step verification.
 27: 
 28: ### 1.3 Scope
 29: 
 30: This PRD covers:
 31: 
 32: - User self-registration with profile fields
 33: - Email verification via AWS SES
 34: - Phone verification via AWS SNS
 35: - Profile state management (PENDING  COMPLETE  ACTIVE)
 36: - Administrator user management interface
 37: - PostgreSQL storage for user data before LDAP activation
 38: 
 39: ## 2. User Stories
 40: 
 41: ### 2.1 New User Registration
 42: 
 43: > **As a** new user,
 44: > **I want to** sign up for an account myself,
 45: > **So that** I don't need to wait for an administrator to create my account.
 46: 
 47: **Acceptance Criteria:**
 48: 
 49: - User can access a signup form from the main application
 50: - Form collects: first name, last name, username, email, phone (with country code),
 51: password
 52: - User selects preferred MFA method (TOTP or SMS)
 53: - Password must be at least 8 characters
 54: - Username must be unique and follow format rules (letters, numbers, underscores,
 55: hyphens)
 56: - Email must be unique and valid format
 57: - Phone number validated with country code
 58: 
 59: ### 2.2 Email Verification
 60: 
 61: > **As a** newly registered user,
 62: > **I want to** verify my email address,
 63: > **So that** the system can confirm I own this email.
 64: 
 65: **Acceptance Criteria:**
 66: 
 67: - Verification email sent automatically upon signup
 68: - Email contains a clickable verification link
 69: - Link expires after 24 hours
 70: - User can request resend of verification email
 71: - Clicking link marks email as verified
 72: - User sees confirmation of successful verification
 73: 
 74: ### 2.3 Phone Verification
 75: 
 76: > **As a** newly registered user,
 77: > **I want to** verify my phone number,
 78: > **So that** the system can confirm I own this phone.
 79: 
 80: **Acceptance Criteria:**
 81: 
 82: - 6-digit verification code sent via SMS upon signup
 83: - Code expires after 1 hour
 84: - User enters code in the application
 85: - User can request resend of verification code
 86: - Correct code marks phone as verified
 87: - User sees confirmation of successful verification
 88: 
 89: ### 2.4 Login Restrictions
 90: 
 91: > **As a** user with incomplete verification,
 92: > **I want to** receive a clear message when I try to log in,
 93: > **So that** I understand what steps I need to complete.
 94: 
 95: **Acceptance Criteria:**
 96: 
 97: - Users with PENDING status cannot log in
 98: - Error message specifies which verifications are missing (email, phone, or both)
 99: - Users with COMPLETE status see message about awaiting admin approval
100: - Only ACTIVE users can complete the login flow
101: 
102: ### 2.5 Admin User Management
103: 
104: > **As an** administrator,
105: > **I want to** view and manage pending user registrations,
106: > **So that** I can approve or reject new user requests.
107: 
108: **Acceptance Criteria:**
109: 
110: - Admin tab visible only to authenticated administrators
111: - Admin can filter users by status (pending, complete, active)
112: - Admin can view user details (name, email, phone, verification status)
113: - Admin can activate users (creates them in LDAP)
114: - Admin can reject users (deletes their registration)
115: - Activated users receive welcome email notification
116: 
117: ## 3. Functional Requirements
118: 
119: ### 3.1 Profile States
120: 
121: | State | Description | Allowed Actions |
122: | ------- | ------------- | ----------------- |
123: | PENDING | User registered but verification incomplete | Verify email, verify phone, resend verification |
124: | COMPLETE | All verifications complete, awaiting admin | Wait for admin activation |
125: | ACTIVE | Admin activated, exists in LDAP | Login, use application |
126: 
127: **State Transitions:**
128: 
129: ```ascii
130: 
131:    SIGNUP    
132: 
133:        
134:        
135:      Email AND Phone
136:    PENDING    
137:                       
138:                                      
139:                               
140:                                 COMPLETE   
141:                               
142:                                       Admin Activation
143:                                      
144:                               
145:                                  ACTIVE    
146:                               
147: ```
148: 
149: ### 3.2 Signup Form Fields
150: 
151: | Field | Type | Required | Validation |
152: | ------- | ------ | ---------- | ------------ |
153: | First Name | Text | Yes | 1-100 characters |
154: | Last Name | Text | Yes | 1-100 characters |
155: | Username | Text | Yes | 3-64 characters, alphanumeric + underscore/hyphen, starts with letter, unique |
156: | Email | Email | Yes | Valid email format, unique |
157: | Phone Country Code | Select | Yes | Valid country code (e.g., +1, +44) |
158: | Phone Number | Tel | Yes | 5-15 digits |
159: | Password | Password | Yes | Minimum 8 characters |
160: | Confirm Password | Password | Yes | Must match password |
161: | MFA Method | Radio | Yes | TOTP (default) or SMS |
162: 
163: ### 3.3 Email Verification
164: 
165: | Requirement | Specification |
166: | ------------- | --------------- |
167: | Delivery Method | AWS SES |
168: | Token Format | UUID |
169: | Token Expiry | 24 hours (configurable) |
170: | Verification URL | `{APP_URL}/verify-email?token={token}&username={username}` |
171: | Resend Cooldown | 60 seconds |
172: 
173: ### 3.4 Phone Verification
174: 
175: | Requirement | Specification |
176: | ------------- | --------------- |
177: | Delivery Method | AWS SNS SMS |
178: | Code Format | 6-digit numeric |
179: | Code Expiry | 1 hour |
180: | Entry Method | Manual input in application |
181: | Resend Cooldown | 60 seconds |
182: 
183: ### 3.5 Admin Activation
184: 
185: When an administrator activates a user:
186: 
187: 1. Create user in LDAP with attributes:
188:    - `uid`: username
189:    - `cn`: full name
190:    - `sn`: last name
191:    - `givenName`: first name
192:    - `mail`: email
193:    - `userPassword`: temporary password
194:    - `uidNumber`: auto-incremented
195:    - `gidNumber`: default users group
196:    - `homeDirectory`: `/home/{username}`
197:    - `objectClass`: inetOrgPerson, posixAccount, shadowAccount
198: 
199: 2. Update user status to ACTIVE in PostgreSQL
200: 
201: 3. Record activation timestamp and admin username
202: 
203: 4. Send welcome email to user
204: 
205: ### 3.6 Admin Authorization
206: 
207: | Requirement | Specification |
208: | ------------- | --------------- |
209: | Authentication | LDAP credentials + MFA code |
210: | Authorization | Member of admin group in LDAP |
211: | Admin Group DN | Configurable (default: `cn=admins,ou=groups,{base_dn}`) |
212: 
213: ## 4. API Endpoints
214: 
215: ### 4.1 Signup Endpoints
216: 
217: | Method | Endpoint | Description |
218: | -------- | ---------- | ------------- |
219: | POST | `/api/auth/signup` | Register new user |
220: | POST | `/api/auth/verify-email` | Verify email with token |
221: | POST | `/api/auth/verify-phone` | Verify phone with code |
222: | POST | `/api/auth/resend-verification` | Resend email or phone verification |
223: | GET | `/api/profile/status/{username}` | Get user profile status |
224: 
225: ### 4.2 Admin Endpoints
226: 
227: | Method | Endpoint | Description |
228: | -------- | ---------- | ------------- |
229: | POST | `/api/admin/login` | Admin login (same as regular + admin check) |
230: | GET | `/api/admin/users` | List users with optional status filter |
231: | POST | `/api/admin/users/{id}/activate` | Activate user to LDAP |
232: | POST | `/api/admin/users/{id}/reject` | Reject and delete user |
233: 
234: ### 4.3 Request/Response Examples
235: 
236: #### Signup Request
237: 
238: ```json
239: {
240:   "username": "jsmith",
241:   "email": "john.smith@example.com",
242:   "first_name": "John",
243:   "last_name": "Smith",
244:   "phone_country_code": "+1",
245:   "phone_number": "5551234567",
246:   "password": "securepassword123",
247:   "mfa_method": "totp"
248: }
249: ```
250: 
251: #### Signup Response
252: 
253: ```json
254: {
255:   "success": true,
256:   "message": "Account created. Please verify your email and phone number.",
257:   "user_id": "550e8400-e29b-41d4-a716-446655440000",
258:   "email_verification_sent": true,
259:   "phone_verification_sent": true
260: }
261: ```
262: 
263: #### Login Error (Pending User)
264: 
265: ```json
266: {
267:   "detail": "Profile incomplete. Please verify your: email, phone"
268: }
269: ```
270: 
271: #### Login Error (Complete User)
272: 
273: ```json
274: {
275:   "detail": "Your profile is awaiting admin approval. Please wait for activation."
276: }
277: ```
278: 
279: ## 5. Data Model
280: 
281: ### 5.1 User Table
282: 
283: ```sql
284: CREATE TABLE users (
285:     id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
286:     username VARCHAR(64) UNIQUE NOT NULL,
287:     email VARCHAR(255) UNIQUE NOT NULL,
288:     first_name VARCHAR(100) NOT NULL,
289:     last_name VARCHAR(100) NOT NULL,
290:     phone_country_code VARCHAR(5) NOT NULL,
291:     phone_number VARCHAR(20) NOT NULL,
292:     password_hash TEXT NOT NULL,
293:     email_verified BOOLEAN DEFAULT FALSE,
294:     phone_verified BOOLEAN DEFAULT FALSE,
295:     status VARCHAR(20) DEFAULT 'pending',
296:     mfa_method VARCHAR(10) DEFAULT 'totp',
297:     totp_secret TEXT,
298:     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
299:     updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
300:     activated_at TIMESTAMP WITH TIME ZONE,
301:     activated_by VARCHAR(64)
302: );
303: ```
304: 
305: ### 5.2 Verification Tokens Table
306: 
307: ```sql
308: CREATE TABLE verification_tokens (
309:     id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
310:     user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
311:     token_type VARCHAR(10) NOT NULL,
312:     token VARCHAR(255) NOT NULL,
313:     expires_at TIMESTAMP WITH TIME ZONE NOT NULL,
314:     used BOOLEAN DEFAULT FALSE,
315:     created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
316: );
317: ```
318: 
319: ## 6. Non-Functional Requirements
320: 
321: ### 6.1 Security
322: 
323: | Requirement | Implementation |
324: | ------------- | ---------------- |
325: | Password Storage | bcrypt hashing |
326: | Token Comparison | Constant-time comparison (prevent timing attacks) |
327: | Rate Limiting | Resend cooldown prevents abuse |
328: | Session Security | Admin credentials validated per request |
329: | Input Validation | Server-side validation of all inputs |
330: | HTTPS | Required for all endpoints |
331: 
332: ### 6.2 Performance
333: 
334: | Metric | Target |
335: | -------- | -------- |
336: | Signup Response Time | < 2 seconds |
337: | Verification Email Delivery | < 30 seconds |
338: | SMS Delivery | < 30 seconds |
339: | Database Queries | < 100ms |
340: 
341: ### 6.3 Scalability
342: 
343: | Component | Scaling Strategy |
344: | ----------- | ------------------ |
345: | Backend API | Horizontal scaling (multiple pods) |
346: | PostgreSQL | Single instance (upgrade to HA if needed) |
347: | SES | AWS managed (scales automatically) |
348: | SNS | AWS managed (scales automatically) |
349: 
350: ### 6.4 Availability
351: 
352: | Component | Target Availability |
353: | ----------- | --------------------- |
354: | API | 99.5% |
355: | Database | 99.5% |
356: | Email Delivery | 99.9% (AWS SES SLA) |
357: | SMS Delivery | 99.9% (AWS SNS SLA) |
358: 
359: ## 7. Infrastructure Requirements
360: 
361: ### 7.1 AWS Services
362: 
363: | Service | Purpose |
364: | --------- | --------- |
365: | SES | Email verification delivery |
366: | SNS | SMS verification delivery |
367: | IAM | IRSA roles for pod access |
368: 
369: ### 7.2 Kubernetes Resources
370: 
371: | Resource | Purpose |
372: | ---------- | --------- |
373: | PostgreSQL (Helm) | User data storage (uses ECR image `postgresql-latest`) |
374: | ConfigMap | Application configuration |
375: | Secret | Database credentials |
376: | ServiceAccount | IRSA for AWS access |
377: 
378: > [!NOTE]
379: >
380: > **ECR Image Support**: PostgreSQL uses ECR images instead of Docker Hub.
381: > The image `bitnami/postgresql:18.1.0-debian-12-r4` is automatically mirrored to
382: > ECR with tag `postgresql-latest` by the `mirror-images-to-ecr.sh` script before
383: > Terraform operations. The ECR registry and repository are computed from
384: > `backend_infra` Terraform state.
385: 
386: ### 7.3 Configuration Variables
387: 
388: | Variable | Description | Default |
389: | ---------- | ------------- | --------- |
390: | `DATABASE_URL` | PostgreSQL connection string | Required |
391: | `SES_SENDER_EMAIL` | Verified sender email | Required |
392: | `EMAIL_VERIFICATION_EXPIRY_HOURS` | Email token expiry | 24 |
393: | `APP_URL` | Application URL for links | Required |
394: | `LDAP_ADMIN_GROUP_DN` | Admin group DN | `cn=admins,ou=groups,{base_dn}` |
395: | `LDAP_USERS_GID` | Default GID for new users | 500 |
396: | `LDAP_UID_START` | Starting UID for new users | 10000 |
397: 
398: ## 8. User Interface
399: 
400: ### 8.1 Tab Structure
401: 
402: ```ascii
403: 
404:   Login    Sign Up   Enroll MFA   Admin  
405: 
406:                                     (hidden until
407:                                      admin login)
408: ```
409: 
410: ### 8.2 Signup Flow
411: 
412: ```ascii
413: 
414:                  Sign Up Form                  
415: 
416:          
417:    First Name         Last Name            
418:          
419:     
420:    Username                                  
421:     
422:     
423:    Email                                     
424:     
425:      
426:    +1     Phone Number                    
427:      
428:     
429:    Password                                  
430:     
431:     
432:    Confirm Password                          
433:     
434:     
435:      Authenticator App                    
436:      SMS                                  
437:     
438:                         
439:               Create Account                 
440:                         
441: 
442: ```
443: 
444: ### 8.3 Verification Status Panel
445: 
446: ```ascii
447: 
448:    Complete Your Registration                         
449:   Please verify your email and phone to continue        
450: 
451:      
452:     Email Verification                 [Resend]     
453:       Check your inbox                                
454:      
455:      
456:     Phone Verification                 [Resend]     
457:       Enter code sent to your phone                   
458:      
459:      
460:    Phone Code: [______] [Verify]                      
461:      
462: 
463: ```
464: 
465: ### 8.4 Admin Panel
466: 
467: ```ascii
468: 
469:    User Management                          [Logout]   
470: 
471:   Filter: [Awaiting Approval ]              [ Refresh]
472: 
473:       
474:    John Smith                                          
475:    @jsmith                                             
476:     j***h@example.com   +1***4567                  
477:    [COMPLETE]  Email  Phone                        
478:    Created: Dec 18, 2024                               
479:                       [ Activate] [ Reject]        
480:       
481:       
482:    Jane Doe                                            
483:    @jdoe                                               
484:    ...                                                 
485:       
486: 
487: ```
488: 
489: ## 9. Testing Requirements
490: 
491: ### 9.1 Unit Tests
492: 
493: - User model validation
494: - Password hashing and verification
495: - Token generation and validation
496: - Profile state transitions
497: 
498: ### 9.2 Integration Tests
499: 
500: - Signup flow end-to-end
501: - Email verification flow
502: - Phone verification flow
503: - Admin activation flow
504: - LDAP user creation
505: 
506: ### 9.3 Security Tests
507: 
508: - SQL injection prevention
509: - XSS prevention
510: - Authentication bypass attempts
511: - Rate limiting effectiveness
512: 
513: ## 10. Deployment Checklist
514: 
515: ### 10.1 Pre-Deployment
516: 
517: - [ ] PostgreSQL deployed and accessible
518: - [ ] SES sender email verified (or domain verified)
519: - [ ] SNS configured for SMS (if using SMS MFA)
520: - [ ] LDAP admin group exists with at least one member
521: - [ ] IAM roles created for IRSA (SES + SNS permissions)
522: - [ ] Environment variables configured
523: 
524: ### 10.2 Post-Deployment
525: 
526: - [ ] Test signup flow with new user
527: - [ ] Verify email delivery and verification
528: - [ ] Verify SMS delivery and verification
529: - [ ] Test admin login and user listing
530: - [ ] Test user activation (verify LDAP user created)
531: - [ ] Test login as activated user
532: 
533: ## 11. Future Enhancements
534: 
535: | Enhancement | Priority | Description |
536: | ------------- | ---------- | ------------- |
537: | Password Reset | High | Self-service password reset via email |
538: | Profile Editing | Medium | Users can update their profile info |
539: | Audit Logging | Medium | Track all admin actions |
540: | Bulk Operations | Low | Admin can activate/reject multiple users |
541: | Email Templates | Low | Customizable email templates |
542: | SSO Integration | Low | OAuth2/OIDC for additional auth options |
543: 
544: ## 12. References
545: 
546: - [AWS SES Documentation](https://docs.aws.amazon.com/ses/)
547: - [AWS SNS SMS Documentation](https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html)
548: - [OpenLDAP Schema](https://www.openldap.org/doc/admin24/schema.html)
549: - [TOTP RFC 6238](https://tools.ietf.org/html/rfc6238)
````

## File: backend_infra/.terraform.lock.hcl
````hcl
  1: # This file is maintained automatically by "terraform init".
  2: # Manual edits may be lost in future updates.
  3: 
  4: provider "registry.terraform.io/hashicorp/aws" {
  5:   version     = "6.21.0"
  6:   constraints = ">= 6.0.0, 6.21.0"
  7:   hashes = [
  8:     "h1:lhPGtXHoctW6UiIg2Av8d6Dk7mLl2J2ORR91ZUYzRVk=",
  9:     "zh:03b65e7d275a48bbe5de9aed2bcacf841ea0a85352744587729d179ceb227994",
 10:     "zh:1a50fc50365602769b6844c6eba920b5c6941161508c2ebd5c1a60f7577edd18",
 11:     "zh:1bcbf2575e462849baa01554be469ac68dbd43fe7929819ab43eb8a849605ce9",
 12:     "zh:28466d206962bfe00a32ecf0a4fa8553a5099521629fce010f486bae2a5f194f",
 13:     "zh:3627c098788e4fc3eb88271101717212f260aa117dad15e648bde6f2889d3536",
 14:     "zh:3f8ae239d1b60a5de3f089810728947c19854eff3c16f22c31e1c8b039dd93a0",
 15:     "zh:62201751f1fc46b6e2720e5d7ea6bab75b98a7eb1f4c3460c258106be5bc5495",
 16:     "zh:86c89c7dd5866fcb57c4d35e7ba6ec849caf70c2fdd2d23c9d05da919ec06c8b",
 17:     "zh:94186ec3908ce6e89eaf98767b6b1e40acfb258de9fe8c09f2a100eb5cfca597",
 18:     "zh:9b12af85486a96aedd8d7984b0ff811a4b42e3d88dad1a3fb4c0b580d04fa425",
 19:     "zh:9d5863a6970735c9e428be91c301789c1e228a3105f711d77efe9c6056bb8295",
 20:     "zh:a94f9abe91656d68a0657d877665766931ae381825fa0b5121da26b3aa3ed15d",
 21:     "zh:df2b293078bb3d31b45bcc6e83c17e790dca40198b8d7069dc3e3b387146937f",
 22:     "zh:e7666954631899756e3bb428c64abcff1c94b7355f7d92eba29541c3d401e472",
 23:     "zh:f142320e9d4a5c663f6e9924abe05274bbbc4031700bac3387e0a67ec6c951ef",
 24:   ]
 25: }
 26: 
 27: provider "registry.terraform.io/hashicorp/cloudinit" {
 28:   version     = "2.3.7"
 29:   constraints = ">= 2.0.0"
 30:   hashes = [
 31:     "h1:M9TpQxKAE/hyOwytdX9MUNZw30HoD/OXqYIug5fkqH8=",
 32:     "zh:06f1c54e919425c3139f8aeb8fcf9bceca7e560d48c9f0c1e3bb0a8ad9d9da1e",
 33:     "zh:0e1e4cf6fd98b019e764c28586a386dc136129fef50af8c7165a067e7e4a31d5",
 34:     "zh:1871f4337c7c57287d4d67396f633d224b8938708b772abfc664d1f80bd67edd",
 35:     "zh:2b9269d91b742a71b2248439d5e9824f0447e6d261bfb86a8a88528609b136d1",
 36:     "zh:3d8ae039af21426072c66d6a59a467d51f2d9189b8198616888c1b7fc42addc7",
 37:     "zh:3ef4e2db5bcf3e2d915921adced43929214e0946a6fb11793085d9a48995ae01",
 38:     "zh:42ae54381147437c83cbb8790cc68935d71b6357728a154109d3220b1beb4dc9",
 39:     "zh:4496b362605ae4cbc9ef7995d102351e2fe311897586ffc7a4a262ccca0c782a",
 40:     "zh:652a2401257a12706d32842f66dac05a735693abcb3e6517d6b5e2573729ba13",
 41:     "zh:7406c30806f5979eaed5f50c548eced2ea18ea121e01801d2f0d4d87a04f6a14",
 42:     "zh:7848429fd5a5bcf35f6fee8487df0fb64b09ec071330f3ff240c0343fe2a5224",
 43:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
 44:   ]
 45: }
 46: 
 47: provider "registry.terraform.io/hashicorp/kubernetes" {
 48:   version = "2.38.0"
 49:   hashes = [
 50:     "h1:soK8Lt0SZ6dB+HsypFRDzuX/npqlMU6M0fvyaR1yW0k=",
 51:     "zh:0af928d776eb269b192dc0ea0f8a3f0f5ec117224cd644bdacdc682300f84ba0",
 52:     "zh:1be998e67206f7cfc4ffe77c01a09ac91ce725de0abaec9030b22c0a832af44f",
 53:     "zh:326803fe5946023687d603f6f1bab24de7af3d426b01d20e51d4e6fbe4e7ec1b",
 54:     "zh:4a99ec8d91193af961de1abb1f824be73df07489301d62e6141a656b3ebfff12",
 55:     "zh:5136e51765d6a0b9e4dbcc3b38821e9736bd2136cf15e9aac11668f22db117d2",
 56:     "zh:63fab47349852d7802fb032e4f2b6a101ee1ce34b62557a9ad0f0f0f5b6ecfdc",
 57:     "zh:924fb0257e2d03e03e2bfe9c7b99aa73c195b1f19412ca09960001bee3c50d15",
 58:     "zh:b63a0be5e233f8f6727c56bed3b61eb9456ca7a8bb29539fba0837f1badf1396",
 59:     "zh:d39861aa21077f1bc899bc53e7233262e530ba8a3a2d737449b100daeb303e4d",
 60:     "zh:de0805e10ebe4c83ce3b728a67f6b0f9d18be32b25146aa89116634df5145ad4",
 61:     "zh:f569b65999264a9416862bca5cd2a6177d94ccb0424f3a4ef424428912b9cb3c",
 62:     "zh:faf23e45f0090eef8ba28a8aac7ec5d4fdf11a36c40a8d286304567d71c1e7db",
 63:   ]
 64: }
 65: 
 66: provider "registry.terraform.io/hashicorp/null" {
 67:   version     = "3.2.4"
 68:   constraints = ">= 3.0.0"
 69:   hashes = [
 70:     "h1:L5V05xwp/Gto1leRryuesxjMfgZwjb7oool4WS1UEFQ=",
 71:     "zh:59f6b52ab4ff35739647f9509ee6d93d7c032985d9f8c6237d1f8a59471bbbe2",
 72:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
 73:     "zh:795c897119ff082133150121d39ff26cb5f89a730a2c8c26f3a9c1abf81a9c43",
 74:     "zh:7b9c7b16f118fbc2b05a983817b8ce2f86df125857966ad356353baf4bff5c0a",
 75:     "zh:85e33ab43e0e1726e5f97a874b8e24820b6565ff8076523cc2922ba671492991",
 76:     "zh:9d32ac3619cfc93eb3c4f423492a8e0f79db05fec58e449dee9b2d5873d5f69f",
 77:     "zh:9e15c3c9dd8e0d1e3731841d44c34571b6c97f5b95e8296a45318b94e5287a6e",
 78:     "zh:b4c2ab35d1b7696c30b64bf2c0f3a62329107bd1a9121ce70683dec58af19615",
 79:     "zh:c43723e8cc65bcdf5e0c92581dcbbdcbdcf18b8d2037406a5f2033b1e22de442",
 80:     "zh:ceb5495d9c31bfb299d246ab333f08c7fb0d67a4f82681fbf47f2a21c3e11ab5",
 81:     "zh:e171026b3659305c558d9804062762d168f50ba02b88b231d20ec99578a6233f",
 82:     "zh:ed0fe2acdb61330b01841fa790be00ec6beaac91d41f311fb8254f74eb6a711f",
 83:   ]
 84: }
 85: 
 86: provider "registry.terraform.io/hashicorp/time" {
 87:   version     = "0.13.1"
 88:   constraints = ">= 0.9.0"
 89:   hashes = [
 90:     "h1:ZT5ppCNIModqk3iOkVt5my8b8yBHmDpl663JtXAIRqM=",
 91:     "zh:02cb9aab1002f0f2a94a4f85acec8893297dc75915f7404c165983f720a54b74",
 92:     "zh:04429b2b31a492d19e5ecf999b116d396dac0b24bba0d0fb19ecaefe193fdb8f",
 93:     "zh:26f8e51bb7c275c404ba6028c1b530312066009194db721a8427a7bc5cdbc83a",
 94:     "zh:772ff8dbdbef968651ab3ae76d04afd355c32f8a868d03244db3f8496e462690",
 95:     "zh:78d5eefdd9e494defcb3c68d282b8f96630502cac21d1ea161f53cfe9bb483b3",
 96:     "zh:898db5d2b6bd6ca5457dccb52eedbc7c5b1a71e4a4658381bcbb38cedbbda328",
 97:     "zh:8de913bf09a3fa7bedc29fec18c47c571d0c7a3d0644322c46f3aa648cf30cd8",
 98:     "zh:9402102c86a87bdfe7e501ffbb9c685c32bbcefcfcf897fd7d53df414c36877b",
 99:     "zh:b18b9bb1726bb8cfbefc0a29cf3657c82578001f514bcf4c079839b6776c47f0",
100:     "zh:b9d31fdc4faecb909d7c5ce41d2479dd0536862a963df434be4b16e8e4edc94d",
101:     "zh:c951e9f39cca3446c060bd63933ebb89cedde9523904813973fbc3d11863ba75",
102:     "zh:e5b773c0d07e962291be0e9b413c7a22c044b8c7b58c76e8aa91d1659990dfb5",
103:   ]
104: }
105: 
106: provider "registry.terraform.io/hashicorp/tls" {
107:   version     = "4.1.0"
108:   constraints = ">= 4.0.0"
109:   hashes = [
110:     "h1:zEv9tY1KR5vaLSyp2lkrucNJ+Vq3c+sTFK9GyQGLtFs=",
111:     "zh:14c35d89307988c835a7f8e26f1b83ce771e5f9b41e407f86a644c0152089ac2",
112:     "zh:2fb9fe7a8b5afdbd3e903acb6776ef1be3f2e587fb236a8c60f11a9fa165faa8",
113:     "zh:35808142ef850c0c60dd93dc06b95c747720ed2c40c89031781165f0c2baa2fc",
114:     "zh:35b5dc95bc75f0b3b9c5ce54d4d7600c1ebc96fbb8dfca174536e8bf103c8cdc",
115:     "zh:38aa27c6a6c98f1712aa5cc30011884dc4b128b4073a4a27883374bfa3ec9fac",
116:     "zh:51fb247e3a2e88f0047cb97bb9df7c228254a3b3021c5534e4563b4007e6f882",
117:     "zh:62b981ce491e38d892ba6364d1d0cdaadcee37cc218590e07b310b1dfa34be2d",
118:     "zh:bc8e47efc611924a79f947ce072a9ad698f311d4a60d0b4dfff6758c912b7298",
119:     "zh:c149508bd131765d1bc085c75a870abb314ff5a6d7f5ac1035a8892d686b6297",
120:     "zh:d38d40783503d278b63858978d40e07ac48123a2925e1a6b47e62179c046f87a",
121:     "zh:f569b65999264a9416862bca5cd2a6177d94ccb0424f3a4ef424428912b9cb3c",
122:     "zh:fb07f708e3316615f6d218cec198504984c0ce7000b9f1eebff7516e384f4b54",
123:   ]
124: }
````

## File: tf_backend_state/CHANGELOG.md
````markdown
  1: # Changelog
  2: 
  3: All notable changes to the Terraform Backend State infrastructure module
  4: will be documented in this file.
  5: 
  6: The format is based on
  7: [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
  8: and this project adheres to
  9: [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
 10: 
 11: ## [2026-01-15] - Automation Improvements and Configuration Simplification
 12: 
 13: ### Added
 14: 
 15: - Enhanced `set-state.sh` script with comprehensive automation:
 16:   - Automatic role assumption from AWS Secrets Manager
 17:   - Intelligent infrastructure provisioning detection
 18:   - Automatic state file download from S3 when bucket exists
 19:   - Terraform validation, plan, and apply workflow integration
 20:   - Bucket name verification and GitHub repository variable management
 21:   - Comprehensive error handling with colored output
 22:   - Always updates bucket name and state file to ensure synchronization
 23: 
 24: ### Changed
 25: 
 26: - Simplified Terraform configuration:
 27:   - Removed `principal_arn` variable - bucket policy now always uses current
 28:     caller's ARN automatically via `data.aws_caller_identity.current.arn`
 29:   - Eliminates need to pass principal ARN as a variable, simplifying
 30:     configuration
 31: - Improved `set-state.sh` script workflow:
 32:   - Removed conditional check for `PROVISIONED_INFRA` - script now always
 33:     updates bucket name and state file
 34:   - Ensures bucket name repository variable and state file are always
 35:     synchronized with latest values
 36:   - Checks for existing `BACKEND_BUCKET_NAME` repository variable to determine
 37:     if infrastructure needs provisioning
 38:   - Automatically downloads existing state file from S3 when bucket is found
 39:   - Validates bucket name consistency between repository variable and Terraform
 40:     output
 41:   - Enhanced credential extraction with jq fallback to sed for broader
 42:     compatibility
 43:   - Improved user feedback with colored status messages (INFO, SUCCESS, ERROR)
 44: 
 45: ### Removed
 46: 
 47: - Removed `principal_arn` variable from `variables.tf` - no longer needed as
 48:   bucket policy automatically uses current caller's ARN
 49: 
 50: ### Security
 51: 
 52: - Enhanced credential handling in `set-state.sh`:
 53:   - Secure role assumption with timestamped session names
 54:   - Credential verification before proceeding with operations
 55:   - Proper error handling for failed role assumptions
 56: 
 57: ## [1.0.0] - 2025-12-19
 58: 
 59: ### Added
 60: 
 61: - Initial Terraform configuration for S3 backend state bucket
 62: - S3 bucket with versioning enabled for state file storage
 63: - Server-side encryption (AES256) for state files at rest
 64: - S3 bucket policy with IAM-based access control
 65: - Public access block configuration to prevent unauthorized access
 66: - Bucket ownership controls to support ACL configuration
 67: - Dynamic bucket naming using prefix and AWS account ID for global
 68:   uniqueness
 69: - Support for optional `principal_arn` variable with automatic detection
 70:   of current caller's ARN
 71: - Terraform output for bucket name
 72: - Comprehensive README documentation with setup instructions
 73: - Local automation scripts (`get-state.sh` and `set-state.sh`) for
 74:   state file management
 75: - GitHub Actions workflow integration support
 76: - AWS Secrets Manager integration for role ARN retrieval in local
 77:   scripts
 78: - GitHub repository variable management for bucket name and
 79:   configuration
 80: - Support for GitHub OIDC authentication via IAM roles
 81: - Automatic state file upload/download functionality
 82: - Environment and prefix-based resource tagging
 83: 
 84: ### Changed
 85: 
 86: - Migrated from DynamoDB-based state locking to S3 file-based locking
 87: - Updated AWS provider to version 6.21.0
 88: - Updated Terraform required version to 1.14.0
 89: - Improved automation scripts to use AWS Secrets Manager instead of
 90:   GitHub CLI for secret access
 91: - Enhanced documentation with detailed troubleshooting sections
 92: - Improved error handling and user feedback in automation scripts
 93: 
 94: ### Fixed
 95: 
 96: - Fixed bucket prefix handling to prevent leading slash issues in
 97:   backend configuration
 98: - Corrected Markdown lint errors for row length across documentation
 99: - Fixed state file management to prevent committing sensitive state to
100:   repository
101: 
102: ### Removed
103: 
104: - Removed DynamoDB table and all related resources (deprecated in favor
105:   of S3 file-based locking)
106: - Removed all references to DynamoDB from code and documentation
107: 
108: ### Security
109: 
110: - Implemented private bucket ACL configuration
111: - Added comprehensive public access blocking
112: - Enabled encryption at rest for all state files
113: - Implemented IAM-based access control with principal ARN support
114: - Added support for OIDC-based authentication (no access keys
115:   required)
116: 
117: ## [0.1.0] - 2025-11-22
118: 
119: ### Added
120: 
121: - Basic S3 bucket configuration
122: - DynamoDB table for state locking (later deprecated)
123: - Initial GitHub Actions workflows
124: - Basic documentation
125: 
126: ## Notes
127: 
128: - **State Locking**: Uses S3 file-based locking (`use_lockfile = true`)
129:   instead of DynamoDB
130: - **Bucket Naming**: Format is `{prefix}-{account-id}-s3-tfstate` to
131:   ensure global uniqueness
132: - **Access Control**: Automatically uses the current caller's ARN via
133:   `data.aws_caller_identity.current.arn` (no manual configuration needed)
134: - **Automation**: Supports both GitHub Actions workflows and local
135:   script execution
136: - **Security**: All state files are encrypted, private, and
137:   access-controlled via IAM policies
138: - **Principal ARN Variable**: The `principal_arn` variable has been removed
139:   - Bucket policy now always uses current caller's ARN automatically
140:   - Works seamlessly with both GitHub Actions and local execution
````

## File: tf_backend_state/get-state.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: print_error() {
 18:     echo -e "${RED}ERROR:${NC} $1" >&2
 19: }
 20: 
 21: print_success() {
 22:     echo -e "${GREEN}SUCCESS:${NC} $1"
 23: }
 24: 
 25: print_info() {
 26:     echo -e "${YELLOW}INFO:${NC} $1"
 27: }
 28: 
 29: 
 30: if ! command -v aws &> /dev/null; then
 31:     print_error "AWS CLI is not installed."
 32:     echo "Please install it from: https://aws.amazon.com/cli/"
 33:     exit 1
 34: fi
 35: 
 36: 
 37: if ! command -v gh &> /dev/null; then
 38:     print_error "GitHub CLI (gh) is not installed."
 39:     echo "Please install it from: https://cli.github.com/"
 40:     echo ""
 41:     echo "Or use the alternative method with curl (requires GITHUB_TOKEN environment variable):"
 42:     echo "  export GITHUB_TOKEN=your_token"
 43:     exit 1
 44: fi
 45: 
 46: 
 47: if ! gh auth status &> /dev/null; then
 48:     print_error "Not authenticated with GitHub CLI."
 49:     echo "Please run: gh auth login"
 50:     exit 1
 51: fi
 52: 
 53: 
 54: if ! command -v jq &> /dev/null; then
 55:     print_error "jq is not installed."
 56:     echo "Please install it:"
 57:     echo "  macOS: brew install jq"
 58:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 59:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 60:     exit 1
 61: fi
 62: 
 63: 
 64: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 65: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 66: 
 67: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 68:     print_error "Could not determine repository information."
 69:     echo "Please ensure you're in a git repository and have proper permissions."
 70:     exit 1
 71: fi
 72: 
 73: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 74: 
 75: 
 76: get_repo_variable() {
 77:     local var_name=$1
 78:     local value
 79: 
 80:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 81: 
 82:     if [ -z "$value" ]; then
 83:         return 1
 84:     fi
 85: 
 86:     echo "$value"
 87: }
 88: 
 89: 
 90: get_aws_secret() {
 91:     local secret_name=$1
 92:     local secret_json
 93:     local exit_code
 94: 
 95: 
 96: 
 97:     secret_json=$(aws secretsmanager get-secret-value \
 98:         --secret-id "$secret_name" \
 99:         --region "${AWS_REGION:-us-east-1}" \
100:         --query SecretString \
101:         --output text 2>&1)
102: 
103: 
104:     exit_code=$?
105: 
106: 
107:     if [ $exit_code -ne 0 ]; then
108:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
109:         print_error "Error: $secret_json"
110:         return 1
111:     fi
112: 
113: 
114:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
115:         print_error "Secret '${secret_name}' contains invalid JSON"
116:         return 1
117:     fi
118: 
119:     echo "$secret_json"
120: }
121: 
122: 
123: get_secret_key_value() {
124:     local secret_json=$1
125:     local key_name=$2
126:     local value
127: 
128: 
129:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
130:         print_error "Invalid JSON provided to get_secret_key_value"
131:         return 1
132:     fi
133: 
134: 
135:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
136: 
137: 
138:     if [ $? -ne 0 ]; then
139:         print_error "Failed to parse JSON or extract key '${key_name}'"
140:         return 1
141:     fi
142: 
143: 
144:     if [ "$value" = "null" ] || [ -z "$value" ]; then
145:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
146:         return 1
147:     fi
148: 
149:     echo "$value"
150: }
151: 
152: 
153: print_info "Retrieving AWS_STATE_ACCOUNT_ROLE_ARN from AWS Secrets Manager..."
154: SECRET_JSON=$(get_aws_secret "github-role" || echo "")
155: if [ -z "$SECRET_JSON" ]; then
156:     print_error "Failed to retrieve secret from AWS Secrets Manager"
157:     exit 1
158: fi
159: 
160: ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
161: if [ -z "$ROLE_ARN" ]; then
162:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
163:     exit 1
164: fi
165: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
166: 
167: 
168: print_info "Retrieving AWS_REGION from repository variables..."
169: REGION=$(get_repo_variable "AWS_REGION" || echo "")
170: if [ -z "$REGION" ]; then
171:     print_info "AWS_REGION not found in repository variables, defaulting to 'us-east-1'"
172:     REGION="us-east-1"
173: else
174:     print_success "Retrieved AWS_REGION: $REGION"
175: fi
176: 
177: print_info "Assuming role: $ROLE_ARN"
178: print_info "Region: $REGION"
179: 
180: 
181: ROLE_SESSION_NAME="get-state-$(date +%s)"
182: 
183: 
184: ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
185:     --role-arn "$ROLE_ARN" \
186:     --role-session-name "$ROLE_SESSION_NAME" \
187:     --region "$REGION" 2>&1)
188: 
189: if [ $? -ne 0 ]; then
190:     print_error "Failed to assume role: $ASSUME_ROLE_OUTPUT"
191:     exit 1
192: fi
193: 
194: 
195: 
196: if command -v jq &> /dev/null; then
197:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
198:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
199:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
200: else
201: 
202:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
203:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
204:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
205: fi
206: 
207: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
208:     print_error "Failed to extract credentials from assume-role output."
209:     print_error "Output was: $ASSUME_ROLE_OUTPUT"
210:     exit 1
211: fi
212: 
213: print_success "Successfully assumed role"
214: 
215: 
216: CALLER_ARN=$(aws sts get-caller-identity --region "$REGION" --query 'Arn' --output text 2>&1)
217: if [ $? -ne 0 ]; then
218:     print_error "Failed to verify assumed role credentials: $CALLER_ARN"
219:     exit 1
220: fi
221: 
222: print_info "Assumed role identity: $CALLER_ARN"
223: 
224: 
225: print_info "Retrieving repository variables from GitHub..."
226: 
227: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME" || echo "")
228: if [ -z "$BUCKET_NAME" ]; then
229:     print_info "BACKEND_BUCKET_NAME not found in repository variables."
230:     print_info "This means the infrastructure has not been provisioned yet."
231:     print_info "There is no existing state file to download."
232:     print_success "Script completed successfully (no state file exists)"
233:     exit 0
234: fi
235: print_success "Retrieved BACKEND_BUCKET_NAME: $BUCKET_NAME"
236: 
237: BACKEND_PREFIX=$(get_repo_variable "BACKEND_PREFIX" || echo "")
238: if [ -z "$BACKEND_PREFIX" ]; then
239:     print_error "BACKEND_PREFIX not found in repository variables."
240:     echo "Please ensure BACKEND_PREFIX is set in GitHub repository variables."
241:     exit 1
242: fi
243: print_success "Retrieved BACKEND_PREFIX: $BACKEND_PREFIX"
244: 
245: 
246: S3_PATH="s3://${BUCKET_NAME}/${BACKEND_PREFIX}"
247: print_info "Checking for state file at: $S3_PATH"
248: 
249: 
250: 
251: if aws s3 ls "$S3_PATH" --region "$REGION" &>/dev/null; then
252:     print_success "State file exists, downloading..."
253: 
254: 
255:     if aws s3 cp "$S3_PATH" terraform.tfstate --region "$REGION"; then
256:         print_success "State file downloaded successfully to terraform.tfstate"
257:     else
258:         print_error "Failed to download state file"
259:         exit 1
260:     fi
261: else
262:     print_info "State file does not exist at $S3_PATH"
263:     print_info "This is expected if this is the first time provisioning the infrastructure."
264: 
265: fi
266: 
267: print_success "Script completed successfully"
````

## File: tf_backend_state/main.tf
````hcl
 1: # Get current AWS account ID and caller identity for unique bucket naming and dynamic principal
 2: data "aws_caller_identity" "current" {}
 3: 
 4: resource "aws_s3_bucket" "terraform_state" {
 5:   # Include account ID in bucket name to ensure global uniqueness
 6:   bucket        = "${var.prefix}-${data.aws_caller_identity.current.account_id}-s3-tfstate"
 7:   force_destroy = true
 8: 
 9:   tags = {
10:     Name      = "${var.prefix}-${data.aws_caller_identity.current.account_id}-s3-tfstate"
11:     Env       = var.env
12:     Terraform = true
13:   }
14: }
15: 
16: resource "aws_s3_bucket_acl" "terraform_state_acl" {
17:   bucket     = aws_s3_bucket.terraform_state.bucket
18:   acl        = "private"
19:   depends_on = [aws_s3_bucket_ownership_controls.terraform_state_acl_ownership]
20: }
21: 
22: # Resource to avoid error "AccessControlListNotSupported: The bucket does not allow ACLs"
23: resource "aws_s3_bucket_ownership_controls" "terraform_state_acl_ownership" {
24:   bucket = aws_s3_bucket.terraform_state.bucket
25:   rule {
26:     object_ownership = "ObjectWriter"
27:   }
28: }
29: 
30: resource "aws_s3_bucket_versioning" "terraform_state_versioning" {
31:   bucket = aws_s3_bucket.terraform_state.bucket
32:   versioning_configuration {
33:     status = "Enabled"
34:   }
35: }
36: 
37: # Block public access to the state bucket
38: resource "aws_s3_bucket_public_access_block" "terraform_state_public_block" {
39:   bucket = aws_s3_bucket.terraform_state.bucket
40: 
41:   block_public_acls       = true
42:   block_public_policy     = true
43:   ignore_public_acls      = true
44:   restrict_public_buckets = true
45: }
46: 
47: resource "aws_s3_bucket_policy" "terraform_state_policy" {
48:   bucket = aws_s3_bucket.terraform_state.bucket
49:   depends_on = [
50:     aws_s3_bucket.terraform_state,
51:     aws_s3_bucket_public_access_block.terraform_state_public_block
52:   ]
53:   policy = jsonencode({
54:     Version = "2012-10-17"
55:     Statement = [
56:       {
57:         Sid    = "ListGetPutDeleteBucketContents"
58:         Effect = "Allow"
59:         Action = [
60:           "s3:ListBucket",
61:           "s3:GetObject",
62:           "s3:PutObject",
63:           "s3:DeleteObject"
64:         ]
65:         Principal = {
66:           AWS = data.aws_caller_identity.current.arn
67:         }
68:         Resource = [
69:           "arn:aws:s3:::${aws_s3_bucket.terraform_state.bucket}",
70:           "arn:aws:s3:::${aws_s3_bucket.terraform_state.bucket}/*"
71:         ]
72:       }
73:     ]
74:   })
75: }
76: 
77: # Add bucket encryption to hide sensitive state data
78: resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state_encryption" {
79:   bucket = aws_s3_bucket.terraform_state.bucket
80:   rule {
81:     apply_server_side_encryption_by_default {
82:       sse_algorithm = "AES256"
83:     }
84:   }
85: }
````

## File: .github/workflows/tfstate_infra_destroying.yaml
````yaml
 1: name: TF Backend State Destroying
 2: 
 3: on:
 4:   workflow_dispatch:
 5: 
 6: jobs:
 7:   InfraProvision:
 8:     runs-on: ubuntu-latest
 9:     permissions:
10:       contents: write
11:       actions: write
12:       id-token: write
13:     env:
14:       AWS_REGION: ${{ vars.AWS_REGION }}
15:     defaults:
16:       run:
17:         working-directory: ./tf_backend_state
18:     steps:
19:       - name: Checkout the repo code
20:         uses: actions/checkout@v4
21: 
22:       - name: Setup terraform
23:         uses: hashicorp/setup-terraform@v3
24:         with:
25:           terraform_version: 1.14.0
26: 
27:       - name: Configure AWS credentials (State Account)
28:         uses: aws-actions/configure-aws-credentials@v4
29:         with:
30:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
31:           role-session-name: GitHubActions-TFStateInfraDestroy
32:           aws-region: ${{ env.AWS_REGION }}
33: 
34:       - name: Download backend state file from S3
35:         run: |
36:           aws s3 cp \
37:             s3://${{ vars.BACKEND_BUCKET_NAME }}/${{ vars.BACKEND_PREFIX }} \
38:             terraform.tfstate
39: 
40:       - name: Terraform init
41:         run: terraform init -backend=false
42: 
43:       - name: Terraform validate
44:         run: terraform validate
45: 
46:       - name: Terraform plan destroy
47:         run: terraform plan -var-file="variables.tfvars" -destroy -out terraform.tfplan
48: 
49:       - name: Destroy backend state
50:         run: terraform apply -auto-approve terraform.tfplan
````

## File: application/backend/src/app/ldap/client.py
````python
  1: import logging
  2: from typing import Optional
  3: 
  4: import ldap3
  5: from ldap3 import ALL, MODIFY_ADD, MODIFY_DELETE, MODIFY_REPLACE, Connection, Server
  6: from ldap3.core.exceptions import LDAPException
  7: from ldap3.utils.dn import escape_rdn
  8: 
  9: from app.config import Settings, get_settings
 10: 
 11: logger = logging.getLogger(__name__)
 12: 
 13: 
 14: class LDAPClient:
 15: 
 16: 
 17:     def __init__(self, settings: Optional[Settings] = None):
 18: 
 19:         self.settings = settings or get_settings()
 20:         self._server: Optional[Server] = None
 21: 
 22:     @property
 23:     def server(self) -> Server:
 24: 
 25:         if self._server is None:
 26:             self._server = Server(
 27:                 host=self.settings.ldap_host,
 28:                 port=self.settings.ldap_port,
 29:                 use_ssl=self.settings.ldap_use_ssl,
 30:                 get_info=ALL,
 31:             )
 32:         return self._server
 33: 
 34:     def _get_admin_connection(self) -> Connection:
 35: 
 36:         return Connection(
 37:             self.server,
 38:             user=self.settings.ldap_admin_dn,
 39:             password=self.settings.ldap_admin_password,
 40:             auto_bind=True,
 41:             raise_exceptions=True,
 42:         )
 43: 
 44:     def _get_user_search_base(self) -> str:
 45: 
 46:         user_search_base = self.settings.ldap_user_search_base
 47:         if not user_search_base.endswith(self.settings.ldap_base_dn):
 48:             user_search_base = f"{user_search_base},{self.settings.ldap_base_dn}"
 49:         return user_search_base
 50: 
 51:     def _get_user_dn(self, username: str) -> str:
 52:         """Construct the user DN from username."""
 53:         return f"uid={username},{self._get_user_search_base()}"
 54: 
 55:     def _get_group_search_base(self) -> str:
 56:         """Get the full group search base DN."""
 57:         group_search_base = self.settings.ldap_group_search_base
 58:         if not group_search_base.endswith(self.settings.ldap_base_dn):
 59:             group_search_base = f"{group_search_base},{self.settings.ldap_base_dn}"
 60:         return group_search_base
 61: 
 62:     def _get_group_dn(self, group_name: str) -> str:
 63:         """Construct the group DN from group name."""
 64:         return f"cn={group_name},{self._get_group_search_base()}"
 65: 
 66:     def _get_next_uid_number(self, conn: Connection) -> int:
 67:         """Get the next available UID number."""
 68:         try:
 69:             conn.search(
 70:                 search_base=self._get_user_search_base(),
 71:                 search_filter="(objectClass=posixAccount)",
 72:                 attributes=["uidNumber"],
 73:             )
 74: 
 75:             max_uid = self.settings.ldap_uid_start
 76:             for entry in conn.entries:
 77:                 if hasattr(entry, "uidNumber") and entry.uidNumber.value:
 78:                     uid = int(entry.uidNumber.value)
 79:                     if uid >= max_uid:
 80:                         max_uid = uid + 1
 81: 
 82:             return max_uid
 83:         except Exception as e:
 84:             logger.warning(f"Error getting next UID, using default: {e}")
 85:             return self.settings.ldap_uid_start
 86: 
 87:     def authenticate(self, username: str, password: str) -> tuple[bool, str]:
 88:         """
 89:         Authenticate a user against LDAP.
 90: 
 91:         Args:
 92:             username: The username to authenticate
 93:             password: The user's password
 94: 
 95:         Returns:
 96:             Tuple of (success: bool, message: str)
 97:         """
 98:         if not password:
 99:             return False, "Password cannot be empty"
100: 
101:         user_dn = self._get_user_dn(username)
102:         logger.debug(f"Attempting to authenticate user DN: {user_dn}")
103: 
104:         try:
105:             conn = Connection(
106:                 self.server,
107:                 user=user_dn,
108:                 password=password,
109:                 auto_bind=True,
110:                 raise_exceptions=True,
111:             )
112:             conn.unbind()
113:             logger.info(f"Successfully authenticated user: {username}")
114:             return True, "Authentication successful"
115:         except ldap3.core.exceptions.LDAPBindError as e:
116:             logger.warning(f"Authentication failed for user {username}: {e}")
117:             return False, "Invalid username or password"
118:         except LDAPException as e:
119:             logger.error(f"LDAP error during authentication: {e}")
120:             return False, f"LDAP error: {e!s}"
121:         except Exception as e:
122:             logger.error(f"Unexpected error during authentication: {e}")
123:             return False, f"Authentication error: {e!s}"
124: 
125:     def user_exists(self, username: str) -> bool:
126:         """
127:         Check if a user exists in LDAP.
128: 
129:         Args:
130:             username: The username to check
131: 
132:         Returns:
133:             True if user exists, False otherwise
134:         """
135:         try:
136:             conn = self._get_admin_connection()
137: 
138:             search_filter = self.settings.ldap_user_search_filter.format(username)
139:             conn.search(
140:                 search_base=self._get_user_search_base(),
141:                 search_filter=search_filter,
142:                 attributes=["uid"],
143:             )
144: 
145:             exists = len(conn.entries) > 0
146:             conn.unbind()
147:             return exists
148:         except LDAPException as e:
149:             logger.error(f"LDAP error checking user existence: {e}")
150:             return False
151: 
152:     def get_user_attribute(
153:         self, username: str, attribute: str
154:     ) -> Optional[str]:
155:         """
156:         Get a user attribute from LDAP.
157: 
158:         Args:
159:             username: The username
160:             attribute: The attribute name to retrieve
161: 
162:         Returns:
163:             The attribute value or None if not found
164:         """
165:         try:
166:             conn = self._get_admin_connection()
167: 
168:             search_filter = self.settings.ldap_user_search_filter.format(username)
169:             conn.search(
170:                 search_base=self._get_user_search_base(),
171:                 search_filter=search_filter,
172:                 attributes=[attribute],
173:             )
174: 
175:             if conn.entries:
176:                 entry = conn.entries[0]
177:                 if hasattr(entry, attribute):
178:                     value = getattr(entry, attribute).value
179:                     conn.unbind()
180:                     return value
181: 
182:             conn.unbind()
183:             return None
184:         except LDAPException as e:
185:             logger.error(f"LDAP error getting user attribute: {e}")
186:             return None
187: 
188:     def create_user(
189:         self,
190:         username: str,
191:         password: str,
192:         first_name: str,
193:         last_name: str,
194:         email: str,
195:     ) -> tuple[bool, str]:
196:         """
197:         Create a new user in LDAP.
198: 
199:         Args:
200:             username: The username (uid)
201:             password: The user's password
202:             first_name: User's first name
203:             last_name: User's last name
204:             email: User's email address
205: 
206:         Returns:
207:             Tuple of (success: bool, message: str)
208:         """
209:         user_dn = self._get_user_dn(username)
210: 
211:         try:
212:             conn = self._get_admin_connection()
213: 
214:             # Check if user already exists
215:             if self.user_exists(username):
216:                 conn.unbind()
217:                 return False, f"User {username} already exists in LDAP"
218: 
219: 
220:             uid_number = self._get_next_uid_number(conn)
221: 
222: 
223: 
224:             attributes = {
225:                 "objectClass": [
226:                     "inetOrgPerson",
227:                     "posixAccount",
228:                     "shadowAccount",
229:                     "top",
230:                 ],
231:                 "uid": username,
232:                 "cn": f"{first_name} {last_name}",
233:                 "sn": last_name,
234:                 "givenName": first_name,
235:                 "mail": email,
236:                 "userPassword": password,
237:                 "uidNumber": str(uid_number),
238:                 "gidNumber": str(self.settings.ldap_users_gid),
239:                 "homeDirectory": f"/home/{username}",
240:                 "loginShell": "/bin/bash",
241:             }
242: 
243: 
244:             success = conn.add(user_dn, attributes=attributes)
245: 
246:             if success:
247:                 logger.info(f"Created LDAP user: {username} (UID: {uid_number})")
248:                 conn.unbind()
249:                 return True, f"User {username} created successfully"
250:             else:
251:                 error_msg = conn.result.get("description", "Unknown error")
252:                 logger.error(f"Failed to create LDAP user {username}: {error_msg}")
253:                 conn.unbind()
254:                 return False, f"Failed to create user: {error_msg}"
255: 
256:         except LDAPException as e:
257:             logger.error(f"LDAP error creating user {username}: {e}")
258:             return False, f"LDAP error: {e!s}"
259:         except Exception as e:
260:             logger.error(f"Unexpected error creating user {username}: {e}")
261:             return False, f"Error creating user: {e!s}"
262: 
263:     def delete_user(self, username: str) -> tuple[bool, str]:
264:         """
265:         Delete a user from LDAP.
266: 
267:         Args:
268:             username: The username to delete
269: 
270:         Returns:
271:             Tuple of (success: bool, message: str)
272:         """
273:         user_dn = self._get_user_dn(username)
274: 
275:         try:
276:             conn = self._get_admin_connection()
277: 
278:             success = conn.delete(user_dn)
279: 
280:             if success:
281:                 logger.info(f"Deleted LDAP user: {username}")
282:                 conn.unbind()
283:                 return True, f"User {username} deleted successfully"
284:             else:
285:                 error_msg = conn.result.get("description", "Unknown error")
286:                 logger.error(f"Failed to delete LDAP user {username}: {error_msg}")
287:                 conn.unbind()
288:                 return False, f"Failed to delete user: {error_msg}"
289: 
290:         except LDAPException as e:
291:             logger.error(f"LDAP error deleting user {username}: {e}")
292:             return False, f"LDAP error: {e!s}"
293:         except Exception as e:
294:             logger.error(f"Unexpected error deleting user {username}: {e}")
295:             return False, f"Error deleting user: {e!s}"
296: 
297:     def is_admin(self, username: str) -> bool:
298:         """
299:         Check if a user is a member of the admin group.
300: 
301:         Args:
302:             username: The username to check
303: 
304:         Returns:
305:             True if user is an admin, False otherwise
306:         """
307:         try:
308:             conn = self._get_admin_connection()
309: 
310:             admin_group_dn = self.settings.ldap_admin_group_dn
311: 
312:             # Search for the admin group and check membership
313:             # Groups typically use 'member' or 'memberUid' attribute
314:             conn.search(
315:                 search_base=admin_group_dn,
316:                 search_filter="(objectClass=*)",
317:                 attributes=["member", "memberUid", "uniqueMember"],
318:             )
319: 
320:             if not conn.entries:
321:                 logger.debug(f"Admin group not found: {admin_group_dn}")
322:                 conn.unbind()
323:                 return False
324: 
325:             entry = conn.entries[0]
326:             user_dn = self._get_user_dn(username)
327: 
328:             # Check different membership attribute types
329:             # member/uniqueMember uses full DN
330:             if hasattr(entry, "member") and entry.member.values:
331:                 if user_dn.lower() in [m.lower() for m in entry.member.values]:
332:                     conn.unbind()
333:                     return True
334: 
335:             if hasattr(entry, "uniqueMember") and entry.uniqueMember.values:
336:                 if user_dn.lower() in [m.lower() for m in entry.uniqueMember.values]:
337:                     conn.unbind()
338:                     return True
339: 
340: 
341:             if hasattr(entry, "memberUid") and entry.memberUid.values:
342:                 if username.lower() in [m.lower() for m in entry.memberUid.values]:
343:                     conn.unbind()
344:                     return True
345: 
346:             conn.unbind()
347:             return False
348: 
349:         except LDAPException as e:
350:             logger.error(f"LDAP error checking admin status for {username}: {e}")
351:             return False
352:         except Exception as e:
353:             logger.error(f"Unexpected error checking admin status for {username}: {e}")
354:             return False
355: 
356:     def add_user_to_group(self, username: str, group_dn: str) -> tuple[bool, str]:
357:         """
358:         Add a user to an LDAP group.
359: 
360:         Args:
361:             username: The username to add
362:             group_dn: The DN of the group
363: 
364:         Returns:
365:             Tuple of (success: bool, message: str)
366:         """
367:         user_dn = self._get_user_dn(username)
368: 
369:         try:
370:             conn = self._get_admin_connection()
371: 
372:             # Try to add as member (for groupOfNames/groupOfUniqueNames)
373:             success = conn.modify(
374:                 group_dn,
375:                 {"member": [(MODIFY_ADD, [user_dn])]}
376:             )
377: 
378:             if not success:
379: 
380:                 success = conn.modify(
381:                     group_dn,
382:                     {"memberUid": [(MODIFY_ADD, [username])]}
383:                 )
384: 
385:             if success:
386:                 logger.info(f"Added user {username} to group {group_dn}")
387:                 conn.unbind()
388:                 return True, f"User added to group successfully"
389:             else:
390:                 error_msg = conn.result.get("description", "Unknown error")
391:                 logger.error(f"Failed to add {username} to group: {error_msg}")
392:                 conn.unbind()
393:                 return False, f"Failed to add to group: {error_msg}"
394: 
395:         except LDAPException as e:
396:             logger.error(f"LDAP error adding user to group: {e}")
397:             return False, f"LDAP error: {e!s}"
398:         except Exception as e:
399:             logger.error(f"Unexpected error adding user to group: {e}")
400:             return False, f"Error: {e!s}"
401: 
402:     def remove_user_from_group(self, username: str, group_dn: str) -> tuple[bool, str]:
403:         """
404:         Remove a user from an LDAP group.
405: 
406:         Args:
407:             username: The username to remove
408:             group_dn: The DN of the group
409: 
410:         Returns:
411:             Tuple of (success: bool, message: str)
412:         """
413:         user_dn = self._get_user_dn(username)
414: 
415:         try:
416:             conn = self._get_admin_connection()
417: 
418:             # Try to remove as member (for groupOfNames/groupOfUniqueNames)
419:             success = conn.modify(
420:                 group_dn,
421:                 {"member": [(MODIFY_DELETE, [user_dn])]}
422:             )
423: 
424:             if not success:
425: 
426:                 success = conn.modify(
427:                     group_dn,
428:                     {"memberUid": [(MODIFY_DELETE, [username])]}
429:                 )
430: 
431:             if success:
432:                 logger.info(f"Removed user {username} from group {group_dn}")
433:                 conn.unbind()
434:                 return True, "User removed from group successfully"
435:             else:
436:                 error_msg = conn.result.get("description", "Unknown error")
437:                 logger.error(f"Failed to remove {username} from group: {error_msg}")
438:                 conn.unbind()
439:                 return False, f"Failed to remove from group: {error_msg}"
440: 
441:         except LDAPException as e:
442:             logger.error(f"LDAP error removing user from group: {e}")
443:             return False, f"LDAP error: {e!s}"
444:         except Exception as e:
445:             logger.error(f"Unexpected error removing user from group: {e}")
446:             return False, f"Error: {e!s}"
447: 
448:     def list_groups(self) -> list[dict]:
449:         """
450:         List all LDAP groups.
451: 
452:         Returns:
453:             List of group dictionaries with dn, name, description, and members
454:         """
455:         groups = []
456:         try:
457:             conn = self._get_admin_connection()
458: 
459:             # Search for all groups
460:             conn.search(
461:                 search_base=self._get_group_search_base(),
462:                 search_filter="(|(objectClass=groupOfNames)(objectClass=groupOfUniqueNames)(objectClass=posixGroup))",
463:                 attributes=["cn", "description", "member", "memberUid", "uniqueMember"],
464:             )
465: 
466:             for entry in conn.entries:
467:                 group_data = {
468:                     "dn": str(entry.entry_dn),
469:                     "name": entry.cn.value if hasattr(entry, "cn") else "",
470:                     "description": entry.description.value if hasattr(entry, "description") and entry.description.value else "",
471:                     "members": [],
472:                 }
473: 
474: 
475:                 if hasattr(entry, "member") and entry.member.values:
476:                     group_data["members"].extend(entry.member.values)
477:                 if hasattr(entry, "uniqueMember") and entry.uniqueMember.values:
478:                     group_data["members"].extend(entry.uniqueMember.values)
479:                 if hasattr(entry, "memberUid") and entry.memberUid.values:
480:                     group_data["members"].extend(entry.memberUid.values)
481: 
482:                 groups.append(group_data)
483: 
484:             conn.unbind()
485:             logger.info(f"Listed {len(groups)} LDAP groups")
486:             return groups
487: 
488:         except LDAPException as e:
489:             logger.error(f"LDAP error listing groups: {e}")
490:             return []
491:         except Exception as e:
492:             logger.error(f"Unexpected error listing groups: {e}")
493:             return []
494: 
495:     def create_group(
496:         self,
497:         name: str,
498:         description: str = "",
499:     ) -> tuple[bool, str, Optional[str]]:
500:         """
501:         Create a new LDAP group.
502: 
503:         Args:
504:             name: The group name (cn)
505:             description: Group description
506: 
507:         Returns:
508:             Tuple of (success: bool, message: str, group_dn: Optional[str])
509:         """
510:         # Escape the group name before using it in a DN or as the cn attribute
511:         safe_name = escape_rdn(name)
512:         group_dn = self._get_group_dn(safe_name)
513: 
514:         try:
515:             conn = self._get_admin_connection()
516: 
517:             # Check if group already exists
518:             conn.search(
519:                 search_base=group_dn,
520:                 search_filter="(objectClass=*)",
521:                 attributes=["cn"],
522:             )
523:             if conn.entries:
524:                 conn.unbind()
525:                 return False, f"Group {name} already exists", None
526: 
527: 
528: 
529:             attributes = {
530:                 "objectClass": ["groupOfNames", "top"],
531:                 "cn": safe_name,
532:                 "description": description or f"Group: {name}",
533:                 "member": [self.settings.ldap_admin_dn],
534:             }
535: 
536:             success = conn.add(group_dn, attributes=attributes)
537: 
538:             if success:
539:                 logger.info(f"Created LDAP group: {name}")
540:                 conn.unbind()
541:                 return True, f"Group {name} created successfully", group_dn
542:             else:
543:                 error_msg = conn.result.get("description", "Unknown error")
544:                 logger.error(f"Failed to create LDAP group {name}: {error_msg}")
545:                 conn.unbind()
546:                 return False, f"Failed to create group: {error_msg}", None
547: 
548:         except LDAPException as e:
549:             logger.error(f"LDAP error creating group {name}: {e}")
550:             return False, f"LDAP error: {e!s}", None
551:         except Exception as e:
552:             logger.error(f"Unexpected error creating group {name}: {e}")
553:             return False, f"Error creating group: {e!s}", None
554: 
555:     def delete_group(self, group_dn: str) -> tuple[bool, str]:
556:         """
557:         Delete an LDAP group.
558: 
559:         Args:
560:             group_dn: The DN of the group to delete
561: 
562:         Returns:
563:             Tuple of (success: bool, message: str)
564:         """
565:         try:
566:             conn = self._get_admin_connection()
567: 
568:             success = conn.delete(group_dn)
569: 
570:             if success:
571:                 logger.info(f"Deleted LDAP group: {group_dn}")
572:                 conn.unbind()
573:                 return True, "Group deleted successfully"
574:             else:
575:                 error_msg = conn.result.get("description", "Unknown error")
576:                 logger.error(f"Failed to delete LDAP group {group_dn}: {error_msg}")
577:                 conn.unbind()
578:                 return False, f"Failed to delete group: {error_msg}"
579: 
580:         except LDAPException as e:
581:             logger.error(f"LDAP error deleting group {group_dn}: {e}")
582:             return False, f"LDAP error: {e!s}"
583:         except Exception as e:
584:             logger.error(f"Unexpected error deleting group {group_dn}: {e}")
585:             return False, f"Error deleting group: {e!s}"
586: 
587:     def update_group(
588:         self,
589:         group_dn: str,
590:         description: Optional[str] = None,
591:     ) -> tuple[bool, str]:
592:         """
593:         Update an LDAP group's description.
594: 
595:         Args:
596:             group_dn: The DN of the group
597:             description: New description (if provided)
598: 
599:         Returns:
600:             Tuple of (success: bool, message: str)
601:         """
602:         try:
603:             conn = self._get_admin_connection()
604: 
605:             modifications = {}
606:             if description is not None:
607:                 modifications["description"] = [(MODIFY_REPLACE, [description])]
608: 
609:             if not modifications:
610:                 conn.unbind()
611:                 return True, "No changes to apply"
612: 
613:             success = conn.modify(group_dn, modifications)
614: 
615:             if success:
616:                 logger.info(f"Updated LDAP group: {group_dn}")
617:                 conn.unbind()
618:                 return True, "Group updated successfully"
619:             else:
620:                 error_msg = conn.result.get("description", "Unknown error")
621:                 logger.error(f"Failed to update LDAP group {group_dn}: {error_msg}")
622:                 conn.unbind()
623:                 return False, f"Failed to update group: {error_msg}"
624: 
625:         except LDAPException as e:
626:             logger.error(f"LDAP error updating group {group_dn}: {e}")
627:             return False, f"LDAP error: {e!s}"
628:         except Exception as e:
629:             logger.error(f"Unexpected error updating group {group_dn}: {e}")
630:             return False, f"Error updating group: {e!s}"
631: 
632:     def get_user_groups(self, username: str) -> list[dict]:
633:         """
634:         Get all groups a user belongs to.
635: 
636:         Args:
637:             username: The username to check
638: 
639:         Returns:
640:             List of group dictionaries with dn and name
641:         """
642:         user_dn = self._get_user_dn(username)
643:         groups = []
644: 
645:         try:
646:             conn = self._get_admin_connection()
647: 
648:             # Search for groups containing this user
649:             # Check both member (DN) and memberUid (username)
650:             search_filter = f"(|(member={user_dn})(memberUid={username})(uniqueMember={user_dn}))"
651:             conn.search(
652:                 search_base=self._get_group_search_base(),
653:                 search_filter=search_filter,
654:                 attributes=["cn", "description"],
655:             )
656: 
657:             for entry in conn.entries:
658:                 groups.append({
659:                     "dn": str(entry.entry_dn),
660:                     "name": entry.cn.value if hasattr(entry, "cn") else "",
661:                     "description": entry.description.value if hasattr(entry, "description") and entry.description.value else "",
662:                 })
663: 
664:             conn.unbind()
665:             logger.debug(f"User {username} belongs to {len(groups)} groups")
666:             return groups
667: 
668:         except LDAPException as e:
669:             logger.error(f"LDAP error getting user groups for {username}: {e}")
670:             return []
671:         except Exception as e:
672:             logger.error(f"Unexpected error getting user groups for {username}: {e}")
673:             return []
674: 
675:     def get_admin_emails(self) -> list[str]:
676:         """
677:         Get email addresses of all admin group members.
678: 
679:         Returns:
680:             List of email addresses
681:         """
682:         emails = []
683:         try:
684:             conn = self._get_admin_connection()
685: 
686:             admin_group_dn = self.settings.ldap_admin_group_dn
687: 
688:             # Get admin group members
689:             conn.search(
690:                 search_base=admin_group_dn,
691:                 search_filter="(objectClass=*)",
692:                 attributes=["member", "memberUid", "uniqueMember"],
693:             )
694: 
695:             if not conn.entries:
696:                 logger.warning(f"Admin group not found: {admin_group_dn}")
697:                 conn.unbind()
698:                 return []
699: 
700:             entry = conn.entries[0]
701:             member_dns = []
702:             member_uids = []
703: 
704:             # Collect member DNs
705:             if hasattr(entry, "member") and entry.member.values:
706:                 member_dns.extend(entry.member.values)
707:             if hasattr(entry, "uniqueMember") and entry.uniqueMember.values:
708:                 member_dns.extend(entry.uniqueMember.values)
709:             if hasattr(entry, "memberUid") and entry.memberUid.values:
710:                 member_uids.extend(entry.memberUid.values)
711: 
712: 
713:             for member_dn in member_dns:
714:                 try:
715:                     conn.search(
716:                         search_base=member_dn,
717:                         search_filter="(objectClass=*)",
718:                         attributes=["mail"],
719:                     )
720:                     if conn.entries and hasattr(conn.entries[0], "mail"):
721:                         mail = conn.entries[0].mail.value
722:                         if mail:
723:                             emails.append(mail)
724:                 except Exception as e:
725:                     logger.debug(f"Could not fetch email for {member_dn}: {e}")
726: 
727:             # Fetch email for each memberUid
728:             for uid in member_uids:
729:                 try:
730:                     search_filter = self.settings.ldap_user_search_filter.format(uid)
731:                     conn.search(
732:                         search_base=self._get_user_search_base(),
733:                         search_filter=search_filter,
734:                         attributes=["mail"],
735:                     )
736:                     if conn.entries and hasattr(conn.entries[0], "mail"):
737:                         mail = conn.entries[0].mail.value
738:                         if mail:
739:                             emails.append(mail)
740:                 except Exception as e:
741:                     logger.debug(f"Could not fetch email for uid {uid}: {e}")
742: 
743:             conn.unbind()
744: 
745:             # Remove duplicates while preserving order
746:             seen = set()
747:             unique_emails = []
748:             for email in emails:
749:                 if email not in seen:
750:                     seen.add(email)
751:                     unique_emails.append(email)
752: 
753:             logger.info(f"Found {len(unique_emails)} admin email addresses")
754:             return unique_emails
755: 
756:         except LDAPException as e:
757:             logger.error(f"LDAP error getting admin emails: {e}")
758:             return []
759:         except Exception as e:
760:             logger.error(f"Unexpected error getting admin emails: {e}")
761:             return []
762: 
763:     def get_group_members(self, group_dn: str) -> list[str]:
764:         """
765:         Get all members of a group.
766: 
767:         Args:
768:             group_dn: The DN of the group
769: 
770:         Returns:
771:             List of member usernames
772:         """
773:         members = []
774:         try:
775:             conn = self._get_admin_connection()
776: 
777:             conn.search(
778:                 search_base=group_dn,
779:                 search_filter="(objectClass=*)",
780:                 attributes=["member", "memberUid", "uniqueMember"],
781:             )
782: 
783:             if not conn.entries:
784:                 conn.unbind()
785:                 return []
786: 
787:             entry = conn.entries[0]
788: 
789: 
790:             if hasattr(entry, "memberUid") and entry.memberUid.values:
791:                 members.extend(entry.memberUid.values)
792: 
793: 
794:             if hasattr(entry, "member") and entry.member.values:
795:                 for member_dn in entry.member.values:
796: 
797:                     if member_dn.lower().startswith("uid="):
798:                         parts = member_dn.split(",")
799:                         if parts:
800:                             uid = parts[0].split("=")[1] if "=" in parts[0] else ""
801:                             if uid:
802:                                 members.append(uid)
803: 
804:             if hasattr(entry, "uniqueMember") and entry.uniqueMember.values:
805:                 for member_dn in entry.uniqueMember.values:
806:                     if member_dn.lower().startswith("uid="):
807:                         parts = member_dn.split(",")
808:                         if parts:
809:                             uid = parts[0].split("=")[1] if "=" in parts[0] else ""
810:                             if uid:
811:                                 members.append(uid)
812: 
813:             conn.unbind()
814: 
815:             # Remove duplicates
816:             return list(set(members))
817: 
818:         except LDAPException as e:
819:             logger.error(f"LDAP error getting group members for {group_dn}: {e}")
820:             return []
821:         except Exception as e:
822:             logger.error(f"Unexpected error getting group members for {group_dn}: {e}")
823:             return []
````

## File: application/backend/src/app/sms/client.py
````python
  1: import logging
  2: import random
  3: import re
  4: import string
  5: from typing import Optional
  6: import hashlib
  7: 
  8: import boto3
  9: from botocore.exceptions import BotoCoreError, ClientError
 10: 
 11: from app.config import Settings, get_settings
 12: 
 13: logger = logging.getLogger(__name__)
 14: 
 15: 
 16: class SMSClient:
 17: 
 18: 
 19: 
 20:     E164_PATTERN = re.compile(r"^\+[1-9]\d{1,14}$")
 21: 
 22:     def __init__(self, settings: Optional[Settings] = None):
 23:         """Initialize SMS client with settings."""
 24:         self.settings = settings or get_settings()
 25:         self._sns_client = None
 26: 
 27:     @property
 28:     def sns_client(self):
 29:         """Get or create SNS client."""
 30:         if self._sns_client is None:
 31:             self._sns_client = boto3.client(
 32:                 "sns",
 33:                 region_name=self.settings.aws_region,
 34:             )
 35:         return self._sns_client
 36: 
 37:     def validate_phone_number(self, phone_number: str) -> tuple[bool, str]:
 38: 
 39: 
 40: 
 41: 
 42: 
 43: 
 44: 
 45: 
 46: 
 47:         if not phone_number:
 48:             return False, "Phone number is required"
 49: 
 50: 
 51:         if not self.E164_PATTERN.match(phone_number):
 52:             return False, (
 53:                 "Invalid phone number format. "
 54:                 "Use E.164 format: +[country code][number] (e.g., +14155552671)"
 55:             )
 56: 
 57:         return True, ""
 58: 
 59:     def generate_verification_code(self, length: int = 6) -> str:
 60:         """
 61:         Generate a random numeric verification code.
 62: 
 63:         Args:
 64:             length: Length of the code (default: 6)
 65: 
 66:         Returns:
 67:             Verification code string
 68:         """
 69:         return "".join(random.choices(string.digits, k=length))
 70: 
 71:     def send_verification_code(
 72:         self,
 73:         phone_number: str,
 74:         code: str,
 75:         sender_id: Optional[str] = None,
 76:     ) -> tuple[bool, str, Optional[str]]:
 77:         """
 78:         Send a verification code via SMS.
 79: 
 80:         Args:
 81:             phone_number: Recipient phone number (E.164 format)
 82:             code: Verification code to send
 83:             sender_id: Optional sender ID override
 84: 
 85:         Returns:
 86:             Tuple of (success, message, message_id)
 87:         """
 88:         # Validate phone number
 89:         is_valid, error = self.validate_phone_number(phone_number)
 90:         if not is_valid:
 91:             return False, error, None
 92: 
 93:         # Format message
 94:         message = self.settings.sms_message_template.format(code=code)
 95: 
 96:         try:
 97:             # Set message attributes
 98:             message_attributes = {
 99:                 "AWS.SNS.SMS.SMSType": {
100:                     "DataType": "String",
101:                     "StringValue": self.settings.sms_type,
102:                 }
103:             }
104: 
105: 
106:             effective_sender_id = sender_id or self.settings.sms_sender_id
107:             if effective_sender_id:
108:                 message_attributes["AWS.SNS.SMS.SenderID"] = {
109:                     "DataType": "String",
110:                     "StringValue": effective_sender_id,
111:                 }
112: 
113: 
114:             response = self.sns_client.publish(
115:                 PhoneNumber=phone_number,
116:                 Message=message,
117:                 MessageAttributes=message_attributes,
118:             )
119: 
120:             message_id = response.get("MessageId")
121:             logger.info(
122:                 f"SMS sent successfully. MessageId: {message_id}"
123:             )
124: 
125:             return True, "Verification code sent", message_id
126: 
127:         except ClientError as e:
128:             error_code = e.response.get("Error", {}).get("Code", "Unknown")
129:             error_message = e.response.get("Error", {}).get("Message", str(e))
130:             logger.error(f"SNS ClientError sending SMS: {error_code} - {error_message}")
131: 
132:             # Handle specific error codes
133:             if error_code == "InvalidParameter":
134:                 return False, "Invalid phone number", None
135:             elif error_code == "OptedOut":
136:                 return False, "Phone number has opted out of SMS", None
137:             elif error_code == "InternalError":
138:                 return False, "SMS service temporarily unavailable", None
139:             else:
140:                 return False, f"Failed to send SMS: {error_message}", None
141: 
142:         except BotoCoreError as e:
143:             logger.error(f"BotoCoreError sending SMS: {e}")
144:             return False, "SMS service error", None
145: 
146:         except Exception as e:
147:             logger.error(f"Unexpected error sending SMS: {e}")
148:             return False, "Failed to send verification code", None
149: 
150:     def subscribe_phone_number(
151:         self,
152:         phone_number: str,
153:         topic_arn: Optional[str] = None,
154:     ) -> tuple[bool, str, Optional[str]]:
155: 
156: 
157: 
158: 
159: 
160: 
161: 
162: 
163: 
164: 
165: 
166:         is_valid, error = self.validate_phone_number(phone_number)
167:         if not is_valid:
168:             return False, error, None
169: 
170:         effective_topic_arn = topic_arn or self.settings.sns_topic_arn
171:         if not effective_topic_arn:
172:             return False, "SNS topic not configured", None
173: 
174:         try:
175:             response = self.sns_client.subscribe(
176:                 TopicArn=effective_topic_arn,
177:                 Protocol="sms",
178:                 Endpoint=phone_number,
179:                 ReturnSubscriptionArn=True,
180:             )
181: 
182:             subscription_arn = response.get("SubscriptionArn")
183:             logger.info(f"Phone number subscribed with ARN: {subscription_arn}")
184: 
185:             return True, "Phone number subscribed successfully", subscription_arn
186: 
187:         except ClientError as e:
188:             error_code = e.response.get("Error", {}).get("Code", "Unknown")
189:             error_message = e.response.get("Error", {}).get("Message", str(e))
190:             logger.error(f"SNS subscribe error: {error_code} - {error_message}")
191:             return False, f"Failed to subscribe: {error_message}", None
192: 
193:         except Exception as e:
194:             logger.error(f"Unexpected error subscribing phone: {e}")
195:             return False, "Failed to subscribe phone number", None
196: 
197:     def unsubscribe(self, subscription_arn: str) -> tuple[bool, str]:
198: 
199: 
200: 
201: 
202: 
203: 
204: 
205: 
206: 
207:         try:
208:             self.sns_client.unsubscribe(SubscriptionArn=subscription_arn)
209:             logger.info(f"Unsubscribed: {subscription_arn}")
210:             return True, "Unsubscribed successfully"
211: 
212:         except ClientError as e:
213:             error_message = e.response.get("Error", {}).get("Message", str(e))
214:             logger.error(f"SNS unsubscribe error: {error_message}")
215:             return False, f"Failed to unsubscribe: {error_message}"
216: 
217:         except Exception as e:
218:             logger.error(f"Unexpected error unsubscribing: {e}")
219:             return False, "Failed to unsubscribe"
220: 
221:     def check_opt_out_status(self, phone_number: str) -> tuple[bool, bool]:
222: 
223: 
224: 
225: 
226: 
227: 
228: 
229: 
230: 
231:         try:
232:             response = self.sns_client.check_if_phone_number_is_opted_out(
233:                 phoneNumber=phone_number
234:             )
235:             return True, response.get("isOptedOut", False)
236: 
237:         except Exception as e:
238:             logger.error(f"Error checking opt-out status: {e}")
239:             return False, False
240: 
241:     def opt_in_phone_number(self, phone_number: str) -> tuple[bool, str]:
242:         """
243:         Opt in a phone number that was previously opted out.
244: 
245:         Args:
246:             phone_number: Phone number to opt in
247: 
248:         Returns:
249:             Tuple of (success, message)
250:         """
251:         try:
252:             self.sns_client.opt_in_phone_number(phoneNumber=phone_number)
253:             phone_hash = hashlib.sha256(phone_number.encode("utf-8")).hexdigest()[:8]
254:             logger.info(f"Phone number opted in (hash={phone_hash})")
255:             return True, "Phone number opted in successfully"
256: 
257:         except ClientError as e:
258:             error_message = e.response.get("Error", {}).get("Message", str(e))
259:             logger.error(f"SNS opt-in error: {error_message}")
260:             return False, f"Failed to opt in: {error_message}"
261: 
262:         except Exception as e:
263:             logger.error(f"Unexpected error opting in phone: {e}")
264:             return False, "Failed to opt in phone number"
````

## File: application/modules/cert-manager/main.tf
````hcl
  1: # cert-manager for automated TLS certificate management
  2: # This creates self-signed certificates for OpenLDAP internal TLS
  3: 
  4: # Install cert-manager via Helm
  5: resource "helm_release" "cert_manager" {
  6:   name             = "cert-manager"
  7:   repository       = "https://charts.jetstack.io"
  8:   chart            = "cert-manager"
  9:   version          = "v1.13.2"
 10:   namespace        = "cert-manager"
 11:   create_namespace = true
 12: 
 13:   set {
 14:     name  = "installCRDs"
 15:     value = "true"
 16:   }
 17: 
 18:   set {
 19:     name  = "webhook.timeoutSeconds"
 20:     value = "30"
 21:   }
 22: 
 23:   set {
 24:     name  = "prometheus.enabled"
 25:     value = "false"
 26:   }
 27: 
 28:   atomic          = true
 29:   cleanup_on_fail = true
 30:   recreate_pods   = true
 31:   force_update    = true
 32:   # Wait for cert-manager to be ready before proceeding
 33:   wait            = true
 34:   wait_for_jobs   = true
 35:   upgrade_install = true
 36: }
 37: 
 38: # Wait for cert-manager webhook to be fully ready before creating certificates
 39: # This ensures the webhook can validate certificate resources
 40: resource "time_sleep" "wait_for_cert_manager_webhook" {
 41:   depends_on      = [helm_release.cert_manager]
 42:   create_duration = "30s"
 43: }
 44: 
 45: # Create a self-signed ClusterIssuer
 46: resource "kubernetes_manifest" "selfsigned_issuer" {
 47:   depends_on = [time_sleep.wait_for_cert_manager_webhook]
 48: 
 49:   manifest = {
 50:     apiVersion = "cert-manager.io/v1"
 51:     kind       = "ClusterIssuer"
 52:     metadata = {
 53:       name = "selfsigned-issuer"
 54:     }
 55:     spec = {
 56:       selfSigned = {}
 57:     }
 58:   }
 59: 
 60:   wait {
 61:     fields = {
 62:       "status.conditions[?(@.type=='Ready')].status" = "True"
 63:     }
 64:   }
 65: }
 66: 
 67: # Create Certificate Authority (CA) certificate
 68: resource "kubernetes_manifest" "openldap_ca" {
 69:   depends_on = [kubernetes_manifest.selfsigned_issuer]
 70: 
 71:   manifest = {
 72:     apiVersion = "cert-manager.io/v1"
 73:     kind       = "Certificate"
 74:     metadata = {
 75:       name      = "openldap-ca"
 76:       namespace = var.namespace
 77:     }
 78:     spec = {
 79:       secretName  = "openldap-ca-secret"
 80:       duration    = "87600h" # 10 years
 81:       renewBefore = "720h"   # 30 days
 82:       isCA        = true
 83:       commonName  = "OpenLDAP CA"
 84:       privateKey = {
 85:         algorithm = "RSA"
 86:         size      = 2048
 87:       }
 88:       issuerRef = {
 89:         name = "selfsigned-issuer"
 90:         kind = "ClusterIssuer"
 91:       }
 92:     }
 93:   }
 94: 
 95:   wait {
 96:     fields = {
 97:       "status.conditions[?(@.type=='Ready')].status" = "True"
 98:     }
 99:   }
100: }
101: 
102: # Create Issuer based on the CA certificate
103: resource "kubernetes_manifest" "openldap_ca_issuer" {
104:   depends_on = [kubernetes_manifest.openldap_ca]
105: 
106:   manifest = {
107:     apiVersion = "cert-manager.io/v1"
108:     kind       = "Issuer"
109:     metadata = {
110:       name      = "openldap-ca-issuer"
111:       namespace = var.namespace
112:     }
113:     spec = {
114:       ca = {
115:         secretName = "openldap-ca-secret"
116:       }
117:     }
118:   }
119: 
120:   wait {
121:     fields = {
122:       "status.conditions[?(@.type=='Ready')].status" = "True"
123:     }
124:   }
125: }
126: 
127: # Create TLS certificate for OpenLDAP
128: resource "kubernetes_manifest" "openldap_tls" {
129:   depends_on = [kubernetes_manifest.openldap_ca_issuer]
130: 
131:   manifest = {
132:     apiVersion = "cert-manager.io/v1"
133:     kind       = "Certificate"
134:     metadata = {
135:       name      = "openldap-tls"
136:       namespace = var.namespace
137:     }
138:     spec = {
139:       secretName  = "openldap-tls"
140:       duration    = "87600h" # 10 years
141:       renewBefore = "720h"   # 30 days
142:       isCA        = false
143:       privateKey = {
144:         algorithm = "RSA"
145:         size      = 2048
146:       }
147:       dnsNames = [
148:         "openldap-stack-ha",
149:         "openldap-stack-ha.${var.namespace}",
150:         "openldap-stack-ha.${var.namespace}.svc",
151:         "openldap-stack-ha.${var.namespace}.svc.cluster.local",
152:         "openldap-stack-ha-headless",
153:         "openldap-stack-ha-headless.${var.namespace}",
154:         "openldap-stack-ha-headless.${var.namespace}.svc",
155:         "openldap-stack-ha-headless.${var.namespace}.svc.cluster.local",
156:         "openldap-stack-ha-0.openldap-stack-ha-headless.${var.namespace}.svc.cluster.local",
157:         "openldap-stack-ha-1.openldap-stack-ha-headless.${var.namespace}.svc.cluster.local",
158:         "openldap-stack-ha-2.openldap-stack-ha-headless.${var.namespace}.svc.cluster.local",
159:         "*.${var.domain_name}",
160:         var.domain_name
161:       ]
162:       issuerRef = {
163:         name = "openldap-ca-issuer"
164:         kind = "Issuer"
165:       }
166:     }
167:   }
168: 
169:   wait {
170:     fields = {
171:       "status.conditions[?(@.type=='Ready')].status" = "True"
172:     }
173:   }
174: }
````

## File: application/modules/openldap/outputs.tf
````hcl
 1: output "namespace" {
 2:   description = "Kubernetes namespace for OpenLDAP"
 3:   value       = kubernetes_namespace.openldap.metadata[0].name
 4: }
 5: 
 6: output "secret_name" {
 7:   description = "Name of the Kubernetes secret for OpenLDAP passwords"
 8:   value       = kubernetes_secret.openldap_passwords.metadata[0].name
 9: }
10: 
11: output "helm_release_name" {
12:   description = "Name of the Helm release"
13:   value       = helm_release.openldap.name
14: }
15: 
16: output "phpldapadmin_ingress_hostname" {
17:   description = "Hostname from phpLDAPadmin ingress (ALB DNS name)"
18:   value       = try(data.kubernetes_ingress_v1.phpldapadmin.status[0].load_balancer[0].ingress[0].hostname, null)
19: }
20: 
21: output "ltb_passwd_ingress_hostname" {
22:   description = "Hostname from ltb-passwd ingress (ALB DNS name)"
23:   value       = try(data.kubernetes_ingress_v1.ltb_passwd.status[0].load_balancer[0].ingress[0].hostname, null)
24: }
25: 
26: output "alb_dns_name" {
27:   description = "ALB DNS name (from either ingress)"
28:   value = try(
29:     data.kubernetes_ingress_v1.phpldapadmin.status[0].load_balancer[0].ingress[0].hostname,
30:     data.kubernetes_ingress_v1.ltb_passwd.status[0].load_balancer[0].ingress[0].hostname,
31:     ""
32:   )
33: }
34: 
35: 
36: ##################### Network Policies ##########################
37: output "network_policy_name" {
38:   description = "Name of the network policy for secure namespace communication"
39:   value       = var.enable_network_policies ? module.network_policies[0].network_policy_name : null
40: }
41: 
42: output "network_policy_namespace" {
43:   description = "Namespace where the network policy is applied"
44:   value       = var.enable_network_policies ? module.network_policies[0].network_policy_namespace : null
45: }
46: 
47: output "network_policy_uid" {
48:   description = "UID of the network policy resource"
49:   value       = var.enable_network_policies ? module.network_policies[0].network_policy_uid : null
50: }
````

## File: application/modules/openldap/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name prefix for resources"
 13:   type        = string
 14: }
 15: 
 16: variable "app_name" {
 17:   description = "Full application name (computed in parent module as prefix-region-app_name-env)"
 18:   type        = string
 19: }
 20: 
 21: variable "openldap_ldap_domain" {
 22:   description = "OpenLDAP domain (e.g., ldap.talorlik.internal)"
 23:   type        = string
 24: }
 25: 
 26: variable "openldap_admin_password" {
 27:   description = "OpenLDAP admin password. MUST be set via TF_VAR_OPENLDAP_ADMIN_PASSWORD environment variable, .env file, or GitHub Secret. Do NOT set in variables.tfvars."
 28:   type        = string
 29:   sensitive   = true
 30: }
 31: 
 32: variable "openldap_config_password" {
 33:   description = "OpenLDAP config password. MUST be set via TF_VAR_OPENLDAP_CONFIG_PASSWORD environment variable, .env file, or GitHub Secret. Do NOT set in variables.tfvars."
 34:   type        = string
 35:   sensitive   = true
 36: }
 37: 
 38: variable "openldap_secret_name" {
 39:   description = "Name of the Kubernetes secret for OpenLDAP passwords"
 40:   type        = string
 41: }
 42: 
 43: variable "storage_class_name" {
 44:   description = "Name of the Kubernetes StorageClass to use for OpenLDAP PVC"
 45:   type        = string
 46: }
 47: 
 48: variable "namespace" {
 49:   description = "Kubernetes namespace for OpenLDAP"
 50:   type        = string
 51:   default     = "ldap"
 52: }
 53: 
 54: variable "phpldapadmin_host" {
 55:   description = "Hostname for phpLDAPadmin ingress (e.g., phpldapadmin.talorlik.com). Derived from domain_name if not provided."
 56:   type        = string
 57: }
 58: 
 59: variable "ltb_passwd_host" {
 60:   description = "Hostname for ltb-passwd ingress (e.g., passwd.talorlik.com). Derived from domain_name if not provided."
 61:   type        = string
 62: }
 63: 
 64: variable "use_alb" {
 65:   description = "Whether to use ALB for ingress"
 66:   type        = bool
 67:   default     = true
 68: }
 69: 
 70: variable "ingress_class_name" {
 71:   description = "Name of the IngressClass for ALB (from ALB module)"
 72:   type        = string
 73:   default     = null
 74: }
 75: 
 76: variable "alb_load_balancer_name" {
 77:   description = "Custom name for the AWS ALB (appears in AWS console). Must be  32 characters per AWS constraints."
 78:   type        = string
 79: }
 80: 
 81: variable "alb_target_type" {
 82:   description = "ALB target type: ip or instance"
 83:   type        = string
 84:   default     = "ip"
 85:   validation {
 86:     condition     = contains(["ip", "instance"], var.alb_target_type)
 87:     error_message = "ALB target type must be either 'ip' or 'instance'"
 88:   }
 89: }
 90: 
 91: variable "acm_cert_arn" {
 92:   description = "ARN of the ACM certificate for HTTPS"
 93:   type        = string
 94: }
 95: 
 96: variable "alb_ssl_policy" {
 97:   description = "ALB SSL policy for HTTPS listeners"
 98:   type        = string
 99: }
100: 
101: 
102: variable "tags" {
103:   description = "Tags to apply to resources"
104:   type        = map(string)
105:   default     = {}
106: }
107: 
108: variable "helm_chart_version" {
109:   description = "OpenLDAP Helm chart version"
110:   type        = string
111:   default     = "4.0.1"
112: }
113: 
114: variable "helm_chart_repository" {
115:   description = "Helm chart repository URL"
116:   type        = string
117:   default     = "https://jp-gouin.github.io/helm-openldap"
118: }
119: 
120: variable "helm_chart_name" {
121:   description = "Helm chart name"
122:   type        = string
123:   default     = "openldap-stack-ha"
124: }
125: 
126: variable "helm_release_name" {
127:   description = "Helm release name"
128:   type        = string
129:   default     = "openldap-stack-ha"
130: }
131: 
132: variable "values_template_path" {
133:   description = "Path to the OpenLDAP values template file"
134:   type        = string
135:   default     = null
136: }
137: 
138: variable "enable_network_policies" {
139:   description = "Whether to enable network policies for the OpenLDAP namespace"
140:   type        = bool
141:   default     = true
142: }
143: 
144: variable "ecr_registry" {
145:   description = "ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)"
146:   type        = string
147: }
148: 
149: variable "ecr_repository" {
150:   description = "ECR repository name"
151:   type        = string
152: }
153: 
154: variable "openldap_image_tag" {
155:   description = "OpenLDAP image tag in ECR"
156:   type        = string
157:   default     = "openldap-1.5.0"
158: }
````

## File: application/modules/redis/README.md
````markdown
  1: # Redis Module
  2: 
  3: Deploys Redis using the Bitnami Helm chart for SMS OTP code storage in the
  4: LDAP 2FA application.
  5: 
  6: ## Purpose
  7: 
  8: This module replaces the in-memory SMS OTP storage with Redis, providing:
  9: 
 10: - **TTL-based expiration**: Automatic cleanup of expired OTP codes
 11: - **Shared state**: OTP codes accessible from any backend replica
 12: - **Persistence**: Data survives pod restarts via RDB snapshots
 13: - **Horizontal scaling**: Enable multiple backend replicas
 14: - **ECR Image Support**: Uses ECR images instead of Docker Hub
 15: (images mirrored via `mirror-images-to-ecr.sh`)
 16: 
 17: ## Architecture
 18: 
 19: ```text
 20: 
 21:                     Kubernetes Cluster                            
 22:                                                                   
 23:     
 24:                 twofa-backend namespace                         
 25:                                                                 
 26:                                 
 27:        Backend                Backend                       
 28:        Pod 1                  Pod 2                         
 29:                                                             
 30:       redis-py               redis-py                       
 31:                                 
 32:                                                               
 33:     
 34:                                                                 
 35:                  SETEX/GET/DEL                                  
 36:                  (with TTL)                                     
 37:                                         
 38:                                                                  
 39:                                                                  
 40:     
 41:                      redis namespace                            
 42:                                                                 
 43:             
 44:                    Redis Standalone                           
 45:                                                               
 46:                     
 47:          Redis Master     PersistentVolume            
 48:          (Port 6379)          (RDB Snapshots)             
 49:                     
 50:                                                               
 51:             
 52:                                                                 
 53:     
 54:                                                                   
 55: 
 56: ```
 57: 
 58: ## Usage
 59: 
 60: ```hcl
 61: module "redis" {
 62:   source = "./modules/redis"
 63: 
 64:   count = var.enable_redis ? 1 : 0
 65: 
 66:   env    = var.env
 67:   region = var.region
 68:   prefix = var.prefix
 69: 
 70:   enable_redis       = var.enable_redis
 71:   namespace          = "redis"
 72:   redis_password     = var.redis_password
 73:   storage_class_name = local.storage_class_name
 74:   storage_size       = var.redis_storage_size
 75: 
 76:   # ECR image configuration
 77:   ecr_registry   = local.ecr_registry
 78:   ecr_repository = local.ecr_repository
 79:   image_tag      = "redis-latest"  # Default, or use specific version
 80: }
 81: ```
 82: 
 83: ## ECR Image Configuration
 84: 
 85: This module uses ECR images instead of Docker Hub to eliminate Docker Hub rate
 86: limiting and external dependencies. Images are automatically mirrored from Docker
 87: Hub to ECR by the `mirror-images-to-ecr.sh` script before Terraform operations.
 88: 
 89: **Image Details:**
 90: 
 91: - **Source Image**: `bitnami/redis:latest` (from Docker Hub, or specific version like `bitnami/redis:8.4.0-debian-12-r6`)
 92: - **ECR Tag**: `redis-latest` (default, or specific version like `redis-8.4.0`)
 93: - **ECR Registry/Repository**: Computed from `backend_infra` Terraform state
 94:   (`ecr_url`)
 95: 
 96: **Image Mirroring:**
 97: 
 98: The `mirror-images-to-ecr.sh` script automatically:
 99: 
100: 1. Checks if the image exists in ECR (skips if already present)
101: 2. Pulls the image from Docker Hub
102: 3. Tags and pushes the image to ECR with the standardized tag
103: 4. Cleans up local images after pushing
104: 
105: **Configuration:**
106: 
107: The ECR registry and repository are automatically computed from the `backend_infra`
108: Terraform state in the parent module (`application/main.tf`). You only need to
109: specify the `image_tag` if you want to use a different tag than the default.
110: 
111: For more information about image mirroring, see the [Application Infrastructure
112: README](../README.md#ecr-image-mirroring-automatic).
113: 
114: ## Requirements
115: 
116: | Name | Version |
117: | ------ | --------- |
118: | terraform | >= 1.0 |
119: | kubernetes | >= 2.0 |
120: | helm | >= 2.0 |
121: 
122: ## Inputs
123: 
124: | Name | Description | Type | Default | Required |
125: | ------ | ------------- | ------ | --------- | :--------: |
126: | env | Deployment environment | `string` | n/a | yes |
127: | region | Deployment region | `string` | n/a | yes |
128: | prefix | Name prefix for resources | `string` | n/a | yes |
129: | enable_redis | Enable Redis deployment | `bool` | `false` | no |
130: | namespace | Kubernetes namespace | `string` | `"redis"` | no |
131: | secret_name | Name of K8s secret for password | `string` | `"redis-secret"` | no |
132: | redis_password | Redis password (min 8 chars) | `string` | n/a | yes |
133: | chart_version | Bitnami chart version | `string` | `"24.0.9"` | no |
134: | storage_class_name | Storage class for PVC | `string` | `""` | no |
135: | storage_size | Storage size for PVC | `string` | `"1Gi"` | no |
136: | persistence_enabled | Enable data persistence | `bool` | `true` | no |
137: | resources | CPU/memory limits/requests | `object` | See variables.tf | no |
138: | metrics_enabled | Enable Prometheus metrics | `bool` | `false` | no |
139: | ecr_registry | ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com) | `string` | n/a | yes |
140: | ecr_repository | ECR repository name | `string` | n/a | yes |
141: | image_tag | Redis image tag in ECR | `string` | `"redis-latest"` | no |
142: | backend_namespace | Namespace where backend pods are deployed (for network policy) | `string` | `"twofa-backend"` | no |
143: 
144: ## Outputs
145: 
146: | Name | Description |
147: | ------ | ------------- |
148: | redis_enabled | Whether Redis is enabled |
149: | redis_host | Redis service hostname |
150: | redis_port | Redis service port |
151: | redis_namespace | Namespace where Redis is deployed |
152: | redis_password_secret_name | Name of password secret |
153: | redis_password_secret_key | Key in secret for password |
154: | redis_connection_url | Connection URL (without password) |
155: 
156: ## Security
157: 
158: - **Authentication**: Password authentication required (`auth.enabled=true`)
159: - **Secret Management**: Password from GitHub Secrets via `TF_VAR_redis_password`
160: - **Network**: ClusterIP service (not exposed externally)
161: - **Container Security**: Runs as non-root user (UID 1001)
162: - **Network Policy**: Should be combined with network policies to restrict access
163: 
164: ## Redis Key Schema
165: 
166: | Key Pattern | Value | TTL | Description |
167: | ------------- | ------- | ----- | ------------- |
168: | `sms_otp:{username}` | JSON data | 300s | SMS verification code |
169: 
170: Example value:
171: 
172: ```json
173: {
174:   "code": "123456",
175:   "phone_number": "+1234567890"
176: }
177: ```
178: 
179: ## Debugging
180: 
181: ```bash
182: # Connect to Redis CLI
183: kubectl exec -it -n redis redis-master-0 -- redis-cli -a $REDIS_PASSWORD
184: 
185: # View all OTP keys
186: KEYS sms_otp:*
187: 
188: # Get specific OTP data
189: GET sms_otp:username
190: 
191: # Check TTL remaining
192: TTL sms_otp:username
193: 
194: # Monitor real-time commands
195: MONITOR
196: ```
197: 
198: ## Related Files
199: 
200: - `application/backend/src/app/redis/client.py` - Python Redis client
201: - `application/backend/helm/ldap-2fa-backend/values.yaml` - Redis config values
202: - `application/modules/network-policies/main.tf` - Network policies
````

## File: application/CROSS-ACCOUNT-ACCESS.md
````markdown
   1: # Cross-Account Access Configuration
   2: 
   3: This document describes the cross-account access requirements between the
   4: **State Account** (where Route53 hosted zone resides) and the
   5: **Deployment Account** (where EKS cluster, ALB, ACM certificates, and application
   6: resources are deployed).
   7: 
   8: ## Overview
   9: 
  10: The application infrastructure requires access to Route53 hosted zones from the
  11: State Account, while deploying resources in the Deployment Account
  12: (development or production).
  13: 
  14: ### Certificate Architecture
  15: 
  16: The certificate architecture uses **Public ACM certificates** with DNS validation:
  17: 
  18: 1. **Public ACM Certificates**: Public ACM certificates are requested in each
  19: deployment account (development, production)
  20: 2. **DNS Validation**: DNS validation records are created in Route53 hosted zone
  21: in the State Account
  22: 3. **Certificate Storage**: Each certificate is stored in its respective deployment
  23: account (not in the State Account)
  24: 4. **No Cross-Account Access**: Since each deployment account has its own certificate,
  25: there's no need for cross-account certificate access
  26: 5. **EKS Auto Mode Compatibility**: This architecture satisfies EKS Auto Mode ALB
  27: controller requirements (certificate must be in the same account as the ALB)
  28: 6. **Browser Trust**: Public ACM certificates are trusted by browsers without warnings
  29: 
  30: **Benefits:**
  31: 
  32: -  Eliminates cross-account certificate access complexity
  33: -  Each account manages its own certificate lifecycle
  34: -  Browser-trusted certificates (no security warnings)
  35: -  Automatic renewal via ACM
  36: -  Free certificates (no cost)
  37: -  No additional provider configuration or credentials needed for certificates
  38: -  Compatible with EKS Auto Mode ALB controller limitations
  39: 
  40: ## Public ACM Certificate Setup and DNS Validation
  41: 
  42: This section provides step-by-step AWS CLI commands to request public ACM certificates
  43: in each deployment account and validate them using DNS records in the State Account's Route53 hosted zone.
  44: 
  45: ### Prerequisites
  46: 
  47: - AWS CLI configured with SSO profiles for State Account and Deployment Accounts
  48: - Access to State Account (Route53 hosted zone)
  49: - Access to Deployment Accounts (production, development)
  50: - `jq` installed for JSON parsing (optional, for advanced parsing)
  51: 
  52: **AWS SSO Profiles:**
  53: - `default` - State Account
  54: - `dev` - Development Deployment Account
  55: - `prod` - Production Deployment Account
  56: 
  57: ### Step 1: Request Public ACM Certificate (Production)
  58: 
  59: Request a public ACM certificate in the production deployment account:
  60: 
  61: ```bash
  62: # Request public certificate with DNS validation
  63: PROD_CERT_ARN=$(aws --profile prod acm request-certificate \
  64:   --domain-name "talorlik.com" \
  65:   --subject-alternative-names "*.talorlik.com" \
  66:   --validation-method DNS \
  67:   --region us-east-1 \
  68:   --tags Key=Name,Value=PublicCertProd Key=Env,Value=prod Key=Purpose,Value=ALB Key=Type,Value=Public \
  69:   --query 'CertificateArn' \
  70:   --output text)
  71: 
  72: echo "Production Certificate ARN: $PROD_CERT_ARN"
  73: ```
  74: 
  75: **Save this ARN** - you'll need it for subsequent steps.
  76: 
  77: ### Step 2: Get DNS Validation Records (Production)
  78: 
  79: Wait a few seconds for AWS to generate validation records, then retrieve them:
  80: 
  81: ```bash
  82: # Wait for AWS to generate validation records
  83: sleep 5
  84: 
  85: # Get validation records
  86: aws --profile prod acm describe-certificate \
  87:   --certificate-arn $PROD_CERT_ARN \
  88:   --region us-east-1 \
  89:   --query 'Certificate.DomainValidationOptions[*].[DomainName,ResourceRecord.Name,ResourceRecord.Type,ResourceRecord.Value]' \
  90:   --output table
  91: ```
  92: 
  93: **Expected Output:**
  94: ```
  95: ----------------------------------------------------------------------------------
  96: ||                          DescribeCertificate                                   |
  97: +------------------+--------------------------------------------+-------+----------+
  98: ||  talorlik.com    |  _xxx.talorlik.com.                       | CNAME |  _yyy... |
  99: ||  *.talorlik.com  |  _xxx.talorlik.com.                       | CNAME |  _yyy... |
 100: +------------------+--------------------------------------------+-------+----------+
 101: ```
 102: 
 103: **Note:** Both domains will use the same CNAME record.
 104: 
 105: ### Step 3: Extract Validation Record Details
 106: 
 107: Extract the validation record name and value:
 108: 
 109: ```bash
 110: # Extract validation record details
 111: VALIDATION_NAME=$(aws --profile prod acm describe-certificate \
 112:   --certificate-arn $PROD_CERT_ARN \
 113:   --region us-east-1 \
 114:   --query 'Certificate.DomainValidationOptions[0].ResourceRecord.Name' \
 115:   --output text)
 116: 
 117: VALIDATION_VALUE=$(aws --profile prod acm describe-certificate \
 118:   --certificate-arn $PROD_CERT_ARN \
 119:   --region us-east-1 \
 120:   --query 'Certificate.DomainValidationOptions[0].ResourceRecord.Value' \
 121:   --output text)
 122: 
 123: echo "Validation Name: $VALIDATION_NAME"
 124: echo "Validation Value: $VALIDATION_VALUE"
 125: ```
 126: 
 127: ### Step 4: Get Route53 Hosted Zone ID (State Account)
 128: 
 129: Get the hosted zone ID for your domain in the State Account:
 130: 
 131: ```bash
 132: # Get hosted zone ID for talorlik.com
 133: ZONE_ID=$(aws --profile default route53 list-hosted-zones-by-name \
 134:   --dns-name talorlik.com \
 135:   --query 'HostedZones[0].Id' \
 136:   --output text | cut -d'/' -f3)
 137: 
 138: echo "Hosted Zone ID: $ZONE_ID"
 139: ```
 140: 
 141: ### Step 5: Create DNS Validation Record in Route53 (State Account)
 142: 
 143: Create the DNS validation record in the State Account's Route53 hosted zone:
 144: 
 145: ```bash
 146: # Create change batch JSON
 147: cat > /tmp/prod-validation-record.json << EOF
 148: {
 149:   "Changes": [
 150:     {
 151:       "Action": "UPSERT",
 152:       "ResourceRecordSet": {
 153:         "Name": "$VALIDATION_NAME",
 154:         "Type": "CNAME",
 155:         "TTL": 300,
 156:         "ResourceRecords": [
 157:           {
 158:             "Value": "$VALIDATION_VALUE"
 159:           }
 160:         ]
 161:       }
 162:     }
 163:   ]
 164: }
 165: EOF
 166: 
 167: # Create the record in Route53 (State Account)
 168: aws --profile default route53 change-resource-record-sets \
 169:   --hosted-zone-id $ZONE_ID \
 170:   --change-batch file:///tmp/prod-validation-record.json
 171: 
 172: echo "DNS validation record created in Route53"
 173: ```
 174: 
 175: ### Step 6: Wait for Certificate Validation (Production)
 176: 
 177: Wait for the certificate to be validated:
 178: 
 179: ```bash
 180: # Check certificate status (should change from PENDING_VALIDATION to ISSUED)
 181: echo "Waiting for certificate validation..."
 182: aws --profile prod acm wait certificate-validated \
 183:   --certificate-arn $PROD_CERT_ARN \
 184:   --region us-east-1
 185: 
 186: echo "Certificate validated successfully!"
 187: 
 188: # Verify status
 189: aws --profile prod acm describe-certificate \
 190:   --certificate-arn $PROD_CERT_ARN \
 191:   --region us-east-1 \
 192:   --query 'Certificate.[Status,Type,Issuer]' \
 193:   --output table
 194: ```
 195: 
 196: **Expected Output:**
 197: ```
 198: ------------------------------------------
 199: ||       DescribeCertificate             |
 200: +----------+--------+--------------------+
 201: ||  ISSUED  | AMAZON | Amazon RSA 2048... |
 202: +----------+--------+--------------------+
 203: ```
 204: 
 205: ### Step 7: Request Public Certificate (Development) - Optional
 206: 
 207: If you want to set up the development environment as well:
 208: 
 209: ```bash
 210: # Request public certificate for dev
 211: DEV_CERT_ARN=$(aws --profile dev acm request-certificate \
 212:   --domain-name "talorlik.com" \
 213:   --subject-alternative-names "*.talorlik.com" \
 214:   --validation-method DNS \
 215:   --region us-east-1 \
 216:   --tags Key=Name,Value=PublicCertDev Key=Env,Value=dev Key=Purpose,Value=ALB Key=Type,Value=Public \
 217:   --query 'CertificateArn' \
 218:   --output text)
 219: 
 220: echo "Development Certificate ARN: $DEV_CERT_ARN"
 221: 
 222: # Wait for validation records
 223: sleep 5
 224: 
 225: # Get validation records
 226: aws --profile dev acm describe-certificate \
 227:   --certificate-arn $DEV_CERT_ARN \
 228:   --region us-east-1 \
 229:   --query 'Certificate.DomainValidationOptions[*].[DomainName,ResourceRecord.Name,ResourceRecord.Type,ResourceRecord.Value]' \
 230:   --output table
 231: 
 232: # Note: If validation record already exists from production setup, dev certificate will validate automatically
 233: # Otherwise, repeat Steps 3-6 for development certificate
 234: ```
 235: 
 236: ### Step 8: Verify Certificates
 237: 
 238: Verify that certificates are issued and ready:
 239: 
 240: ```bash
 241: # List production certificates
 242: aws --profile prod acm list-certificates --region us-east-1 \
 243:   --query 'CertificateSummaryList[?Type==`AMAZON_ISSUED`]' --output table
 244: 
 245: # List development certificates (if applicable)
 246: aws --profile dev acm list-certificates --region us-east-1 \
 247:   --query 'CertificateSummaryList[?Type==`AMAZON_ISSUED`]' --output table
 248: ```
 249: 
 250: ### Important Notes
 251: 
 252: - **Replace Placeholders**: Replace all placeholders in the commands:
 253:   - `talorlik.com`: Your actual domain name
 254:   - Profile names (`prod`, `dev`, `default`) should match your SSO profile names
 255: 
 256: - **Region Consistency**: Ensure all commands use the same region (e.g., `us-east-1`)
 257: 
 258: - **Certificate Validation**: Certificates will be automatically validated once DNS validation records are created in Route53
 259: 
 260: - **Certificate Status**: Wait for certificates to reach `ISSUED` status before using them with ALB
 261: 
 262: - **DNS Propagation**: DNS validation may take a few minutes to propagate
 263: 
 264: - **Reuse Validation Records**: If multiple certificates use the same domain, they may share the same validation record
 265: 
 266: ## Cross-Account Access Requirements
 267: 
 268: ### 1. Route53 Hosted Zone Access
 269: 
 270: **State Account  Deployment Account:**
 271: 
 272: - Route53 hosted zone is queried from State Account using `data.aws_route53_zone`
 273: - Route53 records are created in State Account using `aws_route53_record` resources
 274: - All Route53 operations use the `aws.state_account` provider alias
 275: 
 276: **Required Permissions (State Account Role):**
 277: 
 278: ```json
 279: {
 280:   "Version": "2012-10-17",
 281:   "Statement": [
 282:     {
 283:       "Effect": "Allow",
 284:       "Action": [
 285:         "route53:GetHostedZone",
 286:         "route53:ListHostedZones",
 287:         "route53:ChangeResourceRecordSets",
 288:         "route53:GetChange"
 289:       ],
 290:       "Resource": "*"
 291:     }
 292:   ]
 293: }
 294: ```
 295: 
 296: ### 2. ACM Certificate Access
 297: 
 298: > [!IMPORTANT]
 299: >
 300: > **EKS Auto Mode ALB Controller Limitation**
 301: >
 302: > **EKS Auto Mode ALB controller CANNOT access cross-account ACM certificates.**
 303: >
 304: > The ACM certificate **MUST** be in the **Deployment Account** (same account where
 305: > the ALB is created), not in the State Account.
 306: 
 307: **Certificate Architecture:**
 308: 
 309: - **Public ACM certificates** are requested in each deployment account (development, production)
 310: - DNS validation records are created in Route53 hosted zone in the State Account
 311: - Each deployment account has its own public ACM certificate
 312: - Certificates are stored in their respective deployment accounts (not in the
 313: State Account)
 314: - This eliminates the need for cross-account certificate access
 315: - Certificates are automatically renewed by ACM
 316: 
 317: **Deployment Account Certificate Requirements:**
 318: 
 319: - ACM certificate is queried from Deployment Account using `data.aws_acm_certificate`
 320: (default provider)
 321: - Certificate ARN is passed to ALB and Ingress resources via IngressClassParams
 322: - Certificate must be in the **same account** as the EKS cluster and ALB
 323: - Certificate must be in the **same region** as the ALB/EKS cluster
 324: - Certificate must be validated and in `ISSUED` status
 325: - Certificate is a **public ACM certificate** (Amazon-issued)
 326: - Certificate domain must match the domain used by your application
 327: 
 328: **Required Permissions (Deployment Account Role):**
 329: 
 330: The deployment account role (or default credentials) must have:
 331: 
 332: ```json
 333: {
 334:   "Version": "2012-10-17",
 335:   "Statement": [
 336:     {
 337:       "Effect": "Allow",
 338:       "Action": [
 339:         "acm:ListCertificates",
 340:         "acm:DescribeCertificate"
 341:       ],
 342:       "Resource": "*"
 343:     }
 344:   ]
 345: }
 346: ```
 347: 
 348: **How It Works:**
 349: 
 350: When an ALB is created in the Deployment Account:
 351: 
 352: 1. Terraform queries ACM certificate from Deployment Account using
 353: `data.aws_acm_certificate` (default provider)
 354: 2. Certificate ARN is passed to IngressClassParams (`certificateARNs` field)
 355: 3. EKS Auto Mode ALB controller validates that the certificate exists in the
 356: same account
 357: 4. The ALB listener automatically uses the certificate for HTTPS/TLS termination
 358: 
 359: **Pre-Deployment Requirements:**
 360: 
 361: Since the certificate must be in the Deployment Account, ensure:
 362: 
 363: -  Public ACM certificate is requested in the **Deployment Account**
 364: -  DNS validation records are created in Route53 hosted zone in the **State Account**
 365: -  Certificate exists in the **Deployment Account** (not State Account)
 366: -  Certificate is in the **same region** as the ALB/EKS cluster
 367: -  Certificate is **validated** and in `ISSUED` status
 368: -  Certificate is a **public ACM certificate** (Amazon-issued)
 369: -  Certificate domain matches the domain used by your application
 370: -  Terraform can query the certificate using `data.aws_acm_certificate` with the
 371: default provider (deployment account)
 372: -  No cross-account certificate access is needed (each account has its own certificate)
 373: 
 374: ### 3. ALB Certificate Usage
 375: 
 376: **Deployment Account ALB  Deployment Account Certificate:**
 377: 
 378: - ALB is created in Deployment Account by EKS Auto Mode
 379: - ALB uses ACM certificate ARN from Deployment Account via IngressClassParams
 380: - Certificate ARN is passed to Kubernetes IngressClassParams resource
 381: - EKS Auto Mode handles ALB creation and certificate attachment automatically
 382: 
 383: **Configuration Flow:**
 384: 
 385: 1. Terraform queries ACM certificate from Deployment Account
 386: (using default `aws` provider, not `aws.state_account`)
 387: 2. Certificate ARN is passed to ALB module
 388: 3. ALB module creates IngressClassParams with `certificateARNs` field
 389: 4. EKS Auto Mode creates ALB and attaches certificate from Deployment Account
 390: 5. ALB listener uses certificate for HTTPS/TLS termination
 391: 
 392: ### 4. Route53 Record Creation
 393: 
 394: **Deployment Account  State Account:**
 395: 
 396: - Route53 A (alias) records are created in State Account
 397: - Records point to ALB DNS name in Deployment Account
 398: - All Route53 record resources use `aws.state_account` provider
 399: 
 400: **Record Types Created:**
 401: 
 402: - `phpldapadmin.<domain>`  ALB DNS name (alias record)
 403: - `passwd.<domain>`  ALB DNS name (alias record)
 404: - `app.<domain>`  ALB DNS name (alias record)
 405: - SES verification records (if domain verification enabled)
 406: - SES DKIM records (if domain verification enabled)
 407: 
 408: ## Provider Configuration
 409: 
 410: ### State Account Provider
 411: 
 412: The `aws.state_account` provider alias is configured in `providers.tf`:
 413: 
 414: ```hcl
 415: provider "aws" {
 416:   alias  = "state_account"
 417:   region = var.region
 418: 
 419:   dynamic "assume_role" {
 420:     for_each = var.state_account_role_arn != null ? [1] : []
 421:     content {
 422:       role_arn = var.state_account_role_arn
 423:       # Note: ExternalId is not used for state account role assumption (by design)
 424:     }
 425:   }
 426: }
 427: ```
 428: 
 429: ### Resources Using State Account Provider
 430: 
 431: **Data Sources:**
 432: 
 433: - `data.aws_route53_zone.this` - Queries hosted zone from State Account
 434: - `data.aws_acm_certificate.this` - Queries public ACM certificate from Deployment Account
 435: 
 436: **Resources:**
 437: 
 438: - `aws_route53_record.twofa_app` - Creates A record in State Account
 439: - `aws_route53_record.phpldapadmin` (in openldap module) - Creates A record in
 440: State Account
 441: - `aws_route53_record.ltb_passwd` (in openldap module) - Creates A record in
 442: State Account
 443: - `aws_route53_record.ses_verification` (in ses module) - Creates TXT record in
 444: State Account
 445: - `aws_route53_record.ses_dkim` (in ses module) - Creates CNAME records in
 446: State Account
 447: 
 448: ## State Account Role Trust Relationship
 449: 
 450: The State Account role must trust the Deployment Account role (or GitHub Actions
 451: OIDC provider):
 452: 
 453: ```json
 454: {
 455:   "Version": "2012-10-17",
 456:   "Statement": [
 457:     {
 458:       "Effect": "Allow",
 459:       "Principal": {
 460:         "AWS": "arn:aws:iam::DEPLOYMENT_ACCOUNT_ID:role/github-role"
 461:       },
 462:       "Action": "sts:AssumeRole",
 463:       "Condition": {
 464:         "StringEquals": {
 465:           "sts:ExternalId": null
 466:         }
 467:       }
 468:     }
 469:   ]
 470: }
 471: ```
 472: 
 473: **Note:** ExternalId is **not required** for State Account role assumption (by design).
 474: 
 475: > [!IMPORTANT]
 476: >
 477: > **Self-Assumption Requirement**: If the State Account role is the same as the
 478: > role being assumed (e.g., when `state_account_role_arn` points to the same role
 479: > in the same account), the trust policy must allow the role to assume itself.
 480: > Add the following statement to the trust policy:
 481: >
 482: > ```json
 483: > {
 484: >   "Effect": "Allow",
 485: >   "Principal": {
 486: >     "AWS": "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
 487: >   },
 488: >   "Action": "sts:AssumeRole"
 489: > }
 490: > ```
 491: >
 492: > This is required when Terraform providers need to assume the same role that was
 493: > already assumed by the initial authentication (e.g., when GitHub Actions assumes
 494: > a role and then Terraform tries to assume the same role again via
 495: > `assume_role` in `providers.tf`).
 496: 
 497: ## Verification Checklist
 498: 
 499: ### Configuration Checklist
 500: 
 501: - [x] Route53 hosted zone data source uses `aws.state_account` provider
 502: - [x] ACM certificate data source uses default provider (deployment account)
 503: - [x] All Route53 record resources use `aws.state_account` provider
 504: - [x] State account role ARN is automatically injected by scripts
 505: - [x] State account role has Route53 permissions
 506: - [x] Public ACM certificates are requested in each deployment account
 507: - [x] DNS validation records are created in Route53 hosted zone in State Account
 508: - [x] Each deployment account has its own public ACM certificate
 509: - [x] ALB can use ACM certificate from Deployment Account (same account and region)
 510: - [x] Route53 records point to ALB in Deployment Account
 511: - [x] Certificate ARN is passed correctly to ALB module
 512: - [x] Certificate ARN is passed correctly to OpenLDAP module
 513: - [x] No cross-account certificate access needed (each account uses its own certificate)
 514: 
 515: ### Post-Setup Verification Checklist
 516: 
 517: After setting up certificates, verify:
 518: 
 519: - [ ] **Production certificate validated and ISSUED**
 520:   ```bash
 521:   aws --profile prod acm list-certificates --region us-east-1 \
 522:     --query 'CertificateSummaryList[?Type==`AMAZON_ISSUED`]' --output table
 523:   ```
 524: 
 525: - [ ] **Development certificate validated and ISSUED** (if applicable)
 526:   ```bash
 527:   aws --profile dev acm list-certificates --region us-east-1 \
 528:     --query 'CertificateSummaryList[?Type==`AMAZON_ISSUED`]' --output table
 529:   ```
 530: 
 531: - [ ] **DNS validation records exist in Route53**
 532:   ```bash
 533:   aws --profile default route53 list-resource-record-sets \
 534:     --hosted-zone-id $ZONE_ID \
 535:     --query "ResourceRecordSets[?Type=='CNAME' && contains(Name, '_')]" --output table
 536:   ```
 537: 
 538: - [ ] **ALB using new public certificate**
 539:   ```bash
 540:   # Get ALB ARN
 541:   ALB_ARN=$(aws --profile prod elbv2 describe-load-balancers \
 542:     --names talo-tf-us-east-1-alb-prod \
 543:     --region us-east-1 \
 544:     --query 'LoadBalancers[0].LoadBalancerArn' \
 545:     --output text)
 546: 
 547:   # Check HTTPS listener certificate
 548:   aws --profile prod elbv2 describe-listeners \
 549:     --load-balancer-arn $ALB_ARN \
 550:     --region us-east-1 \
 551:     --query 'Listeners[?Protocol==`HTTPS`].[Certificates[0].CertificateArn,SslPolicy]' \
 552:     --output table
 553: 
 554:   # Check via curl
 555:   curl -vI https://phpldapadmin.talorlik.com 2>&1 | grep -E "issuer:|subject:"
 556:   # Should show: issuer: Amazon
 557:   ```
 558: 
 559: - [ ] **Browser shows secure connection** (manual check)
 560:   - Visit: https://phpldapadmin.talorlik.com
 561:   - Check: Lock icon shows "Secure"
 562:   - Verify: Certificate details show Amazon as issuer
 563:   - Verify: No security warnings
 564: 
 565: ## Troubleshooting
 566: 
 567: ### Issue: "Empty result" when querying Route53 hosted zone
 568: 
 569: **Solution:** Ensure `state_account_role_arn` is set and the role has
 570: `route53:GetHostedZone` permission.
 571: 
 572: ### Issue: "Empty result" when querying ACM certificate
 573: 
 574: **Solution:**
 575: 
 576: - Ensure deployment account credentials/role have `acm:ListCertificates` and
 577: `acm:DescribeCertificate` permissions
 578: - Verify certificate exists in the deployment account (not state account)
 579: - Certificate should be a public ACM certificate requested in the Deployment Account
 580: - Verify certificate is validated and in `ISSUED` status
 581: 
 582: ### Issue: ALB cannot use certificate (CertificateNotFound)
 583: 
 584: **Root Cause:** EKS Auto Mode ALB controller cannot access cross-account certificates.
 585: The certificate must be in the Deployment Account, not the State Account.
 586: 
 587: **Solution:**
 588: 
 589: 1. **Verify certificate is in Deployment Account:**
 590:    - Certificate MUST be in the same account as the EKS cluster and ALB
 591:    - Check certificate account:
 592:    `aws acm describe-certificate --certificate-arn <ARN> --region <region>`
 593:    - Extract account ID from certificate ARN: `arn:aws:acm:region:ACCOUNT_ID:certificate/...`
 594:    - Verify account ID matches Deployment Account ID (not State Account ID)
 595: 
 596: 2. **Create certificate in Deployment Account if missing:**
 597:    - If certificate doesn't exist in Deployment Account, request a public ACM certificate:
 598: 
 599:      ```bash
 600:      # Request public certificate
 601:      CERT_ARN=$(aws --profile <deployment-profile> acm request-certificate \
 602:        --domain-name <your-domain> \
 603:        --subject-alternative-names "*.<your-domain>" \
 604:        --validation-method DNS \
 605:        --region <region> \
 606:        --query 'CertificateArn' \
 607:        --output text)
 608: 
 609:      # Get validation records
 610:      aws --profile <deployment-profile> acm describe-certificate \
 611:        --certificate-arn $CERT_ARN \
 612:        --region <region> \
 613:        --query 'Certificate.DomainValidationOptions[0].ResourceRecord' \
 614:        --output json
 615:      ```
 616: 
 617:    - Create DNS validation record in Route53 hosted zone in State Account
 618:    - Wait for certificate status to be `ISSUED`
 619:    - Certificate will be stored in the Deployment Account (where the request is made)
 620:    - **See the [Public ACM Certificate Setup and DNS Validation](#public-acm-certificate-setup-and-dns-validation) section above for complete setup instructions**
 621: 
 622: 3. **Update Terraform configuration:**
 623:    - Ensure `data.aws_acm_certificate.this` uses default provider (deployment account),
 624:    not `aws.state_account`
 625:    - Certificate data source should NOT have `provider = aws.state_account`
 626: 
 627: 4. **Verify certificate location:**
 628:    - Certificate must be in the same region as ALB/EKS cluster
 629:    - Check certificate region:
 630:    `aws acm describe-certificate --certificate-arn <ARN> --region <region>`
 631: 
 632: 5. **Verify certificate status:**
 633:    - Certificate must be validated and in `ISSUED` status
 634:    - Check status: `aws acm list-certificates --region <region>`
 635: 
 636: 6. **Verify certificate type:**
 637:    - Certificate is a public ACM certificate (Amazon-issued)
 638:    - Certificate is stored in Deployment Account (no cross-account access needed)
 639:    - Each deployment account has its own public ACM certificate
 640: 
 641: 7. **Verify Terraform can access certificate:**
 642:    - Ensure deployment account credentials/role have `acm:DescribeCertificate` permission
 643:    - Verify data source works: Check Terraform plan output for `data.aws_acm_certificate.this.arn`
 644: 
 645: 8. **Verify certificate ARN is passed correctly:**
 646:    - Check that `data.aws_acm_certificate.this.arn` is not null
 647:    - Verify certificate ARN is passed to ALB module: `acm_certificate_arn = data.aws_acm_certificate.this.arn`
 648:    - Verify IngressClassParams has `certificateARNs` field populated
 649: 
 650: 9. **Check ALB listener configuration:**
 651:    - After ALB is created, verify listener has certificate attached
 652:    - Check ALB in AWS Console or via:
 653:    `aws elbv2 describe-listeners --load-balancer-arn <ALB_ARN>`
 654: 
 655: **Common Errors:**
 656: 
 657: - **"CertificateNotFound: Certificate 'arn:aws:acm:...' not found"**: Certificate
 658: is in wrong account (should be in Deployment Account, not State Account)
 659: - **"Certificate not found"**: Certificate is in wrong region or Terraform can't
 660: access it, or certificate hasn't been issued from Private CA yet
 661: - **"Certificate not validated"**: Certificate is still pending validation
 662: (DNS validation records may not be created yet)
 663: - **"Invalid certificate ARN"**: Certificate ARN format is incorrect or certificate
 664: doesn't exist
 665: - **"Certificate not found"**: Certificate doesn't exist or hasn't been requested yet
 666: 
 667: ### Issue: Route53 records cannot be created
 668: 
 669: **Solution:** Ensure State Account role has `route53:ChangeResourceRecordSets`
 670: permission on the hosted zone.
 671: 
 672: ### Issue: Certificate Not Validating
 673: 
 674: **Check DNS record exists:**
 675: ```bash
 676: aws --profile default route53 list-resource-record-sets \
 677:   --hosted-zone-id $ZONE_ID \
 678:   --query "ResourceRecordSets[?Type=='CNAME' && contains(Name, '_')]" \
 679:   --output json
 680: ```
 681: 
 682: **Check DNS propagation:**
 683: ```bash
 684: # Get validation record name
 685: VALIDATION_NAME=$(aws --profile prod acm describe-certificate \
 686:   --certificate-arn $PROD_CERT_ARN \
 687:   --region us-east-1 \
 688:   --query 'Certificate.DomainValidationOptions[0].ResourceRecord.Name' \
 689:   --output text)
 690: 
 691: # Query DNS
 692: dig $VALIDATION_NAME CNAME +short
 693: ```
 694: 
 695: **Solution:** Ensure DNS validation record exists in Route53 and has propagated (may take a few minutes).
 696: 
 697: ### Issue: ALB Not Using New Certificate
 698: 
 699: **Check current ALB certificate:**
 700: ```bash
 701: # Get ALB ARN
 702: ALB_ARN=$(aws --profile prod elbv2 describe-load-balancers \
 703:   --names talo-tf-us-east-1-alb-prod \
 704:   --region us-east-1 \
 705:   --query 'LoadBalancers[0].LoadBalancerArn' \
 706:   --output text)
 707: 
 708: # Check HTTPS listener certificate
 709: aws --profile prod elbv2 describe-listeners \
 710:   --load-balancer-arn $ALB_ARN \
 711:   --region us-east-1 \
 712:   --query 'Listeners[?Protocol==`HTTPS`].[Certificates[0].CertificateArn,SslPolicy]' \
 713:   --output table
 714: ```
 715: 
 716: **Solution:** Delete and recreate IngressClassParams:
 717: ```bash
 718: kubectl delete ingressclassparams talo-tf-us-east-1-icp-alb-ldap-prod
 719: 
 720: # Re-run Terraform
 721: ./setup-application.sh
 722: ```
 723: 
 724: ### Issue: Certificate in Wrong Account
 725: 
 726: **Verify certificate account from ARN:**
 727: ```bash
 728: # Certificate ARN format: arn:aws:acm:region:ACCOUNT_ID:certificate/...
 729: echo $PROD_CERT_ARN
 730: # Account ID should match your deployment account ID
 731: ```
 732: 
 733: **Solution:** Ensure certificate is requested in the deployment account, not the state account.
 734: 
 735: ### Issue: Cannot Delete Certificate (In Use)
 736: 
 737: **Check what's using the certificate:**
 738: ```bash
 739: aws --profile prod acm describe-certificate \
 740:   --certificate-arn <certificate-arn> \
 741:   --region us-east-1 \
 742:   --query 'Certificate.InUseBy' \
 743:   --output table
 744: ```
 745: 
 746: **Solution:** Update ALB to use new certificate first, then delete old certificate.
 747: 
 748: ## Quick Reference: Environment Variables
 749: 
 750: For scripting convenience, set these environment variables:
 751: 
 752: ```bash
 753: # Set profile aliases
 754: export STATE_PROFILE="default"
 755: export PROD_PROFILE="prod"
 756: export DEV_PROFILE="dev"
 757: 
 758: # Set region
 759: export AWS_REGION="us-east-1"
 760: 
 761: # Certificate ARNs (after creation)
 762: export PROD_CERT_ARN="<production-certificate-arn>"
 763: export DEV_CERT_ARN="<development-certificate-arn>"
 764: 
 765: # Route53 Zone ID
 766: export ZONE_ID="<hosted-zone-id>"
 767: ```
 768: 
 769: Then use in commands:
 770: ```bash
 771: aws --profile $PROD_PROFILE acm describe-certificate \
 772:   --certificate-arn $PROD_CERT_ARN \
 773:   --region $AWS_REGION
 774: ```
 775: 
 776: ## Legacy: Private CA Setup (Deprecated)
 777: 
 778: > [!WARNING]
 779: >
 780: > **This section is deprecated.** The recommended approach is to use public ACM certificates
 781: > with DNS validation as described in the [Public ACM Certificate Setup](#public-acm-certificate-setup-and-dns-validation)
 782: > section above.
 783: 
 784: If you need to set up Private CA certificates (not recommended for public-facing applications),
 785: follow these steps:
 786: 
 787: ### Prerequisites
 788: 
 789: - AWS CLI configured with State Account credentials
 790: - AWS RAM (Resource Access Manager) enabled for your organization
 791: - `ca-config.json` file with CA configuration (see example below)
 792: - Appropriate IAM permissions for ACM-PCA, RAM, and ACM operations
 793: 
 794: ### Step 1: Enable Resource Sharing
 795: 
 796: Enable resource sharing within your organization (run this in the management account):
 797: 
 798: ```bash
 799: aws ram enable-sharing-with-aws-organization --region us-east-1
 800: ```
 801: 
 802: ### Step 2: Create a CA Configuration File
 803: 
 804: Create a `ca-config.json` file using the following command:
 805: 
 806: ```bash
 807: # Create ca-config.json
 808: cat > ca-config.json << 'EOF'
 809: {
 810:     "KeyAlgorithm": "RSA_2048",
 811:     "SigningAlgorithm": "SHA256WITHRSA",
 812:     "Subject": {
 813:         "Country": "US",
 814:         "Organization": "YourOrganization",
 815:         "OrganizationalUnit": "IT",
 816:         "CommonName": "Your Organization Root CA"
 817:     }
 818: }
 819: EOF
 820: ```
 821: 
 822: **Replace placeholders:**
 823: 
 824: - `YourOrganization`: Your organization name
 825: - `IT`: Your organizational unit (e.g., "IT", "Security", "Infrastructure")
 826: - `Your Organization Root CA`: Your CA common name
 827: 
 828: ### Step 3: Create the Root CA
 829: 
 830: Create the root Certificate Authority:
 831: 
 832: ```bash
 833: aws acm-pca create-certificate-authority \
 834:     --certificate-authority-configuration file://ca-config.json \
 835:     --certificate-authority-type "ROOT" \
 836:     --region us-east-1 \
 837:     --tags Key=Name,Value=RootCA Key=Purpose,Value=CentralCA
 838: ```
 839: 
 840: > [!NOTE]
 841: >
 842: > Save the CA ARN from the output - you'll need it for the next steps.
 843: 
 844: ### Step 4: Get Certificate Signing Request (CSR)
 845: 
 846: Retrieve the CSR from the newly created CA:
 847: 
 848: ```bash
 849: # Set the CA ARN from the previous command output
 850: CA_ARN="arn:aws:acm-pca:us-east-1:STATE_ACCOUNT_ID:certificate-authority/CA_ID"
 851: 
 852: # Get CSR
 853: aws acm-pca get-certificate-authority-csr \
 854:     --certificate-authority-arn $CA_ARN \
 855:     --region us-east-1 \
 856:     --output text > ca.csr
 857: ```
 858: 
 859: ### Step 5: Issue the Root Certificate
 860: 
 861: Issue the root certificate using the CSR:
 862: 
 863: ```bash
 864: aws acm-pca issue-certificate \
 865:     --certificate-authority-arn $CA_ARN \
 866:     --csr fileb://ca.csr \
 867:     --signing-algorithm "SHA256WITHRSA" \
 868:     --template-arn "arn:aws:acm-pca:::template/RootCACertificate/V1" \
 869:     --validity Value=10,Type="YEARS" \
 870:     --region us-east-1
 871: ```
 872: 
 873: > [!NOTE]
 874: >
 875: > Save the certificate ARN from the output for the next step.
 876: 
 877: ### Step 6: Import the Certificate
 878: 
 879: Import the certificate into the CA:
 880: 
 881: ```bash
 882: # Set the certificate ARN from the previous command output
 883: CERTIFICATE_ARN="arn:aws:acm-pca:us-east-1:STATE_ACCOUNT_ID:certificate-authority/CA_ID/certificate/CERTIFICATE_ID"
 884: 
 885: # Get the certificate
 886: aws acm-pca get-certificate \
 887:     --certificate-authority-arn $CA_ARN \
 888:     --certificate-arn $CERTIFICATE_ARN \
 889:     --region us-east-1 \
 890:     --output text > ca-cert.pem
 891: 
 892: # Import the certificate
 893: aws acm-pca import-certificate-authority-certificate \
 894:     --certificate-authority-arn $CA_ARN \
 895:     --certificate fileb://ca-cert.pem \
 896:     --region us-east-1
 897: ```
 898: 
 899: ### Step 7: Share Private CA via RAM
 900: 
 901: Create a resource share to make the Private CA available to your organization:
 902: 
 903: ```bash
 904: aws ram create-resource-share \
 905:     --name "Private-CA-Share" \
 906:     --resource-arns $CA_ARN \
 907:     --principals "arn:aws:organizations::STATE_ACCOUNT_ID:organization/ORGANIZATION_ID" \
 908:     --region us-east-1 \
 909:     --tags key=Purpose,value=CentralCA key=Organization,value=YourOrg
 910: ```
 911: 
 912: ### Step 8: Verify Resource Share
 913: 
 914: Check the resource share details:
 915: 
 916: ```bash
 917: # Check the resource share details
 918: aws ram get-resource-shares \
 919:     --name "Private-CA-Share" \
 920:     --resource-owner SELF \
 921:     --region us-east-1
 922: 
 923: # Check RAM resource associations
 924: aws ram get-resource-share-associations \
 925:     --association-type RESOURCE \
 926:     --region us-east-1
 927: 
 928: # Check for shared Private CAs
 929: aws acm-pca list-certificate-authorities \
 930:     --region us-east-1
 931: ```
 932: 
 933: ### Step 9: Verify RAM Service Access
 934: 
 935: Verify that RAM service access is enabled for your organization:
 936: 
 937: ```bash
 938: # Run this in the state account
 939: aws organizations list-aws-service-access-for-organization \
 940:     --query 'EnabledServicePrincipals[?ServicePrincipal==`ram.amazonaws.com`]'
 941: 
 942: # Check resource share status
 943: aws ram get-resource-shares \
 944:     --name "Private-CA-Share" \
 945:     --resource-owner SELF \
 946:     --region us-east-1 \
 947:     --query 'resourceShares[0].status'
 948: ```
 949: 
 950: ### Step 10: Request Certificates in Deployment Accounts
 951: 
 952: Switch to each deployment account (development, production) and request certificates:
 953: 
 954: **For Production Account:**
 955: 
 956: ```bash
 957: # Switch to production account credentials first, then run:
 958: aws --profile prod acm request-certificate \
 959:     --domain-name "example.com" \
 960:     --subject-alternative-names "*.example.com" \
 961:     --certificate-authority-arn $CA_ARN \
 962:     --region us-east-1 \
 963:     --tags Key=Name,Value=PrivateCertProd Key=Env,Value=prod Key=Purpose,Value=ALB
 964: ```
 965: 
 966: **For Development Account:**
 967: 
 968: ```bash
 969: # Switch to development account credentials first, then run:
 970: aws --profile dev acm request-certificate \
 971:     --domain-name "example.com" \
 972:     --subject-alternative-names "*.example.com" \
 973:     --certificate-authority-arn $CA_ARN \
 974:     --region us-east-1 \
 975:     --tags Key=Name,Value=PrivateCertDev Key=Env,Value=dev Key=Purpose,Value=ALB
 976: ```
 977: 
 978: ### Step 11: Verify Certificate Authority
 979: 
 980: Check the Private CA details:
 981: 
 982: ```bash
 983: aws acm-pca describe-certificate-authority \
 984:     --certificate-authority-arn $CA_ARN \
 985:     --region us-east-1
 986: ```
 987: 
 988: ### Step 12: Verify ACM Service-Linked Role
 989: 
 990: Check if the ACM service-linked role exists (usually auto-created):
 991: 
 992: ```bash
 993: # Check for ACM service-linked role
 994: aws --profile <sso-profile> iam get-role --role-name AWSServiceRoleForCertificateManager
 995: 
 996: # If it doesn't exist, create it (optional - usually auto-created)
 997: aws --profile <sso-profile> iam create-service-linked-role --aws-service-name acm.amazonaws.com
 998: ```
 999: 
1000: ### Important Notes for Private CA
1001: 
1002: - **Replace Placeholders**: Replace all placeholders in the commands:
1003:   - `STATE_ACCOUNT_ID`: Your State Account ID
1004:   - `CA_ID`: The CA ID from the create command output
1005:   - `CERTIFICATE_ID`: The certificate ID from the issue command output
1006:   - `ORGANIZATION_ID`: Your AWS Organizations ID
1007:   - `example.com`: Your actual domain name
1008:   - `YourOrg`: Your organization name
1009: 
1010: - **Region Consistency**: Ensure all commands use the same region (e.g., `us-east-1`)
1011: 
1012: - **Certificate Validation**: After requesting certificates in deployment accounts,
1013: they will be automatically validated if DNS validation records are created via Route53
1014: 
1015: - **Certificate Status**: Wait for certificates to reach `ISSUED` status before
1016: using them with ALB
1017: 
1018: - **Resource Share**: The Private CA must be shared via RAM before deployment
1019: accounts can request certificates from it
1020: 
1021: - **Browser Warnings**: Private CA certificates will show "Not secure" warnings in browsers
````

## File: application/OPENLDAP-README.md
````markdown
  1: # OPENLDAP
  2: 
  3:  > The `openldap-stack-ha` chart deploys an OpenLDAP multi-master cluster plus
  4:  optional phpLDAPadmin and LTB self-service password UIs. Below is a breakdown
  5:  of what it creates and how all the values control it.
  6: 
  7: ## 1. What the chart deploys
  8: 
  9: The chart's current image targets Bitnami's OpenLDAP image and supports Bitnami
 10: OpenLDAP 2.x.([GitHub][1])
 11: 
 12: > [!NOTE]
 13: >
 14: > I had to override it in the code because it couldn't access that image.
 15: 
 16: ### 1.1 Core OpenLDAP resources
 17: 
 18: From the chart README and a static analysis of rendered manifests:([GitHub][1])
 19: 
 20: 1. StatefulSet
 21: 
 22:    - Kind: `StatefulSet`
 23:    - Name pattern: `<release-name>-openldap`
 24:    - Default `replicaCount` is 3, using multi-master replication.
 25:    - Holds the main OpenLDAP containers plus any configured sidecars or
 26:    initContainers.
 27: 
 28: 2. ConfigMaps
 29: 
 30:    - `release-name-openldap-env`
 31: 
 32:      - Holds environment configuration for the Bitnami OpenLDAP
 33:      container.([Datree][2])
 34:    - Additional ConfigMaps are used when you set:
 35: 
 36:      - `customLdifFiles` (inline LDIF definitions, rendered into a ConfigMap).
 37:      - `customLdifCm` (points to an existing ConfigMap you created).
 38:      - `customSchemaFiles` (extra schema definitions).([GitHub][1])
 39: 
 40: 3. Secrets
 41: 
 42:    - One Secret for OpenLDAP credentials when `global.existingSecret` is not
 43:    set.
 44: 
 45:      - Expected keys if you use your own Secret: `LDAP_ADMIN_PASSWORD` and
 46:      `LDAP_CONFIG_ADMIN_PASSWORD`.([GitHub][1])
 47:    - One Secret for TLS if you enable `initTLSSecret.tls_enabled` and point
 48:    `initTLSSecret.secret` at an existing Secret that has `tls.crt`,
 49:    `tls.key`, `ca.crt`.([GitHub][1])
 50: 
 51: 4. Services
 52:    The presence and shape of services are controlled by the `service.*` and
 53:    `serviceReadOnly.*` values.([GitHub][1])
 54: 
 55:    - Primary Service for the RW cluster:
 56: 
 57:      - Kind: `Service`
 58:      - Type: `ClusterIP` by default (`service.type`).
 59:      - Ports:
 60: 
 61:        - LDAP: `global.ldapPort` (default 389) if `service.enableLdapPort =
 62:        true`.
 63:        - LDAPS: `global.sslLdapPort` (default 636) if `service.enableSslLdapPort
 64:        = true`.
 65:      - Optional fields:
 66: 
 67:        - `service.clusterIP`, `service.loadBalancerIP`,
 68:        - `service.externalIPs`,
 69:        - `service.loadBalancerSourceRanges`,
 70:        - `service.ipFamilyPolicy`,
 71:        - `service.externalTrafficPolicy`.
 72:    - Headless Service:
 73: 
 74:      - Exists because the values mention "service and headless service" for port
 75:      toggles.([GitHub][1])
 76:      - Used by the StatefulSet for stable DNS identities.
 77:    - Read-only Service:
 78: 
 79:      - Controlled by `serviceReadOnly.*` values and exists when you have
 80:      read-only replicas.([GitHub][1])
 81: 
 82: 5. PersistentVolumeClaims (conditionally)
 83: 
 84:    - Only created if `persistence.enabled = true`.([GitHub][1])
 85:    - PVC properties:
 86: 
 87:      - `persistence.storageClass`
 88:      - `persistence.accessMode` (default `ReadWriteOnce`)
 89:      - `persistence.size` (default `8Gi`)
 90:      - `persistence.existingClaim` (if you want to reuse an existing PVC).
 91: 
 92: 6. PodDisruptionBudget (conditionally)
 93: 
 94:    - Only created if `pdb.enabled = true`.([GitHub][1])
 95:    - Controlled by:
 96: 
 97:      - `pdb.minAvailable`
 98:      - `pdb.maxUnavailable`.
 99: 
100: 7. Misc pod-level constructs
101:    Applied to the StatefulSet pod template when you set the corresponding
102:    values:([GitHub][1])
103: 
104:    - Affinity / anti-affinity:
105: 
106:      - `podAffinityPreset`
107:      - `podAntiAffinityPreset`
108:      - `nodeAffinityPreset`
109:      - `affinity`
110:      - `nodeSelector`
111:      - `tolerations`
112:    - Security:
113: 
114:      - `podSecurityContext`
115:      - `containerSecurityContext`
116:      - `priorityClassName`
117:    - Extra containers and volumes:
118: 
119:      - `sidecars`
120:      - `initContainers`
121:      - `extraVolumes`
122:      - `extraVolumeMounts`
123:      - `volumePermissions` init-container.
124:    - Probes:
125: 
126:      - `customReadinessProbe`
127:      - `customLivenessProbe`
128:      - `customStartupProbe`.
129: 
130: 8. Extra objects
131: 
132:    - `extraDeploy` allows you to inject arbitrary Kubernetes manifests that will
133:    be deployed along with the chart.([GitHub][1])
134: 
135: ### 1.2 phpLDAPadmin subchart
136: 
137: From the chart README and Datree analysis:([GitHub][1])
138: 
139: If `phpldapadmin.enabled = true` (default is true):
140: 
141: 1. Deployment
142: 
143:    - Kind: `Deployment`
144:    - Name: `release-name-phpldapadmin`.
145: 2. Service
146: 
147:    - Kind: `Service`
148:    - Type: usually `ClusterIP`, with a port 80 HTTP endpoint.
149: 3. ConfigMap
150: 
151:    - Holds phpLDAPadmin configuration. Datree shows `kind: ConfigMap` for
152:    `release-name-phpldapadmin`.([Datree][2])
153: 4. Ingress (conditionally)
154: 
155:    - Kind: `Ingress`
156:    - Created if you set `phpldapadmin.ingress.enabled = true`, with host/path
157:    from `phpldapadmin.ingress.hosts`, `phpldapadmin.ingress.path`
158:    etc.([GitHub][1])
159: 
160: ### 1.3 LTB self-service password subchart (`ltb-passwd`)
161: 
162: If `ltb-passwd.enabled = true` (default true):([GitHub][1])
163: 
164: 1. Deployment
165: 
166:    - Kind: `Deployment`
167:    - Name: `release-name-ltb-passwd`.
168: 2. Service
169: 
170:    - Kind: `Service`
171:    - Type: `ClusterIP`, port 80 for the web UI.
172: 3. ConfigMap
173: 
174:    - Holds app-level configuration (as seen in the vendored README snippet that
175:    includes `ldap.server`, `ldap.searchBase`, etc.).([OpenCloud Forge][3])
176: 4. Ingress (conditionally)
177: 
178:    - Kind: `Ingress`
179:    - Created if `ltb-passwd.ingress.enabled = true`. Datree shows two Ingresses
180:    for ltb-passwd and phpLDAPadmin.([Datree][2])
181: 
182: ## 2. Value space and behavior
183: 
184: The README lists the core values. I will walk through them by category and map
185: them to behavior.([GitHub][1])
186: 
187: ### 2.1 Global section
188: 
189: Global values mostly affect credentials, ports and image sources.
190: 
191: 1. `global.imageRegistry`
192: 
193:    - Overrides the registry used for all images (OpenLDAP and subcharts).
194:    - Use when you mirror images into a private registry.
195: 
196: 2. `global.imagePullSecrets`
197: 
198:    - List of imagePullSecrets added to all pods.
199:    - Required when the registry needs authentication.
200: 
201: 3. `global.ldapDomain`
202: 
203:    - Logical LDAP domain.
204:    - Can be:
205: 
206:      - Fully DN style: `dc=example,dc=org`
207:      - Simple domain: `example.org`
208:    - Used to generate the base DN and other configuration parameters.
209: 
210: 4. `global.existingSecret`
211: 
212:    - Name of an existing Secret for credentials.
213:    - That Secret must contain:
214: 
215:      - `LDAP_ADMIN_PASSWORD`
216:      - `LDAP_CONFIG_ADMIN_PASSWORD`
217:    - If set, chart will not manage admin/config passwords itself.
218: 
219: 5. `global.adminUser` / `global.adminPassword`
220: 
221:    - Admin user and password for the LDAP directory.
222:    - Passed to the Bitnami OpenLDAP container as env vars and/or referenced from
223:    Secret.
224: 
225: 6. `global.configUser` / `global.configPassword`
226: 
227:    - Credentials for the configuration database (cn=config).
228:    - Used by OpenLDAP for configuration operations.
229: 
230: 7. `global.ldapPort` / `global.sslLdapPort`
231: 
232:    - TCP ports used internally on the Service for LDAP and LDAPS.
233:    - Combined with `service.enableLdapPort` and `service.enableSslLdapPort` to
234:    expose them.
235: 
236: ### 2.2 Application parameters (OpenLDAP core)
237: 
238: All of these apply to the OpenLDAP StatefulSet and its
239: configuration.([GitHub][1])
240: 
241: 1. `replicaCount`
242: 
243:    - Number of multi-master replicas (pods) in the main StatefulSet.
244:    - Default is 3.
245:    - These replicas form the HA write cluster.
246: 
247: 2. `readOnlyReplicaCount`
248: 
249:    - Number of read-only replicas.
250:    - Default 0.
251:    - When greater than 0, additional read-only pods are created and traffic can
252:    be routed to them via `serviceReadOnly.*` configuration.
253: 
254: 3. `users`, `userPasswords`, `group`
255: 
256:    - Used for simple user/group bootstrap when you do not want to supply your
257:    own LDIF.
258:    - `users` and `userPasswords` are comma separated lists; the index pairing
259:    maps user to password.
260:    - `group` defines a group that the created users will belong to.
261:    - Cannot be used together with `customLdifFiles`.
262: 
263: 4. `env`
264: 
265:    - Free-form list of key/value pairs mapped to environment variables on the
266:    OpenLDAP container.
267:    - Used to pass Bitnami-specific flags like `LDAP_SKIP_DEFAULT_TREE`, to
268:    control whether Bitnami creates its default demo tree, and so
269:    on.([GitHub][1])
270: 
271: 5. `initTLSSecret.tls_enabled` / `initTLSSecret.secret`
272: 
273:    - `initTLSSecret.tls_enabled`:
274: 
275:      - Boolean flag enabling or disabling TLS/LDAPS using a custom certificate.
276:    - `initTLSSecret.secret`:
277: 
278:      - Name of the Secret that must contain `tls.key`, `tls.crt`, `ca.crt`.
279:    - When enabled, the pod init phase loads the certificate and configures
280:    OpenLDAP for LDAPS.
281: 
282: 6. `initialSchema`
283: 
284:    - Comma separated list of schema names to seed into `LDAP_EXTRA_SCHEMAS`.
285:    - Default: `"cosine,inetorgperson,nis"`
286:    - Controls which standard schemas are loaded at bootstrap.
287: 
288: 7. `customSchemaFiles`
289: 
290:    - Additional schema files to load, beyond `initialSchema`.
291:    - Typically represented as filename to content mapping in `values.yaml`.
292:    - Used to enable custom objectClasses and attributes.
293: 
294: 8. `customLdifFiles`
295: 
296:    - Inline LDIF content used to bootstrap the directory tree.
297:    - Keys are filenames, values are LDIF contents.([HackMD][4])
298:    - If set, they override the default bootstrap LDIF shipped by Bitnami and the
299:    simple `users`/`group` bootstrap logic.
300: 
301: 9. `customLdifCm`
302: 
303:    - Name of an existing ConfigMap that already contains LDIF files.
304:    - Mutually exclusive with `customLdifFiles`.
305: 
306: 10. `customAcls`
307: 
308:     - Custom ACL configuration to replace default ACLs.
309:     - Used to harden or tune access rules beyond defaults.
310: 
311: 11. Replication block
312: 
313:     - `replication.enabled`
314: 
315:       - Enables multi-master replication. Default `true`.
316:       - Disabling this effectively turns the cluster into a set of
317:       non-replicating pods with shared configuration, not a proper HA
318:       directory.
319:     - `replication.retry`
320: 
321:       - Retry period in seconds for replication operations, default `60`.
322:     - `replication.timeout`
323: 
324:       - Timeout in seconds for replication, default `1`.
325:     - `replication.starttls`
326: 
327:       - Mode of StartTLS for replication traffic, default `critical`.
328:     - `replication.tls_reqcert`
329: 
330:       - Overrides `tls_reqcert` parameter.
331:       - Default `never` and becomes more strict (for example `demand`) when TLS
332:       is enabled.
333:     - `replication.tls_cacert`
334: 
335:       - Overrides the path to the CA cert used by replication when TLS is
336:       enabled.
337:     - `replication.interval`
338: 
339:       - Interval string for replication scheduling, default `00:00:00:10`.
340:     - `replication.clusterName`
341: 
342:       - Cluster name for replication, default `"cluster.local"`.
343: 
344: ### 2.3 phpLDAPadmin configuration
345: 
346: These values control the separate phpLDAPadmin deployment that provides a web
347: UI.([GitHub][1])
348: 
349: 1. `phpldapadmin.enabled`
350: 
351:    - Boolean. Default `true`.
352:    - When false:
353: 
354:      - Deployment, Service and Ingress for phpLDAPadmin are not created.
355: 
356: 2. `phpldapadmin.ingress`
357: 
358:    - Struct controlling Ingress for phpLDAPadmin:
359: 
360:      - `enabled`
361:      - `ingressClassName`
362:      - `annotations`
363:      - `hosts`
364:      - `path`
365:      - `tls`
366:    - Example in README:
367: 
368:      - Host: `phpldapadmin.local`
369:      - Path: `/`
370:      - TLS with secret `ssl-ldap-dedicated-tls`.([GitHub][1])
371: 
372: 3. `phpldapadmin.env`
373: 
374:    - Map of environment variables passed into the phpLDAPadmin container.
375:    - Default includes:
376: 
377:      - `PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "never"`
378:    - You extend this to set LDAP host, base DN, bind DN etc.
379:    - LDAP host must match `namespace.Appfullname` of the OpenLDAP Service
380:    according to the README.([GitHub][1])
381: 
382: ### 2.4 LTB self-service password configuration (`ltb-passwd`)
383: 
384: Values for the password self-service UI.([GitHub][1])
385: 
386: 1. `ltb-passwd.enabled`
387: 
388:    - Boolean. Default `true`.
389:    - Disables the Deployment, Service and Ingress when set to false.
390: 
391: 2. `ltb-passwd.ingress`
392: 
393:    - Struct controlling Ingress for the self-service password UI, similar shape
394:    to phpLDAPadmin's ingress config:
395: 
396:      - `enabled`
397:      - `annotations`
398:      - `hosts`
399:      - `path`
400:      - `tls`
401: 
402: 3. Additional subchart values (from the vendored README snippet):([OpenCloud
403: Forge][3])
404: 
405:    - `replicaCount`
406:    - `image.repository`, `image.tag`, `image.pullPolicy`
407:    - `service.type`, `service.port`
408:    - `ingress.enabled`, `ingress.host`, `ingress.tls`
409:    - `ldap.server`, `ldap.searchBase`, `ldap.bindDN`, `ldap.bindPWKey`,
410:    `ldap.existingSecret`
411:    - `env` list, for example:
412: 
413:      - `SECRETEKEY`
414:      - `LDAP_LOGIN_ATTRIBUTE`
415:        These values bind the web app to the OpenLDAP server and define how users
416:        authenticate to change their own passwords.
417: 
418: ### 2.5 Kubernetes level parameters
419: 
420: These values shape how the core OpenLDAP pods and services behave on the
421: cluster.([GitHub][1])
422: 
423: 1. `updateStrategy`
424: 
425:    - Overrides the StatefulSet `updateStrategy`.
426:    - Allows for `RollingUpdate` tuning or `OnDelete`.
427: 
428: 2. `kubeVersion`
429: 
430:    - Explicit Kubernetes version override for Helm's capabilities logic.
431:    - Useful when Helm cannot detect the server version (for example in certain
432:    CI contexts).
433: 
434: 3. `nameOverride`, `fullnameOverride`
435: 
436:    - Control how the base resource name is constructed.
437:    - `nameOverride` partially overrides the chart's name.
438:    - `fullnameOverride` fully overrides the computed release name.
439: 
440: 4. `commonLabels`
441: 
442:    - Applied to all created resources in addition to default labels.
443:    - Useful for global selectors or ownership tags.
444: 
445: 5. `clusterDomain`
446: 
447:    - Cluster DNS suffix, default `cluster.local`.
448:    - Used when composing hostnames for replication and for generated URLs.
449: 
450: 6. `extraDeploy`
451: 
452:    - Raw YAML snippets that Helm applies along with the chart.
453:    - Enables you to attach extra objects (for example NetworkPolicy,
454:    ServiceMonitor) without forking the chart.
455: 
456: 7. `service.*` and `serviceReadOnly.*`
457:    Both sets have similar keys:([GitHub][1])
458: 
459:    - `annotations`
460:    - `externalIPs`
461:    - `enableLdapPort`
462:    - `enableSslLdapPort`
463:    - `ldapPortNodePort`, `sslLdapPortNodePort`
464:    - `clusterIP`
465:    - `loadBalancerIP`
466:    - `loadBalancerSourceRanges`
467:    - `type`
468:    - `ipFamilyPolicy`
469:    - `externalTrafficPolicy`
470:      They directly control how the Services for the main and read-only LDAP
471:      endpoints are exposed.
472: 
473: 8. Persistence block
474: 
475:    - `persistence.enabled`
476:    - `persistence.storageClass`
477:    - `persistence.existingClaim`
478:    - `persistence.accessMode`
479:    - `persistence.size`
480:      These define whether PVCs exist and how they are sized and bound.
481: 
482: 9. Probes and container overrides
483: 
484:    - `customReadinessProbe`, `customLivenessProbe`, `customStartupProbe`
485: 
486:      - When set, these fully replace the default probe configs in the
487:      StatefulSet.
488:    - `command`, `args`
489: 
490:      - Override the container entrypoint and arguments.
491:    - `resources`
492: 
493:      - CPU/memory requests and limits for the OpenLDAP containers.
494:      - Datree shows that by default requests and limits are empty.([Datree][2])
495: 
496: 10. Security and scheduling knobs
497: 
498:     - `podSecurityContext`
499:     - `containerSecurityContext`
500:     - `podLabels`, `podAnnotations`
501:     - `podAffinityPreset`, `podAntiAffinityPreset`
502:     - `nodeAffinityPreset`, `affinity`
503:     - `nodeSelector`
504:     - `tolerations`
505:     - `priorityClassName`
506:     - `sidecars`, `initContainers`
507:     - `volumePermissions`
508:       These do not create new resource kinds but alter how the pods inside the
509:       existing StatefulSet behave and where they schedule.
510: 
511: ## 3. Net effect on a default install
512: 
513: If you run:
514: 
515: ```bash
516: helm repo add helm-openldap https://jp-gouin.github.io/helm-openldap/
517: helm install my-release helm-openldap/openldap-stack-ha
518: ```
519: 
520: with the default values, the chart will:([GitHub][1])
521: 
522: 1. Create a StatefulSet with 3 OpenLDAP pods with multi-master replication.
523: 2. Create at least one ConfigMap for OpenLDAP env configuration.
524: 3. Create at least one Secret for credentials (unless you point to an existing
525: one).
526: 4. Create internal Services for LDAP and LDAPS, plus a headless Service for the
527: StatefulSet.
528: 5. Not create any PVCs, because `persistence.enabled` defaults to `false`.
529: 6. Create a Deployment, Service, ConfigMap and (if enabled) an Ingress for
530: phpLDAPadmin.
531: 7. Create a Deployment, Service, ConfigMap and (if enabled) an Ingress for
532: ltb-passwd.
533: 
534: All other values progressively refine this baseline: toggling TLS, controlling
535: replication, deciding whether the UIs exist, and tuning how the pods are
536: scheduled and exposed.
537: 
538: [1]: https://github.com/jp-gouin/helm-openldap "GitHub - jp-gouin/helm-openldap:
539: Helm chart of Openldap in High availability with multi-master replication and
540: PhpLdapAdmin and Ltb-Passwd"
541: [2]: https://www.datree.io/helm-chart/openldap-jp-gouin "Openldap Helm Chart |
542: Datree"
543: [3]:
544: https://www.o-forge.io/core/oc-k8s/commit/ba9a971964794bb0f930c7caba69aa4dc73f4d7f.diff?utm_source=chatgpt.com
545: "https://www.o-forge.io/core/oc-k8s/commit/ba9a9719..."
546: [4]:
547: https://hackmd.io/%40tsungjung411/r1Yg3rE9lx?utm_medium=rec&utm_source=chatgpt.com
548: "Kubernetes OpenLDAP "
````

## File: application/OSIXIA-OPENLDAP-REQUIREMENTS.md
````markdown
  1: # OpenLDAP Image Requirements Analysis
  2: 
  3: ## Overview
  4: 
  5: You are using the **osixia/openldap:1.5.0** Docker image with the
  6: **jp-gouin/helm-openldap** Helm chart. The chart is designed for Bitnami
  7: OpenLDAP, which has different environment variables and TLS configuration than
  8: osixia/openldap.
  9: 
 10: ## Key Differences: osixia/openldap vs Bitnami OpenLDAP
 11: 
 12: ### Environment Variables
 13: 
 14: **osixia/openldap** uses different environment variable names than Bitnami:
 15: 
 16: | osixia/openldap | Bitnami (chart default) | Current Config | Status |
 17: | ---------------- | ------------------------ | ---------------- | -------- |
 18: | `LDAP_TLS` | `LDAP_TLS` |  Missing | **NEEDS FIX** |
 19: | `LDAP_TLS_CRT_FILENAME` | N/A |  Wrong (`LDAP_TLS_CERT_FILE`) | **NEEDS FIX** |
 20: | `LDAP_TLS_KEY_FILENAME` | N/A |  Wrong (`LDAP_TLS_KEY_FILE`) | **NEEDS FIX** |
 21: | `LDAP_TLS_CA_CRT_FILENAME` | N/A |  Wrong (`LDAP_TLS_CA_FILE`) | **NEEDS FIX** |
 22: | `LDAP_TLS_ENFORCE` | `LDAP_TLS_ENFORCE` |  Correct | OK |
 23: | `LDAP_TLS_VERIFY_CLIENT` | `LDAP_TLS_VERIFY_CLIENT` |  Correct | OK |
 24: 
 25: ### TLS Certificate Handling
 26: 
 27: **osixia/openldap** expects:
 28: 
 29: - Certificates mounted at `/container/service/slapd/assets/certs/`
 30: - Certificate filenames specified via environment variables (not paths)
 31: - Auto-generation of self-signed certificates if certificates don't exist (when
 32: `LDAP_TLS=true`)
 33: 
 34: **Bitnami** (chart default):
 35: 
 36: - Uses `initTLSSecret.tls_enabled` and `initTLSSecret.secret` to mount
 37: certificates
 38: - Different certificate paths and initialization process
 39: 
 40: ## Required Changes
 41: 
 42: ### 1. Fix TLS Environment Variables
 43: 
 44: **Current (INCORRECT):**
 45: 
 46: ```yaml
 47: env:
 48:   LDAP_TLS_CA_FILE: "/container/service/slapd/assets/certs/ca.crt"
 49:   LDAP_TLS_CERT_FILE: "/container/service/slapd/assets/certs/ldap.crt"
 50:   LDAP_TLS_KEY_FILE: "/container/service/slapd/assets/certs/ldap.key"
 51: ```
 52: 
 53: **Should be (CORRECT for osixia/openldap):**
 54: 
 55: ```yaml
 56: env:
 57:   LDAP_TLS: "true"  # Enable TLS (defaults to true, but explicit is better)
 58:   LDAP_TLS_CRT_FILENAME: "ldap.crt"  # Filename only, not full path
 59:   LDAP_TLS_KEY_FILENAME: "ldap.key"  # Filename only, not full path
 60:   LDAP_TLS_CA_CRT_FILENAME: "ca.crt"  # Filename only, not full path
 61:   LDAP_TLS_ENFORCE: "false"  # Don't enforce TLS (allows both LDAP and LDAPS)
 62:   LDAP_TLS_VERIFY_CLIENT: "never"  # Don't require client certificates
 63: ```
 64: 
 65: ### 2. Certificate Mounting Strategy
 66: 
 67: Since the helm chart's `initTLSSecret` feature is designed for Bitnami, you have
 68: two options:
 69: 
 70: #### Option A: Use Auto-Generated Certificates (Simplest)
 71: 
 72: osixia/openldap will auto-generate self-signed certificates if they don't exist.
 73: This works for internal cluster communication but certificates won't be trusted
 74: by external clients.
 75: 
 76: **Configuration:**
 77: 
 78: ```yaml
 79: env:
 80:   LDAP_TLS: "true"
 81:   LDAP_TLS_ENFORCE: "false"
 82:   LDAP_TLS_VERIFY_CLIENT: "never"
 83:   # No certificate filenames needed - will auto-generate
 84: ```
 85: 
 86: #### Option B: Mount Custom Certificates via Volume
 87: 
 88: Mount certificates from a Kubernetes Secret using `extraVolumes` and
 89: `extraVolumeMounts`:
 90: 
 91: **1. Create a Secret with certificates:**
 92: 
 93: ```bash
 94: kubectl create secret generic openldap-tls-certs \
 95:   --from-file=ldap.crt=/path/to/cert.pem \
 96:   --from-file=ldap.key=/path/to/key.pem \
 97:   --from-file=ca.crt=/path/to/ca.pem \
 98:   -n ldap
 99: ```
100: 
101: **2. Update Helm values:**
102: 
103: ```yaml
104: env:
105:   LDAP_TLS: "true"
106:   LDAP_TLS_CRT_FILENAME: "ldap.crt"
107:   LDAP_TLS_KEY_FILENAME: "ldap.key"
108:   LDAP_TLS_CA_CRT_FILENAME: "ca.crt"
109:   LDAP_TLS_ENFORCE: "false"
110:   LDAP_TLS_VERIFY_CLIENT: "never"
111: 
112: extraVolumes:
113:   - name: tls-certs
114:     secret:
115:       secretName: openldap-tls-certs
116: 
117: extraVolumeMounts:
118:   - name: tls-certs
119:     mountPath: /container/service/slapd/assets/certs
120:     readOnly: true
121: ```
122: 
123: ### 3. Multi-Ingress Single ALB Configuration
124: 
125: Your current ALB configuration is **correct** with the following setup:
126: 
127: ####  Correct Configuration
128: 
129: - `group.name` and `certificateARNs` configured in IngressClassParams
130: (cluster-wide)
131: - Both Ingresses use the same IngressClass (which references IngressClassParams)
132: - Both Ingresses have `alb.ingress.kubernetes.io/load-balancer-name` annotation
133: - Per-Ingress settings (target-type, listen-ports, ssl-redirect) configured in
134: Ingress annotations
135: - `scheme` and `ipAddressType` inherited from IngressClassParams
136: 
137: **Current implementation:**
138: 
139: ```yaml
140: ltb-passwd:
141:   ingress:
142:     annotations:
143:       # Note: group.name and certificate-arn are in IngressClassParams
144:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
145:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
146:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
147:       alb.ingress.kubernetes.io/ssl-redirect: "443"
148:       # scheme, ipAddressType, group.name, and certificateARNs inherited from IngressClassParams
149: 
150: phpldapadmin:
151:   ingress:
152:     annotations:
153:       # Same annotations as ltb-passwd - group.name and certificate-arn are in IngressClassParams
154:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
155:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
156:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
157:       alb.ingress.kubernetes.io/ssl-redirect: "443"
158: ```
159: 
160: ## Summary of Required Changes
161: 
162: ### Priority 1: Fix TLS Environment Variables
163: 
164: 1. Change `LDAP_TLS_CERT_FILE`  `LDAP_TLS_CRT_FILENAME`
165: 2. Change `LDAP_TLS_KEY_FILE`  `LDAP_TLS_KEY_FILENAME`
166: 3. Change `LDAP_TLS_CA_FILE`  `LDAP_TLS_CA_CRT_FILENAME`
167: 4. Remove full paths, use only filenames
168: 5. Add `LDAP_TLS: "true"` explicitly
169: 
170: ### Priority 2: Certificate Mounting
171: 
172: - Choose Option A (auto-generated) or Option B (custom certificates)
173: - If using Option B, add `extraVolumes` and `extraVolumeMounts` configuration
174: 
175: ### Priority 3: ALB Optimization (Optional)
176: 
177: - Remove duplicate TLS annotations from higher-order Ingress
178: - Ensure scheme is only set in IngressClassParams, not Ingress annotations
179: 
180: ## References
181: 
182: - [osixia/openldap GitHub](https://github.com/osixia/docker-openldap)
183: - [osixia/openldap TLS Documentation](https://github.com/osixia/docker-openldap#tls)
184: - [jp-gouin/helm-openldap GitHub](https://github.com/jp-gouin/helm-openldap)
````

## File: application/PRD-2FA-APP.md
````markdown
  1: # 2FA Application - Product Requirements Document
  2: 
  3: ## Overview
  4: 
  5: This document defines the requirements for a two-factor authentication (2FA) GUI
  6: application consisting of a Python backend API and a static HTML/JS/CSS frontend,
  7: integrated with the existing LDAP infrastructure.
  8: 
  9: The application supports **two MFA methods**:
 10: 
 11: 1. **TOTP (Time-based One-Time Password)** - Using authenticator apps like Google
 12:    Authenticator, Authy, etc.
 13: 2. **SMS** - Verification codes sent via AWS SNS to the user's phone number
 14: 
 15: **Repository**: [https://github.com/talorlik/ldap-2fa-on-k8s](https://github.com/talorlik/ldap-2fa-on-k8s)
 16: 
 17: ## Architecture Decisions
 18: 
 19: ### Routing Pattern (Pattern B - Single Domain)
 20: 
 21: | Decision | Value |
 22: | ---------- | ------- |
 23: | Public hostname | `app.<domain>` (e.g., `app.talo-ldap.com`) |
 24: | Frontend path | `/` |
 25: | Backend API path | `/api/*` |
 26: | DNS records needed | One A/ALIAS record |
 27: | Ingress resources | Two (one per application) |
 28: | CORS handling | Not required (same origin) |
 29: 
 30: ### MFA Method Selection
 31: 
 32: | Method | Use Case | Infrastructure |
 33: | -------- | ---------- | ---------------- |
 34: | TOTP | Primary method, no network dependency | None (code generated locally) |
 35: | SMS | Alternative method, requires phone | AWS SNS, VPC endpoints |
 36: 
 37: ### Traffic Flow
 38: 
 39: ```text
 40: Internet (Browser / CLI)
 41:        
 42:          https://app.<domain>/
 43:          https://app.<domain>/api/...
 44:        
 45:  Existing ALB (shared via group.name)
 46:        
 47:         Path: /api/*   Backend Ingress   Backend Service   Backend Pods
 48:                                                                      
 49:                                                    
 50:                                                                                      
 51:                                                                                      
 52:                                              LDAP (ClusterIP)   SNS (VPC Endpoint)  STS (IRSA)
 53:        
 54:         Path: /*       Frontend Ingress  Frontend Service  Frontend Pods
 55: ```
 56: 
 57: ## Directory Structure
 58: 
 59: ```text
 60: ldap-2fa-on-k8s/
 61:  application/
 62:      modules/
 63:         sns/                         # Terraform module for SNS
 64:             main.tf
 65:             variables.tf
 66:             outputs.tf
 67:             README.md
 68:      backend/
 69:         src/
 70:            app/
 71:               main.py
 72:               api/
 73:                  __init__.py
 74:                  routes.py
 75:               ldap/
 76:                  __init__.py
 77:                  client.py
 78:               mfa/
 79:                  __init__.py
 80:                  totp.py
 81:               sms/                 # SMS module for SNS
 82:                  __init__.py
 83:                  client.py
 84:               config.py
 85:            requirements.txt
 86:         helm/
 87:            ldap-2fa-backend/
 88:                Chart.yaml
 89:                values.yaml
 90:                templates/
 91:                    deployment.yaml
 92:                    service.yaml
 93:                    ingress.yaml
 94:                    configmap.yaml
 95:                    secret.yaml
 96:                    serviceaccount.yaml  # For IRSA
 97:         Dockerfile
 98:     
 99:      frontend/
100:          src/
101:             index.html
102:             css/
103:                styles.css
104:             js/
105:                 api.js
106:                 main.js
107:          helm/
108:             ldap-2fa-frontend/
109:                 Chart.yaml
110:                 values.yaml
111:                 templates/
112:                     deployment.yaml
113:                     service.yaml
114:                     ingress.yaml
115:          Dockerfile
116: ```
117: 
118: ## Backend Requirements
119: 
120: ### Functional Requirements
121: 
122: | ID | Requirement |
123: | ---- | ------------- |
124: | BE-01 | Authenticate users against LDAP (bind operation) |
125: | BE-02 | Generate TOTP secrets for MFA enrollment |
126: | BE-03 | Return `otpauth://` URI for QR code generation |
127: | BE-04 | Verify TOTP codes during login |
128: | BE-05 | Provide clear success/failure responses for UI and CLI |
129: | BE-06 | Support multiple MFA methods (TOTP and SMS) |
130: | BE-07 | Allow user to select MFA method during enrollment |
131: | BE-08 | Store user's MFA method preference |
132: 
133: ### SMS-Specific Functional Requirements
134: 
135: | ID | Requirement |
136: | ---- | ------------- |
137: | SMS-01 | Validate phone numbers in E.164 format (e.g., `+14155552671`) |
138: | SMS-02 | Generate random 6-digit verification codes |
139: | SMS-03 | Send verification codes via AWS SNS |
140: | SMS-04 | Implement code expiration (default: 5 minutes) |
141: | SMS-05 | Support phone number subscription to SNS topic (optional) |
142: | SMS-06 | Handle SMS delivery failures gracefully |
143: | SMS-07 | Check and handle phone number opt-out status |
144: 
145: ### API Endpoints
146: 
147: All endpoints must be served under the `/api` prefix (no path rewriting).
148: 
149: #### Core Endpoints
150: 
151: | Method | Endpoint | Description |
152: | -------- | ---------- | ------------- |
153: | `GET` | `/api/healthz` | Liveness/readiness probe (includes SMS status) |
154: | `GET` | `/api/mfa/methods` | List available MFA methods (TOTP, SMS if enabled) |
155: | `GET` | `/api/mfa/status/{username}` | Get user's MFA enrollment status |
156: | `POST` | `/api/auth/enroll` | Enroll user for MFA (TOTP or SMS) |
157: | `POST` | `/api/auth/login` | Validate LDAP credentials + verification code |
158: 
159: #### SMS-Specific Endpoints
160: 
161: | Method | Endpoint | Description |
162: | -------- | ---------- | ------------- |
163: | `POST` | `/api/auth/sms/send-code` | Send SMS verification code to enrolled user |
164: 
165: #### API Documentation Endpoints
166: 
167: FastAPI automatically generates interactive API documentation that is always available:
168: 
169: | Method | Endpoint | Description |
170: | -------- | ---------- | ------------- |
171: | `GET` | `/api/docs` | Swagger UI - Interactive API documentation and testing interface |
172: | `GET` | `/api/redoc` | ReDoc UI - Alternative API documentation interface |
173: | `GET` | `/api/openapi.json` | OpenAPI schema in JSON format |
174: 
175: The Swagger UI provides an interactive interface to explore all available endpoints,
176: view request/response schemas, and test API calls directly from the browser.
177: The documentation automatically updates when API endpoints change.
178: 
179: ### API Request/Response Schemas
180: 
181: #### Enroll Request
182: 
183: ```json
184: {
185:   "username": "string",
186:   "password": "string",
187:   "mfa_method": "totp | sms",
188:   "phone_number": "+14155552671"  // Required if mfa_method is "sms"
189: }
190: ```
191: 
192: #### Enroll Response (TOTP)
193: 
194: ```json
195: {
196:   "success": true,
197:   "message": "MFA enrollment successful",
198:   "mfa_method": "totp",
199:   "otpauth_uri": "otpauth://totp/...",
200:   "secret": "BASE32SECRET"
201: }
202: ```
203: 
204: #### Enroll Response (SMS)
205: 
206: ```json
207: {
208:   "success": true,
209:   "message": "MFA enrollment successful",
210:   "mfa_method": "sms",
211:   "phone_number": "****2671"  // Masked
212: }
213: ```
214: 
215: #### Login Request
216: 
217: ```json
218: {
219:   "username": "string",
220:   "password": "string",
221:   "verification_code": "123456"
222: }
223: ```
224: 
225: #### Send SMS Code Request
226: 
227: ```json
228: {
229:   "username": "string",
230:   "password": "string"
231: }
232: ```
233: 
234: ### Configuration Requirements
235: 
236: | Config Item | Source | Description |
237: | ------------- | -------- | ------------- |
238: | LDAP service DNS | Environment/ConfigMap | Internal Kubernetes service DNS name |
239: | LDAP base DN | Environment/ConfigMap | Base distinguished name for LDAP operations |
240: | LDAP admin credentials | Secret | Bind DN and password for LDAP queries |
241: | MFA settings | Environment/ConfigMap | TOTP issuer name, algorithm settings |
242: 
243: #### SMS Configuration Requirements
244: 
245: | Config Item | Source | Description |
246: | ------------- | -------- | ------------- |
247: | `ENABLE_SMS_2FA` | Environment/ConfigMap | Enable/disable SMS MFA method |
248: | `AWS_REGION` | Environment/ConfigMap | AWS region for SNS |
249: | `SNS_TOPIC_ARN` | Environment/ConfigMap | SNS topic ARN (optional, for subscriptions) |
250: | `SMS_SENDER_ID` | Environment/ConfigMap | SMS sender ID (max 11 chars) |
251: | `SMS_TYPE` | Environment/ConfigMap | `Transactional` or `Promotional` |
252: | `SMS_CODE_LENGTH` | Environment/ConfigMap | Verification code length (default: 6) |
253: | `SMS_CODE_EXPIRY_SECONDS` | Environment/ConfigMap | Code expiration time (default: 300) |
254: | `SMS_MESSAGE_TEMPLATE` | Environment/ConfigMap | Message template with `{code}` placeholder |
255: 
256: ### Technical Requirements
257: 
258: | ID | Requirement |
259: | ---- | ------------- |
260: | BE-T01 | Built with Python (FastAPI recommended) |
261: | BE-T02 | Run with production server (uvicorn/gunicorn) |
262: | BE-T03 | Expose container port 8000 |
263: | BE-T04 | Communicate with LDAP via ClusterIP service (internal only) |
264: | BE-T05 | Use boto3 for AWS SNS integration |
265: | BE-T06 | Use IRSA (IAM Roles for Service Accounts) for SNS access |
266: | BE-T07 | Communicate with SNS via VPC endpoint (private connectivity) |
267: 
268: ## Frontend Requirements
269: 
270: ### Functional Requirements
271: 
272: | ID | Requirement |
273: | ---- | ------------- |
274: | FE-01 | Display enrollment flow: username/password  MFA method selection  setup |
275: | FE-02 | Display login flow: username/password + verification code  success/failure |
276: | FE-03 | Render QR code from backend-provided `otpauth://` URI (TOTP) |
277: | FE-04 | Handle and display error messages from backend |
278: | FE-05 | Allow user to select MFA method (TOTP or SMS) during enrollment |
279: | FE-06 | Show/hide SMS option based on backend configuration |
280: 
281: ### SMS-Specific Frontend Requirements
282: 
283: | ID | Requirement |
284: | ---- | ------------- |
285: | FE-SMS-01 | Display phone number input field for SMS enrollment |
286: | FE-SMS-02 | Validate phone number format (E.164) on client side |
287: | FE-SMS-03 | Show "Send SMS Code" button on login for SMS-enrolled users |
288: | FE-SMS-04 | Display countdown timer after sending SMS code |
289: | FE-SMS-05 | Auto-detect user's MFA method and show appropriate UI |
290: | FE-SMS-06 | Display masked phone number for SMS-enrolled users |
291: 
292: ### Technical Requirements
293: 
294: | ID | Requirement |
295: | ---- | ------------- |
296: | FE-T01 | Static HTML/CSS/JavaScript (no server-side rendering) |
297: | FE-T02 | Call backend using relative URLs (`fetch("/api/...")`) |
298: | FE-T03 | Served via nginx in container |
299: | FE-T04 | Expose container port 80 |
300: 
301: ## Infrastructure Requirements
302: 
303: ### DNS (Route53)
304: 
305: | Requirement |
306: | ------------- |
307: | Create one A/ALIAS record: `app.<domain>`  existing ALB |
308: | Use existing hosted zone |
309: | No separate `api.<domain>` record needed |
310: 
311: ### Ingress Configuration
312: 
313: Both Ingresses share the existing ALB by using the same `IngressClass`, which
314: references `IngressClassParams` containing the shared `group.name`.
315: 
316: #### Backend Ingress
317: 
318: | Setting | Value |
319: | --------- | ------- |
320: | IngressClassName | `${ingressclass_alb_name}` (existing) |
321: | Host | `app.<domain>` |
322: | Path | `/api` |
323: | Path Type | `Prefix` |
324: | Target Service | Backend ClusterIP service |
325: 
326: #### Frontend Ingress
327: 
328: | Setting | Value |
329: | --------- | ------- |
330: | IngressClassName | `${ingressclass_alb_name}` (existing) |
331: | Host | `app.<domain>` |
332: | Path | `/` |
333: | Path Type | `Prefix` |
334: | Target Service | Frontend ClusterIP service |
335: 
336: ### ALB Configuration
337: 
338: #### Cluster-Wide Settings (IngressClassParams)
339: 
340: These settings are configured once at the cluster level via the existing
341: `IngressClassParams` resource and inherited by all Ingresses:
342: 
343: | Setting | Description |
344: | --------- | ------------- |
345: | `scheme` | `internet-facing` |
346: | `ipAddressType` | `ipv4` |
347: | `group.name` | ALB group name (groups multiple Ingresses to single ALB) |
348: | `certificateARNs` | ACM certificate ARN for TLS termination |
349: 
350: #### Per-Ingress Annotations
351: 
352: Each Ingress specifies only per-Ingress settings via annotations:
353: 
354: ```yaml
355: alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
356: alb.ingress.kubernetes.io/target-type: "${app_alb_target_type}"
357: alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
358: alb.ingress.kubernetes.io/ssl-redirect: "${app_alb_ssl_redirect}"
359: ```
360: 
361: | Annotation | Variable | Description |
362: | ------------ | ---------- | ------------- |
363: | `load-balancer-name` | `${alb_load_balancer_name}` | Shared ALB name (same as OpenLDAP) |
364: | `target-type` | `${app_alb_target_type}` | Target type (default: `ip`) |
365: | `listen-ports` |  | HTTPS 443 only |
366: | `ssl-redirect` | `${app_alb_ssl_redirect}` | Redirect port (default: `443`) |
367: 
368: > [!NOTE]
369: >
370: > `group.name`, `scheme`, and `certificate-arn` are NOT specified in
371: > Ingress annotationsthey are inherited from `IngressClassParams`.
372: 
373: ### SMS Infrastructure Requirements (AWS SNS)
374: 
375: #### SNS Topic
376: 
377: | Requirement |
378: | ------------- |
379: | Create SNS topic for SMS notifications |
380: | Configure topic policy to allow IAM role to publish |
381: | Set display name for SMS sender identification |
382: 
383: #### IAM Role for IRSA (IAM Roles for Service Accounts)
384: 
385: | Requirement |
386: | ------------- |
387: | Create IAM role with trust policy for EKS OIDC provider |
388: | Scope trust to specific service account and namespace |
389: | Attach policy with SNS publish permissions |
390: 
391: #### IAM Policy Permissions
392: 
393: ```json
394: {
395:   "Version": "2012-10-17",
396:   "Statement": [
397:     {
398:       "Effect": "Allow",
399:       "Action": ["sns:Publish"],
400:       "Resource": "<SNS_TOPIC_ARN>"
401:     },
402:     {
403:       "Effect": "Allow",
404:       "Action": ["sns:Publish"],
405:       "Resource": "*",
406:       "Condition": {
407:         "StringEquals": { "sns:Protocol": "sms" }
408:       }
409:     },
410:     {
411:       "Effect": "Allow",
412:       "Action": [
413:         "sns:Subscribe",
414:         "sns:Unsubscribe",
415:         "sns:ListSubscriptionsByTopic"
416:       ],
417:       "Resource": "<SNS_TOPIC_ARN>"
418:     },
419:     {
420:       "Effect": "Allow",
421:       "Action": [
422:         "sns:CheckIfPhoneNumberIsOptedOut",
423:         "sns:OptInPhoneNumber"
424:       ],
425:       "Resource": "*"
426:     }
427:   ]
428: }
429: ```
430: 
431: #### VPC Endpoints (Required for Private Connectivity)
432: 
433: | Endpoint | Service | Purpose |
434: | ---------- | --------- | --------- |
435: | STS | `com.amazonaws.<region>.sts` | IRSA - pods assume IAM roles |
436: | SNS | `com.amazonaws.<region>.sns` | Send SMS without NAT gateway |
437: 
438: #### Service Account Configuration
439: 
440: ```yaml
441: apiVersion: v1
442: kind: ServiceAccount
443: metadata:
444:   name: ldap-2fa-backend
445:   namespace: 2fa-app
446:   annotations:
447:     eks.amazonaws.com/role-arn: <IAM_ROLE_ARN>
448: ```
449: 
450: ### Terraform Module: SNS
451: 
452: The SNS Terraform module (`application/modules/sns/`) creates:
453: 
454: | Resource | Description |
455: | ---------- | ------------- |
456: | `aws_sns_topic` | SNS topic for SMS |
457: | `aws_sns_topic_policy` | Topic policy for IAM role access |
458: | `aws_iam_role` | IAM role for IRSA |
459: | `aws_iam_role_policy` | SNS publish/subscribe permissions |
460: | `aws_sns_sms_preferences` | Account-level SMS settings (optional) |
461: 
462: #### Module Inputs
463: 
464: | Variable | Description | Default |
465: | ---------- | ------------- | --------- |
466: | `enable_sms_2fa` | Enable SMS 2FA resources | `false` |
467: | `sns_topic_name` | SNS topic name component | `2fa-sms` |
468: | `sns_display_name` | SMS sender display name | `2FA Verification` |
469: | `service_account_namespace` | K8s namespace | `2fa-app` |
470: | `service_account_name` | K8s service account | `ldap-2fa-backend` |
471: | `sms_sender_id` | SMS sender ID | `2FA` |
472: | `sms_type` | SMS type | `Transactional` |
473: | `sms_monthly_spend_limit` | Monthly SMS budget | `10` |
474: 
475: #### Module Outputs
476: 
477: | Output | Description |
478: | -------- | ------------- |
479: | `sns_topic_arn` | SNS topic ARN |
480: | `iam_role_arn` | IAM role ARN for IRSA |
481: | `service_account_annotation` | Annotation for K8s service account |
482: 
483: ## GitOps Requirements (ArgoCD)
484: 
485: ### ArgoCD Applications
486: 
487: | Application | Helm Chart Path | Namespace |
488: | ------------- | ----------------- | ----------- |
489: | `ldap-2fa-backend` | `application/backend/helm/ldap-2fa-backend` | `2fa-app` |
490: | `ldap-2fa-frontend` | `application/frontend/helm/ldap-2fa-frontend` | `2fa-app` |
491: 
492: ### Sync Configuration
493: 
494: | Setting | Value |
495: | --------- | ------- |
496: | Automated sync | Enabled |
497: | Self-heal | Enabled |
498: | Prune | Enabled |
499: 
500: ### Helm Values for SMS
501: 
502: The backend Helm chart must support these SMS-related values:
503: 
504: ```yaml
505: sms:
506:   enabled: true
507:   awsRegion: "us-east-1"
508:   snsTopicArn: ""
509:   senderId: "2FA"
510:   smsType: "Transactional"
511:   codeLength: 6
512:   codeExpirySeconds: 300
513:   messageTemplate: "Your verification code is: {code}. It expires in 5 minutes."
514: 
515: serviceAccountIAM:
516:   roleArn: ""  # From Terraform output
517: ```
518: 
519: ## CI/CD Requirements (GitHub Actions)
520: 
521: ### Backend Workflow
522: 
523: | Trigger | `application/backend/**` changes |
524: | --------- | ------------------------------- |
525: | Steps | 1. Build Docker image |
526: | | 2. Tag with commit SHA |
527: | | 3. Push to ECR |
528: | | 4. Update `values.yaml` with new image tag |
529: | | 5. Commit and push changes |
530: 
531: ### Frontend Workflow
532: 
533: | Trigger | `application/frontend/**` changes |
534: | --------- | ----------------------------------- |
535: | Steps | Same pattern as backend |
536: 
537: ### ECR Image Mirroring for Third-Party Images
538: 
539: > [!NOTE]
540: >
541: > **ECR Image Mirroring**: Third-party container images (OpenLDAP, PostgreSQL, Redis)
542: > are automatically mirrored from Docker Hub to ECR by the `mirror-images-to-ecr.sh`
543: > script before Terraform operations. This eliminates Docker Hub rate limiting
544: > and external dependencies. The script:
545: >
546: > - Checks if images exist in ECR (skips if already present)
547: > - Pulls images from Docker Hub
548: > - Tags and pushes to ECR with standardized tags
549: > - Runs automatically in `setup-application.sh` (local) and GitHub Actions workflows
550: >
551: > For details, see [ECR Image Mirroring](../PRD.md#ecr-image-mirroring) in the
552: > main PRD.
553: 
554: ## Security Requirements
555: 
556: | ID | Requirement |
557: | ---- | ------------- |
558: | SEC-01 | LDAP server must remain internal-only (ClusterIP, no public Ingress) |
559: | SEC-02 | Backend communicates with LDAP via internal Kubernetes DNS only |
560: | SEC-03 | TLS termination at ALB for all public traffic |
561: | SEC-04 | LDAP credentials stored in Kubernetes Secrets |
562: | SEC-05 | TOTP secrets must be securely generated and transmitted |
563: 
564: ### SMS Security Requirements
565: 
566: | ID | Requirement |
567: | ---- | ------------- |
568: | SEC-SMS-01 | Phone numbers must be validated (E.164 format) |
569: | SEC-SMS-02 | SMS codes must expire after configurable timeout |
570: | SEC-SMS-03 | Use constant-time comparison for code verification |
571: | SEC-SMS-04 | Implement rate limiting for SMS send requests |
572: | SEC-SMS-05 | Backend must use IRSA (no hardcoded AWS credentials) |
573: | SEC-SMS-06 | SNS access must go through VPC endpoint (no public internet) |
574: | SEC-SMS-07 | IAM role must be scoped to specific service account |
575: | SEC-SMS-08 | Mask phone numbers in API responses and logs |
576: 
577: ## Acceptance Criteria
578: 
579: ### Core Acceptance Criteria
580: 
581: | ID | Criterion |
582: | ---- | ----------- |
583: | AC-01 | `https://app.<domain>` loads the frontend UI |
584: | AC-02 | Enrollment flow displays a TOTP QR code scannable by Google Authenticator |
585: | AC-03 | Login succeeds only with correct LDAP password AND correct TOTP code |
586: | AC-04 | `curl -X POST https://app.<domain>/api/auth/login ...` works from outside the cluster |
587: | AC-05 | LDAP server is not accessible from outside the cluster |
588: | AC-06 | ArgoCD shows two healthy Applications |
589: | AC-07 | Code changes trigger automatic deployment via ArgoCD sync |
590: 
591: ### SMS Acceptance Criteria
592: 
593: | ID | Criterion |
594: | ---- | ----------- |
595: | AC-SMS-01 | `/api/mfa/methods` returns `["totp", "sms"]` when SMS is enabled |
596: | AC-SMS-02 | User can enroll with SMS by providing phone number |
597: | AC-SMS-03 | SMS verification code is received on enrolled phone |
598: | AC-SMS-04 | Login succeeds with correct LDAP password AND correct SMS code |
599: | AC-SMS-05 | Expired SMS codes are rejected |
600: | AC-SMS-06 | Invalid phone numbers are rejected during enrollment |
601: | AC-SMS-07 | SMS send button shows countdown timer |
602: | AC-SMS-08 | Backend uses VPC endpoint for SNS (no NAT gateway traffic) |
603: 
604: ## Dependencies
605: 
606: ### Existing Infrastructure (Prerequisites)
607: 
608: - EKS cluster with Auto Mode enabled
609: - EKS cluster with OIDC provider enabled (`enable_irsa = true`)
610: - ALB via IngressClass/IngressClassParams
611: - OpenLDAP stack-ha deployed
612: - Route53 hosted zone configured
613: - ACM certificate provisioned and validated
614: - ArgoCD EKS Capability module deployed
615: - ArgoCD Application module configured
616: - ECR repository (created in `backend_infra`) for all images, distinguished by tags
617: 
618: ### SMS-Specific Prerequisites
619: 
620: - VPC endpoint for STS (`enable_sts_endpoint = true` in `backend_infra`)
621: - VPC endpoint for SNS (`enable_sns_endpoint = true` in `backend_infra`)
622: - SNS Terraform module deployed (`enable_sms_2fa = true` in `application`)
623: - IAM role ARN configured in Helm values (`serviceAccountIAM.roleArn`)
624: 
625: ## Implementation Checklist
626: 
627: ### Core Implementation
628: 
629: - [ ] Create backend directory structure
630: - [ ] Implement backend Python API with `/api/*` endpoints
631: - [ ] Create backend Dockerfile
632: - [ ] Create backend Helm chart with Ingress (`/api`, order 10)
633: - [ ] Create frontend directory structure
634: - [ ] Implement frontend HTML/JS/CSS
635: - [ ] Create frontend Dockerfile
636: - [ ] Create frontend Helm chart with Ingress (`/`, order 20)
637: - [ ] Create Route53 A/ALIAS record for `app.<domain>`
638: - [ ] Configure ArgoCD Application for backend
639: - [ ] Configure ArgoCD Application for frontend
640: - [ ] Create GitHub Actions workflow for backend CI/CD
641: - [ ] Create GitHub Actions workflow for frontend CI/CD
642: - [ ] Verify end-to-end enrollment flow (TOTP)
643: - [ ] Verify end-to-end login flow (TOTP)
644: - [ ] Verify CLI access via API endpoint
645: 
646: ### SMS Implementation
647: 
648: - [ ] Create SNS Terraform module (`application/modules/sns/`)
649: - [ ] Add SMS variables to `application/variables.tf`
650: - [ ] Add SNS module invocation to `application/main.tf`
651: - [ ] Enable STS VPC endpoint in `backend_infra`
652: - [ ] Enable SNS VPC endpoint in `backend_infra`
653: - [ ] Enable IRSA on EKS cluster (`enable_irsa = true`)
654: - [ ] Create backend SMS client (`app/sms/client.py`)
655: - [ ] Add SMS configuration to backend `config.py`
656: - [ ] Update backend API routes for SMS support
657: - [ ] Add boto3 to backend `requirements.txt`
658: - [ ] Update backend Helm chart with SMS configuration
659: - [ ] Add IRSA annotation to service account template
660: - [ ] Update frontend with MFA method selection UI
661: - [ ] Update frontend with SMS phone input
662: - [ ] Update frontend with "Send SMS Code" button
663: - [ ] Create Kubernetes secret for LDAP password
664: - [ ] Configure Helm values with IAM role ARN
665: - [ ] Verify end-to-end SMS enrollment flow
666: - [ ] Verify end-to-end SMS login flow
667: - [ ] Verify SMS code expiration
668: - [ ] Verify VPC endpoint usage (no NAT traffic)
````

## File: application/set-k8s-env.sh
````bash
  1: set -e
  2: 
  3: cd "$(dirname "$0")"
  4: 
  5: # Colors for output (if not already defined by sourcing script)
  6: if [ -z "${RED:-}" ]; then
  7:     RED='\033[0;31m'
  8:     GREEN='\033[0;32m'
  9:     YELLOW='\033[1;33m'
 10:     NC='\033[0m' # No Color
 11: fi
 12: 
 13: # Function to print colored messages (if not already defined by sourcing script)
 14: if ! declare -f print_error > /dev/null; then
 15:     print_error() {
 16:         echo -e "${RED}ERROR:${NC} $1" >&2
 17:     }
 18: fi
 19: 
 20: if ! declare -f print_success > /dev/null; then
 21:     print_success() {
 22:         echo -e "${GREEN}SUCCESS:${NC} $1"
 23:     }
 24: fi
 25: 
 26: if ! declare -f print_info > /dev/null; then
 27:     print_info() {
 28:         echo -e "${YELLOW}INFO:${NC} $1"
 29:     }
 30: fi
 31: 
 32: echo "Using AWS credentials from environment variables"
 33: echo "Fetching cluster name from backend_infra Terraform state..."
 34: 
 35: 
 36: BACKEND_FILE="${BACKEND_FILE:-backend.hcl}"
 37: 
 38: 
 39: if [ ! -f "$BACKEND_FILE" ]; then
 40:     echo "ERROR: $BACKEND_FILE not found. Run ./setup-application.sh or the application_infra_provisioning GitHub workflow first."
 41:     exit 1
 42: fi
 43: 
 44: 
 45: BACKEND_BUCKET=$(grep 'bucket' "$BACKEND_FILE" | sed 's/.*"\(.*\)".*/\1/')
 46: BACKEND_REGION=$(grep 'region' "$BACKEND_FILE" | sed 's/.*"\(.*\)".*/\1/')
 47: BACKEND_KEY="backend_state/terraform.tfstate"
 48: 
 49: echo "Backend S3 bucket: $BACKEND_BUCKET"
 50: echo "Backend region: $BACKEND_REGION"
 51: 
 52: 
 53: WORKSPACE=$(terraform workspace show 2>/dev/null || echo "default")
 54: echo "Terraform workspace: $WORKSPACE"
 55: 
 56: 
 57: if [ "$WORKSPACE" = "default" ]; then
 58:     STATE_KEY="$BACKEND_KEY"
 59: else
 60:     STATE_KEY="env:/$WORKSPACE/$BACKEND_KEY"
 61: fi
 62: 
 63: echo "Fetching cluster name from s3://$BACKEND_BUCKET/$STATE_KEY"
 64: 
 65: 
 66: CLUSTER_NAME=$(aws s3 cp "s3://$BACKEND_BUCKET/$STATE_KEY" - 2>/dev/null | jq -r '.outputs.cluster_name.value' || echo "")
 67: 
 68: if [ -z "$CLUSTER_NAME" ] || [ "$CLUSTER_NAME" = "null" ]; then
 69:     echo "ERROR: Could not retrieve cluster name from backend_infra state."
 70:     echo "Make sure backend_infra has been deployed and outputs cluster_name."
 71:     exit 1
 72: fi
 73: 
 74: echo "Cluster name: $CLUSTER_NAME"
 75: 
 76: 
 77: 
 78: 
 79: AWS_REGION="${AWS_REGION:-$BACKEND_REGION}"
 80: 
 81: if [ -z "$DEPLOYMENT_ROLE_ARN" ]; then
 82:     print_error "DEPLOYMENT_ROLE_ARN is not set. Run ./setup-application.sh first."
 83:     exit 1
 84: fi
 85: 
 86: if [ -z "$EXTERNAL_ID" ]; then
 87:     print_error "EXTERNAL_ID is not set. Run ./setup-application.sh first."
 88:     exit 1
 89: fi
 90: 
 91: print_info "Assuming Deployment Account role: $DEPLOYMENT_ROLE_ARN"
 92: print_info "Region: $AWS_REGION"
 93: 
 94: DEPLOYMENT_ROLE_SESSION_NAME="setup-application-deployment-$(date +%s)"
 95: 
 96: 
 97: DEPLOYMENT_ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
 98:     --role-arn "$DEPLOYMENT_ROLE_ARN" \
 99:     --role-session-name "$DEPLOYMENT_ROLE_SESSION_NAME" \
100:     --external-id "$EXTERNAL_ID" \
101:     --region "$AWS_REGION" 2>&1)
102: 
103: if [ $? -ne 0 ]; then
104:     print_error "Failed to assume Deployment Account role: $DEPLOYMENT_ASSUME_ROLE_OUTPUT"
105:     exit 1
106: fi
107: 
108: 
109: if command -v jq &> /dev/null; then
110:     export AWS_ACCESS_KEY_ID=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
111:     export AWS_SECRET_ACCESS_KEY=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
112:     export AWS_SESSION_TOKEN=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
113: else
114: 
115:     export AWS_ACCESS_KEY_ID=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
116:     export AWS_SECRET_ACCESS_KEY=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
117:     export AWS_SESSION_TOKEN=$(echo "$DEPLOYMENT_ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
118: fi
119: 
120: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
121:     print_error "Failed to extract Deployment Account credentials from assume-role output."
122:     print_error "Output was: $DEPLOYMENT_ASSUME_ROLE_OUTPUT"
123:     exit 1
124: fi
125: 
126: 
127: DEPLOYMENT_CALLER_ARN=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
128: if [ $? -ne 0 ]; then
129:     print_error "Failed to verify Deployment Account role credentials: $DEPLOYMENT_CALLER_ARN"
130:     exit 1
131: fi
132: 
133: print_success "Successfully assumed Deployment Account role"
134: print_info "Deployment Account role identity: $DEPLOYMENT_CALLER_ARN"
135: echo ""
136: 
137: # Use VARIABLES_FILE from environment if available, otherwise default to variables.tfvars
138: VARIABLES_FILE="${VARIABLES_FILE:-variables.tfvars}"
139: 
140: # Update variables.tfvars
141: print_info "Updating ${VARIABLES_FILE} with selected values..."
142: 
143: if [ ! -f "$VARIABLES_FILE" ]; then
144:     print_error "Variables file '${VARIABLES_FILE}' not found."
145:     exit 1
146: fi
147: 
148: 
149: if [[ "$OSTYPE" == "darwin"* ]]; then
150: 
151:     sed -i '' "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT:-prod}\"|" "$VARIABLES_FILE"
152:     sed -i '' "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
153:     # Add or update deployment_account_role_arn
154:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
155:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
156:     else
157:         sed -i '' "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
158:     fi
159:     # Add or update deployment_account_external_id
160:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
161:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
162:     else
163:         sed -i '' "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
164:     fi
165:     # Add or update state_account_role_arn (if provided)
166:     if [ -n "${STATE_ACCOUNT_ROLE_ARN:-}" ]; then
167:         if ! grep -q "^state_account_role_arn" "$VARIABLES_FILE"; then
168:             echo "state_account_role_arn = \"${STATE_ACCOUNT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
169:         else
170:             sed -i '' "s|^state_account_role_arn[[:space:]]*=.*|state_account_role_arn = \"${STATE_ACCOUNT_ROLE_ARN}\"|" "$VARIABLES_FILE"
171:         fi
172:     fi
173: else
174:     # Linux sed
175:     sed -i "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT:-prod}\"|" "$VARIABLES_FILE"
176:     sed -i "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
177:     # Add or update deployment_account_role_arn
178:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
179:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
180:     else
181:         sed -i "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
182:     fi
183:     # Add or update deployment_account_external_id
184:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
185:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
186:     else
187:         sed -i "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
188:     fi
189:     # Add or update state_account_role_arn (if provided)
190:     if [ -n "${STATE_ACCOUNT_ROLE_ARN:-}" ]; then
191:         if ! grep -q "^state_account_role_arn" "$VARIABLES_FILE"; then
192:             echo "state_account_role_arn = \"${STATE_ACCOUNT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
193:         else
194:             sed -i "s|^state_account_role_arn[[:space:]]*=.*|state_account_role_arn = \"${STATE_ACCOUNT_ROLE_ARN}\"|" "$VARIABLES_FILE"
195:         fi
196:     fi
197: fi
198: 
199: print_success "Updated ${VARIABLES_FILE}"
200: echo ""
201: print_info "  - env: ${ENVIRONMENT:-prod}"
202: print_info "  - region: ${AWS_REGION}"
203: echo ""
204: 
205: # Get cluster endpoint
206: # IMPORTANT: This command must use credentials for the deployment account where the EKS cluster exists
207: # Credentials are set via environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN)
208: echo "Fetching cluster endpoint..."
209: KUBERNETES_MASTER=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.endpoint' --output text 2>/dev/null || echo "")
210: 
211: if [ -z "$KUBERNETES_MASTER" ]; then
212:     print_error "Could not retrieve cluster endpoint. Make sure the cluster exists and you have AWS credentials configured."
213:     exit 1
214: fi
215: 
216: echo "Kubernetes Master: $KUBERNETES_MASTER"
217: 
218: 
219: export KUBERNETES_MASTER
220: export KUBE_CONFIG_PATH="${KUBE_CONFIG_PATH:-$HOME/.kube/config}"
221: 
222: 
223: 
224: 
225: print_info "Updating kubeconfig for cluster: $CLUSTER_NAME"
226: print_info "Region: $AWS_REGION"
227: 
228: 
229: KUBE_CONFIG_DIR=$(dirname "$KUBE_CONFIG_PATH")
230: if [ ! -d "$KUBE_CONFIG_DIR" ]; then
231:     mkdir -p "$KUBE_CONFIG_DIR"
232:     print_info "Created kubeconfig directory: $KUBE_CONFIG_DIR"
233: fi
234: 
235: 
236: 
237: 
238: print_info "Configuring kubeconfig with AWS CLI exec plugin for dynamic authentication..."
239: 
240: 
241: CLUSTER_CA_DATA=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.certificateAuthority.data' --output text 2>/dev/null)
242: 
243: if [ -z "$CLUSTER_CA_DATA" ]; then
244:     print_error "Failed to retrieve cluster certificate authority data"
245:     exit 1
246: fi
247: 
248: 
249: cat > "$KUBE_CONFIG_PATH" <<'EOF'
250: apiVersion: v1
251: kind: Config
252: clusters:
253: - cluster:
254:     certificate-authority-data: CLUSTER_CA_DATA_PLACEHOLDER
255:     server: KUBERNETES_MASTER_PLACEHOLDER
256:   name: CLUSTER_NAME_PLACEHOLDER
257: contexts:
258: - context:
259:     cluster: CLUSTER_NAME_PLACEHOLDER
260:     user: CLUSTER_NAME_PLACEHOLDER
261:   name: CLUSTER_NAME_PLACEHOLDER
262: current-context: CLUSTER_NAME_PLACEHOLDER
263: users:
264: - name: CLUSTER_NAME_PLACEHOLDER
265:   user:
266:     exec:
267:       apiVersion: client.authentication.k8s.io/v1beta1
268:       command: aws
269:       args:
270:       - eks
271:       - get-token
272:       - --cluster-name
273:       - CLUSTER_NAME_PLACEHOLDER
274:       - --region
275:       - AWS_REGION_PLACEHOLDER
276: 
277: 
278: 
279:       env: null
280: EOF
281: 
282: 
283: if [[ "$OSTYPE" == "darwin"* ]]; then
284: 
285:     sed -i '' "s|CLUSTER_CA_DATA_PLACEHOLDER|$CLUSTER_CA_DATA|g" "$KUBE_CONFIG_PATH"
286:     sed -i '' "s|KUBERNETES_MASTER_PLACEHOLDER|$KUBERNETES_MASTER|g" "$KUBE_CONFIG_PATH"
287:     sed -i '' "s|CLUSTER_NAME_PLACEHOLDER|$CLUSTER_NAME|g" "$KUBE_CONFIG_PATH"
288:     sed -i '' "s|AWS_REGION_PLACEHOLDER|$AWS_REGION|g" "$KUBE_CONFIG_PATH"
289: else
290: 
291:     sed -i "s|CLUSTER_CA_DATA_PLACEHOLDER|$CLUSTER_CA_DATA|g" "$KUBE_CONFIG_PATH"
292:     sed -i "s|KUBERNETES_MASTER_PLACEHOLDER|$KUBERNETES_MASTER|g" "$KUBE_CONFIG_PATH"
293:     sed -i "s|CLUSTER_NAME_PLACEHOLDER|$CLUSTER_NAME|g" "$KUBE_CONFIG_PATH"
294:     sed -i "s|AWS_REGION_PLACEHOLDER|$AWS_REGION|g" "$KUBE_CONFIG_PATH"
295: fi
296: 
297: print_success "Kubeconfig configured with exec plugin"
298: print_info "Kubeconfig path: $KUBE_CONFIG_PATH"
299: print_info "kubectl will dynamically fetch tokens using current AWS credentials"
300: 
301: echo ""
302: echo " Environment variables set successfully!"
303: echo ""
304: echo "KUBERNETES_MASTER=$KUBERNETES_MASTER"
305: echo "KUBE_CONFIG_PATH=$KUBE_CONFIG_PATH"
306: echo ""
307: echo "To use these variables in your current shell, run:"
308: echo "  source ./set-k8s-env.sh"
````

## File: backend_infra/modules/endpoints/README.md
````markdown
  1: # VPC Endpoints Module
  2: 
  3: This module creates VPC endpoints (PrivateLink) to enable secure access to AWS
  4: services from EKS nodes without requiring internet gateway access.
  5: 
  6: ## Purpose
  7: 
  8: The endpoints module enables secure, private communication between EKS nodes and
  9: AWS services, allowing:
 10: 
 11: - **SSM Session Manager** access to nodes without public IPs
 12: - **IRSA (IAM Roles for Service Accounts)** for pods to assume IAM roles
 13: - **SMS 2FA** via SNS for sending verification codes
 14: - **No internet gateway dependency** for AWS service communication
 15: 
 16: ## Key Features
 17: 
 18: ### VPC Endpoints Created
 19: 
 20: The module creates the following VPC endpoints:
 21: 
 22: #### SSM Endpoints (Always Enabled)
 23: 
 24: 1. **SSM Endpoint** (`com.amazonaws.<region>.ssm`)
 25:    - Core Systems Manager service endpoint
 26: 
 27: 2. **SSM Messages Endpoint** (`com.amazonaws.<region>.ssmmessages`)
 28:    - Enables Session Manager message passing
 29: 
 30: 3. **EC2 Messages Endpoint** (`com.amazonaws.<region>.ec2messages`)
 31:    - Enables EC2 instance messaging for SSM agent communication
 32: 
 33: #### STS Endpoint (Optional, Default: Enabled)
 34: 
 35: 1. **STS Endpoint** (`com.amazonaws.<region>.sts`)
 36:    - **Required for IRSA** (IAM Roles for Service Accounts)
 37:    - Allows pods to call `sts:AssumeRoleWithWebIdentity`
 38:    - Enable with `enable_sts_endpoint = true`
 39: 
 40: #### SNS Endpoint (Optional, Default: Disabled)
 41: 
 42: 1. **SNS Endpoint** (`com.amazonaws.<region>.sns`)
 43:    - **Required for SMS 2FA** functionality
 44:    - Allows pods to send SMS via SNS
 45:    - Enable with `enable_sns_endpoint = true`
 46: 
 47: ### Security Configuration
 48: 
 49: - **Security Group**: Dedicated security group for VPC endpoints
 50: - **Ingress Rules**:
 51:   - Allows HTTPS (port 443) from EKS node security group
 52:   - Allows HTTPS (port 443) from VPC CIDR (for pods)
 53: - **Egress Rules**: Allows all outbound traffic
 54: - **Private DNS**: Enabled for seamless service discovery
 55: 
 56: ### Network Configuration
 57: 
 58: - **Endpoint Type**: Interface endpoints (PrivateLink)
 59: - **Subnet Placement**: Deployed in private subnets
 60: - **High Availability**: Endpoints are created across multiple availability zones
 61: 
 62: ## Variables
 63: 
 64: | Variable | Description | Required | Default |
 65: | ---------- | ------------- | ---------- | --------- |
 66: | `env` | Deployment environment (e.g., prod, dev) | Yes | - |
 67: | `region` | AWS region | Yes | - |
 68: | `prefix` | Prefix added to all resource names | Yes | - |
 69: | `vpc_id` | ID of the VPC where endpoints will be created | Yes | - |
 70: | `vpc_cidr` | CIDR block of the VPC (for security group rules) | Yes | - |
 71: | `private_subnets` | List of private subnet IDs for endpoint placement | Yes | - |
 72: | `endpoint_sg_name` | Name for the VPC endpoint security group | Yes | - |
 73: | `node_security_group_id` | Security group ID of EKS nodes | Yes | - |
 74: | `enable_sts_endpoint` | Whether to create STS endpoint (for IRSA) | No | `true` |
 75: | `enable_sns_endpoint` | Whether to create SNS endpoint (for SMS 2FA) | No | `false` |
 76: | `tags` | Map of tags to apply to resources | Yes | - |
 77: 
 78: ## Usage Example
 79: 
 80: ```hcl
 81: module "endpoints" {
 82:   source                 = "./modules/endpoints"
 83:   env                    = var.env
 84:   region                 = var.region
 85:   prefix                 = var.prefix
 86:   vpc_id                 = module.vpc.vpc_id
 87:   vpc_cidr               = var.vpc_cidr
 88:   private_subnets        = module.vpc.private_subnets
 89:   endpoint_sg_name       = var.endpoint_sg_name
 90:   node_security_group_id = module.eks.node_security_group_id
 91:   enable_sts_endpoint    = true   # Required for IRSA
 92:   enable_sns_endpoint    = true   # Required for SMS 2FA
 93:   tags                   = local.tags
 94: }
 95: ```
 96: 
 97: ## IRSA (IAM Roles for Service Accounts)
 98: 
 99: When `enable_sts_endpoint = true`, pods can assume IAM roles using service accounts:
100: 
101: 1. The EKS cluster must have OIDC provider enabled
102: (`enable_irsa = true` in EKS module)
103: 2. Create an IAM role with a trust policy for the service account
104: 3. Annotate the Kubernetes service account with the IAM role ARN
105: 4. Pods using that service account can call AWS APIs
106: 
107: Example service account:
108: 
109: ```yaml
110: apiVersion: v1
111: kind: ServiceAccount
112: metadata:
113:   name: my-app
114:   namespace: my-namespace
115:   annotations:
116:     eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/my-role
117: ```
118: 
119: ## SNS for SMS 2FA
120: 
121: When `enable_sns_endpoint = true`, pods can send SMS via SNS:
122: 
123: 1. Enable the SNS VPC endpoint
124: 2. Create IAM role with SNS publish permissions
125: 3. Configure IRSA for the backend service account
126: 4. Backend can call `sns.publish()` to send SMS
127: 
128: ## Outputs
129: 
130: | Output | Description |
131: | -------- | ------------- |
132: | `vpc_endpoint_sg_id` | Security group ID for VPC endpoints |
133: | `vpc_endpoint_ssm_id` | VPC endpoint ID for SSM |
134: | `vpc_endpoint_ssmmessages_id` | VPC endpoint ID for SSM Messages |
135: | `vpc_endpoint_ec2messages_id` | VPC endpoint ID for EC2 Messages |
136: | `vpc_endpoint_sts_id` | VPC endpoint ID for STS (null if disabled) |
137: | `vpc_endpoint_sns_id` | VPC endpoint ID for SNS (null if disabled) |
138: | `vpc_endpoint_ids` | List of all enabled VPC endpoint IDs |
139: 
140: ## Cost Considerations
141: 
142: - Interface endpoints incur hourly charges per endpoint per availability zone
143: - Data transfer charges apply for data processed through endpoints
144: - Estimated monthly cost per endpoint: ~$7-10/AZ
145: - Consider whether you need SNS endpoint (can use NAT gateway instead)
146: 
147: ## Accessing Nodes via SSM
148: 
149: After deployment, you can access EKS nodes using AWS Systems Manager Session
150: Manager:
151: 
152: ```bash
153: aws ssm start-session --target <instance-id>
154: ```
155: 
156: No SSH keys or bastion hosts required!
157: 
158: ## References
159: 
160: - [AWS VPC Endpoints](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html)
161: - [IRSA Documentation](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html)
162: - [AWS SNS SMS](https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html)
163: - [VPC Endpoint Pricing](https://aws.amazon.com/privatelink/pricing/)
````

## File: docs/dark-theme.css
````css
  1: * {
  2:     margin: 0;
  3:     padding: 0;
  4:     box-sizing: border-box;
  5: }
  6: 
  7: :root {
  8:     --primary-color: #58a6ff;
  9:     --primary-hover: #79c0ff;
 10:     --bg-color: #0d1117;
 11:     --text-color: #c9d1d9;
 12:     --border-color: #30363d;
 13:     --code-bg: #161b22;
 14:     --nav-bg: #161b22;
 15:     --nav-shadow: rgba(0, 0, 0, 0.5);
 16:     --section-bg: #161b22;
 17:     --link-color: #58a6ff;
 18: }
 19: 
 20: body {
 21:     font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
 22:     line-height: 1.6;
 23:     color: var(--text-color);
 24:     background-color: var(--bg-color);
 25:     padding-top: 80px;
 26: }
 27: 
 28: 
 29: .navbar {
 30:     position: fixed;
 31:     top: 0;
 32:     left: 0;
 33:     right: 0;
 34:     background-color: var(--nav-bg);
 35:     border-bottom: 1px solid var(--border-color);
 36:     box-shadow: 0 2px 4px var(--nav-shadow);
 37:     z-index: 1000;
 38:     padding: 5px 20px;
 39: }
 40: 
 41: .nav-container {
 42:     max-width: 1200px;
 43:     margin: 0 auto;
 44:     padding: 0;
 45:     display: flex;
 46:     justify-content: space-between;
 47:     align-items: center;
 48: }
 49: 
 50: .nav-logo {
 51:     display: flex;
 52:     align-items: center;
 53:     font-size: 18px;
 54:     font-weight: 600;
 55:     color: var(--text-color);
 56:     text-decoration: none;
 57:     padding: 0;
 58:     margin-right: 20px;
 59: }
 60: 
 61: .nav-menu {
 62:     display: flex;
 63:     list-style: none;
 64:     gap: 10px;
 65:     align-items: center;
 66:     padding: 0;
 67: }
 68: 
 69: .nav-menu li {
 70:     display: flex;
 71:     align-items: center;
 72:     padding: 10px 12px;
 73: }
 74: 
 75: .nav-menu a {
 76:     display: flex;
 77:     align-items: center;
 78:     color: var(--text-color);
 79:     text-decoration: none;
 80:     font-size: 14px;
 81:     transition: color 0.2s;
 82:     border-bottom: 2px solid transparent;
 83: }
 84: 
 85: .nav-menu a:hover {
 86:     color: var(--primary-color);
 87:     border-bottom-color: var(--primary-color);
 88: }
 89: 
 90: .nav-menu a.active {
 91:     color: var(--primary-color);
 92:     border-bottom-color: var(--primary-color);
 93: }
 94: 
 95: .mobile-menu-toggle {
 96:     display: none;
 97:     background: none;
 98:     border: none;
 99:     font-size: 24px;
100:     cursor: pointer;
101:     padding: 10px;
102:     color: var(--text-color);
103: }
104: 
105: 
106: .theme-toggle {
107:     background: none;
108:     border: 1px solid var(--border-color);
109:     border-radius: 6px;
110:     color: var(--text-color);
111:     cursor: pointer;
112:     font-size: 20px;
113:     padding: 4px 10px;
114:     margin-left: 10px;
115:     transition: all 0.2s;
116:     display: flex;
117:     align-items: center;
118:     justify-content: center;
119: }
120: 
121: .theme-toggle:hover {
122:     background-color: var(--section-bg);
123:     border-color: var(--primary-color);
124:     color: var(--primary-color);
125: }
126: 
127: .theme-toggle:focus {
128:     outline: 2px solid var(--primary-color);
129:     outline-offset: 2px;
130: }
131: 
132: .theme-toggle .icon {
133:     display: inline-block;
134:     transition: transform 0.3s;
135: }
136: 
137: .theme-toggle .icon.hidden {
138:     display: none;
139: }
140: 
141: 
142: .hero {
143:     color: var(--text-color);
144:     padding: 60px 20px 0 20px;
145:     text-align: center;
146: }
147: 
148: .hero h1 {
149:     font-size: 2.5em;
150:     margin-bottom: 20px;
151:     font-weight: 600;
152:     color: var(--text-color);
153: }
154: 
155: 
156: h1 {
157:     font-size: 2.5em;
158:     font-weight: 600;
159: }
160: 
161: h2 {
162:     font-size: 2em;
163:     font-weight: 600;
164: }
165: 
166: h3 {
167:     font-size: 1.5em;
168:     font-weight: 600;
169: }
170: 
171: h4 {
172:     font-size: 1.25em;
173:     font-weight: 600;
174: }
175: 
176: h5 {
177:     font-size: 1.1em;
178:     font-weight: 600;
179: }
180: 
181: .hero p {
182:     font-size: 1.2em;
183:     margin-bottom: 30px;
184:     opacity: 0.95;
185:     color: var(--text-color);
186: }
187: 
188: .hero-content {
189:     max-width: 1200px;
190:     margin: 0 auto;
191: }
192: 
193: .hero-banner {
194:     max-width: 100%;
195:     height: auto;
196:     margin-top: 30px;
197:     border-radius: 8px;
198:     box-shadow: 0 4px 6px rgba(0, 0, 0, 0.5);
199:     filter: brightness(0.9);
200: }
201: 
202: 
203: section {
204:     max-width: 1200px;
205:     margin: 0 auto;
206:     padding: 40px 20px 0 20px;
207:     scroll-margin-top: 100px;
208: }
209: 
210: section:last-child {
211:     padding-bottom: 40px;
212: }
213: 
214: section h2 {
215:     font-size: 2em;
216:     font-weight: 600;
217:     margin-bottom: 20px;
218:     padding-bottom: 10px;
219:     border-bottom: 2px solid var(--border-color);
220:     color: var(--text-color);
221: }
222: 
223: section h3 {
224:     font-size: 1.5em;
225:     font-weight: 600;
226:     margin-top: 30px;
227:     margin-bottom: 15px;
228:     color: var(--text-color);
229: }
230: 
231: section h4 {
232:     font-size: 1.25em;
233:     font-weight: 600;
234:     margin-top: 20px;
235:     margin-bottom: 10px;
236:     color: var(--text-color);
237: }
238: 
239: section h5 {
240:     font-size: 1.1em;
241:     font-weight: 600;
242:     margin-top: 15px;
243:     margin-bottom: 8px;
244:     color: var(--text-color);
245: }
246: 
247: 
248: .card {
249:     background: var(--section-bg);
250:     border: 1px solid var(--border-color);
251:     border-radius: 6px;
252:     padding: 20px;
253:     margin-bottom: 20px;
254:     box-shadow: 0 1px 3px rgba(0, 0, 0, 0.3);
255: }
256: 
257: .card h3 {
258:     margin-top: 0;
259:     color: var(--primary-color);
260: }
261: 
262: 
263: ul, ol {
264:     list-style-position: inside;
265: }
266: 
267: ul ul, ol ul {
268:     padding-left: 20px;
269: }
270: 
271: li p {
272:     padding-left: 20px;
273:     margin-top: 15px;
274: }
275: 
276: 
277: a {
278:     color: var(--link-color);
279:     text-decoration: none;
280: }
281: 
282: a:hover {
283:     text-decoration: underline;
284:     color: var(--primary-hover);
285: }
286: 
287: 
288: p {
289:     margin-bottom: 15px;
290: }
291: 
292: #architecture p {
293:     margin-top: 15px;
294: }
295: 
296: #architecture p:first-child {
297:     margin-top: 0;
298: }
299: 
300: p:last-child {
301:     margin-bottom: 0;
302: }
303: 
304: .deployment-card p:last-child {
305:     margin-top: 15px;
306: }
307: 
308: #security p:last-child, #getting-started p:last-child {
309:     margin-top: 15px;
310: }
311: 
312: 
313: code {
314:     background-color: var(--code-bg);
315:     padding: 2px 6px;
316:     border-radius: 3px;
317:     font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
318:     font-size: 0.9em;
319:     color: #f85149;
320:     border: 1px solid var(--border-color);
321: }
322: 
323: pre {
324:     background-color: var(--code-bg);
325:     padding: 16px;
326:     border-radius: 6px;
327:     overflow-x: auto;
328:     margin-bottom: 15px;
329:     border: 1px solid var(--border-color);
330: }
331: 
332: pre code {
333:     background: none;
334:     padding: 0;
335:     border: none;
336:     color: var(--text-color);
337: }
338: 
339: 
340: table {
341:     width: 100%;
342:     border-collapse: collapse;
343:     margin-bottom: 20px;
344: }
345: 
346: table th, table td {
347:     padding: 12px;
348:     text-align: left;
349:     border: 1px solid var(--border-color);
350:     color: var(--text-color);
351: }
352: 
353: table th {
354:     background-color: var(--primary-color);
355:     color: #0d1117;
356:     font-weight: 600;
357: }
358: 
359: table tbody tr:nth-child(even) {
360:     background-color: var(--section-bg);
361: }
362: 
363: table tbody tr:hover {
364:     background-color: rgba(88, 166, 255, 0.1);
365: }
366: 
367: 
368: .deployment-options {
369:     display: grid;
370:     grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
371:     gap: 20px;
372:     margin-top: 20px;
373: }
374: 
375: .deployment-card {
376:     background: var(--section-bg);
377:     border: 2px solid var(--border-color);
378:     border-radius: 8px;
379:     padding: 25px;
380: }
381: 
382: .deployment-card h4 {
383:     margin-top: 0;
384:     color: var(--primary-color);
385: }
386: 
387: .deployment-card p,
388: .deployment-card li {
389:     color: var(--text-color);
390: }
391: 
392: .deployment-card p {
393:     margin-top: 15px;
394: }
395: 
396: 
397: .doc-grid {
398:     display: grid;
399:     grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
400:     gap: 20px;
401:     margin-top: 20px;
402: }
403: 
404: .doc-item {
405:     background: var(--section-bg);
406:     border: 1px solid var(--border-color);
407:     border-radius: 6px;
408:     padding: 15px;
409:     transition: transform 0.2s, box-shadow 0.2s, border-color 0.2s;
410: }
411: 
412: .doc-item:hover {
413:     transform: translateY(-2px);
414:     box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
415:     border-color: var(--primary-color);
416: }
417: 
418: .doc-item a {
419:     font-weight: 500;
420:     display: block;
421:     margin-bottom: 8px;
422:     color: var(--link-color);
423: }
424: 
425: .doc-item a:hover {
426:     color: var(--primary-hover);
427: }
428: 
429: .doc-item p {
430:     font-size: 0.9em;
431:     color: #8b949e;
432:     margin: 0;
433: }
434: 
435: 
436: .badge {
437:     display: inline-block;
438:     padding: 4px 8px;
439:     background-color: var(--primary-color);
440:     color: #0d1117;
441:     border-radius: 3px;
442:     font-size: 0.8em;
443:     font-weight: 600;
444:     margin-left: 8px;
445: }
446: 
447: 
448: footer {
449:     background-color: var(--section-bg);
450:     border-top: 1px solid var(--border-color);
451:     padding: 30px 20px;
452:     text-align: center;
453:     color: #8b949e;
454: }
455: 
456: 
457: @media (max-width: 768px) {
458:     .mobile-menu-toggle {
459:         display: block;
460:     }
461: 
462:     .nav-menu {
463:         position: fixed;
464:         left: -100%;
465:         top: 60px;
466:         flex-direction: column;
467:         background-color: var(--nav-bg);
468:         width: 100%;
469:         text-align: center;
470:         transition: 0.3s;
471:         box-shadow: 0 10px 27px rgba(0, 0, 0, 0.3);
472:         padding: 20px 0;
473:         border-bottom: 1px solid var(--border-color);
474:     }
475: 
476:     .nav-menu.active {
477:         left: 0;
478:     }
479: 
480:     .nav-menu li {
481:         width: 100%;
482:     }
483: 
484:     .nav-menu a {
485:         padding: 15px;
486:         border-bottom: none;
487:         border-left: 3px solid transparent;
488:     }
489: 
490:     .nav-menu a:hover,
491:     .nav-menu a.active {
492:         border-left-color: var(--primary-color);
493:         border-bottom-color: transparent;
494:     }
495: 
496:     .theme-toggle {
497:         margin-left: 0;
498:         margin-top: 10px;
499:     }
500: 
501:     .hero h1 {
502:         font-size: 2em;
503:     }
504: 
505:     .hero p {
506:         font-size: 1em;
507:     }
508: 
509:     .deployment-options {
510:         grid-template-columns: 1fr;
511:     }
512: 
513:     .doc-grid {
514:         grid-template-columns: 1fr;
515:     }
516: 
517:     section h2 {
518:         font-size: 1.5em;
519:     }
520: 
521:     section h3 {
522:         font-size: 1.3em;
523:     }
524: 
525:     section h4 {
526:         font-size: 1.15em;
527:     }
528: 
529:     section h5 {
530:         font-size: 1.05em;
531:     }
532: }
533: 
534: 
535: html {
536:     scroll-behavior: smooth;
537: }
538: 
539: 
540: .scroll-to-top {
541:     position: fixed;
542:     bottom: 30px;
543:     right: 30px;
544:     width: 50px;
545:     height: 50px;
546:     border-radius: 50%;
547:     background-color: rgba(88, 166, 255, 0.15);
548:     backdrop-filter: blur(8px);
549:     -webkit-backdrop-filter: blur(8px);
550:     border: 2px solid rgba(88, 166, 255, 0.3);
551:     color: var(--primary-color);
552:     cursor: pointer;
553:     display: flex;
554:     align-items: center;
555:     justify-content: center;
556:     z-index: 999;
557:     opacity: 0;
558:     visibility: hidden;
559:     pointer-events: none;
560:     transition: opacity 0.3s ease, visibility 0.3s ease, transform 0.3s ease, background-color 0.3s ease, border-color 0.3s ease;
561:     box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
562: }
563: 
564: .scroll-to-top.visible {
565:     opacity: 1;
566:     visibility: visible;
567:     pointer-events: auto;
568: }
569: 
570: .scroll-to-top:hover {
571:     background-color: rgba(88, 166, 255, 0.25);
572:     border-color: rgba(88, 166, 255, 0.5);
573:     transform: translateY(-3px);
574:     box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
575: }
576: 
577: .scroll-to-top:active {
578:     transform: translateY(-1px);
579: }
580: 
581: .scroll-to-top svg {
582:     width: 24px;
583:     height: 24px;
584: }
585: 
586: @media (max-width: 768px) {
587:     .scroll-to-top {
588:         bottom: 20px;
589:         right: 20px;
590:         width: 45px;
591:         height: 45px;
592:     }
593:     .scroll-to-top svg {
594:         width: 20px;
595:         height: 20px;
596:     }
597: }
````

## File: docs/light-theme.css
````css
  1: * {
  2:     margin: 0;
  3:     padding: 0;
  4:     box-sizing: border-box;
  5: }
  6: 
  7: :root {
  8:     --primary-color: #0366d6;
  9:     --primary-hover: #0256c2;
 10:     --bg-color: #ffffff;
 11:     --text-color: #24292e;
 12:     --border-color: #e1e4e8;
 13:     --code-bg: #f6f8fa;
 14:     --nav-bg: #ffffff;
 15:     --nav-shadow: rgba(0, 0, 0, 0.1);
 16:     --section-bg: #fafbfc;
 17:     --link-color: #0366d6;
 18: }
 19: 
 20: body {
 21:     font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
 22:     line-height: 1.6;
 23:     color: var(--text-color);
 24:     background-color: var(--bg-color);
 25:     padding-top: 80px;
 26: }
 27: 
 28: 
 29: .navbar {
 30:     position: fixed;
 31:     top: 0;
 32:     left: 0;
 33:     right: 0;
 34:     background-color: var(--nav-bg);
 35:     border-bottom: 1px solid var(--border-color);
 36:     box-shadow: 0 2px 4px var(--nav-shadow);
 37:     z-index: 1000;
 38:     padding: 5px 20px;
 39: }
 40: 
 41: .nav-container {
 42:     max-width: 1200px;
 43:     margin: 0 auto;
 44:     padding: 0;
 45:     display: flex;
 46:     justify-content: space-between;
 47:     align-items: center;
 48: }
 49: 
 50: .nav-logo {
 51:     display: flex;
 52:     align-items: center;
 53:     font-size: 18px;
 54:     font-weight: 600;
 55:     color: var(--text-color);
 56:     text-decoration: none;
 57:     padding: 0;
 58:     margin-right: 20px;
 59: }
 60: 
 61: .nav-menu {
 62:     display: flex;
 63:     list-style: none;
 64:     gap: 10px;
 65:     align-items: center;
 66:     padding: 0;
 67: }
 68: 
 69: .nav-menu li {
 70:     display: flex;
 71:     align-items: center;
 72:     padding: 10px 12px;
 73: }
 74: 
 75: .nav-menu a {
 76:     display: flex;
 77:     align-items: center;
 78:     padding: 15px 12px;
 79:     color: var(--text-color);
 80:     text-decoration: none;
 81:     font-size: 14px;
 82:     transition: color 0.2s;
 83:     border-bottom: 2px solid transparent;
 84: }
 85: 
 86: .nav-menu a:hover {
 87:     color: var(--primary-color);
 88:     border-bottom-color: var(--primary-color);
 89: }
 90: 
 91: .nav-menu a.active {
 92:     color: var(--primary-color);
 93:     border-bottom-color: var(--primary-color);
 94: }
 95: 
 96: .mobile-menu-toggle {
 97:     display: none;
 98:     background: none;
 99:     border: none;
100:     font-size: 24px;
101:     cursor: pointer;
102:     padding: 10px;
103:     color: var(--text-color);
104: }
105: 
106: 
107: .theme-toggle {
108:     background: none;
109:     border: 1px solid var(--border-color);
110:     border-radius: 6px;
111:     color: var(--text-color);
112:     cursor: pointer;
113:     font-size: 20px;
114:     padding: 4px 10px;
115:     margin-left: 10px;
116:     transition: all 0.2s;
117:     display: flex;
118:     align-items: center;
119:     justify-content: center;
120: }
121: 
122: .theme-toggle:hover {
123:     background-color: var(--section-bg);
124:     border-color: var(--primary-color);
125:     color: var(--primary-color);
126: }
127: 
128: .theme-toggle:focus {
129:     outline: 2px solid var(--primary-color);
130:     outline-offset: 2px;
131: }
132: 
133: .theme-toggle .icon {
134:     display: inline-block;
135:     transition: transform 0.3s;
136: }
137: 
138: .theme-toggle .icon.hidden {
139:     display: none;
140: }
141: 
142: 
143: .hero {
144:     color: var(--text-color);
145:     padding: 60px 20px 0 20px;
146:     text-align: center;
147: }
148: 
149: .hero h1 {
150:     font-size: 2.5em;
151:     margin-bottom: 20px;
152:     font-weight: 600;
153:     color: var(--text-color);
154: }
155: 
156: 
157: h1 {
158:     font-size: 2.5em;
159:     font-weight: 600;
160: }
161: 
162: h2 {
163:     font-size: 2em;
164:     font-weight: 600;
165: }
166: 
167: h3 {
168:     font-size: 1.5em;
169:     font-weight: 600;
170: }
171: 
172: h4 {
173:     font-size: 1.25em;
174:     font-weight: 600;
175: }
176: 
177: h5 {
178:     font-size: 1.1em;
179:     font-weight: 600;
180: }
181: 
182: .hero p {
183:     font-size: 1.2em;
184:     margin-bottom: 30px;
185:     opacity: 0.95;
186:     color: var(--text-color);
187: }
188: 
189: .hero-content {
190:     max-width: 1200px;
191:     margin: 0 auto;
192: }
193: 
194: .hero-banner {
195:     max-width: 100%;
196:     height: auto;
197:     margin-top: 30px;
198:     border-radius: 8px;
199:     box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
200: }
201: 
202: 
203: section {
204:     max-width: 1200px;
205:     margin: 0 auto;
206:     padding: 40px 20px 0 20px;
207:     scroll-margin-top: 100px;
208: }
209: 
210: section:last-child {
211:     padding-bottom: 40px;
212: }
213: 
214: section h2 {
215:     font-size: 2em;
216:     font-weight: 600;
217:     margin-bottom: 20px;
218:     padding-bottom: 10px;
219:     border-bottom: 2px solid var(--border-color);
220:     color: var(--text-color);
221: }
222: 
223: section h3 {
224:     font-size: 1.5em;
225:     font-weight: 600;
226:     margin-top: 30px;
227:     margin-bottom: 15px;
228:     color: var(--text-color);
229: }
230: 
231: section h4 {
232:     font-size: 1.25em;
233:     font-weight: 600;
234:     margin-top: 20px;
235:     margin-bottom: 10px;
236:     color: var(--text-color);
237: }
238: 
239: section h5 {
240:     font-size: 1.1em;
241:     font-weight: 600;
242:     margin-top: 15px;
243:     margin-bottom: 8px;
244:     color: var(--text-color);
245: }
246: 
247: 
248: .card {
249:     background: var(--bg-color);
250:     border: 1px solid var(--border-color);
251:     border-radius: 6px;
252:     padding: 20px;
253:     margin-bottom: 20px;
254:     box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
255: }
256: 
257: .card h3 {
258:     margin-top: 0;
259:     color: var(--primary-color);
260: }
261: 
262: 
263: ul, ol {
264:     list-style-position: inside;
265: }
266: 
267: ul ul, ol ul {
268:     padding-left: 20px;
269: }
270: 
271: li p {
272:     padding-left: 20px;
273:     margin-top: 15px;
274: }
275: 
276: 
277: a {
278:     color: var(--link-color);
279:     text-decoration: none;
280: }
281: 
282: a:hover {
283:     text-decoration: underline;
284: }
285: 
286: 
287: p {
288:     margin-bottom: 15px;
289: }
290: 
291: #architecture p {
292:     margin-top: 15px;
293: }
294: 
295: #architecture p:first-child {
296:     margin-top: 0;
297: }
298: 
299: p:last-child {
300:     margin-bottom: 0;
301: }
302: 
303: .deployment-card p:last-child {
304:     margin-top: 15px;
305: }
306: 
307: #security p:last-child, #getting-started p:last-child {
308:     margin-top: 15px;
309: }
310: 
311: 
312: code {
313:     background-color: var(--code-bg);
314:     padding: 2px 6px;
315:     border-radius: 3px;
316:     font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
317:     font-size: 0.9em;
318:     color: #d73a49;
319:     border: 1px solid var(--border-color);
320:     font-weight: 500;
321: }
322: 
323: pre {
324:     background-color: var(--code-bg);
325:     padding: 16px;
326:     border-radius: 6px;
327:     overflow-x: auto;
328:     margin-bottom: 15px;
329:     border: 1px solid var(--border-color);
330: }
331: 
332: pre code {
333:     background: none;
334:     padding: 0;
335:     border: none;
336:     color: var(--text-color);
337:     font-weight: normal;
338: }
339: 
340: 
341: table {
342:     width: 100%;
343:     border-collapse: collapse;
344:     margin-bottom: 20px;
345: }
346: 
347: table th, table td {
348:     padding: 12px;
349:     text-align: left;
350:     border: 1px solid var(--border-color);
351: }
352: 
353: table th {
354:     background-color: var(--primary-color);
355:     color: white;
356:     font-weight: 600;
357: }
358: 
359: table tbody tr:nth-child(even) {
360:     background-color: var(--section-bg);
361: }
362: 
363: 
364: .deployment-options {
365:     display: grid;
366:     grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
367:     gap: 20px;
368:     margin-top: 20px;
369: }
370: 
371: .deployment-card {
372:     background: var(--section-bg);
373:     border: 2px solid var(--border-color);
374:     border-radius: 8px;
375:     padding: 25px;
376: }
377: 
378: .deployment-card h4 {
379:     margin-top: 0;
380:     color: var(--primary-color);
381: }
382: 
383: .deployment-card p {
384:     margin-top: 15px;
385: }
386: 
387: 
388: .doc-grid {
389:     display: grid;
390:     grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
391:     gap: 20px;
392:     margin-top: 20px;
393: }
394: 
395: .doc-item {
396:     background: var(--section-bg);
397:     border: 1px solid var(--border-color);
398:     border-radius: 6px;
399:     padding: 15px;
400:     transition: transform 0.2s, box-shadow 0.2s;
401: }
402: 
403: .doc-item:hover {
404:     transform: translateY(-2px);
405:     box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
406: }
407: 
408: .doc-item a {
409:     font-weight: 500;
410:     display: block;
411:     margin-bottom: 8px;
412: }
413: 
414: .doc-item p {
415:     font-size: 0.9em;
416:     color: #586069;
417:     margin: 0;
418: }
419: 
420: 
421: .badge {
422:     display: inline-block;
423:     padding: 4px 8px;
424:     background-color: var(--primary-color);
425:     color: white;
426:     border-radius: 3px;
427:     font-size: 0.8em;
428:     font-weight: 600;
429:     margin-left: 8px;
430: }
431: 
432: 
433: footer {
434:     background-color: var(--section-bg);
435:     border-top: 1px solid var(--border-color);
436:     padding: 30px 20px;
437:     text-align: center;
438:     color: #586069;
439: }
440: 
441: 
442: @media (max-width: 768px) {
443:     .mobile-menu-toggle {
444:         display: block;
445:     }
446: 
447:     .nav-menu {
448:         position: fixed;
449:         left: -100%;
450:         top: 60px;
451:         flex-direction: column;
452:         background-color: var(--nav-bg);
453:         width: 100%;
454:         text-align: center;
455:         transition: 0.3s;
456:         box-shadow: 0 10px 27px rgba(0, 0, 0, 0.05);
457:         padding: 20px 0;
458:         border-bottom: 1px solid var(--border-color);
459:     }
460: 
461:     .nav-menu.active {
462:         left: 0;
463:     }
464: 
465:     .nav-menu li {
466:         width: 100%;
467:     }
468: 
469:     .nav-menu a {
470:         padding: 15px;
471:         border-bottom: none;
472:         border-left: 3px solid transparent;
473:     }
474: 
475:             .nav-menu a:hover,
476:             .nav-menu a.active {
477:                 border-left-color: var(--primary-color);
478:                 border-bottom-color: transparent;
479:             }
480: 
481:             .theme-toggle {
482:                 margin-left: 0;
483:                 margin-top: 10px;
484:             }
485: 
486:             .hero h1 {
487:                 font-size: 2em;
488:             }
489: 
490:     .hero p {
491:         font-size: 1em;
492:     }
493: 
494:     .deployment-options {
495:         grid-template-columns: 1fr;
496:     }
497: 
498:     .doc-grid {
499:         grid-template-columns: 1fr;
500:     }
501: 
502:     section h2 {
503:         font-size: 1.5em;
504:     }
505: 
506:     section h3 {
507:         font-size: 1.3em;
508:     }
509: 
510:     section h4 {
511:         font-size: 1.15em;
512:     }
513: 
514:     section h5 {
515:         font-size: 1.05em;
516:     }
517: }
518: 
519: 
520: html {
521:     scroll-behavior: smooth;
522: }
523: 
524: 
525: .scroll-to-top {
526:     position: fixed;
527:     bottom: 30px;
528:     right: 30px;
529:     width: 50px;
530:     height: 50px;
531:     border-radius: 50%;
532:     background-color: rgba(3, 102, 214, 0.15);
533:     backdrop-filter: blur(8px);
534:     -webkit-backdrop-filter: blur(8px);
535:     border: 2px solid rgba(3, 102, 214, 0.3);
536:     color: var(--primary-color);
537:     cursor: pointer;
538:     display: flex;
539:     align-items: center;
540:     justify-content: center;
541:     z-index: 999;
542:     opacity: 0;
543:     visibility: hidden;
544:     pointer-events: none;
545:     transition: opacity 0.3s ease, visibility 0.3s ease, transform 0.3s ease, background-color 0.3s ease, border-color 0.3s ease;
546:     box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
547: }
548: 
549: .scroll-to-top.visible {
550:     opacity: 1;
551:     visibility: visible;
552:     pointer-events: auto;
553: }
554: 
555: .scroll-to-top:hover {
556:     background-color: rgba(3, 102, 214, 0.25);
557:     border-color: rgba(3, 102, 214, 0.5);
558:     transform: translateY(-3px);
559:     box-shadow: 0 6px 16px rgba(0, 0, 0, 0.15);
560: }
561: 
562: .scroll-to-top:active {
563:     transform: translateY(-1px);
564: }
565: 
566: .scroll-to-top svg {
567:     width: 24px;
568:     height: 24px;
569: }
570: 
571: @media (max-width: 768px) {
572:     .scroll-to-top {
573:         bottom: 20px;
574:         right: 20px;
575:         width: 45px;
576:         height: 45px;
577:     }
578:     .scroll-to-top svg {
579:         width: 20px;
580:         height: 20px;
581:     }
582: }
````

## File: tf_backend_state/set-state.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: print_error() {
 18:     echo -e "${RED}ERROR:${NC} $1" >&2
 19: }
 20: 
 21: print_success() {
 22:     echo -e "${GREEN}SUCCESS:${NC} $1"
 23: }
 24: 
 25: print_info() {
 26:     echo -e "${YELLOW}INFO:${NC} $1"
 27: }
 28: 
 29: 
 30: if ! command -v aws &> /dev/null; then
 31:     print_error "AWS CLI is not installed."
 32:     echo "Please install it from: https://aws.amazon.com/cli/"
 33:     exit 1
 34: fi
 35: 
 36: 
 37: if ! command -v gh &> /dev/null; then
 38:     print_error "GitHub CLI (gh) is not installed."
 39:     echo "Please install it from: https://cli.github.com/"
 40:     echo ""
 41:     echo "Or use the alternative method with curl (requires GITHUB_TOKEN environment variable):"
 42:     echo "  export GITHUB_TOKEN=your_token"
 43:     exit 1
 44: fi
 45: 
 46: 
 47: if ! gh auth status &> /dev/null; then
 48:     print_error "Not authenticated with GitHub CLI."
 49:     echo "Please run: gh auth login"
 50:     exit 1
 51: fi
 52: 
 53: 
 54: if ! command -v jq &> /dev/null; then
 55:     print_error "jq is not installed."
 56:     echo "Please install it:"
 57:     echo "  macOS: brew install jq"
 58:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 59:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 60:     exit 1
 61: fi
 62: 
 63: 
 64: if ! command -v terraform &> /dev/null; then
 65:     print_error "Terraform is not installed."
 66:     echo "Please install it from: https://www.terraform.io/downloads"
 67:     exit 1
 68: fi
 69: 
 70: 
 71: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 72: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 73: 
 74: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 75:     print_error "Could not determine repository information."
 76:     echo "Please ensure you're in a git repository and have proper permissions."
 77:     exit 1
 78: fi
 79: 
 80: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 81: 
 82: 
 83: get_repo_variable() {
 84:     local var_name=$1
 85:     local value
 86: 
 87:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 88: 
 89:     if [ -z "$value" ]; then
 90:         return 1
 91:     fi
 92: 
 93:     echo "$value"
 94: }
 95: 
 96: 
 97: set_repo_variable() {
 98:     local var_name=$1
 99:     local var_value=$2
100: 
101:     if gh variable set "${var_name}" --body "${var_value}" --repo "${REPO_OWNER}/${REPO_NAME}" 2>/dev/null; then
102:         return 0
103:     else
104:         return 1
105:     fi
106: }
107: 
108: 
109: get_aws_secret() {
110:     local secret_name=$1
111:     local secret_json
112:     local exit_code
113: 
114: 
115: 
116:     secret_json=$(aws secretsmanager get-secret-value \
117:         --secret-id "$secret_name" \
118:         --region "${AWS_REGION:-us-east-1}" \
119:         --query SecretString \
120:         --output text 2>&1)
121: 
122: 
123:     exit_code=$?
124: 
125: 
126:     if [ $exit_code -ne 0 ]; then
127:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
128:         print_error "Error: $secret_json"
129:         return 1
130:     fi
131: 
132: 
133:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
134:         print_error "Secret '${secret_name}' contains invalid JSON"
135:         return 1
136:     fi
137: 
138:     echo "$secret_json"
139: }
140: 
141: 
142: get_secret_key_value() {
143:     local secret_json=$1
144:     local key_name=$2
145:     local value
146: 
147: 
148:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
149:         print_error "Invalid JSON provided to get_secret_key_value"
150:         return 1
151:     fi
152: 
153: 
154:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
155: 
156: 
157:     if [ $? -ne 0 ]; then
158:         print_error "Failed to parse JSON or extract key '${key_name}'"
159:         return 1
160:     fi
161: 
162: 
163:     if [ "$value" = "null" ] || [ -z "$value" ]; then
164:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
165:         return 1
166:     fi
167: 
168:     echo "$value"
169: }
170: 
171: 
172: print_info "Retrieving AWS_STATE_ACCOUNT_ROLE_ARN from AWS Secrets Manager..."
173: SECRET_JSON=$(get_aws_secret "github-role" || echo "")
174: if [ -z "$SECRET_JSON" ]; then
175:     print_error "Failed to retrieve secret from AWS Secrets Manager"
176:     exit 1
177: fi
178: 
179: ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
180: if [ -z "$ROLE_ARN" ]; then
181:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
182:     exit 1
183: fi
184: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
185: 
186: 
187: print_info "Retrieving AWS_REGION from repository variables..."
188: REGION=$(get_repo_variable "AWS_REGION" || echo "")
189: if [ -z "$REGION" ]; then
190:     print_info "AWS_REGION not found in repository variables, defaulting to 'us-east-1'"
191:     REGION="us-east-1"
192: else
193:     print_success "Retrieved AWS_REGION: $REGION"
194: fi
195: 
196: print_info "Assuming role: $ROLE_ARN"
197: print_info "Region: $REGION"
198: 
199: 
200: ROLE_SESSION_NAME="set-state-$(date +%s)"
201: 
202: 
203: ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
204:     --role-arn "$ROLE_ARN" \
205:     --role-session-name "$ROLE_SESSION_NAME" \
206:     --region "$REGION" 2>&1)
207: 
208: if [ $? -ne 0 ]; then
209:     print_error "Failed to assume role: $ASSUME_ROLE_OUTPUT"
210:     exit 1
211: fi
212: 
213: 
214: 
215: if command -v jq &> /dev/null; then
216:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
217:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
218:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
219: else
220: 
221:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
222:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
223:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
224: fi
225: 
226: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
227:     print_error "Failed to extract credentials from assume-role output."
228:     print_error "Output was: $ASSUME_ROLE_OUTPUT"
229:     exit 1
230: fi
231: 
232: print_success "Successfully assumed role"
233: 
234: 
235: CALLER_ARN=$(aws sts get-caller-identity --region "$REGION" --query 'Arn' --output text 2>&1)
236: if [ $? -ne 0 ]; then
237:     print_error "Failed to verify assumed role credentials: $CALLER_ARN"
238:     exit 1
239: fi
240: 
241: print_info "Assumed role identity: $CALLER_ARN"
242: 
243: 
244: print_info "Retrieving BACKEND_PREFIX from repository variables..."
245: BACKEND_PREFIX=$(get_repo_variable "BACKEND_PREFIX" || echo "")
246: if [ -z "$BACKEND_PREFIX" ]; then
247:     print_error "BACKEND_PREFIX not found in repository variables."
248:     echo "Please ensure BACKEND_PREFIX is set in GitHub repository variables."
249:     exit 1
250: fi
251: print_success "Retrieved BACKEND_PREFIX: $BACKEND_PREFIX"
252: 
253: 
254: print_info "Checking for existing BACKEND_BUCKET_NAME in repository variables..."
255: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME" || echo "")
256: 
257: if [ -z "$BUCKET_NAME" ]; then
258:     print_info "BACKEND_BUCKET_NAME not found in repository variables."
259:     print_info "This means the infrastructure has not been provisioned yet."
260:     print_info "Proceeding with Terraform provisioning..."
261: 
262: 
263:     if [ ! -f "variables.tfvars" ]; then
264:         print_error "variables.tfvars file not found in current directory."
265:         echo "Please ensure variables.tfvars exists with required variables."
266:         exit 1
267:     fi
268:     print_success "Found variables.tfvars file"
269: 
270: 
271:     print_info "Running terraform init..."
272:     if ! terraform init -backend=false; then
273:         print_error "Terraform init failed."
274:         exit 1
275:     fi
276:     print_success "Terraform initialized"
277: 
278: 
279:     print_info "Running terraform validate..."
280:     if ! terraform validate; then
281:         print_error "Terraform validation failed."
282:         exit 1
283:     fi
284:     print_success "Terraform validation passed"
285: 
286: 
287:     print_info "Running terraform plan..."
288:     if ! terraform plan -var-file="variables.tfvars" -out terraform.tfplan; then
289:         print_error "Terraform plan failed."
290:         exit 1
291:     fi
292:     print_success "Terraform plan completed"
293: 
294: 
295:     print_info "Running terraform apply..."
296:     if ! terraform apply -auto-approve terraform.tfplan; then
297:         print_error "Terraform apply failed."
298:         exit 1
299:     fi
300:     print_success "Terraform apply completed"
301: 
302: 
303:     print_info "Retrieving bucket name from Terraform output..."
304:     BUCKET_NAME=$(terraform output -raw bucket_name 2>/dev/null || echo "")
305:     if [ -z "$BUCKET_NAME" ]; then
306:         print_error "Failed to retrieve bucket name from Terraform output."
307:         echo "Please check Terraform outputs."
308:         exit 1
309:     fi
310:     print_success "Retrieved bucket name: $BUCKET_NAME"
311: else
312:     print_success "Found existing BACKEND_BUCKET_NAME: $BUCKET_NAME"
313: 
314: 
315:     S3_PATH="s3://${BUCKET_NAME}/${BACKEND_PREFIX}"
316:     print_info "Checking for existing state file at: $S3_PATH"
317: 
318:     if aws s3 ls "$S3_PATH" --region "$REGION" &>/dev/null; then
319:         print_info "State file exists in S3, downloading..."
320:         if aws s3 cp "$S3_PATH" terraform.tfstate --region "$REGION"; then
321:             print_success "State file downloaded successfully from S3"
322:         else
323:             print_error "Failed to download state file from S3"
324:             exit 1
325:         fi
326:     else
327:         print_info "State file does not exist in S3"
328: 
329:         if [ ! -f "terraform.tfstate" ]; then
330:             print_error "terraform.tfstate file not found locally and not in S3."
331:             echo "Please ensure you have run 'terraform apply' first to generate the state file."
332:             exit 1
333:         fi
334:         print_success "Found terraform.tfstate file locally"
335:     fi
336: 
337: 
338:     print_info "Verifying bucket name from Terraform output..."
339:     TERRAFORM_BUCKET_NAME=$(terraform output -raw bucket_name 2>/dev/null || echo "")
340:     if [ -n "$TERRAFORM_BUCKET_NAME" ] && [ "$TERRAFORM_BUCKET_NAME" != "$BUCKET_NAME" ]; then
341:         print_error "Bucket name mismatch!"
342:         echo "Repository variable BACKEND_BUCKET_NAME: $BUCKET_NAME"
343:         echo "Terraform output bucket_name: $TERRAFORM_BUCKET_NAME"
344:         echo "Please verify the bucket name is correct."
345:         exit 1
346:     fi
347:     print_success "Bucket name verified"
348: fi
349: 
350: print_info "Saving bucket name to GitHub repository variable..."
351: if set_repo_variable "BACKEND_BUCKET_NAME" "$BUCKET_NAME"; then
352:     print_success "Saved BACKEND_BUCKET_NAME to repository variables"
353: else
354:     print_error "Failed to save BACKEND_BUCKET_NAME to repository variables."
355:     echo "Please ensure you have proper permissions to write repository variables."
356:     exit 1
357: fi
358: 
359: S3_PATH="s3://${BUCKET_NAME}/${BACKEND_PREFIX}"
360: print_info "Uploading state file to: $S3_PATH"
361: 
362: if aws s3 cp terraform.tfstate "$S3_PATH" --region "$REGION"; then
363:     print_success "State file uploaded successfully to $S3_PATH"
364: else
365:     print_error "Failed to upload state file to S3"
366:     exit 1
367: fi
368: 
369: print_success "Script completed successfully"
````

## File: application/modules/cert-manager/README.md
````markdown
  1: # cert-manager Module
  2: 
  3: This module installs cert-manager and creates a self-signed TLS certificate for
  4: OpenLDAP internal communication.
  5: 
  6: ## Purpose
  7: 
  8: cert-manager automatically generates and manages TLS certificates for OpenLDAP
  9: to enable secure LDAP connections (StartTLS/LDAPS).
 10: 
 11: ## What it Creates
 12: 
 13: 1. **cert-manager** - Installed via Helm chart
 14:    - Deployed in `cert-manager` namespace
 15:    - Automatically installs CRDs
 16:    - Manages certificate lifecycle automatically
 17: 
 18: 2. **ClusterIssuer** (`selfsigned-issuer`) - Creates self-signed certificate authority
 19:    - Cluster-wide resource
 20:    - Uses self-signed certificate authority
 21:    - Managed via `kubernetes_manifest` resource
 22: 
 23: 3. **CA Certificate** (`openldap-ca`) - Certificate Authority certificate
 24:    - Creates a Kubernetes secret named `openldap-ca-secret` in the specified namespace
 25:    - Valid for 10 years
 26:    - Used as the root CA for signing OpenLDAP certificates
 27:    - Managed via `kubernetes_manifest` resource
 28: 
 29: 4. **Issuer** (`openldap-ca-issuer`) - Issuer based on the CA certificate
 30:    - Namespace-scoped resource
 31:    - References the CA certificate secret
 32:    - Used to sign the OpenLDAP TLS certificate
 33:    - Managed via `kubernetes_manifest` resource
 34: 
 35: 5. **Certificate** (`openldap-tls`) - TLS certificate for OpenLDAP
 36:    - Creates a Kubernetes secret named `openldap-tls` in the specified namespace
 37:    - Signed by the CA issuer
 38:    - Valid for 10 years
 39:    - Auto-renews 30 days before expiration
 40:    - Includes DNS names for all OpenLDAP service endpoints
 41:    - Managed via `kubernetes_manifest` resource
 42: 
 43: ## Certificate DNS Names
 44: 
 45: The certificate includes the following DNS names:
 46: 
 47: - `openldap-stack-ha`
 48: - `openldap-stack-ha.ldap`
 49: - `openldap-stack-ha.ldap.svc`
 50: - `openldap-stack-ha.ldap.svc.cluster.local`
 51: - `openldap-stack-ha-headless`
 52: - `openldap-stack-ha-headless.ldap`
 53: - `openldap-stack-ha-headless.ldap.svc`
 54: - `openldap-stack-ha-headless.ldap.svc.cluster.local`
 55: - `openldap-stack-ha-0.openldap-stack-ha-headless.ldap.svc.cluster.local`
 56: - `openldap-stack-ha-1.openldap-stack-ha-headless.ldap.svc.cluster.local`
 57: - `openldap-stack-ha-2.openldap-stack-ha-headless.ldap.svc.cluster.local`
 58: - `*.talorlik.com`
 59: - `talorlik.com`
 60: 
 61: ## Usage
 62: 
 63: ```hcl
 64: module "cert_manager" {
 65:   source = "./modules/cert-manager"
 66: 
 67:   cluster_name = "my-eks-cluster"
 68:   namespace    = "ldap"
 69:   domain_name  = "talorlik.com"
 70: 
 71:   depends_on = [data.aws_eks_cluster.cluster]
 72: }
 73: ```
 74: 
 75: ## Inputs
 76: 
 77: | Name | Description | Type | Required |
 78: | ------ | ------------- | ------ | ---------- |
 79: | cluster_name | Name of the EKS cluster | string | yes |
 80: | namespace | Kubernetes namespace where OpenLDAP is deployed | string | yes |
 81: | domain_name | Domain name for certificate DNS names | string | yes |
 82: 
 83: ## Outputs
 84: 
 85: | Name | Description |
 86: | ------ | ------------- |
 87: | certificate_secret_name | Kubernetes secret name for TLS cert (always `openldap-tls`) |
 88: 
 89: ## How OpenLDAP Uses the Certificate
 90: 
 91: The OpenLDAP Helm chart is configured to use this certificate via:
 92: 
 93: ```yaml
 94: env:
 95:   LDAP_TLS_ENFORCE: "true"
 96:   LDAP_TLS_VERIFY_CLIENT: "never"
 97: 
 98: customTLS:
 99:   enabled: true
100:   secret: openldap-tls
101: ```
102: 
103: ## Verifying Certificate Creation
104: 
105: ```bash
106: # Check cert-manager is running
107: kubectl get pods -n cert-manager
108: 
109: # Check ClusterIssuer
110: kubectl get clusterissuer selfsigned-issuer
111: 
112: # Check CA Certificate
113: kubectl get certificate -n ldap openldap-ca
114: 
115: # Check Issuer
116: kubectl get issuer -n ldap openldap-ca-issuer
117: 
118: # Check Certificate status
119: kubectl get certificate -n ldap openldap-tls
120: 
121: # View certificate details
122: kubectl describe certificate -n ldap openldap-tls
123: 
124: # Check the secret was created
125: kubectl get secret -n ldap openldap-tls
126: ```
127: 
128: ## Notes
129: 
130: - Uses Helm provider to install cert-manager (no kubectl required)
131: - Uses `kubernetes_manifest` resources for cert-manager CRDs
132: (ClusterIssuer, Issuer, Certificate)
133: - All resources are managed natively by Terraform with proper state tracking
134: - cert-manager version: v1.13.2
135: - Requires Helm provider to be configured with access to the EKS cluster
````

## File: application/modules/postgresql/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name prefix for resources"
 13:   type        = string
 14: }
 15: 
 16: variable "namespace" {
 17:   description = "Kubernetes namespace for PostgreSQL"
 18:   type        = string
 19:   default     = "ldap-2fa"
 20: }
 21: 
 22: variable "secret_name" {
 23:   description = "Name of the Kubernetes secret for PostgreSQL password"
 24:   type        = string
 25:   default     = "postgresql-secret"
 26: }
 27: 
 28: variable "chart_version" {
 29:   description = "PostgreSQL Helm chart version"
 30:   type        = string
 31:   default     = "18.1.15"
 32: }
 33: 
 34: variable "database_name" {
 35:   description = "Name of the database to create"
 36:   type        = string
 37:   default     = "ldap2fa"
 38: }
 39: 
 40: variable "database_username" {
 41:   description = "Database username"
 42:   type        = string
 43:   default     = "ldap2fa"
 44: }
 45: 
 46: variable "database_password" {
 47:   description = "Database password"
 48:   type        = string
 49:   sensitive   = true
 50: }
 51: 
 52: variable "storage_class" {
 53:   description = "Storage class for PostgreSQL PVC"
 54:   type        = string
 55:   default     = ""
 56: }
 57: 
 58: variable "storage_size" {
 59:   description = "Storage size for PostgreSQL PVC"
 60:   type        = string
 61:   default     = "8Gi"
 62: }
 63: 
 64: variable "resources" {
 65:   description = "Resource limits and requests for PostgreSQL"
 66:   type = object({
 67:     limits = object({
 68:       cpu    = string
 69:       memory = string
 70:     })
 71:     requests = object({
 72:       cpu    = string
 73:       memory = string
 74:     })
 75:   })
 76:   default = {
 77:     limits = {
 78:       cpu    = "500m"
 79:       memory = "512Mi"
 80:     }
 81:     requests = {
 82:       cpu    = "250m"
 83:       memory = "256Mi"
 84:     }
 85:   }
 86: }
 87: 
 88: variable "tags" {
 89:   description = "Tags to apply to resources"
 90:   type        = map(string)
 91:   default     = {}
 92: }
 93: 
 94: variable "ecr_registry" {
 95:   description = "ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)"
 96:   type        = string
 97: }
 98: 
 99: variable "ecr_repository" {
100:   description = "ECR repository name"
101:   type        = string
102: }
103: 
104: variable "image_tag" {
105:   description = "PostgreSQL image tag in ECR"
106:   type        = string
107:   default     = "postgresql-latest"
108: }
109: 
110: variable "values_template_path" {
111:   description = "Path to the PostgreSQL values template file"
112:   type        = string
113:   default     = null
114: }
````

## File: application/modules/redis/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name prefix added to all resources"
 13:   type        = string
 14: }
 15: 
 16: variable "enable_redis" {
 17:   description = "Enable Redis deployment"
 18:   type        = bool
 19:   default     = false
 20: }
 21: 
 22: variable "namespace" {
 23:   description = "Kubernetes namespace for Redis"
 24:   type        = string
 25:   default     = "redis"
 26: }
 27: 
 28: variable "secret_name" {
 29:   description = "Name of the Kubernetes secret for Redis password"
 30:   type        = string
 31:   default     = "redis-secret"
 32: }
 33: 
 34: variable "redis_password" {
 35:   description = "Redis authentication password (from GitHub Secrets via TF_VAR_redis_password)"
 36:   type        = string
 37:   sensitive   = true
 38: 
 39:   validation {
 40:     condition     = length(var.redis_password) >= 8
 41:     error_message = "Redis password must be at least 8 characters."
 42:   }
 43: }
 44: 
 45: variable "chart_version" {
 46:   description = "Bitnami Redis Helm chart version"
 47:   type        = string
 48:   default     = "24.0.9"
 49: }
 50: 
 51: variable "storage_class_name" {
 52:   description = "Storage class for Redis PVC"
 53:   type        = string
 54:   default     = ""
 55: }
 56: 
 57: variable "storage_size" {
 58:   description = "Storage size for Redis PVC"
 59:   type        = string
 60:   default     = "1Gi"
 61: }
 62: 
 63: variable "persistence_enabled" {
 64:   description = "Enable persistence for Redis data"
 65:   type        = bool
 66:   default     = true
 67: }
 68: 
 69: variable "resources" {
 70:   description = "Resource limits and requests for Redis"
 71:   type = object({
 72:     limits = object({
 73:       cpu    = string
 74:       memory = string
 75:     })
 76:     requests = object({
 77:       cpu    = string
 78:       memory = string
 79:     })
 80:   })
 81:   default = {
 82:     limits = {
 83:       cpu    = "500m"
 84:       memory = "256Mi"
 85:     }
 86:     requests = {
 87:       cpu    = "100m"
 88:       memory = "128Mi"
 89:     }
 90:   }
 91: }
 92: 
 93: variable "metrics_enabled" {
 94:   description = "Enable Prometheus metrics exporter"
 95:   type        = bool
 96:   default     = false
 97: }
 98: 
 99: variable "tags" {
100:   description = "Tags to apply to resources"
101:   type        = map(string)
102:   default     = {}
103: }
104: 
105: variable "backend_namespace" {
106:   description = "Namespace where the backend pods are deployed (for network policy)"
107:   type        = string
108:   default     = "twofa-backend"
109: }
110: 
111: variable "ecr_registry" {
112:   description = "ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)"
113:   type        = string
114: }
115: 
116: variable "ecr_repository" {
117:   description = "ECR repository name"
118:   type        = string
119: }
120: 
121: variable "image_tag" {
122:   description = "Redis image tag in ECR"
123:   type        = string
124:   default     = "redis-latest"
125: }
126: 
127: variable "values_template_path" {
128:   description = "Path to the Redis values template file"
129:   type        = string
130:   default     = null
131: }
````

## File: .gitignore
````
 1: # Local .terraform directories
 2: **/.terraform/*
 3: 
 4: # .tfstate files
 5: *.tfstate
 6: *.tfstate.*
 7: 
 8: # Crash log files
 9: crash.log
10: crash.*.log
11: 
12: # Exclude all .tfvars files, which are likely to contain sensitive data, such as
13: # password, private keys, and other secrets. These should not be part of version
14: # control as they are data points which are potentially sensitive and subject
15: # to change depending on the environment.
16: # *.tfvars
17: *.tfvars.json
18: 
19: # Ignore override files as they are usually used to override resources locally and so
20: # are not checked in
21: override.tf
22: override.tf.json
23: *_override.tf
24: *_override.tf.json
25: 
26: # Ignore transient lock info files created by terraform apply
27: .terraform.tfstate.lock.info
28: 
29: # Include override files you do wish to add to version control using negated pattern
30: # !example_override.tf
31: 
32: # Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan
33: # example: *tfplan*
34: *.plan
35: *.tfplan
36: 
37: # Ignore CLI configuration files
38: .terraformrc
39: terraform.rc
40: 
41: .cursor/
42: 
43: .idea/
44: 
45: .vscode/
46: # Snyk Security Extension - AI Rules (auto-generated)
47: .cursor/rules/snyk_rules.mdc
48: 
49: # Generated backend configuration (created from tfstate-backend-values-template.hcl)
50: backend_infra/backend.hcl
51: application/backend.hcl
52: 
53: .env
54: 
55: .DS_Store
56: 
57: ca-config.json
58: ca.csr
59: ca-cert.pem
````

## File: SECRETS_REQUIREMENTS.md
````markdown
  1: # Secrets Requirements
  2: 
  3: This document consolidates all secrets-related information for the LDAP 2FA on
  4: Kubernetes project. It covers both AWS Secrets Manager (for local scripts) and
  5: GitHub Repository Secrets (for GitHub Actions workflows).
  6: 
  7: ## Overview
  8: 
  9: The project uses secrets in two different contexts:
 10: 
 11: 1. **AWS Secrets Manager** - Used by local bash scripts
 12: (`setup-backend.sh`, `setup-application.sh`, `set-state.sh`, `get-state.sh`)
 13: 2. **GitHub Repository Secrets** - Used by GitHub Actions workflows
 14: 
 15: > [!NOTE]
 16: >
 17: > Local scripts retrieve secrets from **AWS Secrets Manager**, while GitHub Actions
 18: > workflows use **GitHub Repository Secrets**. Both must be configured for the
 19: > project to work in both contexts.
 20: 
 21: ## Secret Categories
 22: 
 23: ### 1. IAM Role ARNs
 24: 
 25: These are used for AWS authentication and role assumption:
 26: 
 27: - `AWS_STATE_ACCOUNT_ROLE_ARN` - Role for Terraform state backend operations and
 28:   Route53/ACM cross-account access
 29: - `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` - Role for production deployments
 30: - `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` - Role for development deployments
 31: 
 32: ### 1.1. ExternalId for Cross-Account Role Assumption
 33: 
 34: - `AWS_ASSUME_EXTERNAL_ID` - ExternalId for cross-account role assumption security
 35:   - **Purpose:** Prevents confused deputy attacks when assuming deployment account
 36:   roles
 37:   - **Generation:** `openssl rand -hex 32`
 38:   - **Storage:**
 39:     - AWS Secrets Manager: Plain text secret named `external-id`
 40:     - GitHub: Repository secret `AWS_ASSUME_EXTERNAL_ID`
 41:   - **Requirement:** Must match the ExternalId configured in deployment account
 42:   role Trust Relationships
 43:   - **Used By:** `setup-backend.sh`, `setup-application.sh`, and all GitHub Actions
 44:   workflows
 45: 
 46: ### 2. Application Passwords
 47: 
 48: These are used for application infrastructure components:
 49: 
 50: - `TF_VAR_OPENLDAP_ADMIN_PASSWORD` - OpenLDAP admin password
 51: - `TF_VAR_OPENLDAP_CONFIG_PASSWORD` - OpenLDAP configuration password
 52: - `TF_VAR_POSTGRESQL_PASSWORD` - PostgreSQL database password
 53: - `TF_VAR_REDIS_PASSWORD` - Redis authentication password (minimum 8 characters)
 54: 
 55: ### 3. GitHub Token
 56: 
 57: - `GH_TOKEN` - GitHub Personal Access Token with `repo` scope
 58: (for repository variable updates)
 59: 
 60: ## AWS Secrets Manager Configuration
 61: 
 62: Local bash scripts retrieve secrets from AWS Secrets Manager. Two separate secrets
 63: are used:
 64: 
 65: ### Secret 1: `github-role`
 66: 
 67: Contains IAM role ARNs for AWS authentication:
 68: 
 69: ```json
 70: {
 71:   "AWS_STATE_ACCOUNT_ROLE_ARN": "arn:aws:iam::<state-account-id>:role/<role-name>",
 72:   "AWS_PRODUCTION_ACCOUNT_ROLE_ARN": "arn:aws:iam::<prod-account-id>:role/<role-name>",
 73:   "AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN": "arn:aws:iam::<dev-account-id>:role/<role-name>"
 74: }
 75: ```
 76: 
 77: ### Secret 2: `tf-vars`
 78: 
 79: Contains Terraform variable values (passwords):
 80: 
 81: ```json
 82: {
 83:   "TF_VAR_OPENLDAP_ADMIN_PASSWORD": "<admin-password>",
 84:   "TF_VAR_OPENLDAP_CONFIG_PASSWORD": "<config-password>",
 85:   "TF_VAR_POSTGRESQL_PASSWORD": "<postgresql-password>",
 86:   "TF_VAR_REDIS_PASSWORD": "<redis-password>"
 87: }
 88: ```
 89: 
 90: ### Secret 3: `external-id`
 91: 
 92: Contains ExternalId for cross-account role assumption (plain text, not JSON):
 93: 
 94: ```text
 95: <generated-external-id>
 96: ```
 97: 
 98: **Important:** This is a plain text secret, not JSON. Generate using:
 99: 
100: ```bash
101: openssl rand -hex 32
102: ```
103: 
104: The same value must be:
105: 
106: - Stored in AWS Secrets Manager as `external-id` (plain text)
107: - Stored in GitHub repository secret `AWS_ASSUME_EXTERNAL_ID`
108: - Added to deployment account role Trust Relationships as a condition
109: 
110: ### Creating AWS Secrets Manager Secrets
111: 
112: #### Create the `github-role` secret
113: 
114: ```bash
115: aws secretsmanager create-secret \
116:   --name github-role \
117:   --secret-string '{
118:     "AWS_STATE_ACCOUNT_ROLE_ARN": "arn:aws:iam::123456789012:role/TerraformStateRole",
119:     "AWS_PRODUCTION_ACCOUNT_ROLE_ARN": "arn:aws:iam::987654321098:role/TerraformDeploymentRole",
120:     "AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN": "arn:aws:iam::111222333444:role/TerraformDeploymentRole"
121:   }' \
122:   --region us-east-1
123: ```
124: 
125: Or update an existing secret:
126: 
127: ```bash
128: aws secretsmanager update-secret \
129:   --secret-id github-role \
130:   --secret-string '{
131:     "AWS_STATE_ACCOUNT_ROLE_ARN": "arn:aws:iam::123456789012:role/TerraformStateRole",
132:     "AWS_PRODUCTION_ACCOUNT_ROLE_ARN": "arn:aws:iam::987654321098:role/TerraformDeploymentRole",
133:     "AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN": "arn:aws:iam::111222333444:role/TerraformDeploymentRole"
134:   }' \
135:   --region us-east-1
136: ```
137: 
138: #### Create the `tf-vars` secret
139: 
140: ```bash
141: aws secretsmanager create-secret \
142:   --name tf-vars \
143:   --secret-string '{
144:     "TF_VAR_OPENLDAP_ADMIN_PASSWORD": "YourAdminPasswordHere",
145:     "TF_VAR_OPENLDAP_CONFIG_PASSWORD": "YourConfigPasswordHere",
146:     "TF_VAR_POSTGRESQL_PASSWORD": "YourPostgreSQLPasswordHere",
147:     "TF_VAR_REDIS_PASSWORD": "YourRedisPasswordHere"
148:   }' \
149:   --region us-east-1
150: ```
151: 
152: Or update an existing secret:
153: 
154: ```bash
155: aws secretsmanager update-secret \
156:   --secret-id tf-vars \
157:   --secret-string '{
158:     "TF_VAR_OPENLDAP_ADMIN_PASSWORD": "YourAdminPasswordHere",
159:     "TF_VAR_OPENLDAP_CONFIG_PASSWORD": "YourConfigPasswordHere",
160:     "TF_VAR_POSTGRESQL_PASSWORD": "YourPostgreSQLPasswordHere",
161:     "TF_VAR_REDIS_PASSWORD": "YourRedisPasswordHere"
162:   }' \
163:   --region us-east-1
164: ```
165: 
166: ### Creating the `external-id` secret
167: 
168: ```bash
169: # Generate ExternalId
170: EXTERNAL_ID=$(openssl rand -hex 32)
171: echo "Generated ExternalId: $EXTERNAL_ID"
172: 
173: # Create the secret in AWS Secrets Manager
174: aws secretsmanager create-secret \
175:   --name external-id \
176:   --secret-string "$EXTERNAL_ID" \
177:   --region us-east-1
178: ```
179: 
180: Or update an existing secret:
181: 
182: ```bash
183: aws secretsmanager update-secret \
184:   --secret-id external-id \
185:   --secret-string "$EXTERNAL_ID" \
186:   --region us-east-1
187: ```
188: 
189: > [!IMPORTANT]
190: >
191: > The same ExternalId value must be:
192: >
193: > 1. Stored in AWS Secrets Manager as `external-id` (plain text)
194: > 2. Stored in GitHub repository secret `AWS_ASSUME_EXTERNAL_ID`
195: > 3. Added to deployment account role Trust Relationships as a condition:
196: >
197: >    ```json
198: >    {
199: >      "Condition": {
200: >        "StringEquals": {
201: >          "sts:ExternalId": "<generated-external-id>"
202: >        }
203: >      }
204: >    }
205: >    ```
206: 
207: > [!IMPORTANT]
208: >
209: > **Bidirectional Trust Relationships Required:**
210: >
211: > For multi-account setups, both trust relationships must be configured:
212: >
213: > 1. **Deployment Account Roles** must trust the State Account role (already
214: >    documented above) **with ExternalId condition**
215: > 2. **State Account Role** must also trust the Deployment Account roles in its
216: >    Trust Relationship
217: >
218: > **ExternalId Still Required**: The ExternalId security mechanism is still
219: > required when the state account role assumes deployment account roles. The
220: > ExternalId condition must be present in the deployment account roles' Trust
221: > Relationships, and the state account role must provide the ExternalId when
222: > assuming those roles. The ExternalId is retrieved from `AWS_ASSUME_EXTERNAL_ID`
223: > secret (for GitHub Actions) or AWS Secrets Manager (for local deployment).
224: >
225: > Update the state account role's (`github-actions-state-role`) Trust
226: > Relationship to include the deployment account role ARNs:
227: >
228: > ```json
229: > {
230: >   "Version": "2012-10-17",
231: >   "Statement": [
232: >     {
233: >       "Effect": "Allow",
234: >       "Principal": {
235: >         "Federated": "arn:aws:iam::STATE_ACCOUNT_ID:oidc-provider/token.actions.githubusercontent.com"
236: >       },
237: >       "Action": "sts:AssumeRoleWithWebIdentity",
238: >       "Condition": {
239: >         "StringLike": {
240: >           "token.actions.githubusercontent.com:sub": "repo:YOUR_ORG/YOUR_REPO:*"
241: >         }
242: >       }
243: >     },
244: >     {
245: >       "Effect": "Allow",
246: >       "Principal": {
247: >         "AWS": [
248: >           "arn:aws:iam::PRODUCTION_ACCOUNT_ID:role/github-role",
249: >           "arn:aws:iam::DEVELOPMENT_ACCOUNT_ID:role/github-role",
250: >           "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
251: >         ]
252: >       },
253: >       "Action": "sts:AssumeRole"
254: >     }
255: >   ]
256: > }
257: > ```
258: >
259: > Replace `PRODUCTION_ACCOUNT_ID` and `DEVELOPMENT_ACCOUNT_ID` with your actual
260: > account IDs, and `github-role` with your actual deployment role names.
261: >
262: > > [!IMPORTANT]
263: > >
264: > > **Self-Assumption Statement**: The last statement allows the role to assume
265: > itself. This is required when:
266: >
267: > - The State Account role is used for both backend state operations and
268: > Route53/ACM access (when `state_account_role_arn` points to the same role)
269: > - Terraform providers need to assume the same role that was already assumed
270: > by the initial authentication
271: > - You encounter errors like "User: arn:aws:sts::ACCOUNT_ID:assumed-role/github-role/SESSION
272: > is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::ACCOUNT_ID:role/github-role"
273: 
274: ### IAM Permissions for AWS Secrets Manager
275: 
276: The AWS credentials used to run local scripts must have the following permissions:
277: 
278: ```json
279: {
280:   "Version": "2012-10-17",
281:   "Statement": [
282:     {
283:       "Effect": "Allow",
284:       "Action": [
285:         "secretsmanager:GetSecretValue",
286:         "secretsmanager:DescribeSecret"
287:       ],
288:       "Resource": [
289:         "arn:aws:secretsmanager:*:*:secret:github-role-*",
290:         "arn:aws:secretsmanager:*:*:secret:tf-vars-*",
291:         "arn:aws:secretsmanager:*:*:secret:external-id-*"
292:       ]
293:     }
294:   ]
295: }
296: ```
297: 
298: ## GitHub Repository Secrets Configuration
299: 
300: GitHub Actions workflows use **repository secrets**, not AWS Secrets Manager.
301: Configure these at:
302: **Repository  Settings  Secrets and variables  Actions  Secrets**
303: 
304: ### Required GitHub Repository Secrets
305: 
306: | Secret Name | Type | Description | Used By |
307: | ------------- | ------ | ------------- | --------- |
308: | `AWS_STATE_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for backend state operations (S3 bucket access) | All workflows |
309: | `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for production deployments | Workflows (when `prod` environment) |
310: | `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for development deployments | Workflows (when `dev` environment) |
311: | `AWS_ASSUME_EXTERNAL_ID` | ExternalId | ExternalId for cross-account role assumption security | All deployment workflows |
312: | `TF_VAR_OPENLDAP_ADMIN_PASSWORD` | Password | OpenLDAP admin password | Application deployment workflows |
313: | `TF_VAR_OPENLDAP_CONFIG_PASSWORD` | Password | OpenLDAP config password | Application deployment workflows |
314: | `TF_VAR_POSTGRESQL_PASSWORD` | Password | PostgreSQL database password | Application deployment workflows |
315: | `TF_VAR_REDIS_PASSWORD` | Password | Redis password for SMS OTP storage (minimum 8 characters) | Application deployment workflows |
316: | `GH_TOKEN` | GitHub PAT | GitHub Personal Access Token with `repo` scope | State backend provisioning workflow |
317: 
318: ### Setting Up GitHub Repository Secrets
319: 
320: 1. Navigate to your repository on GitHub
321: 2. Go to **Settings  Secrets and variables  Actions  Secrets**
322: 3. Click **New repository secret**
323: 4. Enter the secret name and value
324: 5. Click **Add secret**
325: 
326: ### GitHub Token Setup
327: 
328: The `GH_TOKEN` secret is a GitHub Personal Access Token (PAT) with `repo` scope:
329: 
330: 1. Go to GitHub  Settings  Developer settings  Personal access tokens  Tokens
331: (classic)
332: 2. Click "Generate new token (classic)"
333: 3. Give it a descriptive name (e.g., "Terraform Backend State")
334: 4. Select scope: **`repo`** (Full control of private repositories)
335: 5. Click "Generate token" and copy it immediately
336: 6. Store it as a repository secret named `GH_TOKEN`
337: 
338: **Used for**: Creating/updating repository variables after state backend provisioning
339: 
340: ## Secret Details
341: 
342: ### IAM Role ARNs
343: 
344: #### AWS_STATE_ACCOUNT_ROLE_ARN
345: 
346: - **Type:** String (IAM Role ARN)
347: - **Description:** The ARN of the IAM role in the state account used for
348:   Terraform backend state operations (S3 bucket access) and Route53/ACM
349:   cross-account access
350: backend state operations (S3 bucket access for Terraform state)
351: - **Format:** `arn:aws:iam::<account-id>:role/<role-name>`
352: - **Example:** `arn:aws:iam::123456789012:role/TerraformStateRole`
353: - **Used By:**
354:   - `setup-backend.sh`
355:   - `setup-application.sh`
356:   - `set-state.sh`
357:   - `get-state.sh`
358:   - All GitHub Actions workflows
359: - **Trust Relationship Requirement:** For multi-account setups, the state account
360: role's Trust Relationship must include the deployment account role ARNs to enable
361: bidirectional trust. See the "Bidirectional Trust Relationships Required" section
362: above (in the ExternalId configuration) for configuration details.
363: - **Self-Assumption Requirement:** If the State Account role is used for both
364: backend state operations and Route53/ACM access (when `state_account_role_arn` points
365: to the same role), the trust policy must allow the role to assume itself. See the
366: "Bidirectional Trust Relationships Required" section above for the complete trust
367: policy example including the self-assumption statement.
368: 
369: #### AWS_PRODUCTION_ACCOUNT_ROLE_ARN
370: 
371: - **Type:** String (IAM Role ARN)
372: - **Description:** The ARN of the IAM role in the production deployment account
373: used for Terraform provider assume_role operations
374: - **Format:** `arn:aws:iam::<account-id>:role/<role-name>`
375: - **Example:** `arn:aws:iam::987654321098:role/TerraformDeploymentRole`
376: - **Used By:**
377:   - `setup-backend.sh` (when environment is "prod")
378:   - `setup-application.sh` (when environment is "prod")
379:   - GitHub Actions workflows (when `prod` environment is selected)
380: 
381: #### AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN
382: 
383: - **Type:** String (IAM Role ARN)
384: - **Description:** The ARN of the IAM role in the development deployment account
385: used for Terraform provider assume_role operations
386: - **Format:** `arn:aws:iam::<account-id>:role/<role-name>`
387: - **Example:** `arn:aws:iam::111222333444:role/TerraformDeploymentRole`
388: - **Used By:**
389:   - `setup-backend.sh` (when environment is "dev")
390:   - `setup-application.sh` (when environment is "dev")
391:   - GitHub Actions workflows (when `dev` environment is selected)
392: 
393: #### AWS_ASSUME_EXTERNAL_ID
394: 
395: - **Secret Location:**
396:   - AWS Secrets Manager: Plain text secret named `external-id`
397:   - GitHub: Repository secret `AWS_ASSUME_EXTERNAL_ID`
398: - **Type:** String (ExternalId)
399: - **Description:** ExternalId for cross-account role assumption security. Prevents
400: confused deputy attacks by ensuring only authorized callers can assume deployment
401: account roles. Must match the ExternalId configured in deployment account role Trust
402: Relationships.
403: - **Generation:** `openssl rand -hex 32`
404: - **Format:** Hexadecimal string (64 characters)
405: - **Example:** `a1b2c3d4e5f6789012345678901234567890abcdef1234567890abcdef123456`
406: - **Used By:**
407:   - `setup-backend.sh` (retrieved from AWS Secrets Manager)
408:   - `setup-application.sh` (retrieved from AWS Secrets Manager)
409:   - All GitHub Actions workflows (retrieved from GitHub secrets)
410: - **Security Note:** This is a sensitive security credential and must be stored
411: securely. The same value must be configured in:
412:   1. AWS Secrets Manager as `external-id` (plain text)
413:   2. GitHub repository secret `AWS_ASSUME_EXTERNAL_ID`
414:   3. Deployment account role Trust Relationships (as a condition)
415: 
416: ### Application Passwords
417: 
418: #### TF_VAR_OPENLDAP_ADMIN_PASSWORD
419: 
420: - **Secret Location:**
421:   - AWS Secrets Manager: `tf-vars` secret, key `TF_VAR_OPENLDAP_ADMIN_PASSWORD`
422:   - GitHub: Repository secret `TF_VAR_OPENLDAP_ADMIN_PASSWORD`
423: - **Type:** String (Password)
424: - **Description:** The admin password for OpenLDAP
425: - **Exported As:** `TF_VAR_openldap_admin_password` (lowercase) - Terraform automatically
426: recognizes `TF_VAR_` prefix
427: - **Format:** Plain text password string
428: - **Example:** `MySecureAdminPassword123!`
429: - **Used By:** `setup-application.sh` only
430: - **Security Note:** This is a sensitive value and should be stored securely
431: 
432: > [!IMPORTANT]
433: >
434: > The secret key in AWS/GitHub remains uppercase (`TF_VAR_OPENLDAP_ADMIN_PASSWORD`),
435: > but when exported as an environment variable, it must be lowercase (`TF_VAR_openldap_admin_password`)
436: > to match the variable name in `variables.tf`.
437: 
438: #### TF_VAR_OPENLDAP_CONFIG_PASSWORD
439: 
440: - **Secret Location:**
441:   - AWS Secrets Manager: `tf-vars` secret, key `TF_VAR_OPENLDAP_CONFIG_PASSWORD`
442:   - GitHub: Repository secret `TF_VAR_OPENLDAP_CONFIG_PASSWORD`
443: - **Type:** String (Password)
444: - **Description:** The configuration password for OpenLDAP (cn=config)
445: - **Exported As:** `TF_VAR_openldap_config_password` (lowercase)
446: - **Format:** Plain text password string
447: - **Example:** `MySecureConfigPassword456!`
448: - **Used By:** `setup-application.sh` only
449: - **Security Note:** This is a sensitive value and should be stored securely
450: 
451: #### TF_VAR_POSTGRESQL_PASSWORD
452: 
453: - **Secret Location:**
454:   - AWS Secrets Manager: `tf-vars` secret, key `TF_VAR_POSTGRESQL_PASSWORD`
455:   - GitHub: Repository secret `TF_VAR_POSTGRESQL_PASSWORD` (note: some docs may
456:   reference `TF_VAR_POSTGRES_PASSWORD`, but the correct name is `TF_VAR_POSTGRESQL_PASSWORD`)
457: - **Type:** String (Password)
458: - **Description:** The password for PostgreSQL database used for user management
459: and verification token storage
460: - **Exported As:** `TF_VAR_postgresql_database_password` (lowercase)
461: - **Format:** Plain text password string
462: - **Example:** `MySecurePostgreSQLPassword789!`
463: - **Used By:** `setup-application.sh` only
464: - **Security Note:** This is a sensitive value and should be stored securely
465: 
466: #### TF_VAR_REDIS_PASSWORD
467: 
468: - **Secret Location:**
469:   - AWS Secrets Manager: `tf-vars` secret, key `TF_VAR_REDIS_PASSWORD`
470:   - GitHub: Repository secret `TF_VAR_REDIS_PASSWORD`
471: - **Type:** String (Password)
472: - **Description:** The password for Redis used for SMS OTP code storage with
473: TTL-based expiration
474: - **Exported As:** `TF_VAR_redis_password` (lowercase)
475: - **Format:** Plain text password string (minimum 8 characters)
476: - **Example:** `MySecureRedisPassword012!`
477: - **Used By:** `setup-application.sh` only
478: - **Security Note:** This is a sensitive value and should be stored securely
479: - **Minimum Length:** 8 characters (Redis requirement)
480: 
481: ## Implementation Notes
482: 
483: ### Case Sensitivity
484: 
485: TF_VAR environment variables are case-sensitive and must match the variable names
486: defined in `variables.tf`.
487: 
488: - **Secret names in AWS/GitHub:** Remain uppercase (e.g., `TF_VAR_OPENLDAP_ADMIN_PASSWORD`)
489: - **Environment variables:** Must be lowercase (e.g., `TF_VAR_openldap_admin_password`)
490: to match Terraform variable names
491: 
492: ### Secret Retrieval Strategy
493: 
494: 1. **Three Secret Calls:** Local scripts retrieve secrets from three separate secrets
495: in AWS Secrets Manager:
496:    - `github-role` - Contains all IAM role ARNs (single call, JSON format)
497:    - `tf-vars` - Contains all Terraform variable values (single call, JSON format)
498:    - `external-id` - Contains ExternalId for cross-account role assumption
499:    (single call, plain text)
500:    This minimizes AWS CLI calls by fetching all required values from each secret
501:    in one operation.
502: 
503: 2. **JSON Validation:** Scripts validate that each secret contains valid JSON
504: before attempting to extract values.
505: 
506: 3. **Error Handling:** If any required key is missing or empty, scripts will exit
507: with an error message indicating which key failed.
508: 
509: 4. **Environment-Based Selection:** Scripts automatically select the appropriate
510: deployment role ARN based on the selected environment (prod vs dev).
511: 
512: 5. **Terraform Integration:** All Terraform variables are exported as environment
513: variables with the `TF_VAR_` prefix, which Terraform automatically recognizes
514: as variable values.
515: 
516: 6. **Separation of Concerns:** ARNs and passwords are stored in separate secrets
517: for better security and organization.
518: 
519: ### Local Script Behavior
520: 
521: Local bash scripts (`setup-backend.sh`, `setup-application.sh`, `set-state.sh`,
522: `get-state.sh`):
523: 
524: - Retrieve role ARNs from AWS Secrets Manager secret `github-role`
525: - Retrieve ExternalId from AWS Secrets Manager secret `external-id` (plain text)
526: - Retrieve passwords from AWS Secrets Manager secret `tf-vars`
527: - Export them as environment variables for Terraform
528: - Automatically handle case conversion (uppercase secrets  lowercase environment
529: variables)
530: - Add ExternalId to `variables.tfvars` for Terraform provider configuration
531: 
532: ### GitHub Actions Workflow Behavior
533: 
534: GitHub Actions workflows:
535: 
536: - Retrieve secrets directly from GitHub Repository Secrets
537: - Automatically export them as environment variables for Terraform
538: - Handle case conversion in workflow YAML
539: 
540: Example workflow configuration:
541: 
542: ```yaml
543: env:
544:   TF_VAR_openldap_admin_password: ${{ secrets.TF_VAR_OPENLDAP_ADMIN_PASSWORD }}
545:   TF_VAR_openldap_config_password: ${{ secrets.TF_VAR_OPENLDAP_CONFIG_PASSWORD }}
546:   TF_VAR_postgresql_database_password: ${{ secrets.TF_VAR_POSTGRESQL_PASSWORD }}
547:   TF_VAR_redis_password: ${{ secrets.TF_VAR_REDIS_PASSWORD }}
548: ```
549: 
550: ## Summary Tables
551: 
552: ### AWS Secrets Manager Secrets (for Local Bash Scripts)
553: 
554: | Secret Name | Key Name | Type | Required For | Description |
555: | ------------- | ---------- | ------ | -------------- | ------------- |
556: | `github-role` | `AWS_STATE_ACCOUNT_ROLE_ARN` | IAM Role ARN | All scripts | Role for backend state operations and Route53/ACM access |
557: | `github-role` | `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` | IAM Role ARN | Scripts (prod) | Role for production deployments |
558: | `github-role` | `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` | IAM Role ARN | Scripts (dev) | Role for development deployments |
559: | `external-id` | (plain text) | ExternalId | `setup-backend.sh`, `setup-application.sh` | ExternalId for cross-account role assumption security |
560: | `tf-vars` | `TF_VAR_OPENLDAP_ADMIN_PASSWORD` | Password | `setup-application.sh` | OpenLDAP admin password (exported as `TF_VAR_openldap_admin_password`) |
561: | `tf-vars` | `TF_VAR_OPENLDAP_CONFIG_PASSWORD` | Password | `setup-application.sh` | OpenLDAP config password (exported as `TF_VAR_openldap_config_password`) |
562: | `tf-vars` | `TF_VAR_POSTGRESQL_PASSWORD` | Password | `setup-application.sh` | PostgreSQL database password (exported as `TF_VAR_postgresql_database_password`) |
563: | `tf-vars` | `TF_VAR_REDIS_PASSWORD` | Password | `setup-application.sh` | Redis password for SMS OTP storage (exported as `TF_VAR_redis_password`) |
564: 
565: ### GitHub Repository Secrets (for GitHub Actions Workflows)
566: 
567: | Secret Name | Type | Description |
568: | ------------- | ------ | ------------- |
569: | `AWS_STATE_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for backend state operations and Route53/ACM access |
570: | `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for production deployments |
571: | `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` | IAM Role ARN | Role for development deployments |
572: | `AWS_ASSUME_EXTERNAL_ID` | ExternalId | ExternalId for cross-account role assumption security (must match deployment account role Trust Relationship) |
573: | `TF_VAR_OPENLDAP_ADMIN_PASSWORD` | Password | OpenLDAP admin password |
574: | `TF_VAR_OPENLDAP_CONFIG_PASSWORD` | Password | OpenLDAP config password |
575: | `TF_VAR_POSTGRESQL_PASSWORD` | Password | PostgreSQL database password |
576: | `TF_VAR_REDIS_PASSWORD` | Password | Redis password for SMS OTP storage (minimum 8 characters) |
577: | `GH_TOKEN` | GitHub PAT | GitHub Personal Access Token with `repo` scope |
578: 
579: ## Troubleshooting
580: 
581: ### AWS Secrets Manager Issues (Local Scripts)
582: 
583: **Problem:** Local scripts cannot retrieve secrets from AWS Secrets Manager
584: 
585: **Common issues and solutions:**
586: 
587: - **Secret doesn't exist:** Ensure secret named `github-role` or `tf-vars` exists
588: in AWS Secrets Manager
589: - **Access denied:** Your AWS credentials must have `secretsmanager:GetSecretValue`
590: permission for the secrets
591: - **Key not found:** Ensure the secret JSON contains the required keys
592: - **Invalid JSON:** Verify the secret value is valid JSON format
593: - **Wrong region:** Ensure your AWS CLI is configured to the correct region where
594: the secrets exist
595: 
596: **Verification:**
597: 
598: ```bash
599: # Test secret retrieval manually
600: aws secretsmanager get-secret-value --secret-id github-role --query SecretString --output text | jq .
601: aws secretsmanager get-secret-value --secret-id tf-vars --query SecretString --output text | jq .
602: ```
603: 
604: ### GitHub Secrets Issues
605: 
606: **Problem:** GitHub Actions workflows cannot access secrets
607: 
608: **Common issues and solutions:**
609: 
610: - **Secret not configured:** Ensure all required secrets are set in
611: Repository Settings  Secrets and variables  Actions  Secrets
612: - **Wrong secret name:** Verify secret names match exactly (case-sensitive)
613: - **Insufficient permissions:** Ensure the workflow has access to repository secrets
614: - **Secret not available in workflow:** Check that secrets are referenced correctly
615: in workflow YAML
616: 
617: ### Case Sensitivity Issues
618: 
619: **Problem:** Terraform variables not recognized
620: 
621: **Solution:** Ensure environment variables use lowercase to match `variables.tf`:
622: 
623: - Secret: `TF_VAR_OPENLDAP_ADMIN_PASSWORD` (uppercase in GitHub/AWS)
624: - Environment variable: `TF_VAR_openldap_admin_password` (lowercase for Terraform)
625: 
626: ## Related Documentation
627: 
628: - [Main README](README.md) - Project overview and setup instructions
629: - [Application Infrastructure README](application/README.md) - Application deployment
630: details
631: - [Backend Infrastructure README](backend_infra/README.md) - Backend infrastructure
632: setup
633: - [Terraform Backend State README](tf_backend_state/README.md) - State backend
634: configuration
````

## File: .github/workflows/tfstate_infra_provisioning.yaml
````yaml
  1: name: TF Backend State Provisioning
  2: 
  3: on:
  4:   workflow_dispatch:
  5: 
  6: jobs:
  7:   InfraProvision:
  8:     runs-on: ubuntu-latest
  9:     permissions:
 10:       contents: write
 11:       actions: write
 12:       id-token: write
 13:     env:
 14:       AWS_REGION: ${{ vars.AWS_REGION }}
 15:     defaults:
 16:       run:
 17:         working-directory: ./tf_backend_state
 18:     steps:
 19:       - name: Checkout the repo code
 20:         uses: actions/checkout@v4
 21: 
 22:       - name: Setup terraform
 23:         uses: hashicorp/setup-terraform@v3
 24:         with:
 25:           terraform_version: 1.14.0
 26: 
 27:       - name: Configure AWS credentials (State Account)
 28:         uses: aws-actions/configure-aws-credentials@v4
 29:         with:
 30:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
 31:           role-session-name: GitHubActions-TFStateInfraProvision
 32:           aws-region: ${{ env.AWS_REGION }}
 33: 
 34:       - name: Check for existing state file
 35:         uses: actions/github-script@v7
 36:         id: check_state
 37:         with:
 38:           github-token: ${{ secrets.GH_TOKEN }}
 39:           script: |
 40:             const repo = context.repo;
 41:             let bucketName = '';
 42:             let exists = 'false';
 43: 
 44:             try {
 45:               // Try to get existing BACKEND_BUCKET_NAME variable
 46:               const response = await github.rest.actions.getRepoVariable({
 47:                 owner: repo.owner,
 48:                 repo: repo.repo,
 49:                 name: 'BACKEND_BUCKET_NAME'
 50:               });
 51:               bucketName = response.data.value || '';
 52:               if (bucketName) {
 53:                 console.log(`Found existing BACKEND_BUCKET_NAME: ${bucketName}`);
 54:                 exists = 'true';
 55:               } else {
 56:                 console.log('BACKEND_BUCKET_NAME variable exists but is empty');
 57:                 exists = 'false';
 58:               }
 59:             } catch (error) {
 60:               if (error.status === 404) {
 61:                 console.log('BACKEND_BUCKET_NAME variable does not exist, proceeding with new provisioning');
 62:                 exists = 'false';
 63:               } else {
 64:                 console.error('Error checking repository variable:', error.message);
 65:                 throw error;
 66:               }
 67:             }
 68: 
 69:             // Always set outputs to avoid linter warnings
 70:             core.setOutput('bucket_name', bucketName);
 71:             core.setOutput('exists', exists);
 72: 
 73:       - name: Download existing state file if available
 74: 
 75:         if: steps.check_state.outputs.exists == 'true' && steps.check_state.outputs.bucket_name != ''
 76:         env:
 77:           BUCKET_NAME: ${{ steps.check_state.outputs.bucket_name }}
 78:           BACKEND_PREFIX: ${{ vars.BACKEND_PREFIX }}
 79:         run: |
 80:           if [ -z "$BUCKET_NAME" ] || [ -z "$BACKEND_PREFIX" ]; then
 81:             echo "Bucket name or prefix is empty, skipping state file download"
 82:             exit 0
 83:           fi
 84: 
 85:           S3_PATH="s3://${BUCKET_NAME}/${BACKEND_PREFIX}"
 86:           echo "Attempting to download state file from: ${S3_PATH}"
 87: 
 88:           if aws s3 ls "$S3_PATH" 2>/dev/null | grep -q .; then
 89:             echo "State file exists, downloading..."
 90:             aws s3 cp "$S3_PATH" terraform.tfstate
 91:             echo "State file downloaded successfully"
 92:           else
 93:             echo "State file does not exist in S3, proceeding with new provisioning"
 94:           fi
 95: 
 96:       - name: Terraform init
 97:         run: terraform init -backend=false
 98: 
 99:       - name: Terraform validate
100:         run: terraform validate
101: 
102:       - name: Terraform plan
103:         run: terraform plan -var-file="variables.tfvars" -out terraform.tfplan
104: 
105:       - name: Provision backend state
106:         id: provision_backend
107:         run: |
108:           terraform apply -auto-approve terraform.tfplan
109:           BUCKET_NAME=$(terraform output -raw bucket_name)
110:           echo "bucket_name=$BUCKET_NAME" >> $GITHUB_OUTPUT
111: 
112:       - name: Save bucket name to GitHub repository variable
113:         uses: actions/github-script@v7
114:         env:
115:           BUCKET_NAME: ${{ steps.provision_backend.outputs.bucket_name }}
116:         with:
117:           github-token: ${{ secrets.GH_TOKEN }}
118:           script: |
119:             const bucketName = process.env.BUCKET_NAME;
120:             const repo = context.repo;
121: 
122:             if (!bucketName || bucketName.trim() === '') {
123:               throw new Error('BUCKET_NAME is not set or is empty');
124:             }
125: 
126:             console.log(`Saving bucket name: ${bucketName}`);
127: 
128:             try {
129:               // Try to get existing bucket name variable
130:               try {
131:                 await github.rest.actions.getRepoVariable({
132:                   owner: repo.owner,
133:                   repo: repo.repo,
134:                   name: 'BACKEND_BUCKET_NAME'
135:                 });
136: 
137:                 // Update existing bucket name variable
138:                 await github.rest.actions.updateRepoVariable({
139:                   owner: repo.owner,
140:                   repo: repo.repo,
141:                   name: 'BACKEND_BUCKET_NAME',
142:                   value: bucketName
143:                 });
144:                 console.log('Updated repository variable BACKEND_BUCKET_NAME');
145:               } catch (error) {
146:                 if (error.status === 404) {
147:                   // Variable doesn't exist, create it
148:                   await github.rest.actions.createRepoVariable({
149:                     owner: repo.owner,
150:                     repo: repo.repo,
151:                     name: 'BACKEND_BUCKET_NAME',
152:                     value: bucketName
153:                   });
154:                   console.log('Created repository variable BACKEND_BUCKET_NAME');
155:                 } else {
156:                   throw error;
157:                 }
158:               }
159:             } catch (error) {
160:               console.error('Error saving repository variable:', error.message);
161:               console.error('Note: GITHUB_TOKEN may need write permissions for repository variables.');
162:               console.error('Please ensure "Allow GitHub Actions to create and approve pull requests" is enabled in repository settings.');
163:               throw error;
164:             }
165: 
166:       - name: Upload backend state file to S3
167: 
168:         env:
169:           BUCKET_NAME: ${{ steps.provision_backend.outputs.bucket_name }}
170:           BACKEND_PREFIX: ${{ vars.BACKEND_PREFIX }}
171:         run: |
172:           if [ -z "$BUCKET_NAME" ] || [ -z "$BACKEND_PREFIX" ]; then
173:             echo "Error: BUCKET_NAME or BACKEND_PREFIX is empty"
174:             exit 1
175:           fi
176:           echo "Uploading state file to s3://${BUCKET_NAME}/${BACKEND_PREFIX}"
177:           aws s3 cp terraform.tfstate s3://${BUCKET_NAME}/${BACKEND_PREFIX}
178:           echo "State file uploaded successfully"
````

## File: application/modules/alb/main.tf
````hcl
  1: # *** EKS Auto mode has its own load balancer driver ***
  2: # So there is no need to configure AWS Load Balancer Controller
  3: 
  4: # *** EKS Auto Mode takes care of IAM permissions ***
  5: # There is no need to attach AWSLoadBalancerControllerIAMPolicy to the EKS Node IAM Role
  6: 
  7: locals {
  8:   # ingress_alb_name            = "${var.prefix}-${var.region}-${var.ingress_alb_name}-${var.env}"
  9:   # service_alb_name            = "${var.prefix}-${var.region}-${var.service_alb_name}-${var.env}"
 10:   ingressclass_alb_name       = "${var.prefix}-${var.region}-${var.ingressclass_alb_name}-${var.env}"
 11:   ingressclassparams_alb_name = "${var.prefix}-${var.region}-${var.ingressclassparams_alb_name}-${var.env}"
 12: }
 13: 
 14: # Kubernetes Ingress and Service resources commented out
 15: # These are not needed - OpenLDAP Helm chart creates its own Ingress resources
 16: # which will use the IngressClass defined below
 17: 
 18: # resource "kubernetes_ingress_v1" "ingress_alb" {
 19: #   metadata {
 20: #     name      = local.ingress_alb_name
 21: #     namespace = "default"
 22: #     annotations = merge(
 23: #       {
 24: #         "alb.ingress.kubernetes.io/scheme"         = "internet-facing"
 25: #         "alb.ingress.kubernetes.io/tags"          = "Terraform=true,Environment=${var.env}"
 26: #         "alb.ingress.kubernetes.io/target-type"   = "ip"
 27: #         "alb.ingress.kubernetes.io/listen-ports" = var.acm_certificate_arn != null ? "[{\"HTTP\":80},{\"HTTPS\":443}]" : "[{\"HTTP\":80}]"
 28: #       },
 29: #       var.acm_certificate_arn != null ? {
 30: #         "alb.ingress.kubernetes.io/certificate-arn" = var.acm_certificate_arn
 31: #         "alb.ingress.kubernetes.io/ssl-redirect"    = "443"
 32: #         "alb.ingress.kubernetes.io/ssl-policy"      = "ELBSecurityPolicy-TLS13-1-0-PQ-2025-09"
 33: #       } : {}
 34: #     )
 35: #   }
 36: #
 37: #   spec {
 38: #     # this matches the name of IngressClass.
 39: #     # this can be omitted if you have a default ingressClass in cluster: the one with ingressclass.kubernetes.io/is-default-class: "true"  annotation
 40: #     ingress_class_name = local.ingressclass_alb_name
 41: #
 42: #     rule {
 43: #       http {
 44: #         path {
 45: #           path      = "/"
 46: #           path_type = "Prefix"
 47: #
 48: #           backend {
 49: #             service {
 50: #               name = kubernetes_service_v1.service_alb.metadata[0].name
 51: #               port {
 52: #                 number = 8080
 53: #               }
 54: #             }
 55: #           }
 56: #         }
 57: #       }
 58: #     }
 59: #   }
 60: # }
 61: #
 62: # # Kubernetes Service for the App
 63: # resource "kubernetes_service_v1" "service_alb" {
 64: #   metadata {
 65: #     name      = local.service_alb_name
 66: #     namespace = "default"
 67: #     labels = {
 68: #       app = var.app_name
 69: #     }
 70: #   }
 71: #
 72: #   spec {
 73: #     selector = {
 74: #       app = var.app_name
 75: #     }
 76: #
 77: #     port {
 78: #       port        = 8080
 79: #       target_port = 8080
 80: #     }
 81: #
 82: #     type = "ClusterIP"
 83: #   }
 84: # }
 85: 
 86: # The IngressClassParams resource is a custom Kubernetes resource (CRD) provided by EKS Auto Mode.
 87: # We use the `kubernetes_manifest` resource to manage it in a Terraform-native way.
 88: #
 89: #  RISKS AND MITIGATION:
 90: #
 91: # 1. CRD Availability Risk:
 92: #    - The IngressClassParams CRD is installed by EKS Auto Mode when the cluster is created
 93: #    - If Terraform runs before Auto Mode finishes initializing, the CRD may not exist
 94: #    - This causes failures during `terraform apply` (not plan, since we can't check CRD existence in plan)
 95: #
 96: # 2. Mitigation Strategies:
 97: #    a) Ensure cluster is fully ready: The Kubernetes provider uses data sources that require
 98: #       the cluster to exist, but doesn't guarantee CRD availability
 99: #    b) Use time_sleep for initial deployments: Adds a delay to allow Auto Mode to initialize
100: #    c) Retry logic: Terraform will retry on apply, but you may need to run apply multiple times
101: #    d) Manual verification: Check CRD exists: `kubectl get crd ingressclassparams.eks.amazonaws.com`
102: #
103: # 3. Alternative Approach:
104: #    If you experience frequent CRD availability issues, consider:
105: #    - Using the original null_resource + kubectl approach (more forgiving)
106: #    - Adding a data source to check CRD existence first (requires kubectl provider)
107: #    - Using a Helm chart that handles CRD installation
108: #
109: # Annotation Strategy (cluster-wide defaults):
110: # - IngressClassParams defines cluster-wide defaults that apply to all Ingresses using this IngressClass
111: # - EKS Auto Mode IngressClassParams supports: scheme, ipAddressType, group.name, and certificateARNs
112: # - Per-Ingress ALB configuration (load-balancer-name, listen-ports, ssl-redirect, target-type)
113: #   should be defined at the Ingress level via annotations
114: # - All Ingresses using this IngressClass inherit cluster-wide settings from IngressClassParams
115: 
116: # Optional: Add a delay for initial cluster setup to allow EKS Auto Mode to install CRDs
117: #
118: # IMPORTANT: There is NO Terraform resource that represents "CRD is installed"
119: # The IngressClassParams CRD is installed asynchronously by EKS Auto Mode after cluster creation.
120: # The cluster resource (module.eks in backend_infra) completes before CRDs are guaranteed to exist.
121: #
122: # What we're actually waiting for:
123: # - NOT a Terraform resource (there isn't one for CRD availability)
124: # - The asynchronous EKS Auto Mode process to install the CRD
125: # - This typically happens within seconds of cluster creation, but isn't guaranteed
126: #
127: # Set wait_for_crd = true for initial deployments, false after cluster is established
128: resource "time_sleep" "wait_for_eks_auto_mode" {
129:   # Always create the resource, but use 0s duration when wait_for_crd is false
130:   # This allows us to always reference it in depends_on (which requires a static list)
131:   create_duration = var.wait_for_crd ? "30s" : "0s"
132: 
133:   # Trigger recreation if cluster changes (helps with new cluster deployments)
134:   triggers = {
135:     cluster_name = var.cluster_name
136:   }
137: }
138: 
139: resource "kubernetes_manifest" "ingressclassparams_alb" {
140:   # Wait for:
141:   # 1. The Kubernetes provider to be configured (implicit via data.aws_eks_cluster)
142:   # 2. Optionally, a delay to allow EKS Auto Mode to install the CRD
143:   #
144:   # Note: We can't explicitly depend on the CRD existing because there's no Terraform
145:   # resource for it. The time_sleep is a workaround for the asynchronous CRD installation.
146:   # When wait_for_crd is false, time_sleep has 0s duration (no actual delay).
147:   depends_on = [time_sleep.wait_for_eks_auto_mode]
148: 
149:   manifest = {
150:     apiVersion = "eks.amazonaws.com/v1"
151:     kind       = "IngressClassParams"
152:     metadata = {
153:       name = local.ingressclassparams_alb_name
154:     }
155:     spec = merge(
156:       {
157:         scheme        = var.alb_scheme
158:         ipAddressType = var.alb_ip_address_type
159:         group = {
160:           name = var.alb_group_name
161:         }
162:       },
163:       var.acm_certificate_arn != null && var.acm_certificate_arn != "" ? {
164:         certificateARNs = [var.acm_certificate_arn]
165:       } : {}
166:     )
167:   }
168: 
169:   # Wait for the resource to be created and ready
170:   # This ensures the resource exists before dependent resources are created
171:   wait {
172:     fields = {
173:       "metadata.name" = local.ingressclassparams_alb_name
174:     }
175:   }
176: 
177:   # Use server-side apply to handle conflicts better
178:   # This is safer for custom resources that might be managed elsewhere
179:   computed_fields = ["metadata.labels", "metadata.annotations"]
180: }
181: 
182: # IngressClass binds Ingress resources to EKS Auto Mode controller
183: # and references IngressClassParams for cluster-wide ALB defaults
184: resource "kubernetes_ingress_class_v1" "ingressclass_alb" {
185:   depends_on = [kubernetes_manifest.ingressclassparams_alb]
186:   metadata {
187:     name = local.ingressclass_alb_name
188: 
189:     # Use this annotation to set an IngressClass as Default
190:     # If an Ingress doesn't specify a class, it will use the Default
191:     annotations = {
192:       "ingressclass.kubernetes.io/is-default-class" = "true"
193:     }
194:   }
195: 
196:   spec {
197:     # Configures the IngressClass to use EKS Auto Mode (built-in load balancer driver)
198:     controller = "eks.amazonaws.com/alb"
199:     parameters {
200:       api_group = "eks.amazonaws.com"
201:       kind      = "IngressClassParams"
202:       # References IngressClassParams which contains cluster-wide defaults (scheme, ipAddressType, group.name, certificateARNs)
203:       name = local.ingressclassparams_alb_name
204:     }
205:   }
206: }
````

## File: application/modules/argocd/main.tf
````hcl
  1: locals {
  2:   argocd_role_name       = "${var.prefix}-${var.region}-${var.argocd_role_name_component}-${var.env}"
  3:   argocd_capability_name = "${var.prefix}-${var.region}-${var.argocd_capability_name_component}-${var.env}"
  4: 
  5:   tags = {
  6:     Env       = "${var.env}"
  7:     Terraform = "true"
  8:   }
  9: }
 10: 
 11: # IAM Trust Policy for ArgoCD Capability Role
 12: data "aws_iam_policy_document" "argocd_assume_role" {
 13:   statement {
 14:     effect = "Allow"
 15: 
 16:     principals {
 17:       type        = "Service"
 18:       identifiers = ["capabilities.eks.amazonaws.com"]
 19:     }
 20: 
 21:     actions = [
 22:       "sts:AssumeRole",
 23:       "sts:TagSession",
 24:     ]
 25:   }
 26: }
 27: 
 28: # IAM Role for ArgoCD Capability
 29: resource "aws_iam_role" "argocd_capability" {
 30:   name = local.argocd_role_name
 31: 
 32:   assume_role_policy = data.aws_iam_policy_document.argocd_assume_role.json
 33: 
 34:   tags = merge(
 35:     local.tags,
 36:     {
 37:       Name = local.argocd_role_name
 38:     }
 39:   )
 40: 
 41:   # Force replacement if trust policy changes to ensure AWS validates correctly
 42:   lifecycle {
 43:     create_before_destroy = true
 44:   }
 45: }
 46: 
 47: # IAM Policy Document for ArgoCD Capability
 48: data "aws_iam_policy_document" "argocd_capability" {
 49:   statement {
 50:     sid    = "EKSDescribe"
 51:     effect = "Allow"
 52: 
 53:     actions = [
 54:       "eks:DescribeCluster",
 55:       "eks:ListClusters",
 56:       "eks:DescribeUpdate",
 57:       "eks:ListUpdates"
 58:     ]
 59: 
 60:     resources = var.iam_policy_eks_resources
 61:   }
 62: 
 63:   statement {
 64:     sid    = "SecretsManager"
 65:     effect = "Allow"
 66: 
 67:     actions = [
 68:       "secretsmanager:GetSecretValue",
 69:       "secretsmanager:DescribeSecret",
 70:       "secretsmanager:ListSecrets"
 71:     ]
 72: 
 73:     resources = var.iam_policy_secrets_manager_resources
 74:   }
 75: 
 76:   statement {
 77:     sid    = "CodeConnections"
 78:     effect = "Allow"
 79: 
 80:     actions = [
 81:       "codeconnections:ListConnections",
 82:       "codeconnections:GetConnection"
 83:     ]
 84: 
 85:     resources = var.iam_policy_code_connections_resources
 86:   }
 87: 
 88:   dynamic "statement" {
 89:     for_each = var.enable_ecr_access ? [1] : []
 90:     content {
 91:       sid    = "ECRAccess"
 92:       effect = "Allow"
 93: 
 94:       actions = [
 95:         "ecr:GetAuthorizationToken",
 96:         "ecr:BatchCheckLayerAvailability",
 97:         "ecr:GetDownloadUrlForLayer",
 98:         "ecr:BatchGetImage"
 99:       ]
100: 
101:       resources = var.iam_policy_ecr_resources
102:     }
103:   }
104: 
105:   dynamic "statement" {
106:     for_each = var.enable_codecommit_access ? [1] : []
107:     content {
108:       sid    = "CodeCommitAccess"
109:       effect = "Allow"
110: 
111:       actions = [
112:         "codecommit:GitPull",
113:         "codecommit:GetRepository"
114:       ]
115: 
116:       resources = var.iam_policy_codecommit_resources
117:     }
118:   }
119: }
120: 
121: # Attach IAM Policy to Role
122: resource "aws_iam_role_policy" "argocd_capability" {
123:   name   = "${local.argocd_role_name}-policy"
124:   role   = aws_iam_role.argocd_capability.id
125:   policy = data.aws_iam_policy_document.argocd_capability.json
126: }
127: 
128: # EKS Cluster Data Source
129: data "aws_eks_cluster" "this" {
130:   name = var.cluster_name
131: }
132: 
133: # Wait for IAM role to propagate before creating EKS capability
134: resource "time_sleep" "wait_for_iam_propagation" {
135:   depends_on = [
136:     aws_iam_role.argocd_capability,
137:     aws_iam_role_policy.argocd_capability
138:   ]
139: 
140:   create_duration = "30s"
141: }
142: 
143: # EKS Capability for ArgoCD
144: resource "aws_eks_capability" "argocd" {
145:   cluster_name    = var.cluster_name
146:   capability_name = local.argocd_capability_name
147:   type            = "ARGOCD"
148: 
149:   role_arn                  = aws_iam_role.argocd_capability.arn
150:   delete_propagation_policy = var.delete_propagation_policy
151: 
152:   configuration {
153:     argo_cd {
154:       namespace = var.argocd_namespace
155: 
156:       aws_idc {
157:         idc_instance_arn = var.idc_instance_arn
158:         idc_region       = var.idc_region
159:       }
160: 
161:       dynamic "rbac_role_mapping" {
162:         for_each = var.rbac_role_mappings
163:         content {
164:           role = rbac_role_mapping.value.role
165: 
166:           dynamic "identity" {
167:             for_each = rbac_role_mapping.value.identities
168:             content {
169:               id   = identity.value.id
170:               type = identity.value.type
171:             }
172:           }
173:         }
174:       }
175: 
176:       dynamic "network_access" {
177:         for_each = length(var.argocd_vpce_ids) > 0 ? [1] : []
178:         content {
179:           vpce_ids = var.argocd_vpce_ids
180:         }
181:       }
182:     }
183:   }
184: 
185:   tags = merge(
186:     local.tags,
187:     {
188:       Name                 = local.argocd_capability_name
189:       "eks:cluster"        = var.cluster_name
190:       "eks:capabilityType" = "ARGOCD"
191:     }
192:   )
193: 
194:   depends_on = [
195:     aws_iam_role.argocd_capability,
196:     aws_iam_role_policy.argocd_capability,
197:     time_sleep.wait_for_iam_propagation
198:   ]
199: }
200: 
201: # External data source to query ArgoCD capability details via AWS CLI
202: # This automatically retrieves server_url and status without manual CLI commands
203: data "external" "argocd_capability" {
204:   program = ["bash", "-c", <<-EOT
205:     # Check if jq is available
206:     if ! command -v jq &> /dev/null; then
207:       echo '{"server_url":"","status":"","error":"jq is required but not installed"}' >&2
208:       exit 1
209:     fi
210: 
211:     # Query the capability
212:     result=$(aws eks describe-capability \
213:       --cluster-name "${var.cluster_name}" \
214:       --capability-name "${local.argocd_capability_name}" \
215:       --capability-type ARGOCD \
216:       --region "${var.region}" \
217:       2>&1) || {
218:       # If capability doesn't exist yet or command failed, return empty values
219:       echo '{"server_url":"","status":""}'
220:       exit 0
221:     }
222: 
223:     # Extract and format as JSON using jq
224:     echo "$result" | jq -c '{
225:       server_url: (.capability.configuration.argoCd.serverUrl // .configuration.argoCd.serverUrl // ""),
226:       status: (.capability.status // .status // "")
227:     }' 2>/dev/null || echo '{"server_url":"","status":""}'
228:   EOT
229:   ]
230: 
231:   depends_on = [aws_eks_capability.argocd]
232: }
233: 
234: # Cluster Registration Secret
235: resource "kubernetes_secret" "argocd_local_cluster" {
236:   metadata {
237:     name      = var.local_cluster_secret_name
238:     namespace = var.argocd_namespace
239:     labels = {
240:       "argocd.argoproj.io/secret-type" = "cluster"
241:     }
242:   }
243: 
244:   data = {
245:     name    = base64encode(var.local_cluster_secret_name)
246:     server  = base64encode(data.aws_eks_cluster.this.arn)
247:     project = base64encode(var.argocd_project_name)
248:   }
249: 
250:   type = "Opaque"
251: 
252:   depends_on = [
253:     aws_eks_capability.argocd
254:   ]
255: }
````

## File: application/outputs.tf
````hcl
  1: output "alb_dns_name" {
  2:   description = "DNS name of the shared ALB created by Ingress resources"
  3:   value       = var.use_alb ? local.alb_dns_name : null
  4: }
  5: 
  6: output "route53_acm_cert_arn" {
  7:   description = "ACM certificate ARN (validated and ready for use)"
  8:   value       = data.aws_acm_certificate.this.arn
  9: }
 10: 
 11: output "route53_domain_name" {
 12:   description = "Root domain name"
 13:   value       = var.domain_name
 14: }
 15: 
 16: output "route53_zone_id" {
 17:   description = "Route53 hosted zone ID"
 18:   value       = data.aws_route53_zone.this.zone_id
 19: }
 20: 
 21: output "route53_name_servers" {
 22:   description = "Route53 name servers (for registrar configuration)"
 23:   value       = data.aws_route53_zone.this.name_servers
 24: }
 25: 
 26: ##################### ALB Module ##########################
 27: output "alb_ingress_class_name" {
 28:   description = "Name of the IngressClass for shared ALB"
 29:   value       = var.use_alb ? module.alb[0].ingress_class_name : null
 30: }
 31: 
 32: output "alb_ingress_class_params_name" {
 33:   description = "Name of the IngressClassParams for ALB configuration"
 34:   value       = var.use_alb ? module.alb[0].ingress_class_params_name : null
 35: }
 36: 
 37: output "alb_scheme" {
 38:   description = "ALB scheme configured in IngressClassParams"
 39:   value       = var.use_alb ? module.alb[0].alb_scheme : null
 40: }
 41: 
 42: output "alb_ip_address_type" {
 43:   description = "ALB IP address type configured in IngressClassParams"
 44:   value       = var.use_alb ? module.alb[0].alb_ip_address_type : null
 45: }
 46: 
 47: ##################### Network Policies Module ##########################
 48: # Network policies are created within the openldap module
 49: # These outputs expose the network policy information from the openldap module
 50: output "network_policy_name" {
 51:   description = "Name of the network policy for secure namespace communication"
 52:   value       = module.openldap.network_policy_name
 53: }
 54: 
 55: output "network_policy_namespace" {
 56:   description = "Namespace where the network policy is applied"
 57:   value       = module.openldap.network_policy_namespace
 58: }
 59: 
 60: output "network_policy_uid" {
 61:   description = "UID of the network policy resource"
 62:   value       = module.openldap.network_policy_uid
 63: }
 64: 
 65: ##################### PostgreSQL ##########################
 66: output "postgresql_host" {
 67:   description = "PostgreSQL service hostname"
 68:   value       = var.enable_postgresql ? module.postgresql[0].host : null
 69: }
 70: 
 71: output "postgresql_connection_url" {
 72:   description = "PostgreSQL connection URL (without password)"
 73:   value       = var.enable_postgresql ? module.postgresql[0].connection_url : null
 74: }
 75: 
 76: output "postgresql_database" {
 77:   description = "PostgreSQL database name"
 78:   value       = var.enable_postgresql ? module.postgresql[0].database : null
 79: }
 80: 
 81: ##################### SES Email ##########################
 82: output "ses_sender_email" {
 83:   description = "SES verified sender email"
 84:   value       = var.enable_email_verification ? module.ses[0].sender_email : null
 85: }
 86: 
 87: output "ses_iam_role_arn" {
 88:   description = "ARN of the IAM role for SES access (for IRSA)"
 89:   value       = var.enable_email_verification ? module.ses[0].iam_role_arn : null
 90: }
 91: 
 92: output "ses_verification_status" {
 93:   description = "SES verification status/instructions"
 94:   value       = var.enable_email_verification ? module.ses[0].verification_status : null
 95: }
 96: 
 97: ##################### SNS SMS 2FA ##########################
 98: output "sns_topic_arn" {
 99:   description = "ARN of the SNS topic for SMS 2FA"
100:   value       = var.enable_sms_2fa ? module.sns[0].sns_topic_arn : null
101: }
102: 
103: output "sns_topic_name" {
104:   description = "Name of the SNS topic"
105:   value       = var.enable_sms_2fa ? module.sns[0].sns_topic_name : null
106: }
107: 
108: output "sns_iam_role_arn" {
109:   description = "ARN of the IAM role for SNS publishing (for IRSA)"
110:   value       = var.enable_sms_2fa ? module.sns[0].iam_role_arn : null
111: }
112: 
113: output "sns_service_account_annotation" {
114:   description = "Annotation to add to Kubernetes service account for IRSA"
115:   value       = var.enable_sms_2fa ? module.sns[0].service_account_annotation : null
116: }
117: 
118: ##################### Redis SMS OTP Storage ##########################
119: output "redis_host" {
120:   description = "Redis service hostname"
121:   value       = var.enable_redis ? module.redis[0].redis_host : null
122: }
123: 
124: output "redis_port" {
125:   description = "Redis service port"
126:   value       = var.enable_redis ? module.redis[0].redis_port : null
127: }
128: 
129: output "redis_namespace" {
130:   description = "Kubernetes namespace where Redis is deployed"
131:   value       = var.enable_redis ? module.redis[0].redis_namespace : null
132: }
133: 
134: output "redis_password_secret_name" {
135:   description = "Name of the Kubernetes secret containing Redis password"
136:   value       = var.enable_redis ? module.redis[0].redis_password_secret_name : null
137: }
138: 
139: output "redis_password_secret_key" {
140:   description = "Key in the secret for Redis password"
141:   value       = var.enable_redis ? module.redis[0].redis_password_secret_key : null
142: }
143: 
144: ##################### 2FA Application ##########################
145: output "twofa_app_url" {
146:   description = "URL for the 2FA application (frontend)"
147:   value       = var.twofa_app_host != null ? "https://${var.twofa_app_host}" : null
148: }
149: 
150: output "twofa_api_url" {
151:   description = "URL for the 2FA API (backend)"
152:   value       = var.twofa_app_host != null ? "https://${var.twofa_app_host}/api" : null
153: }
154: 
155: ##################### ArgoCD Applications ##########################
156: output "argocd_backend_app_name" {
157:   description = "Name of the ArgoCD Application for backend"
158:   value       = var.enable_argocd_apps ? var.argocd_app_backend_name : null
159: }
160: 
161: output "argocd_frontend_app_name" {
162:   description = "Name of the ArgoCD Application for frontend"
163:   value       = var.enable_argocd_apps ? var.argocd_app_frontend_name : null
164: }
````

## File: backend_infra/main.tf
````hcl
  1: # Dynamic Account ID
  2: data "aws_caller_identity" "current" {}
  3: 
  4: data "aws_availability_zones" "available" {
  5:   state = "available"
  6: }
  7: 
  8: # Logging Prefix Pattern
  9: locals {
 10:   current_identity = data.aws_caller_identity.current.arn
 11:   current_account  = data.aws_caller_identity.current.account_id
 12:   azs              = slice(data.aws_availability_zones.available.names, 0, 2)
 13:   vpc_name         = "${var.prefix}-${var.region}-${var.vpc_name}-${var.env}"
 14:   ngw_name         = "${var.prefix}-${var.region}-${var.ngw_name}-${var.env}"
 15:   igw_name         = "${var.prefix}-${var.region}-${var.igw_name}-${var.env}"
 16:   route_table_name = "${var.prefix}-${var.region}-${var.route_table_name}-${var.env}"
 17:   public_subnet_names = [
 18:     "${local.vpc_name}-public-subnet-1",
 19:     "${local.vpc_name}-public-subnet-2"
 20:   ]
 21:   private_subnet_names = [
 22:     "${local.vpc_name}-private-subnet-1",
 23:     "${local.vpc_name}-private-subnet-2"
 24:   ]
 25:   cluster_name = "${var.prefix}-${var.region}-${var.cluster_name}-${var.env}"
 26:   tags = {
 27:     Env       = "${var.env}"
 28:     Terraform = "true"
 29:   }
 30: }
 31: 
 32: module "vpc" {
 33:   source  = "terraform-aws-modules/vpc/aws"
 34:   version = "6.5.1"
 35:   name    = local.vpc_name
 36:   cidr    = var.vpc_cidr
 37:   azs     = local.azs
 38:   ### Private Subnets ###
 39:   private_subnets      = [for k, v in local.azs : cidrsubnet(var.vpc_cidr, 4, k)]
 40:   private_subnet_names = local.private_subnet_names
 41:   private_subnet_tags = {
 42:     "kubernetes.io/role/internal-elb"             = 1
 43:     "kubernetes.io/cluster/${local.cluster_name}" = "shared"
 44:   }
 45:   ### Public Subnets ###
 46:   public_subnets      = [for k, v in local.azs : cidrsubnet(var.vpc_cidr, 8, k + 48)]
 47:   public_subnet_names = local.public_subnet_names
 48:   public_subnet_tags = {
 49:     "kubernetes.io/role/elb"                      = 1
 50:     "kubernetes.io/cluster/${local.cluster_name}" = "shared"
 51:   }
 52: 
 53:   create_database_subnet_group = false
 54:   # manage_default_network_acl    = false
 55:   # manage_default_route_table    = false
 56:   # manage_default_security_group = false
 57: 
 58:   enable_dns_hostnames = true
 59:   enable_dns_support   = true
 60: 
 61:   enable_dhcp_options      = true
 62:   dhcp_options_domain_name = "ec2.internal"
 63: 
 64:   enable_nat_gateway = true
 65:   single_nat_gateway = true
 66:   nat_gateway_tags = {
 67:     "Name"                                        = "${local.ngw_name}"
 68:     "kubernetes.io/cluster/${local.cluster_name}" = "shared"
 69:   }
 70: 
 71:   create_igw             = true
 72:   create_egress_only_igw = false
 73:   enable_vpn_gateway     = false
 74: 
 75:   private_route_table_tags = {
 76:     Name = local.route_table_name
 77:   }
 78: 
 79:   igw_tags = {
 80:     Name = "${local.igw_name}"
 81:   }
 82: 
 83:   tags = local.tags
 84: }
 85: 
 86: module "eks" {
 87:   source  = "terraform-aws-modules/eks/aws"
 88:   version = "21.9.0"
 89: 
 90:   name                   = local.cluster_name
 91:   kubernetes_version     = var.k8s_version
 92:   endpoint_public_access = true
 93: 
 94:   enable_cluster_creator_admin_permissions = true
 95: 
 96:   # Enable OIDC provider for IRSA (IAM Roles for Service Accounts)
 97:   # This is required for pods to assume IAM roles (e.g., for SNS access)
 98:   enable_irsa = true
 99: 
100:   compute_config = {
101:     enabled    = true
102:     node_pools = ["general-purpose"]
103:   }
104: 
105:   vpc_id     = module.vpc.vpc_id
106:   subnet_ids = module.vpc.private_subnets
107: 
108:   enabled_log_types           = ["api", "audit", "authenticator", "controllerManager", "scheduler"]
109:   create_cloudwatch_log_group = true
110: 
111:   node_iam_role_additional_policies = {
112:     "AmazonSSMManagedInstanceCore" = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
113:   }
114: 
115:   tags = local.tags
116: }
117: 
118: module "endpoints" {
119:   source                 = "./modules/endpoints"
120:   env                    = var.env
121:   region                 = var.region
122:   prefix                 = var.prefix
123:   vpc_id                 = module.vpc.vpc_id
124:   vpc_cidr               = var.vpc_cidr
125:   private_subnets        = module.vpc.private_subnets
126:   endpoint_sg_name       = var.endpoint_sg_name
127:   node_security_group_id = module.eks.node_security_group_id
128:   enable_sts_endpoint    = var.enable_sts_endpoint
129:   enable_sns_endpoint    = var.enable_sns_endpoint
130:   tags                   = local.tags
131: }
132: 
133: # module "ebs" {
134: #   source         = "./modules/ebs"
135: #   env            = var.env
136: #   region         = var.region
137: #   prefix         = var.prefix
138: #   ebs_name       = var.ebs_name
139: #   ebs_claim_name = var.ebs_claim_name
140: #
141: #   # Give time for the cluster to complete (controllers, RBAC and IAM propagation)
142: #   depends_on = [module.eks]
143: # }
144: 
145: module "ecr" {
146:   source               = "./modules/ecr"
147:   env                  = var.env
148:   region               = var.region
149:   prefix               = var.prefix
150:   ecr_name             = var.ecr_name
151:   image_tag_mutability = var.image_tag_mutability
152:   policy               = jsonencode(var.ecr_lifecycle_policy)
153:   tags                 = local.tags
154: }
````

## File: .github/workflows/backend_infra_destroying.yaml
````yaml
  1: name: Backend Infra Destroying
  2: 
  3: on:
  4:   workflow_dispatch:
  5:     inputs:
  6:       region:
  7:         description: 'Select AWS Region'
  8:         required: true
  9:         type: choice
 10:         default: 'us-east-1: N. Virginia'
 11:         options:
 12:           - 'us-east-1: N. Virginia'
 13:           - 'us-east-2: Ohio'
 14:       environment:
 15:         description: 'Select Environment'
 16:         required: true
 17:         type: choice
 18:         default: prod
 19:         options:
 20:           - prod
 21:           - dev
 22: 
 23: jobs:
 24:   SetRegion:
 25:     runs-on: ubuntu-latest
 26:     permissions: {}
 27:     outputs:
 28:       region_code: ${{ steps.set_region.outputs.region_code }}
 29:     steps:
 30:       - name: Set Region
 31:         id: set_region
 32:         run: |
 33:           SELECTED_REGION="${{ inputs.region }}"
 34:           echo "region_code=${SELECTED_REGION%%:*}" >> $GITHUB_OUTPUT
 35: 
 36:   InfraDestroy:
 37:     runs-on: ubuntu-latest
 38:     needs:
 39:       - SetRegion
 40:     permissions:
 41:       contents: write
 42:       actions: write
 43:       id-token: write
 44:     env:
 45:       AWS_REGION: ${{ needs.SetRegion.outputs.region_code }}
 46:     defaults:
 47:       run:
 48:         working-directory: ./backend_infra
 49:     steps:
 50:       - name: Checkout the repo code
 51:         uses: actions/checkout@v4
 52: 
 53:       - name: Setup terraform
 54:         uses: hashicorp/setup-terraform@v3
 55:         with:
 56:           terraform_version: 1.14.0
 57: 
 58:       - name: Configure AWS credentials (State Account)
 59:         uses: aws-actions/configure-aws-credentials@v4
 60:         with:
 61:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
 62:           role-session-name: GitHubActions-BackendInfraDestroy
 63:           aws-region: ${{ env.AWS_REGION }}
 64: 
 65:       - name: Create backend.hcl from placeholder
 66:         run: |
 67:           cp tfstate-backend-values-template.hcl backend.hcl
 68:           sed -i -e "s|<BACKEND_BUCKET_NAME>|${{ vars.BACKEND_BUCKET_NAME }}|g" \
 69:           -e "s|<BACKEND_PREFIX>|${{ vars.BACKEND_PREFIX }}|g" \
 70:           -e "s|<AWS_REGION>|${{ env.AWS_REGION }}|g" \
 71:           backend.hcl
 72:           echo "Created backend.hcl:"
 73:           cat backend.hcl
 74: 
 75:       - name: Update variables.tfvars
 76:         run: |
 77:           sed -i "s|^env[[:space:]]*=.*|env = \"${{ inputs.environment }}\"|" variables.tfvars
 78:           sed -i "s|^region[[:space:]]*=.*|region = \"${{ env.AWS_REGION }}\"|" variables.tfvars
 79: 
 80:           DEPLOYMENT_ROLE_ARN="${{ inputs.environment == 'prod' && secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN || secrets.AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN }}"
 81:           if ! grep -q "^deployment_account_role_arn" variables.tfvars; then
 82:             echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> variables.tfvars
 83:           else
 84:             sed -i "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" variables.tfvars
 85:           fi
 86: 
 87:           EXTERNAL_ID="${{ secrets.AWS_ASSUME_EXTERNAL_ID }}"
 88:           if ! grep -q "^deployment_account_external_id" variables.tfvars; then
 89:             echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> variables.tfvars
 90:           else
 91:             sed -i "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" variables.tfvars
 92:           fi
 93:           echo "Updated variables.tfvars:"
 94:           cat variables.tfvars
 95: 
 96:       - name: Terraform init
 97:         run: terraform init -backend-config=backend.hcl
 98: 
 99:       - name: Terraform workspace
100:         run: |
101:           WORKSPACE="${{ env.AWS_REGION }}-${{ inputs.environment }}"
102:           terraform workspace select $WORKSPACE || terraform workspace new $WORKSPACE
103: 
104:       - name: Terraform validate
105:         run: terraform validate
106: 
107:       - name: Terraform plan destroy
108:         run: terraform plan -var-file="variables.tfvars" -destroy -out terraform.tfplan
109: 
110:       - name: Destroy backend infrastructure
111:         run: terraform apply -auto-approve terraform.tfplan
````

## File: .github/workflows/backend_infra_provisioning.yaml
````yaml
  1: name: Backend Infra Provisioning
  2: 
  3: on:
  4:   workflow_dispatch:
  5:     inputs:
  6:       region:
  7:         description: 'Select AWS Region'
  8:         required: true
  9:         type: choice
 10:         default: 'us-east-1: N. Virginia'
 11:         options:
 12:           - 'us-east-1: N. Virginia'
 13:           - 'us-east-2: Ohio'
 14:       environment:
 15:         description: 'Select Environment'
 16:         required: true
 17:         type: choice
 18:         default: prod
 19:         options:
 20:           - prod
 21:           - dev
 22: 
 23: jobs:
 24:   SetRegion:
 25:     runs-on: ubuntu-latest
 26:     permissions:
 27:       contents: read
 28:     outputs:
 29:       region_code: ${{ steps.set_region.outputs.region_code }}
 30:     steps:
 31:       - name: Set Region
 32:         id: set_region
 33:         run: |
 34:           SELECTED_REGION="${{ inputs.region }}"
 35:           echo "region_code=${SELECTED_REGION%%:*}" >> $GITHUB_OUTPUT
 36: 
 37:   InfraProvision:
 38:     runs-on: ubuntu-latest
 39:     needs:
 40:       - SetRegion
 41:     permissions:
 42:       contents: write
 43:       actions: write
 44:       id-token: write
 45:     env:
 46:       AWS_REGION: ${{ needs.SetRegion.outputs.region_code }}
 47:     defaults:
 48:       run:
 49:         working-directory: ./backend_infra
 50:     steps:
 51:       - name: Checkout the repo code
 52:         uses: actions/checkout@v4
 53: 
 54:       - name: Setup terraform
 55:         uses: hashicorp/setup-terraform@v3
 56:         with:
 57:           terraform_version: 1.14.0
 58: 
 59:       - name: Configure AWS credentials (State Account)
 60:         uses: aws-actions/configure-aws-credentials@v4
 61:         with:
 62:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
 63:           role-session-name: GitHubActions-BackendInfraProvision
 64:           aws-region: ${{ env.AWS_REGION }}
 65: 
 66:       - name: Create backend.hcl from placeholder
 67:         run: |
 68:           cp tfstate-backend-values-template.hcl backend.hcl
 69:           sed -i -e "s|<BACKEND_BUCKET_NAME>|${{ vars.BACKEND_BUCKET_NAME }}|g" \
 70:           -e "s|<BACKEND_PREFIX>|${{ vars.BACKEND_PREFIX }}|g" \
 71:           -e "s|<AWS_REGION>|${{ env.AWS_REGION }}|g" \
 72:           backend.hcl
 73:           echo "Created backend.hcl:"
 74:           cat backend.hcl
 75: 
 76:       - name: Update variables.tfvars
 77:         run: |
 78:           sed -i "s|^env[[:space:]]*=.*|env = \"${{ inputs.environment }}\"|" variables.tfvars
 79:           sed -i "s|^region[[:space:]]*=.*|region = \"${{ env.AWS_REGION }}\"|" variables.tfvars
 80: 
 81:           DEPLOYMENT_ROLE_ARN="${{ inputs.environment == 'prod' && secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN || secrets.AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN }}"
 82:           if ! grep -q "^deployment_account_role_arn" variables.tfvars; then
 83:             echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> variables.tfvars
 84:           else
 85:             sed -i "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" variables.tfvars
 86:           fi
 87: 
 88:           EXTERNAL_ID="${{ secrets.AWS_ASSUME_EXTERNAL_ID }}"
 89:           if ! grep -q "^deployment_account_external_id" variables.tfvars; then
 90:             echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> variables.tfvars
 91:           else
 92:             sed -i "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" variables.tfvars
 93:           fi
 94:           echo "Updated variables.tfvars:"
 95:           cat variables.tfvars
 96: 
 97:       - name: Terraform init
 98:         run: terraform init -backend-config=backend.hcl
 99: 
100:       - name: Terraform workspace
101:         run: |
102:           WORKSPACE="${{ env.AWS_REGION }}-${{ inputs.environment }}"
103:           terraform workspace select $WORKSPACE || terraform workspace new $WORKSPACE
104: 
105:       - name: Terraform validate
106:         run: terraform validate
107: 
108:       - name: Terraform plan
109:         run: terraform plan -var-file="variables.tfvars" -out terraform.tfplan
110: 
111:       - name: Provision backend infrastructure
112:         run: terraform apply -auto-approve terraform.tfplan
````

## File: application/modules/alb/README.md
````markdown
  1: # ALB Module
  2: 
  3: This module creates Kubernetes IngressClass and IngressClassParams resources for
  4: EKS Auto Mode Application Load Balancer (ALB) provisioning.
  5: 
  6: ## Purpose
  7: 
  8: The ALB module configures EKS Auto Mode's built-in load balancer driver to
  9: automatically provision and manage Application Load Balancers when Ingress
 10: resources are created. It provides:
 11: 
 12: - **IngressClass**: Binds Ingress resources to EKS Auto Mode ALB controller
 13: - **IngressClassParams**: Defines cluster-wide ALB defaults (scheme, IP type,
 14: group name, certificate ARNs)
 15: 
 16: ## Key Features
 17: 
 18: ### EKS Auto Mode Integration
 19: 
 20: - **Built-in Load Balancer Driver**: EKS Auto Mode includes its own ALB driver
 21: (`eks.amazonaws.com/alb`), no need to install AWS Load Balancer Controller
 22: - **Automatic IAM Permissions**: EKS Auto Mode handles IAM permissions
 23: automatically - no need to attach `AWSLoadBalancerControllerIAMPolicy`
 24: - **Simplified Configuration**: No separate controller pods on worker nodes
 25: 
 26: ### IngressClassParams Configuration
 27: 
 28: EKS Auto Mode IngressClassParams supports these cluster-wide defaults:
 29: 
 30: | Setting | Description |
 31: | --------- | ------------- |
 32: | `scheme` | `internet-facing` or `internal` |
 33: | `ipAddressType` | `ipv4` or `dualstack` |
 34: | `group.name` | ALB group name for grouping multiple Ingresses |
 35: | `certificateARNs` | ACM certificate ARNs for TLS termination |
 36: 
 37: > [!NOTE]
 38: >
 39: > Unlike AWS Load Balancer Controller, EKS Auto Mode IngressClassParams
 40: > does NOT support subnets, security groups, or tags.
 41: 
 42: ### Annotation Strategy
 43: 
 44: The module implements a two-tier configuration approach:
 45: 
 46: 1. **Cluster-wide defaults** (IngressClassParams):
 47:    - `scheme`, `ipAddressType`, `group.name`, `certificateARNs`
 48:    - Inherited by all Ingresses using this IngressClass
 49: 
 50: 2. **Per-Ingress settings** (Ingress annotations):
 51:    - `alb.ingress.kubernetes.io/load-balancer-name` - AWS ALB name (max 32 characters)
 52:    - `alb.ingress.kubernetes.io/target-type` - IP or instance
 53:    - `alb.ingress.kubernetes.io/listen-ports` - HTTP/HTTPS ports
 54:    - `alb.ingress.kubernetes.io/ssl-redirect` - HTTPS redirect
 55: 
 56: > [!NOTE]
 57: >
 58: > `group.name` and `certificateARNs` are configured in IngressClassParams (cluster-wide),
 59: > not in Ingress annotations. This centralizes TLS and group configuration at the
 60: > cluster level, reducing annotation duplication.
 61: 
 62: ### ALB Naming
 63: 
 64: The configuration supports separate naming for:
 65: 
 66: - **ALB Group Name** (`alb_group_name`): Kubernetes identifier (max 63 characters)
 67:   - used to group multiple Ingresses
 68:   - Configured in IngressClassParams (`group.name`)
 69:   - Used internally by Kubernetes to group Ingresses that share the same ALB
 70:   - Defaults to `app_name` if not provided
 71: 
 72: - **ALB Load Balancer Name** (`load-balancer-name` annotation): AWS resource name
 73: (max 32 characters)
 74:   - appears in AWS console
 75:   - Configured in Ingress annotations (per-Ingress)
 76:   - The actual AWS ALB resource name visible in AWS console
 77:   - Should be truncated to 32 characters if needed
 78: 
 79: Both names are automatically constructed from prefix, region, and environment,
 80: with proper truncation to respect limits. The module handles name generation automatically,
 81: but you can override `alb_group_name` if needed.
 82: 
 83: ## What it Creates
 84: 
 85: 1. **IngressClassParams** (`null_resource.apply_ingressclassparams_manifest`)
 86:    - Custom resource for EKS Auto Mode ALB configuration
 87:    - Applied via `kubectl apply` (no native Terraform resource available)
 88:    - Contains cluster-wide ALB defaults
 89: 
 90: 2. **IngressClass** (`kubernetes_ingress_class_v1.ingressclass_alb`)
 91:    - Kubernetes IngressClass resource
 92:    - References IngressClassParams for ALB defaults
 93:    - Set as default IngressClass for the cluster
 94:    - Uses `eks.amazonaws.com/alb` controller
 95: 
 96: ## Prerequisites
 97: 
 98: - EKS cluster with Auto Mode enabled (`compute_config.enabled = true`)
 99: - AWS CLI installed and configured with cluster access
100: - ACM certificate for HTTPS/TLS termination
101: - `kubectl` configured with cluster access
102: - EKS Auto Mode CRD (`ingressclassparams.eks.amazonaws.com`) must be available (use `wait_for_crd = true` for initial deployments)
103: 
104: ## Usage
105: 
106: ```hcl
107: module "alb" {
108:   source = "./modules/alb"
109: 
110:   env          = "prod"
111:   region       = "us-east-1"
112:   prefix       = "myorg"
113:   cluster_name = "my-eks-cluster"
114:   app_name     = "my-app"
115: 
116:   ingressclass_alb_name       = "ic-alb"
117:   ingressclassparams_alb_name = "icp-alb"
118: 
119:   alb_scheme          = "internet-facing"
120:   alb_ip_address_type = "ipv4"
121:   alb_group_name      = "my-app-alb-group"
122:   acm_certificate_arn = "arn:aws:acm:us-east-1:123456789012:certificate/abc123"
123: 
124:   # Set to true for initial cluster deployments to wait for CRD
125:   wait_for_crd = false
126: }
127: ```
128: 
129: ## Inputs
130: 
131: | Name | Description | Type | Required | Default |
132: | ------ | ------------- | ------ | ---------- | --------- |
133: | env | Environment suffix for resource names | string | yes | - |
134: | region | Deployment region | string | yes | - |
135: | prefix | Prefix for resource names | string | yes | - |
136: | app_name | Application name | string | yes | - |
137: | cluster_name | Name of EKS cluster | string | yes | - |
138: | ingressclass_alb_name | Name component for IngressClass | string | yes | - |
139: | ingressclassparams_alb_name | Name component for IngressClassParams | string | yes | - |
140: | acm_certificate_arn | ACM certificate ARN for HTTPS | string | no | null |
141: | alb_scheme | ALB scheme (`internet-facing` or `internal`) | string | no | "internet-facing" |
142: | alb_ip_address_type | IP address type (`ipv4` or `dualstack`) | string | no | "ipv4" |
143: | alb_group_name | ALB group name (max 63 chars) | string | no | null |
144: | wait_for_crd | Whether to wait for EKS Auto Mode CRD before creating IngressClassParams | bool | no | false |
145: 
146: ## Outputs
147: 
148: | Name | Description |
149: | ------ | ------------- |
150: | ingress_class_name | Name of the IngressClass for shared ALB |
151: | ingress_class_params_name | Name of the IngressClassParams |
152: | alb_scheme | ALB scheme configured in IngressClassParams |
153: | alb_ip_address_type | ALB IP address type configured in IngressClassParams |
154: 
155: ## How Ingresses Use This Module
156: 
157: After deploying this module, Ingress resources can use the IngressClass:
158: 
159: ```yaml
160: apiVersion: networking.k8s.io/v1
161: kind: Ingress
162: metadata:
163:   name: my-app
164:   namespace: my-namespace
165:   annotations:
166:     # Per-Ingress settings
167:     alb.ingress.kubernetes.io/load-balancer-name: "my-alb"
168:     alb.ingress.kubernetes.io/target-type: "ip"
169:     alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
170:     alb.ingress.kubernetes.io/ssl-redirect: "443"
171: spec:
172:   ingressClassName: myorg-us-east-1-ic-alb-prod  # From module output
173:   rules:
174:     - host: app.example.com
175:       http:
176:         paths:
177:           - path: /
178:             pathType: Prefix
179:             backend:
180:               service:
181:                 name: my-service
182:                 port:
183:                   number: 80
184: ```
185: 
186: ## Multi-Ingress Single ALB
187: 
188: Multiple Ingresses can share a single ALB by:
189: 
190: 1. Using the same IngressClass (which references IngressClassParams with
191: `group.name`)
192: 2. All Ingresses in the group are routed through the same ALB
193: 3. Host-based routing directs traffic to appropriate services
194: 
195: Example:
196: 
197: - `phpldapadmin.example.com`  phpLDAPadmin service
198: - `passwd.example.com`  LTB-passwd service
199: - `app.example.com`  2FA application
200: 
201: ## Verifying Deployment
202: 
203: ```bash
204: # Check IngressClass
205: kubectl get ingressclass
206: kubectl describe ingressclass myorg-us-east-1-ic-alb-prod
207: 
208: # Check IngressClassParams
209: kubectl get ingressclassparams
210: kubectl describe ingressclassparams myorg-us-east-1-icp-alb-prod
211: 
212: # Check Ingresses using this IngressClass
213: kubectl get ingress -A -o wide
214: 
215: # Verify ALB was created
216: aws elbv2 describe-load-balancers --region us-east-1
217: ```
218: 
219: ## Differences: EKS Auto Mode vs AWS Load Balancer Controller
220: 
221: | Feature | EKS Auto Mode | AWS Load Balancer Controller |
222: | --------- | --------------- | ------------------------------ |
223: | Controller | `eks.amazonaws.com/alb` | `alb.ingress.kubernetes.io` |
224: | API Group | `eks.amazonaws.com` | `elbv2.k8s.aws` |
225: | IAM Setup | Automatic | Requires IAM policy |
226: | Installation | Built-in | Requires Helm chart |
227: | IngressClassParams | `scheme`, `ipAddressType`, `group.name`, `certificateARNs` | All above plus `subnets`, `securityGroups`, `tags` |
228: 
229: ## Internet-Facing ALB Configuration
230: 
231: The ALB is configured as `internet-facing` by default to enable:
232: 
233: - **Public Access**: Access to UIs from anywhere on the internet
234: - **User Convenience**: Public accessibility for user-facing services
235: - **HTTPS Only**: Secure communication with TLS termination at ALB
236: - **DNS Required**: Proper DNS configuration required for public access
237: 
238: When using `internet-facing` scheme:
239: 
240: - ALB is accessible from the internet
241: - Requires ACM certificate for HTTPS/TLS termination
242: - Route53 DNS records should point to ALB DNS name
243: - Security groups must allow HTTPS (443) traffic from internet
244: 
245: For internal-only access, set `alb_scheme = "internal"` to create an internal ALB
246: accessible only from within the VPC.
247: 
248: ## Notes
249: 
250: - IngressClassParams is created via `kubernetes_manifest` resource (native Terraform support)
251: - The IngressClass is set as the default class for the cluster
252: - ALB is automatically provisioned when Ingress resources are created
253: - Changes to IngressClassParams trigger resource recreation
254: - The actual ALB is created automatically by EKS Auto Mode when the Helm chart
255: creates Ingress resources that reference the IngressClass
256: - Multiple Ingresses can share a single ALB by using the same `group.name` in IngressClassParams
257: - For initial cluster deployments, set `wait_for_crd = true` to allow EKS Auto Mode to install the IngressClassParams CRD
258: - The module includes a `time_sleep` resource to handle CRD availability timing issues
259: 
260: ## References
261: 
262: - [AWS EKS Auto Mode Documentation](https://docs.aws.amazon.com/eks/latest/userguide/eks-auto-mode.html)
263: - [EKS Auto Mode IngressClassParams](https://docs.aws.amazon.com/eks/latest/userguide/eks-auto-mode-ingress.html)
264: - [Kubernetes IngressClass Documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class)
````

## File: application/modules/openldap/main.tf
````hcl
  1: locals {
  2:   # Determine values template path
  3:   values_template_path = var.values_template_path != null ? var.values_template_path : "${path.module}/../../helm/openldap-values.tpl.yaml"
  4: 
  5:   openldap_values = templatefile(
  6:     local.values_template_path,
  7:     {
  8:       storage_class_name   = var.storage_class_name
  9:       openldap_ldap_domain = var.openldap_ldap_domain
 10:       openldap_secret_name = var.openldap_secret_name
 11:       app_name             = var.app_name
 12:       # ECR image configuration
 13:       ecr_registry       = var.ecr_registry
 14:       ecr_repository     = var.ecr_repository
 15:       openldap_image_tag = var.openldap_image_tag
 16:       # ALB configuration - IngressClassParams handles scheme and ipAddressType
 17:       ingress_class_name     = var.use_alb && var.ingress_class_name != null ? var.ingress_class_name : "alb"
 18:       alb_load_balancer_name = var.alb_load_balancer_name
 19:       acm_cert_arn           = var.acm_cert_arn
 20:       phpldapadmin_host      = var.phpldapadmin_host
 21:       ltb_passwd_host        = var.ltb_passwd_host
 22:       # Per-Ingress annotations still needed for grouping, TLS, ports, etc.
 23:       alb_target_type = var.alb_target_type
 24:       alb_ssl_policy  = var.alb_ssl_policy
 25:     }
 26:   )
 27: }
 28: 
 29: # Create namespace for OpenLDAP
 30: resource "kubernetes_namespace" "openldap" {
 31:   metadata {
 32:     name = var.namespace
 33: 
 34:     labels = {
 35:       name        = var.namespace
 36:       environment = var.env
 37:       managed-by  = "terraform"
 38:     }
 39:   }
 40: 
 41:   lifecycle {
 42:     # Ignore changes to labels that might be modified by ArgoCD, Helm, or other controllers
 43:     ignore_changes = [
 44:       metadata[0].labels,
 45:       metadata[0].annotations,
 46:     ]
 47:   }
 48: }
 49: 
 50: # Create Kubernetes secret for OpenLDAP passwords
 51: # Passwords are sourced from GitHub Secrets via TF_VAR_openldap_admin_password and TF_VAR_openldap_config_password
 52: resource "kubernetes_secret" "openldap_passwords" {
 53:   metadata {
 54:     name      = var.openldap_secret_name
 55:     namespace = kubernetes_namespace.openldap.metadata[0].name
 56: 
 57:     labels = {
 58:       app         = "openldap"
 59:       environment = var.env
 60:       managed-by  = "terraform"
 61:     }
 62:   }
 63: 
 64:   data = {
 65:     "LDAP_ADMIN_PASSWORD"        = var.openldap_admin_password
 66:     "LDAP_CONFIG_ADMIN_PASSWORD" = var.openldap_config_password
 67:   }
 68: 
 69:   type = "Opaque"
 70: 
 71:   lifecycle {
 72:     # Ignore changes to labels/annotations that might be modified by ArgoCD, Helm, or other controllers
 73:     # This prevents Terraform from trying to recreate the secret if it's modified externally
 74:     ignore_changes = [
 75:       metadata[0].labels,
 76:       metadata[0].annotations,
 77:     ]
 78:     # Create before destroy to avoid downtime if secret needs to be recreated
 79:     create_before_destroy = true
 80:   }
 81: 
 82:   depends_on = [kubernetes_namespace.openldap]
 83: }
 84: 
 85: # Helm release for OpenLDAP Stack HA
 86: resource "helm_release" "openldap" {
 87:   name       = var.helm_release_name
 88:   repository = var.helm_chart_repository
 89:   chart      = var.helm_chart_name
 90:   version    = var.helm_chart_version
 91: 
 92:   namespace        = kubernetes_namespace.openldap.metadata[0].name
 93:   create_namespace = false
 94: 
 95:   atomic          = true
 96:   cleanup_on_fail = true
 97:   # Force recreation on configuration changes
 98:   recreate_pods   = true
 99:   force_update    = true
100:   wait            = true
101:   wait_for_jobs   = true
102:   upgrade_install = true
103:   # 5 minute timeout as requested
104:   timeout = 300 # 5 minutes in seconds
105: 
106:   # Allow replacement if name conflict occurs
107:   replace = true
108: 
109:   values = [local.openldap_values]
110: 
111:   depends_on = [
112:     kubernetes_namespace.openldap,
113:     kubernetes_secret.openldap_passwords,
114:   ]
115: }
116: 
117: # Create Network Policies for secure internal cluster communication
118: # Generic policies: Any service can communicate with any service, but only on secure ports
119: module "network_policies" {
120:   source = "../network-policies"
121: 
122:   count = var.enable_network_policies ? 1 : 0
123: 
124:   namespace = var.namespace
125: 
126:   depends_on = [helm_release.openldap]
127: }
128: 
129: # Get Ingress resources created by Helm chart to extract ALB DNS names
130: data "kubernetes_ingress_v1" "phpldapadmin" {
131:   metadata {
132:     name      = "${var.helm_release_name}-phpldapadmin"
133:     namespace = var.namespace
134:   }
135: 
136:   depends_on = [helm_release.openldap]
137: }
138: 
139: data "kubernetes_ingress_v1" "ltb_passwd" {
140:   metadata {
141:     name      = "${var.helm_release_name}-ltb-passwd"
142:     namespace = var.namespace
143:   }
144: 
145:   depends_on = [helm_release.openldap]
146: }
````

## File: application/modules/redis/main.tf
````hcl
  1: /**
  2:  * Redis Module
  3:  *
  4:  * Deploys Redis using the Bitnami Helm chart for SMS OTP code storage
  5:  * in the LDAP 2FA application. Provides TTL-based automatic expiration
  6:  * and shared state across backend replicas.
  7:  */
  8: 
  9: locals {
 10:   name = "${var.prefix}-${var.region}-redis-${var.env}"
 11: 
 12:   # Determine values template path
 13:   values_template_path = var.values_template_path != null ? var.values_template_path : "${path.module}/../../helm/redis-values.tpl.yaml"
 14: 
 15:   # Build Redis Helm values using templatefile
 16:   # Note: We pass the secret name variable (not resource) to avoid circular dependency
 17:   # The secret resource is created separately with the same name
 18:   redis_values = templatefile(
 19:     local.values_template_path,
 20:     {
 21:       secret_name              = var.secret_name
 22:       persistence_enabled      = var.persistence_enabled
 23:       storage_class_name       = var.storage_class_name
 24:       storage_size             = var.storage_size
 25:       resources_requests_cpu   = var.resources.requests.cpu
 26:       resources_requests_memory = var.resources.requests.memory
 27:       resources_limits_cpu     = var.resources.limits.cpu
 28:       resources_limits_memory  = var.resources.limits.memory
 29:       metrics_enabled          = var.metrics_enabled
 30:       ecr_registry             = var.ecr_registry
 31:       ecr_repository           = var.ecr_repository
 32:       image_tag                = var.image_tag
 33:     }
 34:   )
 35: }
 36: 
 37: # Create namespace for Redis
 38: resource "kubernetes_namespace" "redis" {
 39:   count = var.enable_redis ? 1 : 0
 40: 
 41:   metadata {
 42:     name = var.namespace
 43: 
 44:     labels = {
 45:       name        = var.namespace
 46:       environment = var.env
 47:       managed-by  = "terraform"
 48:     }
 49:   }
 50: 
 51:   lifecycle {
 52:     ignore_changes = [metadata[0].labels]
 53:   }
 54: }
 55: 
 56: # Create Kubernetes secret for Redis password
 57: # Password is sourced from GitHub Secrets via TF_VAR_redis_password
 58: resource "kubernetes_secret" "redis_password" {
 59:   count = var.enable_redis ? 1 : 0
 60: 
 61:   metadata {
 62:     name      = var.secret_name
 63:     namespace = kubernetes_namespace.redis[0].metadata[0].name
 64: 
 65:     labels = {
 66:       app         = local.name
 67:       environment = var.env
 68:       managed-by  = "terraform"
 69:     }
 70:   }
 71: 
 72:   data = {
 73:     "redis-password" = var.redis_password
 74:   }
 75: 
 76:   type = "Opaque"
 77: }
 78: 
 79: # Redis Helm release using Bitnami chart
 80: resource "helm_release" "redis" {
 81:   count = var.enable_redis ? 1 : 0
 82: 
 83:   name       = local.name
 84:   repository = "https://charts.bitnami.com/bitnami"
 85:   chart      = "redis"
 86:   version    = var.chart_version
 87:   namespace  = kubernetes_namespace.redis[0].metadata[0].name
 88: 
 89:   atomic          = true
 90:   cleanup_on_fail = true
 91:   recreate_pods   = true
 92:   force_update    = true
 93:   wait            = true
 94:   wait_for_jobs   = true
 95:   timeout         = 600 # Reduced from 1200 to 600 seconds (10 min) for faster debugging
 96:   upgrade_install = true
 97: 
 98:   # Allow replacement if name conflict occurs
 99:   replace = true
100: 
101:   # Use templatefile to inject values into the official Bitnami Redis Helm chart values template
102:   # Note: The secret name is passed to the template, and the secret resource is created separately
103:   values = [local.redis_values]
104: 
105:   depends_on = [
106:     kubernetes_namespace.redis[0],
107:     kubernetes_secret.redis_password[0],
108:   ]
109: }
110: 
111: # Network Policy: Allow backend pods to connect to Redis
112: # This policy restricts Redis access to only the backend namespace/pods
113: resource "kubernetes_network_policy_v1" "allow_backend_to_redis" {
114:   count = var.enable_redis ? 1 : 0
115: 
116:   metadata {
117:     name      = "allow-backend-to-redis"
118:     namespace = kubernetes_namespace.redis[0].metadata[0].name
119: 
120:     labels = {
121:       app         = local.name
122:       environment = var.env
123:       managed-by  = "terraform"
124:     }
125:   }
126: 
127:   spec {
128:     # Apply to Redis pods
129:     pod_selector {
130:       match_labels = {
131:         "app.kubernetes.io/name" = "redis"
132:       }
133:     }
134: 
135:     policy_types = ["Ingress"]
136: 
137:     # Allow ingress from backend namespace on Redis port
138:     ingress {
139:       from {
140:         namespace_selector {
141:           match_labels = {
142:             name = var.backend_namespace
143:           }
144:         }
145:         pod_selector {
146:           match_labels = {
147:             "app.kubernetes.io/name" = "ldap-2fa-backend"
148:           }
149:         }
150:       }
151:       ports {
152:         protocol = "TCP"
153:         port     = 6379
154:       }
155:     }
156: 
157:     # Allow ingress from within the Redis namespace (for Redis probes, etc.)
158:     ingress {
159:       from {
160:         pod_selector {}
161:       }
162:       ports {
163:         protocol = "TCP"
164:         port     = 6379
165:       }
166:     }
167:   }
168: 
169:   depends_on = [
170:     kubernetes_namespace.redis[0],
171:     helm_release.redis[0],
172:   ]
173: }
````

## File: application/PRD-DOMAIN.md
````markdown
  1: # DOMAIN SETUP AND LINKING TO ALB AND LDAP
  2: 
  3: > [!NOTE]
  4: >
  5: > This document describes creating Route53 hosted zone and ACM
  6: > certificate resources via Terraform. However, the current implementation in
  7: > `main.tf` uses **data sources** to reference existing resources instead of
  8: > creating them. The Route53 module (`modules/route53/`) exists but is commented
  9: > out. If you want to create these resources via Terraform, uncomment the module
 10: > and update the code accordingly.
 11: 
 12: There are three separate pieces:
 13: 
 14: 1. Public DNS zone for talorlik.com.
 15: 2. ACM certificate for talorlik.com / *.talorlik.com, validated via Route53.
 16: 3. Using that ACM ARN in ALB (via Ingress annotations).
 17: 
 18: Below is a linear Terraform-centric setup.
 19: 
 20: ## 1. Route53 hosted zone for `talorlik.com`
 21: 
 22: In `backend_infra`:
 23: 
 24: ```hcl
 25: resource "aws_route53_zone" "talo_ldap" {
 26:   name = "talorlik.com"
 27: }
 28: ```
 29: 
 30: If the domain is registered elsewhere, point the registrar's NS records at
 31: `aws_route53_zone.talo_ldap.name_servers`.
 32: 
 33: ## 2. ACM certificate with DNS validation
 34: 
 35: ALB needs an ACM cert in the same region as the ALB / EKS cluster.
 36: 
 37: > [!IMPORTANT]
 38: >
 39: > **Public ACM Certificate Architecture**: The current implementation uses
 40: > **Public ACM certificates** (Amazon-issued) with DNS validation:
 41: >
 42: > - Public ACM certificates are requested in each deployment account
 43: >   (development, production)
 44: > - DNS validation records are created in Route53 hosted zone in the State Account
 45: > - Certificates are stored in their respective deployment accounts (not State
 46: >   Account)
 47: > - This eliminates cross-account certificate access complexity
 48: > - Certificates are automatically renewed by ACM (no manual intervention required)
 49: > - Browser-trusted certificates (no security warnings)
 50: >
 51: > See [Public ACM Certificate Setup and DNS Validation](./CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 52: > for detailed setup instructions with step-by-step AWS CLI commands.
 53: 
 54: **For Public ACM certificates** (current implementation):
 55: 
 56: Certificates are requested in each deployment account as public ACM certificates:
 57: 
 58: ```bash
 59: # In production account
 60: aws acm request-certificate \
 61:     --domain-name "talorlik.com" \
 62:     --subject-alternative-names "*.talorlik.com" \
 63:     --validation-method DNS \
 64:     --region us-east-1
 65: ```
 66: 
 67: **For Private CA-based certificates** (legacy approach, deprecated):
 68: 
 69: ```hcl
 70: resource "aws_acm_certificate" "talo_ldap" {
 71:   domain_name               = "talorlik.com"
 72:   validation_method         = "DNS"
 73:   subject_alternative_names = ["*.talorlik.com"]
 74: 
 75:   lifecycle {
 76:     create_before_destroy = true
 77:   }
 78: }
 79: ```
 80: 
 81: ## 3. DNS validation records in Route53
 82: 
 83: Create validation records in the hosted zone using `domain_validation_options`:
 84: 
 85: ```hcl
 86: resource "aws_route53_record" "talo_ldap_cert_validation" {
 87:   for_each = {
 88:     for dvo in aws_acm_certificate.talo_ldap.domain_validation_options : dvo.domain_name => {
 89:       name   = dvo.resource_record_name
 90:       record = dvo.resource_record_value
 91:       type   = dvo.resource_record_type
 92:     }
 93:   }
 94: 
 95:   zone_id = aws_route53_zone.talo_ldap.zone_id
 96:   name    = each.value.name
 97:   type    = each.value.type
 98:   ttl     = 60
 99: 
100:   records = [each.value.record]
101: }
102: ```
103: 
104: ## 4. Finalize ACM certificate
105: 
106: Bind the certificate to its DNS validation records:
107: 
108: ```hcl
109: resource "aws_acm_certificate_validation" "talo_ldap" {
110:   certificate_arn = aws_acm_certificate.talo_ldap.arn
111: 
112:   validation_record_fqdns = [
113:     for r in aws_route53_record.talo_ldap_cert_validation : r.fqdn
114:   ]
115: }
116: ```
117: 
118: After this, `aws_acm_certificate_validation.talo_ldap.certificate_arn` is the
119: "ready" cert ARN for ALB.
120: 
121: ## 5. Terraform outputs: `acm_cert_arn` and `domain_name`
122: 
123: In the same module (`backend_infra`) define:
124: 
125: ```hcl
126: output "acm_cert_arn" {
127:   description = "ACM certificate ARN for talorlik.com (*.talorlik.com)"
128:   value       = aws_acm_certificate_validation.talo_ldap.certificate_arn
129: }
130: 
131: output "domain_name" {
132:   description = "Root domain name for LDAP app"
133:   value       = aws_route53_zone.talo_ldap.name
134: }
135: ```
136: 
137: If `backend_infra` is called as a module, the root module will see:
138: 
139: - `module.backend_infra.acm_cert_arn`
140: - `module.backend_infra.domain_name`
141: 
142: These are what you feed into Helm templates or other modules.
143: 
144: ## 6. Use outputs inside the same module for Helm values
145: 
146: If Helm is deployed from `backend_infra` itself, you can use the outputs as
147: locals directly (no extra wiring):
148: 
149: ```hcl
150: locals {
151:   openldap_domain_name = aws_route53_zone.talo_ldap.name
152:   openldap_phpldapadmin_host = "phpldapadmin.${local.openldap_domain_name}"
153:   openldap_ltb_passwd_host   = "passwd.${local.openldap_domain_name}"
154: 
155:   openldap_values = templatefile(
156:     "${path.module}/helm/openldap-values.tpl.yaml",
157:     {
158:       acm_cert_arn       = aws_acm_certificate_validation.talo_ldap.certificate_arn
159:       phpldapadmin_host  = local.openldap_phpldapadmin_host
160:       ltb_passwd_host    = local.openldap_ltb_passwd_host
161:       # plus LDAP domain, passwords, PVC name, etc.
162:       openldap_ldap_domain     = "talorlik.com"
163:       openldap_admin_password  = var.openldap_admin_password
164:       openldap_config_password = var.openldap_config_password
165:     }
166:   )
167: }
168: ```
169: 
170: If Helm is in another module, pass outputs `acm_cert_arn` and `domain_name` into
171: that module as variables and derive the hosts there.
172: 
173: ## 7. Values template for `openldap-stack-ha` (using ACM ARN and domain)
174: 
175: Example `helm/openldap-values.tpl.yaml` excerpt:
176: 
177: ```yaml
178: global:
179:   imageRegistry: ""
180:   imagePullSecrets: []
181:   storageClass: ""
182:   ldapDomain: "${openldap_ldap_domain}"
183:   adminPassword:  "${openldap_admin_password}"
184:   configPassword: "${openldap_config_password}"
185:   ldapPort: 389
186:   sslLdapPort: 636
187: 
188: persistence:
189:   enabled: true
190:   accessModes:
191:     - ReadWriteOnce
192:   size: 8Gi
193: 
194: service:
195:   annotations: {}
196:   externalIPs: []
197:   type: ClusterIP
198:   sessionAffinity: None
199: 
200: ltb-passwd:
201:   enabled: true
202:   image:
203:     tag: 5.2.3
204:   ingress:
205:     enabled: true
206:     annotations:
207:       kubernetes.io/ingress.class: alb
208:       alb.ingress.kubernetes.io/scheme: internal
209:       alb.ingress.kubernetes.io/target-type: ip
210:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
211:       alb.ingress.kubernetes.io/certificate-arn: "${acm_cert_arn}"
212:     path: /
213:     pathType: Prefix
214:     hosts:
215:       - "${ltb_passwd_host}"
216:   ldap:
217:     bindPWKey: LDAP_ADMIN_PASSWORD
218: 
219: phpldapadmin:
220:   enabled: true
221:   env:
222:     PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "never"
223:   ingress:
224:     enabled: true
225:     annotations:
226:       kubernetes.io/ingress.class: alb
227:       alb.ingress.kubernetes.io/scheme: internal
228:       alb.ingress.kubernetes.io/target-type: ip
229:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
230:       alb.ingress.kubernetes.io/certificate-arn: "${acm_cert_arn}"
231:     path: /
232:     pathType: Prefix
233:     hosts:
234:       - "${phpldapadmin_host}"
235: ```
236: 
237: LDAP service itself stays `ClusterIP`, so only the GUI Ingresses are exposed via
238: ALB using that ACM certificate.
239: 
240: ## 8. Helm release for OpenLDAP from Terraform
241: 
242: In `backend_infra`:
243: 
244: ```hcl
245: resource "helm_release" "openldap" {
246:   name       = "openldap-stack-ha"
247:   repository = "https://jp-gouin.github.io/helm-openldap"
248:   chart      = "openldap-stack-ha"
249:   version    = "4.0.1"
250: 
251:   namespace        = "ldap"
252:   create_namespace = true
253: 
254:   values = [local.openldap_values]
255: 
256:   depends_on = [
257:     aws_eks_cluster.main,
258:     aws_acm_certificate_validation.talo_ldap,
259:     # PVC / StorageClass resources, if managed here
260:   ]
261: }
262: ```
263: 
264: EKS Auto Mode with AWS Load Balancer Controller will see the Ingresses and
265: provision an internal ALB with HTTPS listeners using `acm_cert_arn`.
266: 
267: ## 9. Route53 records for application and GUIs
268: 
269: Once the ALB exists, Route53 A (alias) records are created using the dedicated
270: `route53_record` module. This module supports cross-account deployments where
271: Route53 hosted zones are in a different account (State Account) than the ALB
272: (Deployment Account).
273: 
274: **Current Implementation:**
275: 
276: The `application/main.tf` uses the `route53_record` module to create separate
277: A (alias) records for each subdomain:
278: 
279: ```hcl
280: # Route53 record for phpLDAPadmin
281: module "route53_record_phpldapadmin" {
282:   source = "./modules/route53_record"
283: 
284:   count = var.use_alb && local.phpldapadmin_host != "" ? 1 : 0
285: 
286:   zone_id      = data.aws_route53_zone.this.zone_id
287:   name         = local.phpldapadmin_host
288:   alb_dns_name = data.aws_lb.alb[0].dns_name
289:   alb_zone_id  = local.alb_zone_id
290: 
291:   depends_on = [
292:     module.openldap,  # Ensures Ingress is created (which triggers ALB creation)
293:     data.aws_lb.alb,  # Ensures ALB exists before creating record
294:   ]
295: 
296:   providers = {
297:     aws.state_account = aws.state_account
298:   }
299: }
300: 
301: # Route53 record for ltb-passwd
302: module "route53_record_ltb_passwd" {
303:   source = "./modules/route53_record"
304: 
305:   count = var.use_alb && local.ltb_passwd_host != "" ? 1 : 0
306: 
307:   zone_id      = data.aws_route53_zone.this.zone_id
308:   name         = local.ltb_passwd_host
309:   alb_dns_name = data.aws_lb.alb[0].dns_name
310:   alb_zone_id  = local.alb_zone_id
311: 
312:   depends_on = [
313:     module.openldap,  # Ensures Ingress is created (which triggers ALB creation)
314:     data.aws_lb.alb,  # Ensures ALB exists before creating record
315:   ]
316: 
317:   providers = {
318:     aws.state_account = aws.state_account
319:   }
320: }
321: 
322: # Route53 record for 2FA application
323: module "route53_record_twofa_app" {
324:   source = "./modules/route53_record"
325: 
326:   count = var.use_alb && local.twofa_app_host != "" ? 1 : 0
327: 
328:   zone_id      = data.aws_route53_zone.this.zone_id
329:   name         = local.twofa_app_host
330:   alb_dns_name = data.aws_lb.alb[0].dns_name
331:   alb_zone_id  = local.alb_zone_id
332: 
333:   depends_on = [
334:     module.openldap,  # Ensures Ingress is created (which triggers ALB creation)
335:     data.aws_lb.alb,  # Ensures ALB exists before creating record
336:   ]
337: 
338:   providers = {
339:     aws.state_account = aws.state_account
340:   }
341: }
342: ```
343: 
344: **Key Features:**
345: 
346: - **Cross-Account Support**: Uses state account provider (`aws.state_account`) to
347:   create records in State Account while ALB is in Deployment Account
348: - **Precondition Validation**: Ensures ALB DNS name is available before record
349:   creation
350: - **Proper Dependencies**: Records are created after OpenLDAP module (ensures
351:   Ingress exists, which triggers ALB creation) and ALB data source
352: - **ALB Zone ID Mapping**: Automatically selects the correct ALB zone ID based
353:   on region (comprehensive mapping for 13 AWS regions)
354: - **Safe Updates**: Uses `create_before_destroy` lifecycle to prevent DNS
355:   downtime
356: 
357: > [!NOTE]
358: >
359: > For detailed Route53 record module documentation, including variables, outputs,
360: > dependencies, usage examples, and ALB zone_id mapping, see the [Route53 Record
361: > Module Documentation](modules/route53_record/README.md).
362: 
363: Now:
364: 
365: - `output.acm_cert_arn` is the ACM cert used by the ALB for HTTPS.
366: - `output.domain_name` is `talorlik.com`, from which you derive
367: `phpldapadmin.talorlik.com`, `passwd.talorlik.com`, and later app endpoints.
368: - LDAP stays internal (`ClusterIP`), while the admin/password GUIs and app
369: endpoints are exposed via ALB with TLS terminated using that ACM certificate.
````

## File: application/providers.tf
````hcl
  1: terraform {
  2:   required_providers {
  3:     aws = {
  4:       source  = "hashicorp/aws"
  5:       version = ">= 6.21.0"
  6:     }
  7:     kubernetes = {
  8:       source  = "hashicorp/kubernetes"
  9:       version = "~> 2.0"
 10:     }
 11:     helm = {
 12:       source  = "hashicorp/helm"
 13:       version = "~> 2.0"
 14:     }
 15:     time = {
 16:       source  = "hashicorp/time"
 17:       version = "~> 0.9"
 18:     }
 19:   }
 20: 
 21:   backend "s3" {
 22:     # Backend configuration provided via backend.hcl file
 23:     encrypt      = true
 24:     use_lockfile = true
 25:   }
 26: 
 27:   required_version = "~> 1.14.0"
 28: }
 29: 
 30: provider "aws" {
 31:   region = var.region
 32: 
 33:   # Assume role in deployment account (Account B) if role ARN is provided
 34:   # This allows GitHub Actions to authenticate with Account A (for state)
 35:   # while Terraform provider uses Account B (for resource deployment)
 36:   # ExternalId is required for security when assuming cross-account roles
 37:   dynamic "assume_role" {
 38:     for_each = var.deployment_account_role_arn != null ? [1] : []
 39:     content {
 40:       role_arn    = var.deployment_account_role_arn
 41:       external_id = var.deployment_account_external_id
 42:     }
 43:   }
 44: }
 45: 
 46: # Provider alias for state account (where Route53 hosted zone and Private CA reside)
 47: provider "aws" {
 48:   alias  = "state_account"
 49:   region = var.region
 50: 
 51:   # Assume role in state account if role ARN is provided
 52:   # This allows querying Route53 hosted zones from the state account
 53:   # while deploying resources to the deployment account
 54:   # Note: ACM certificates are in deployment accounts (issued from Private CA in State Account)
 55:   # Note: ExternalId is not used for state account role assumption (by design)
 56:   dynamic "assume_role" {
 57:     for_each = var.state_account_role_arn != null ? [1] : []
 58:     content {
 59:       role_arn = var.state_account_role_arn
 60:     }
 61:   }
 62: }
 63: 
 64: # Read backend.hcl to get bucket and region for remote state
 65: data "local_file" "backend_config" {
 66:   filename = "${path.module}/backend.hcl"
 67: }
 68: 
 69: locals {
 70:   # Parse backend.hcl to extract bucket, and region
 71:   # backend.hcl format: bucket = "value", region = "value"
 72:   # If backend.hcl doesn't exist, these will be null and remote state won't be used
 73:   backend_bucket = try(
 74:     regex("bucket\\s*=\\s*\"([^\"]+)\"", data.local_file.backend_config.content)[0],
 75:     null
 76:   )
 77:   backend_key = "backend_state/terraform.tfstate" # backend_infra state key
 78:   backend_region = try(
 79:     regex("region\\s*=\\s*\"([^\"]+)\"", data.local_file.backend_config.content)[0],
 80:     var.region
 81:   )
 82: 
 83:   # Determine workspace name: use provided variable or derive from region and env
 84:   # This matches the workspace naming convention used in scripts: ${region}-${env}
 85:   # The workspace argument in terraform_remote_state will handle the workspace prefix automatically
 86:   terraform_workspace = coalesce(
 87:     var.terraform_workspace,
 88:     "${var.region}-${var.env}"
 89:   )
 90: }
 91: 
 92: # Retrieve cluster name from backend_infra state
 93: # Uses the workspace argument to automatically handle workspace-prefixed state keys
 94: # Reference: https://developer.hashicorp.com/terraform/language/state/remote-state-data
 95: data "terraform_remote_state" "backend_infra" {
 96:   count   = local.backend_bucket != null ? 1 : 0
 97:   backend = "s3"
 98: 
 99:   # Use workspace argument to specify which workspace state to access
100:   # For S3 backend: "default" workspace uses base key, other workspaces use env:/${workspace}/${key}
101:   # Always pass the workspace value explicitly to ensure correct state lookup
102:   workspace = local.terraform_workspace
103: 
104:   config = merge(
105:     {
106:       bucket = local.backend_bucket
107:       key    = local.backend_key
108:       region = local.backend_region
109:     },
110:     # Add assume_role block to assume state account role when accessing remote state
111:     # This allows cross-account state access without requiring provider configuration
112:     # Note: Terraform 1.6.0+ requires assume_role block instead of top-level role_arn
113:     var.state_account_role_arn != null ? {
114:       assume_role = {
115:         role_arn = var.state_account_role_arn
116:       }
117:     } : {}
118:   )
119: }
120: 
121: locals {
122:   # Get cluster name from remote state if available, otherwise use provided value or calculate it
123:   cluster_name = coalesce(
124:     try(data.terraform_remote_state.backend_infra[0].outputs.cluster_name, null),
125:     var.cluster_name,
126:     "${var.prefix}-${var.region}-${var.cluster_name_component}-${var.env}"
127:   )
128: }
129: 
130: data "aws_eks_cluster" "cluster" {
131:   name = local.cluster_name
132: }
133: 
134: data "aws_eks_cluster_auth" "cluster" {
135:   name = local.cluster_name
136: }
137: 
138: provider "kubernetes" {
139:   host                   = data.aws_eks_cluster.cluster.endpoint
140:   cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority[0].data)
141:   token                  = data.aws_eks_cluster_auth.cluster.token
142: }
143: 
144: provider "helm" {
145:   kubernetes {
146:     host                   = data.aws_eks_cluster.cluster.endpoint
147:     cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority[0].data)
148:     token                  = data.aws_eks_cluster_auth.cluster.token
149:   }
150: }
````

## File: backend_infra/outputs.tf
````hcl
  1: output "aws_account" {
  2:   description = "The AWS Account ID"
  3:   value       = local.current_account
  4: }
  5: 
  6: output "region" {
  7:   description = "The AWS region"
  8:   value       = var.region
  9: }
 10: 
 11: output "env" {
 12:   description = "The Environment e.g. prod"
 13:   value       = var.env
 14: }
 15: 
 16: output "prefix" {
 17:   description = "The prefix to all names"
 18:   value       = var.prefix
 19: }
 20: 
 21: ###################### VPC ######################
 22: output "vpc_id" {
 23:   description = "The VPC's ID"
 24:   value       = module.vpc.vpc_id
 25: }
 26: 
 27: output "default_security_group_id" {
 28:   description = "The default security group for the VPC"
 29:   value       = module.vpc.default_security_group_id
 30: }
 31: 
 32: output "public_subnets" {
 33:   description = "The VPC's associated public subnets."
 34:   value       = module.vpc.public_subnets
 35: }
 36: 
 37: output "private_subnets" {
 38:   description = "The VPC's associated private subnets."
 39:   value       = module.vpc.private_subnets
 40: }
 41: 
 42: output "igw_id" {
 43:   description = "The Internet Gateway's ID"
 44:   value       = module.vpc.igw_id
 45: }
 46: 
 47: ########## Kubernetes Cluster ##############
 48: 
 49: output "cluster_name" {
 50:   description = "The Name of Kubernetes Cluster"
 51:   value       = local.cluster_name
 52: }
 53: 
 54: output "cluster_endpoint" {
 55:   description = "EKS Cluster API Endpoint"
 56:   value       = module.eks.cluster_endpoint
 57: }
 58: 
 59: output "cluster_arn" {
 60:   description = "EKS Cluster ARN"
 61:   value       = module.eks.cluster_arn
 62: }
 63: 
 64: output "oidc_provider_arn" {
 65:   description = "OIDC provider ARN for IRSA"
 66:   value       = module.eks.oidc_provider_arn
 67: }
 68: 
 69: output "oidc_provider_url" {
 70:   description = "OIDC provider URL (without https://)"
 71:   value       = replace(module.eks.cluster_oidc_issuer_url, "https://", "")
 72: }
 73: 
 74: ##################### VPC Endpoints ##########################
 75: output "vpc_endpoint_sg_id" {
 76:   description = "Security group ID for VPC endpoints"
 77:   value       = module.endpoints.vpc_endpoint_sg_id
 78: }
 79: 
 80: output "vpc_endpoint_ssm_id" {
 81:   description = "VPC endpoint ID for SSM"
 82:   value       = module.endpoints.vpc_endpoint_ssm_id
 83: }
 84: 
 85: output "vpc_endpoint_ssmmessages_id" {
 86:   description = "VPC endpoint ID for SSM Messages"
 87:   value       = module.endpoints.vpc_endpoint_ssmmessages_id
 88: }
 89: 
 90: output "vpc_endpoint_ec2messages_id" {
 91:   description = "VPC endpoint ID for EC2 Messages"
 92:   value       = module.endpoints.vpc_endpoint_ec2messages_id
 93: }
 94: 
 95: output "vpc_endpoint_ids" {
 96:   description = "List of all VPC endpoint IDs"
 97:   value       = module.endpoints.vpc_endpoint_ids
 98: }
 99: 
100: output "vpc_endpoint_sts_id" {
101:   description = "VPC endpoint ID for STS (IRSA)"
102:   value       = module.endpoints.vpc_endpoint_sts_id
103: }
104: 
105: output "vpc_endpoint_sns_id" {
106:   description = "VPC endpoint ID for SNS (SMS 2FA)"
107:   value       = module.endpoints.vpc_endpoint_sns_id
108: }
109: 
110: ##################### ECR ##########################
111: output "ecr_name" {
112:   description = "ECR repository name"
113:   value       = module.ecr.ecr_name
114: }
115: 
116: output "ecr_arn" {
117:   description = "ECR repository ARN"
118:   value       = module.ecr.ecr_arn
119: }
120: 
121: output "ecr_url" {
122:   description = "ECR repository URL"
123:   value       = module.ecr.ecr_url
124: }
125: 
126: output "ecr_registry" {
127:   description = "ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)"
128:   value       = module.ecr.ecr_registry
129: }
130: 
131: output "ecr_repository" {
132:   description = "ECR repository name (without registry prefix)"
133:   value       = module.ecr.ecr_repository
134: }
135: 
136: ##################### EBS ##########################
137: # output "ebs_pvc_name" {
138: #   value = module.ebs.ebs_pvc_name
139: # }
140: #
141: # output "ebs_storage_class_name" {
142: #   value = module.ebs.ebs_storage_class_name
143: # }
````

## File: backend_infra/setup-backend.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: PLACEHOLDER_FILE="tfstate-backend-values-template.hcl"
 18: BACKEND_FILE="backend.hcl"
 19: VARIABLES_FILE="variables.tfvars"
 20: 
 21: 
 22: print_error() {
 23:     echo -e "${RED}ERROR:${NC} $1" >&2
 24: }
 25: 
 26: print_success() {
 27:     echo -e "${GREEN}SUCCESS:${NC} $1"
 28: }
 29: 
 30: print_info() {
 31:     echo -e "${YELLOW}INFO:${NC} $1"
 32: }
 33: 
 34: 
 35: if ! command -v aws &> /dev/null; then
 36:     print_error "AWS CLI is not installed."
 37:     echo "Please install it from: https://aws.amazon.com/cli/"
 38:     exit 1
 39: fi
 40: 
 41: 
 42: if ! command -v terraform &> /dev/null; then
 43:     print_error "Terraform is not installed."
 44:     echo "Please install it from: https://www.terraform.io/downloads"
 45:     exit 1
 46: fi
 47: 
 48: 
 49: if ! command -v gh &> /dev/null; then
 50:     print_error "GitHub CLI (gh) is not installed."
 51:     echo "Please install it from: https://cli.github.com/"
 52:     exit 1
 53: fi
 54: 
 55: 
 56: if ! gh auth status &> /dev/null; then
 57:     print_error "Not authenticated with GitHub CLI."
 58:     echo "Please run: gh auth login"
 59:     exit 1
 60: fi
 61: 
 62: 
 63: if ! command -v jq &> /dev/null; then
 64:     print_error "jq is not installed."
 65:     echo "Please install it:"
 66:     echo "  macOS: brew install jq"
 67:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 68:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 69:     exit 1
 70: fi
 71: 
 72: 
 73: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 74: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 75: 
 76: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 77:     print_error "Could not determine repository information."
 78:     echo "Please ensure you're in a git repository and have proper permissions."
 79:     exit 1
 80: fi
 81: 
 82: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 83: 
 84: 
 85: get_repo_variable() {
 86:     local var_name=$1
 87:     local value
 88: 
 89:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 90: 
 91:     if [ -z "$value" ]; then
 92:         print_error "Repository variable '${var_name}' not found or not accessible."
 93:         return 1
 94:     fi
 95: 
 96:     echo "$value"
 97: }
 98: 
 99: 
100: get_aws_secret() {
101:     local secret_name=$1
102:     local secret_json
103:     local exit_code
104: 
105: 
106: 
107:     secret_json=$(aws secretsmanager get-secret-value \
108:         --secret-id "$secret_name" \
109:         --region "${AWS_REGION:-us-east-1}" \
110:         --query SecretString \
111:         --output text 2>&1)
112: 
113: 
114:     exit_code=$?
115: 
116: 
117:     if [ $exit_code -ne 0 ]; then
118:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
119:         print_error "Error: $secret_json"
120:         return 1
121:     fi
122: 
123: 
124:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
125:         print_error "Secret '${secret_name}' contains invalid JSON"
126:         return 1
127:     fi
128: 
129:     echo "$secret_json"
130: }
131: 
132: 
133: get_aws_plaintext_secret() {
134:     local secret_name=$1
135:     local secret_value
136:     local exit_code
137: 
138: 
139: 
140:     secret_value=$(aws secretsmanager get-secret-value \
141:         --secret-id "$secret_name" \
142:         --region "${AWS_REGION:-us-east-1}" \
143:         --query SecretString \
144:         --output text 2>&1)
145: 
146: 
147:     exit_code=$?
148: 
149: 
150:     if [ $exit_code -ne 0 ]; then
151:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
152:         print_error "Error: $secret_value"
153:         return 1
154:     fi
155: 
156: 
157:     if [ -z "$secret_value" ]; then
158:         print_error "Secret '${secret_name}' is empty"
159:         return 1
160:     fi
161: 
162:     echo "$secret_value"
163: }
164: 
165: 
166: get_secret_key_value() {
167:     local secret_json=$1
168:     local key_name=$2
169:     local value
170: 
171: 
172:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
173:         print_error "Invalid JSON provided to get_secret_key_value"
174:         return 1
175:     fi
176: 
177: 
178:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
179: 
180: 
181:     if [ $? -ne 0 ]; then
182:         print_error "Failed to parse JSON or extract key '${key_name}'"
183:         return 1
184:     fi
185: 
186: 
187:     if [ "$value" = "null" ] || [ -z "$value" ]; then
188:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
189:         return 1
190:     fi
191: 
192:     echo "$value"
193: }
194: 
195: 
196: echo ""
197: print_info "Select AWS Region:"
198: echo "1) us-east-1: N. Virginia (default)"
199: echo "2) us-east-2: Ohio"
200: read -p "Enter choice [1-2] (default: 1): " region_choice
201: 
202: case ${region_choice:-1} in
203:     1)
204:         SELECTED_REGION="us-east-1: N. Virginia"
205:         ;;
206:     2)
207:         SELECTED_REGION="us-east-2: Ohio"
208:         ;;
209:     *)
210:         print_error "Invalid choice. Using default: us-east-1: N. Virginia"
211:         SELECTED_REGION="us-east-1: N. Virginia"
212:         ;;
213: esac
214: 
215: 
216: AWS_REGION="${SELECTED_REGION%%:*}"
217: print_success "Selected region: ${SELECTED_REGION} (${AWS_REGION})"
218: 
219: echo ""
220: print_info "Select Environment:"
221: echo "1) prod (default)"
222: echo "2) dev"
223: read -p "Enter choice [1-2] (default: 1): " env_choice
224: 
225: case ${env_choice:-1} in
226:     1)
227:         ENVIRONMENT="prod"
228:         ;;
229:     2)
230:         ENVIRONMENT="dev"
231:         ;;
232:     *)
233:         print_error "Invalid choice. Using default: prod"
234:         ENVIRONMENT="prod"
235:         ;;
236: esac
237: 
238: print_success "Selected environment: ${ENVIRONMENT}"
239: echo ""
240: 
241: # Retrieve all role ARNs from AWS Secrets Manager in a single call
242: # This minimizes AWS CLI calls by fetching all required role ARNs at once
243: print_info "Retrieving role ARNs from AWS Secrets Manager..."
244: SECRET_JSON=$(get_aws_secret "github-role" || echo "")
245: if [ -z "$SECRET_JSON" ]; then
246:     print_error "Failed to retrieve secret from AWS Secrets Manager"
247:     exit 1
248: fi
249: 
250: 
251: STATE_ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
252: if [ -z "$STATE_ROLE_ARN" ]; then
253:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
254:     exit 1
255: fi
256: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
257: 
258: 
259: if [ "$ENVIRONMENT" = "prod" ]; then
260:     DEPLOYMENT_ROLE_ARN_KEY="AWS_PRODUCTION_ACCOUNT_ROLE_ARN"
261: else
262:     DEPLOYMENT_ROLE_ARN_KEY="AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN"
263: fi
264: 
265: 
266: DEPLOYMENT_ROLE_ARN=$(get_secret_key_value "$SECRET_JSON" "$DEPLOYMENT_ROLE_ARN_KEY" || echo "")
267: if [ -z "$DEPLOYMENT_ROLE_ARN" ]; then
268:     print_error "Failed to retrieve ${DEPLOYMENT_ROLE_ARN_KEY} from secret"
269:     exit 1
270: fi
271: print_success "Retrieved ${DEPLOYMENT_ROLE_ARN_KEY}"
272: 
273: 
274: ROLE_ARN="$STATE_ROLE_ARN"
275: 
276: print_info "Assuming role: $ROLE_ARN"
277: print_info "Region: $AWS_REGION"
278: 
279: 
280: ROLE_SESSION_NAME="setup-backend-$(date +%s)"
281: 
282: 
283: ASSUME_ROLE_OUTPUT=$(aws sts assume-role \
284:     --role-arn "$ROLE_ARN" \
285:     --role-session-name "$ROLE_SESSION_NAME" \
286:     --region "$AWS_REGION" 2>&1)
287: 
288: if [ $? -ne 0 ]; then
289:     print_error "Failed to assume role: $ASSUME_ROLE_OUTPUT"
290:     exit 1
291: fi
292: 
293: 
294: 
295: if command -v jq &> /dev/null; then
296:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.AccessKeyId')
297:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SecretAccessKey')
298:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | jq -r '.Credentials.SessionToken')
299: else
300: 
301:     export AWS_ACCESS_KEY_ID=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
302:     export AWS_SECRET_ACCESS_KEY=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
303:     export AWS_SESSION_TOKEN=$(echo "$ASSUME_ROLE_OUTPUT" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
304: fi
305: 
306: if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
307:     print_error "Failed to extract credentials from assume-role output."
308:     print_error "Output was: $ASSUME_ROLE_OUTPUT"
309:     exit 1
310: fi
311: 
312: print_success "Successfully assumed role"
313: 
314: 
315: CALLER_ARN=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
316: if [ $? -ne 0 ]; then
317:     print_error "Failed to verify assumed role credentials: $CALLER_ARN"
318:     exit 1
319: fi
320: 
321: print_info "Assumed role identity: $CALLER_ARN"
322: echo ""
323: 
324: # Retrieve ExternalId from AWS Secrets Manager (plain text secret)
325: # Must be retrieved after assuming role to have AWS credentials
326: print_info "Retrieving ExternalId from AWS Secrets Manager..."
327: EXTERNAL_ID=$(get_aws_plaintext_secret "external-id" || echo "")
328: if [ -z "$EXTERNAL_ID" ]; then
329:     print_error "Failed to retrieve 'external-id' secret from AWS Secrets Manager"
330:     exit 1
331: fi
332: print_success "Retrieved ExternalId"
333: 
334: 
335: print_info "Retrieving repository variables..."
336: 
337: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME") || exit 1
338: print_success "Retrieved BACKEND_BUCKET_NAME"
339: 
340: BACKEND_PREFIX=$(get_repo_variable "BACKEND_PREFIX") || exit 1
341: print_success "Retrieved BACKEND_PREFIX"
342: 
343: 
344: if [ -f "$BACKEND_FILE" ]; then
345:     print_info "${BACKEND_FILE} already exists. Skipping creation."
346: else
347: 
348:     if [ ! -f "$PLACEHOLDER_FILE" ]; then
349:         print_error "Placeholder file '${PLACEHOLDER_FILE}' not found."
350:         exit 1
351:     fi
352: 
353: 
354:     print_info "Creating ${BACKEND_FILE} from ${PLACEHOLDER_FILE} with retrieved values..."
355: 
356: 
357:     cp "$PLACEHOLDER_FILE" "$BACKEND_FILE"
358: 
359: 
360:     if [[ "$OSTYPE" == "darwin"* ]]; then
361: 
362:         sed -i '' "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
363:         sed -i '' "s|<BACKEND_PREFIX>|${BACKEND_PREFIX}|g" "$BACKEND_FILE"
364:         sed -i '' "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
365:     else
366:         # Linux sed
367:         sed -i "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
368:         sed -i "s|<BACKEND_PREFIX>|${BACKEND_PREFIX}|g" "$BACKEND_FILE"
369:         sed -i "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
370:     fi
371: 
372:     print_success "Created ${BACKEND_FILE}"
373: fi
374: 
375: # Update variables.tfvars
376: print_info "Updating ${VARIABLES_FILE} with selected values..."
377: 
378: if [ ! -f "$VARIABLES_FILE" ]; then
379:     print_error "Variables file '${VARIABLES_FILE}' not found."
380:     exit 1
381: fi
382: 
383: # Update variables.tfvars (works on macOS and Linux)
384: if [[ "$OSTYPE" == "darwin"* ]]; then
385:     # macOS sed requires -i '' for in-place editing
386:     sed -i '' "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT}\"|" "$VARIABLES_FILE"
387:     sed -i '' "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
388:     # Add or update deployment_account_role_arn
389:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
390:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
391:     else
392:         sed -i '' "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
393:     fi
394:     # Add or update deployment_account_external_id
395:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
396:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
397:     else
398:         sed -i '' "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
399:     fi
400: else
401: 
402:     sed -i "s|^env[[:space:]]*=.*|env                    = \"${ENVIRONMENT}\"|" "$VARIABLES_FILE"
403:     sed -i "s|^region[[:space:]]*=.*|region                 = \"${AWS_REGION}\"|" "$VARIABLES_FILE"
404: 
405:     if ! grep -q "^deployment_account_role_arn" "$VARIABLES_FILE"; then
406:         echo "deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"" >> "$VARIABLES_FILE"
407:     else
408:         sed -i "s|^deployment_account_role_arn[[:space:]]*=.*|deployment_account_role_arn = \"${DEPLOYMENT_ROLE_ARN}\"|" "$VARIABLES_FILE"
409:     fi
410: 
411:     if ! grep -q "^deployment_account_external_id" "$VARIABLES_FILE"; then
412:         echo "deployment_account_external_id = \"${EXTERNAL_ID}\"" >> "$VARIABLES_FILE"
413:     else
414:         sed -i "s|^deployment_account_external_id[[:space:]]*=.*|deployment_account_external_id = \"${EXTERNAL_ID}\"|" "$VARIABLES_FILE"
415:     fi
416: fi
417: 
418: print_success "Updated ${VARIABLES_FILE}"
419: echo ""
420: print_success "Configuration files updated successfully!"
421: echo ""
422: print_info "Backend file: ${BACKEND_FILE}"
423: print_info "  - bucket: ${BUCKET_NAME}"
424: print_info "  - key: ${BACKEND_PREFIX}"
425: print_info "  - region: ${AWS_REGION}"
426: echo ""
427: print_info "Variables file: ${VARIABLES_FILE}"
428: print_info "  - env: ${ENVIRONMENT}"
429: print_info "  - region: ${AWS_REGION}"
430: echo ""
431: 
432: # Terraform workspace name
433: WORKSPACE_NAME="${AWS_REGION}-${ENVIRONMENT}"
434: 
435: # Terraform init
436: print_info "Running terraform init with backend configuration..."
437: terraform init -backend-config="${BACKEND_FILE}"
438: 
439: # Terraform workspace
440: print_info "Selecting or creating workspace: ${WORKSPACE_NAME}..."
441: terraform workspace select "${WORKSPACE_NAME}" || terraform workspace new "${WORKSPACE_NAME}"
442: 
443: # Terraform validate
444: print_info "Running terraform validate..."
445: terraform validate
446: 
447: # Terraform plan
448: print_info "Running terraform plan..."
449: terraform plan -var-file="${VARIABLES_FILE}" -out terraform.tfplan
450: 
451: # Terraform apply
452: print_info "Running terraform apply..."
453: terraform apply -auto-approve terraform.tfplan
454: 
455: echo ""
456: print_success "Script completed successfully!"
````

## File: backend_infra/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name added to all resources"
 13:   type        = string
 14: }
 15: 
 16: variable "deployment_account_role_arn" {
 17:   description = "ARN of the IAM role to assume in the deployment account (Account B). Required when using GitHub Actions with multi-account setup."
 18:   type        = string
 19:   default     = null
 20:   nullable    = true
 21: }
 22: 
 23: variable "deployment_account_external_id" {
 24:   description = "ExternalId for cross-account role assumption security. Required when assuming roles in deployment accounts. Must match the ExternalId configured in the deployment account role's Trust Relationship. Retrieved from AWS Secrets Manager (secret: 'external-id') for local deployment or GitHub secret (AWS_ASSUME_EXTERNAL_ID) for GitHub Actions."
 25:   type        = string
 26:   default     = null
 27:   nullable    = true
 28:   sensitive   = true
 29: }
 30: 
 31: ###################### VPC #########################
 32: 
 33: variable "vpc_name" {
 34:   description = "The name of the VPC"
 35:   type        = string
 36: }
 37: 
 38: variable "vpc_cidr" {
 39:   description = "CIDR block for VPC"
 40:   type        = string
 41: }
 42: 
 43: variable "igw_name" {
 44:   description = "The name of the Internet Gateway"
 45:   type        = string
 46: }
 47: 
 48: variable "ngw_name" {
 49:   description = "The name of the NAT Gateway"
 50:   type        = string
 51: }
 52: 
 53: variable "route_table_name" {
 54:   description = "The name of the route table"
 55:   type        = string
 56: }
 57: 
 58: ############ Kubernetes Cluster #################
 59: 
 60: variable "k8s_version" {
 61:   description = "The version of Kubernetes to deploy."
 62:   type        = string
 63: }
 64: 
 65: variable "cluster_name" {
 66:   description = "The Name of Kubernetes Cluster"
 67:   type        = string
 68: }
 69: 
 70: ##################### Endpoints ##########################
 71: 
 72: variable "endpoint_sg_name" {
 73:   description = "The name of the endpoint security group"
 74:   type        = string
 75: }
 76: 
 77: variable "enable_sts_endpoint" {
 78:   description = "Whether to create STS VPC endpoint (required for IRSA)"
 79:   type        = bool
 80:   default     = true
 81: }
 82: 
 83: variable "enable_sns_endpoint" {
 84:   description = "Whether to create SNS VPC endpoint (required for SMS 2FA)"
 85:   type        = bool
 86:   default     = false
 87: }
 88: 
 89: ##################### EBS ##########################
 90: 
 91: variable "ebs_name" {
 92:   description = "The name of the EBS"
 93:   type        = string
 94: }
 95: 
 96: variable "ebs_claim_name" {
 97:   description = "The name of the EBS claim"
 98:   type        = string
 99: }
100: 
101: ##################### ECR ##########################
102: 
103: variable "ecr_name" {
104:   description = "The name of the ECR"
105:   type        = string
106: }
107: 
108: variable "image_tag_mutability" {
109:   description = "The value that determines if the image is overridable"
110:   type        = string
111: }
112: 
113: variable "ecr_lifecycle_policy" {}
````

## File: .github/workflows/application_infra_destroying.yaml
````yaml
  1: name: Application Infra Destroying
  2: 
  3: 
  4: 
  5: 
  6: 
  7: 
  8: 
  9: 
 10: 
 11: 
 12: 
 13: 
 14: 
 15: 
 16: on:
 17:   workflow_dispatch:
 18:     inputs:
 19:       region:
 20:         description: 'Select AWS Region'
 21:         required: true
 22:         type: choice
 23:         default: 'us-east-1: N. Virginia'
 24:         options:
 25:           - 'us-east-1: N. Virginia'
 26:           - 'us-east-2: Ohio'
 27:       environment:
 28:         description: 'Select Environment'
 29:         required: true
 30:         type: choice
 31:         default: prod
 32:         options:
 33:           - prod
 34:           - dev
 35: 
 36: jobs:
 37:   SetRegion:
 38:     runs-on: ubuntu-latest
 39:     permissions:
 40:       contents: read
 41:     outputs:
 42:       region_code: ${{ steps.set_region.outputs.region_code }}
 43:     steps:
 44:       - name: Set Region
 45:         id: set_region
 46:         run: |
 47:           SELECTED_REGION="${{ inputs.region }}"
 48:           echo "region_code=${SELECTED_REGION%%:*}" >> $GITHUB_OUTPUT
 49: 
 50:   InfraDestroy:
 51:     runs-on: ubuntu-latest
 52:     needs:
 53:       - SetRegion
 54:     permissions:
 55:       contents: write
 56:       actions: write
 57:       id-token: write
 58:     env:
 59:       AWS_REGION: ${{ needs.SetRegion.outputs.region_code }}
 60: 
 61: 
 62:       TF_VAR_openldap_admin_password: ${{ secrets.TF_VAR_OPENLDAP_ADMIN_PASSWORD }}
 63:       TF_VAR_openldap_config_password: ${{ secrets.TF_VAR_OPENLDAP_CONFIG_PASSWORD }}
 64: 
 65:       TF_VAR_redis_password: ${{ secrets.TF_VAR_REDIS_PASSWORD }}
 66: 
 67:       TF_VAR_postgresql_database_password: ${{ secrets.TF_VAR_POSTGRESQL_PASSWORD }}
 68:     defaults:
 69:       run:
 70:         working-directory: ./application
 71:     steps:
 72:       - name: Checkout the repo code
 73:         uses: actions/checkout@v4
 74: 
 75:       - name: Setup terraform
 76:         uses: hashicorp/setup-terraform@v3
 77:         with:
 78:           terraform_version: 1.14.0
 79: 
 80:       - name: Export environment variables for set-k8s-env.sh
 81:         run: |
 82: 
 83:           echo "BACKEND_FILE=backend.hcl" >> $GITHUB_ENV
 84:           echo "VARIABLES_FILE=variables.tfvars" >> $GITHUB_ENV
 85:           echo "ENVIRONMENT=${{ inputs.environment }}" >> $GITHUB_ENV
 86: 
 87:           if [ "${{ inputs.environment }}" = "prod" ]; then
 88:             echo "DEPLOYMENT_ROLE_ARN=${{ secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 89:           else
 90:             echo "DEPLOYMENT_ROLE_ARN=${{ secrets.AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 91:           fi
 92:           echo "EXTERNAL_ID=${{ secrets.AWS_ASSUME_EXTERNAL_ID }}" >> $GITHUB_ENV
 93: 
 94:           echo "STATE_ACCOUNT_ROLE_ARN=${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 95: 
 96:       - name: Configure AWS credentials (State Account)
 97:         uses: aws-actions/configure-aws-credentials@v4
 98:         with:
 99:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
100:           role-session-name: GitHubActions-ApplicationInfraDestroy-State
101:           aws-region: ${{ env.AWS_REGION }}
102: 
103:       - name: Create backend.hcl from placeholder
104:         run: |
105: 
106:           if [ ! -f "backend.hcl" ]; then
107:             cp tfstate-backend-values-template.hcl backend.hcl
108:             sed -i -e "s|<BACKEND_BUCKET_NAME>|${{ vars.BACKEND_BUCKET_NAME }}|g" \
109:             -e "s|<APPLICATION_PREFIX>|${{ vars.APPLICATION_PREFIX }}|g" \
110:             -e "s|<AWS_REGION>|${{ env.AWS_REGION }}|g" \
111:             backend.hcl
112:             echo "Created backend.hcl:"
113:             cat backend.hcl
114:           else
115:             echo "backend.hcl already exists. Skipping creation."
116:           fi
117: 
118:       - name: Terraform init
119:         run: terraform init -backend-config=backend.hcl
120: 
121:       - name: Terraform workspace
122:         run: |
123:           WORKSPACE="${{ env.AWS_REGION }}-${{ inputs.environment }}"
124:           terraform workspace select $WORKSPACE || terraform workspace new $WORKSPACE
125: 
126:       - name: Terraform validate
127:         run: terraform validate
128: 
129:       - name: Set Kubernetes environment variables
130:         run: |
131: 
132: 
133:           chmod +x ./set-k8s-env.sh
134:           source ./set-k8s-env.sh
135: 
136:           echo "TF_VAR_kubernetes_master=$KUBERNETES_MASTER" >> $GITHUB_ENV
137:           echo "TF_VAR_kube_config_path=$KUBE_CONFIG_PATH" >> $GITHUB_ENV
138: 
139:       - name: Configure AWS credentials (State Account for Terraform)
140:         uses: aws-actions/configure-aws-credentials@v4
141:         with:
142:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
143:           role-session-name: GitHubActions-ApplicationInfraDestroy-Terraform
144:           aws-region: ${{ env.AWS_REGION }}
145: 
146:       - name: Terraform plan destroy
147:         run: terraform plan -var-file="variables.tfvars" -destroy -out terraform.tfplan
148: 
149:       - name: Destroy application infrastructure
150:         run: terraform apply -auto-approve terraform.tfplan
````

## File: application/helm/openldap-values.tpl.yaml
````yaml
  1: replicaCount: 3
  2: 
  3: 
  4: replication:
  5:   enabled: true
  6:   retry: 60
  7:   timeout: 30
  8:   interval: "00:00:00:10"
  9:   starttls: "critical"
 10:   tls_reqcert: "never"
 11:   clusterName: "cluster.local"
 12: 
 13: 
 14: image:
 15:   registry: "${ecr_registry}"
 16:   repository: "${ecr_repository}"
 17:   tag: "${openldap_image_tag}"
 18:   pullPolicy: IfNotPresent
 19: 
 20: global:
 21:   imageRegistry: ""
 22:   imagePullSecrets: []
 23:   storageClass: "${storage_class_name}"
 24:   ldapDomain: "${openldap_ldap_domain}"
 25:   existingSecret: "${openldap_secret_name}"
 26:   ldapPort: 389
 27:   sslLdapPort: 636
 28: 
 29: # Enable TLS with auto-generated certificates for osixia/openldap image
 30: # osixia/openldap uses different environment variable names than Bitnami
 31: # Note: LDAP_ADMIN_PASSWORD and LDAP_CONFIG_PASSWORD are now sourced from the Kubernetes secret
 32: # specified in global.existingSecret
 33: env:
 34:   LDAP_DOMAIN: "${openldap_ldap_domain}"
 35:   # Enable TLS (osixia/openldap will auto-generate certificates if they don't exist)
 36:   LDAP_TLS: "true"
 37: 
 38:   LDAP_TLS_ENFORCE: "false"
 39: 
 40:   LDAP_TLS_VERIFY_CLIENT: "never"
 41: 
 42: 
 43:   LDAP_TLS_CRT_FILENAME: "ldap.crt"
 44:   LDAP_TLS_KEY_FILENAME: "ldap.key"
 45:   LDAP_TLS_CA_CRT_FILENAME: "ca.crt"
 46: 
 47: persistence:
 48:   enabled: true
 49:   accessModes:
 50:     - ReadWriteOnce
 51:   size: 8Gi
 52: 
 53: service:
 54:   annotations: {}
 55:   externalIPs: []
 56:   type: ClusterIP
 57:   sessionAffinity: None
 58: 
 59: ltb-passwd:
 60:   enabled: true
 61:   image:
 62:     tag: 5.2.3
 63:   podLabels:
 64:     app: "${app_name}"
 65: 
 66:   env:
 67:     LDAPTLS_REQCERT: "allow"
 68:   ingress:
 69:     enabled: true
 70:     ingressClassName: "${ingress_class_name}"
 71:     annotations:
 72: 
 73:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
 74:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
 75:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
 76:       alb.ingress.kubernetes.io/ssl-redirect: "443"
 77:       alb.ingress.kubernetes.io/ssl-policy: "${alb_ssl_policy}"
 78: 
 79:     path: /
 80:     pathType: Prefix
 81:     hosts:
 82:       - "${ltb_passwd_host}"
 83:   ldap:
 84:     bindPWKey: LDAP_ADMIN_PASSWORD
 85: 
 86: phpldapadmin:
 87:   enabled: true
 88: 
 89:   env:
 90:     PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "allow"
 91:   podLabels:
 92:     app: "${app_name}"
 93:   ingress:
 94:     enabled: true
 95:     ingressClassName: "${ingress_class_name}"
 96:     annotations:
 97:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
 98:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
 99:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
100:       alb.ingress.kubernetes.io/ssl-redirect: "443"
101:       alb.ingress.kubernetes.io/ssl-policy: "${alb_ssl_policy}"
102:     path: /
103:     pathType: Prefix
104:     hosts:
105:       - "${phpldapadmin_host}"
````

## File: application/modules/postgresql/main.tf
````hcl
  1: /**
  2:  * PostgreSQL Module
  3:  *
  4:  * Deploys PostgreSQL using the Bitnami Helm chart for user storage
  5:  * in the LDAP 2FA application signup system.
  6:  */
  7: 
  8: locals {
  9:   name = "${var.prefix}-${var.region}-postgresql-${var.env}"
 10: 
 11:   # Determine values template path
 12:   values_template_path = var.values_template_path != null ? var.values_template_path : "${path.module}/../../helm/postgresql-values.tpl.yaml"
 13: 
 14:   # Build PostgreSQL Helm values using templatefile
 15:   # Note: We pass the secret name variable (not resource) to avoid circular dependency
 16:   # The secret resource is created separately with the same name
 17:   postgresql_values = templatefile(
 18:     local.values_template_path,
 19:     {
 20:       secret_name              = var.secret_name
 21:       database_name            = var.database_name
 22:       database_username        = var.database_username
 23:       storage_class            = var.storage_class
 24:       storage_size             = var.storage_size
 25:       resources_requests_cpu   = var.resources.requests.cpu
 26:       resources_requests_memory = var.resources.requests.memory
 27:       resources_limits_cpu     = var.resources.limits.cpu
 28:       resources_limits_memory  = var.resources.limits.memory
 29:       ecr_registry             = var.ecr_registry
 30:       ecr_repository           = var.ecr_repository
 31:       image_tag                = var.image_tag
 32:     }
 33:   )
 34: }
 35: 
 36: # Create namespace if it doesn't exist
 37: resource "kubernetes_namespace" "postgresql" {
 38:   metadata {
 39:     name = var.namespace
 40: 
 41:     labels = {
 42:       name        = var.namespace
 43:       environment = var.env
 44:       managed-by  = "terraform"
 45:     }
 46:   }
 47: 
 48:   lifecycle {
 49:     ignore_changes = [metadata[0].labels]
 50:   }
 51: }
 52: 
 53: # Create Kubernetes secret for PostgreSQL password
 54: # Password is sourced from GitHub Secrets via TF_VAR_postgresql_database_password
 55: resource "kubernetes_secret" "postgresql_password" {
 56:   metadata {
 57:     name      = var.secret_name
 58:     namespace = kubernetes_namespace.postgresql.metadata[0].name
 59: 
 60:     labels = {
 61:       app         = local.name
 62:       environment = var.env
 63:       managed-by  = "terraform"
 64:     }
 65:   }
 66: 
 67:   data = {
 68:     "password" = var.database_password
 69:   }
 70: 
 71:   type = "Opaque"
 72: }
 73: 
 74: # PostgreSQL Helm release
 75: resource "helm_release" "postgresql" {
 76:   name       = local.name
 77:   # repository = "https://charts.bitnami.com/bitnami"
 78:   repository = "oci://registry-1.docker.io/bitnamicharts"
 79:   chart      = "postgresql"
 80:   version    = var.chart_version
 81:   namespace  = kubernetes_namespace.postgresql.metadata[0].name
 82: 
 83:   atomic          = true
 84:   cleanup_on_fail = true
 85:   recreate_pods   = true
 86:   force_update    = true
 87:   wait            = true
 88:   wait_for_jobs   = true
 89:   timeout         = 600 # Reduced from 1200 to 600 seconds (10 min) for faster debugging
 90:   upgrade_install = true
 91: 
 92:   # Allow replacement if name conflict occurs
 93:   replace = true
 94: 
 95:   # Use templatefile to inject values into the official Bitnami PostgreSQL Helm chart values template
 96:   # Note: The secret name is passed to the template, and the secret resource is created separately
 97:   values = [local.postgresql_values]
 98: 
 99:   depends_on = [
100:     kubernetes_namespace.postgresql,
101:     kubernetes_secret.postgresql_password,
102:   ]
103: }
````

## File: application/setup-application.sh
````bash
  1: set -euo pipefail
  2: 
  3: 
  4: 
  5: unset AWS_ACCESS_KEY_ID 2>/dev/null || true
  6: unset AWS_SECRET_ACCESS_KEY 2>/dev/null || true
  7: unset AWS_SESSION_TOKEN 2>/dev/null || true
  8: unset AWS_PROFILE 2>/dev/null || true
  9: 
 10: 
 11: RED='\033[0;31m'
 12: GREEN='\033[0;32m'
 13: YELLOW='\033[1;33m'
 14: NC='\033[0m'
 15: 
 16: 
 17: PLACEHOLDER_FILE="tfstate-backend-values-template.hcl"
 18: BACKEND_FILE="backend.hcl"
 19: VARIABLES_FILE="variables.tfvars"
 20: 
 21: 
 22: export BACKEND_FILE
 23: export VARIABLES_FILE
 24: 
 25: 
 26: print_error() {
 27:     echo -e "${RED}ERROR:${NC} $1" >&2
 28: }
 29: 
 30: print_success() {
 31:     echo -e "${GREEN}SUCCESS:${NC} $1"
 32: }
 33: 
 34: print_info() {
 35:     echo -e "${YELLOW}INFO:${NC} $1"
 36: }
 37: 
 38: 
 39: if ! command -v aws &> /dev/null; then
 40:     print_error "AWS CLI is not installed."
 41:     echo "Please install it from: https://aws.amazon.com/cli/"
 42:     exit 1
 43: fi
 44: 
 45: 
 46: if ! command -v terraform &> /dev/null; then
 47:     print_error "Terraform is not installed."
 48:     echo "Please install it from: https://www.terraform.io/downloads"
 49:     exit 1
 50: fi
 51: 
 52: 
 53: if ! command -v gh &> /dev/null; then
 54:     print_error "GitHub CLI (gh) is not installed."
 55:     echo "Please install it from: https://cli.github.com/"
 56:     exit 1
 57: fi
 58: 
 59: 
 60: if ! gh auth status &> /dev/null; then
 61:     print_error "Not authenticated with GitHub CLI."
 62:     echo "Please run: gh auth login"
 63:     exit 1
 64: fi
 65: 
 66: 
 67: if ! command -v jq &> /dev/null; then
 68:     print_error "jq is not installed."
 69:     echo "Please install it:"
 70:     echo "  macOS: brew install jq"
 71:     echo "  Linux: sudo apt-get install jq (or use your package manager)"
 72:     echo "  Or visit: https://stedolan.github.io/jq/download/"
 73:     exit 1
 74: fi
 75: 
 76: 
 77: REPO_OWNER=$(gh repo view --json owner --jq '.owner.login' 2>/dev/null || echo "")
 78: REPO_NAME=$(gh repo view --json name --jq '.name' 2>/dev/null || echo "")
 79: 
 80: if [ -z "$REPO_OWNER" ] || [ -z "$REPO_NAME" ]; then
 81:     print_error "Could not determine repository information."
 82:     echo "Please ensure you're in a git repository and have proper permissions."
 83:     exit 1
 84: fi
 85: 
 86: print_info "Repository: ${REPO_OWNER}/${REPO_NAME}"
 87: 
 88: 
 89: get_repo_variable() {
 90:     local var_name=$1
 91:     local value
 92: 
 93:     value=$(gh variable list --repo "${REPO_OWNER}/${REPO_NAME}" --json name,value --jq ".[] | select(.name == \"${var_name}\") | .value" 2>/dev/null || echo "")
 94: 
 95:     if [ -z "$value" ]; then
 96:         print_error "Repository variable '${var_name}' not found or not accessible."
 97:         return 1
 98:     fi
 99: 
100:     echo "$value"
101: }
102: 
103: 
104: get_aws_secret() {
105:     local secret_name=$1
106:     local secret_json
107:     local exit_code
108: 
109: 
110: 
111:     secret_json=$(aws secretsmanager get-secret-value \
112:         --secret-id "$secret_name" \
113:         --region "${AWS_REGION:-us-east-1}" \
114:         --query SecretString \
115:         --output text 2>&1)
116: 
117: 
118:     exit_code=$?
119: 
120: 
121:     if [ $exit_code -ne 0 ]; then
122:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
123:         print_error "Error: $secret_json"
124:         return 1
125:     fi
126: 
127: 
128:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
129:         print_error "Secret '${secret_name}' contains invalid JSON"
130:         return 1
131:     fi
132: 
133:     echo "$secret_json"
134: }
135: 
136: 
137: get_aws_plaintext_secret() {
138:     local secret_name=$1
139:     local secret_value
140:     local exit_code
141: 
142: 
143: 
144:     secret_value=$(aws secretsmanager get-secret-value \
145:         --secret-id "$secret_name" \
146:         --region "${AWS_REGION:-us-east-1}" \
147:         --query SecretString \
148:         --output text 2>&1)
149: 
150: 
151:     exit_code=$?
152: 
153: 
154:     if [ $exit_code -ne 0 ]; then
155:         print_error "Failed to retrieve secret '${secret_name}' from AWS Secrets Manager"
156:         print_error "Error: $secret_value"
157:         return 1
158:     fi
159: 
160: 
161:     if [ -z "$secret_value" ]; then
162:         print_error "Secret '${secret_name}' is empty"
163:         return 1
164:     fi
165: 
166:     echo "$secret_value"
167: }
168: 
169: 
170: get_secret_key_value() {
171:     local secret_json=$1
172:     local key_name=$2
173:     local value
174: 
175: 
176:     if ! echo "$secret_json" | jq empty 2>/dev/null; then
177:         print_error "Invalid JSON provided to get_secret_key_value"
178:         return 1
179:     fi
180: 
181: 
182:     value=$(echo "$secret_json" | jq -r ".[\"${key_name}\"]" 2>/dev/null)
183: 
184: 
185:     if [ $? -ne 0 ]; then
186:         print_error "Failed to parse JSON or extract key '${key_name}'"
187:         return 1
188:     fi
189: 
190: 
191:     if [ "$value" = "null" ] || [ -z "$value" ]; then
192:         print_error "Key '${key_name}' not found in secret JSON or value is empty"
193:         return 1
194:     fi
195: 
196:     echo "$value"
197: }
198: 
199: 
200: 
201: 
202: 
203: 
204: 
205: assume_aws_role() {
206:     local role_arn=$1
207:     local external_id=${2:-}
208:     local role_description=${3:-"role"}
209:     local session_name_suffix=${4:-"setup-application"}
210: 
211:     if [ -z "$role_arn" ]; then
212:         print_error "Role ARN is required for assume_aws_role"
213:         return 1
214:     fi
215: 
216:     print_info "Assuming ${role_description}: $role_arn"
217:     print_info "Region: $AWS_REGION"
218: 
219: 
220:     local role_session_name="${session_name_suffix}-$(date +%s)"
221:     local assume_role_output
222: 
223: 
224: 
225:     if [ -n "$external_id" ]; then
226:         assume_role_output=$(aws sts assume-role \
227:             --role-arn "$role_arn" \
228:             --role-session-name "$role_session_name" \
229:             --external-id "$external_id" \
230:             --region "$AWS_REGION" 2>&1)
231:     else
232:         assume_role_output=$(aws sts assume-role \
233:             --role-arn "$role_arn" \
234:             --role-session-name "$role_session_name" \
235:             --region "$AWS_REGION" 2>&1)
236:     fi
237: 
238:     if [ $? -ne 0 ]; then
239:         print_error "Failed to assume ${role_description}: $assume_role_output"
240:         return 1
241:     fi
242: 
243: 
244: 
245:     local access_key_id
246:     local secret_access_key
247:     local session_token
248: 
249:     if command -v jq &> /dev/null; then
250:         access_key_id=$(echo "$assume_role_output" | jq -r '.Credentials.AccessKeyId')
251:         secret_access_key=$(echo "$assume_role_output" | jq -r '.Credentials.SecretAccessKey')
252:         session_token=$(echo "$assume_role_output" | jq -r '.Credentials.SessionToken')
253:     else
254: 
255:         access_key_id=$(echo "$assume_role_output" | sed -n 's/.*"AccessKeyId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
256:         secret_access_key=$(echo "$assume_role_output" | sed -n 's/.*"SecretAccessKey"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
257:         session_token=$(echo "$assume_role_output" | sed -n 's/.*"SessionToken"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p')
258:     fi
259: 
260:     if [ -z "$access_key_id" ] || [ -z "$secret_access_key" ] || [ -z "$session_token" ]; then
261:         print_error "Failed to extract credentials from assume-role output."
262:         print_error "Output was: $assume_role_output"
263:         return 1
264:     fi
265: 
266: 
267:     export AWS_ACCESS_KEY_ID="$access_key_id"
268:     export AWS_SECRET_ACCESS_KEY="$secret_access_key"
269:     export AWS_SESSION_TOKEN="$session_token"
270: 
271:     print_success "Successfully assumed ${role_description}"
272: 
273: 
274:     local caller_arn
275:     caller_arn=$(aws sts get-caller-identity --region "$AWS_REGION" --query 'Arn' --output text 2>&1)
276:     if [ $? -ne 0 ]; then
277:         print_error "Failed to verify assumed role credentials: $caller_arn"
278:         return 1
279:     fi
280: 
281:     print_info "${role_description} identity: $caller_arn"
282:     return 0
283: }
284: 
285: 
286: echo ""
287: print_info "Select AWS Region:"
288: echo "1) us-east-1: N. Virginia (default)"
289: echo "2) us-east-2: Ohio"
290: read -p "Enter choice [1-2] (default: 1): " region_choice
291: 
292: case ${region_choice:-1} in
293:     1)
294:         SELECTED_REGION="us-east-1: N. Virginia"
295:         ;;
296:     2)
297:         SELECTED_REGION="us-east-2: Ohio"
298:         ;;
299:     *)
300:         print_error "Invalid choice. Using default: us-east-1: N. Virginia"
301:         SELECTED_REGION="us-east-1: N. Virginia"
302:         ;;
303: esac
304: 
305: 
306: AWS_REGION="${SELECTED_REGION%%:*}"
307: export AWS_REGION
308: print_success "Selected region: ${SELECTED_REGION} (${AWS_REGION})"
309: 
310: echo ""
311: print_info "Select Environment:"
312: echo "1) prod (default)"
313: echo "2) dev"
314: read -p "Enter choice [1-2] (default: 1): " env_choice
315: 
316: case ${env_choice:-1} in
317:     1)
318:         ENVIRONMENT="prod"
319:         ;;
320:     2)
321:         ENVIRONMENT="dev"
322:         ;;
323:     *)
324:         print_error "Invalid choice. Using default: prod"
325:         ENVIRONMENT="prod"
326:         ;;
327: esac
328: 
329: print_success "Selected environment: ${ENVIRONMENT}"
330: export ENVIRONMENT
331: echo ""
332: 
333: # Retrieve role ARNs from AWS Secrets Manager in a single call
334: # This minimizes AWS CLI calls by fetching all required role ARNs at once
335: print_info "Retrieving role ARNs from AWS Secrets Manager..."
336: ROLE_SECRET_JSON=$(get_aws_secret "github-role" || echo "")
337: if [ -z "$ROLE_SECRET_JSON" ]; then
338:     print_error "Failed to retrieve 'github-role' secret from AWS Secrets Manager"
339:     exit 1
340: fi
341: 
342: 
343: STATE_ROLE_ARN=$(get_secret_key_value "$ROLE_SECRET_JSON" "AWS_STATE_ACCOUNT_ROLE_ARN" || echo "")
344: if [ -z "$STATE_ROLE_ARN" ]; then
345:     print_error "Failed to retrieve AWS_STATE_ACCOUNT_ROLE_ARN from secret"
346:     exit 1
347: fi
348: export STATE_ACCOUNT_ROLE_ARN="$STATE_ROLE_ARN"
349: print_success "Retrieved AWS_STATE_ACCOUNT_ROLE_ARN"
350: 
351: 
352: if [ "$ENVIRONMENT" = "prod" ]; then
353:     DEPLOYMENT_ROLE_ARN_KEY="AWS_PRODUCTION_ACCOUNT_ROLE_ARN"
354: else
355:     DEPLOYMENT_ROLE_ARN_KEY="AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN"
356: fi
357: 
358: 
359: DEPLOYMENT_ROLE_ARN=$(get_secret_key_value "$ROLE_SECRET_JSON" "$DEPLOYMENT_ROLE_ARN_KEY" || echo "")
360: if [ -z "$DEPLOYMENT_ROLE_ARN" ]; then
361:     print_error "Failed to retrieve ${DEPLOYMENT_ROLE_ARN_KEY} from secret"
362:     exit 1
363: fi
364: export DEPLOYMENT_ROLE_ARN
365: print_success "Retrieved ${DEPLOYMENT_ROLE_ARN_KEY}"
366: 
367: 
368: print_info "Retrieving ExternalId from AWS Secrets Manager..."
369: EXTERNAL_ID=$(get_aws_plaintext_secret "external-id" || echo "")
370: if [ -z "$EXTERNAL_ID" ]; then
371:     print_error "Failed to retrieve 'external-id' secret from AWS Secrets Manager"
372:     exit 1
373: fi
374: export EXTERNAL_ID
375: print_success "Retrieved ExternalId"
376: 
377: 
378: print_info "Retrieving Terraform variables from AWS Secrets Manager..."
379: TF_VARS_SECRET_JSON=$(get_aws_secret "tf-vars" || echo "")
380: if [ -z "$TF_VARS_SECRET_JSON" ]; then
381:     print_error "Failed to retrieve 'tf-vars' secret from AWS Secrets Manager"
382:     exit 1
383: fi
384: 
385: 
386: TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_OPENLDAP_ADMIN_PASSWORD" || echo "")
387: if [ -z "$TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE" ]; then
388:     print_error "Failed to retrieve TF_VAR_OPENLDAP_ADMIN_PASSWORD from secret"
389:     exit 1
390: fi
391: print_success "Retrieved TF_VAR_OPENLDAP_ADMIN_PASSWORD"
392: 
393: TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_OPENLDAP_CONFIG_PASSWORD" || echo "")
394: if [ -z "$TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE" ]; then
395:     print_error "Failed to retrieve TF_VAR_OPENLDAP_CONFIG_PASSWORD from secret"
396:     exit 1
397: fi
398: print_success "Retrieved TF_VAR_OPENLDAP_CONFIG_PASSWORD"
399: 
400: 
401: TF_VAR_POSTGRESQL_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_POSTGRESQL_PASSWORD" || echo "")
402: if [ -z "$TF_VAR_POSTGRESQL_PASSWORD_VALUE" ]; then
403:     print_error "Failed to retrieve TF_VAR_POSTGRESQL_PASSWORD from secret"
404:     exit 1
405: fi
406: print_success "Retrieved TF_VAR_POSTGRESQL_PASSWORD"
407: 
408: 
409: TF_VAR_REDIS_PASSWORD_VALUE=$(get_secret_key_value "$TF_VARS_SECRET_JSON" "TF_VAR_REDIS_PASSWORD" || echo "")
410: if [ -z "$TF_VAR_REDIS_PASSWORD_VALUE" ]; then
411:     print_error "Failed to retrieve TF_VAR_REDIS_PASSWORD from secret"
412:     exit 1
413: fi
414: print_success "Retrieved TF_VAR_REDIS_PASSWORD"
415: 
416: 
417: 
418: 
419: export TF_VAR_openldap_admin_password="$TF_VAR_OPENLDAP_ADMIN_PASSWORD_VALUE"
420: export TF_VAR_openldap_config_password="$TF_VAR_OPENLDAP_CONFIG_PASSWORD_VALUE"
421: export TF_VAR_postgresql_database_password="$TF_VAR_POSTGRESQL_PASSWORD_VALUE"
422: export TF_VAR_redis_password="$TF_VAR_REDIS_PASSWORD_VALUE"
423: 
424: print_success "Retrieved and exported all secrets from AWS Secrets Manager"
425: echo ""
426: 
427: # Retrieve repository variables
428: print_info "Retrieving repository variables..."
429: 
430: BUCKET_NAME=$(get_repo_variable "BACKEND_BUCKET_NAME") || exit 1
431: print_success "Retrieved BACKEND_BUCKET_NAME"
432: 
433: APPLICATION_PREFIX=$(get_repo_variable "APPLICATION_PREFIX") || exit 1
434: print_success "Retrieved APPLICATION_PREFIX"
435: 
436: 
437: if [ -f "$BACKEND_FILE" ]; then
438:     print_info "${BACKEND_FILE} already exists. Skipping creation."
439: else
440: 
441:     if [ ! -f "$PLACEHOLDER_FILE" ]; then
442:         print_error "Placeholder file '${PLACEHOLDER_FILE}' not found."
443:         exit 1
444:     fi
445: 
446: 
447:     print_info "Creating ${BACKEND_FILE} from ${PLACEHOLDER_FILE} with retrieved values..."
448: 
449: 
450:     cp "$PLACEHOLDER_FILE" "$BACKEND_FILE"
451: 
452: 
453:     if [[ "$OSTYPE" == "darwin"* ]]; then
454: 
455:         sed -i '' "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
456:         sed -i '' "s|<APPLICATION_PREFIX>|${APPLICATION_PREFIX}|g" "$BACKEND_FILE"
457:         sed -i '' "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
458:     else
459: 
460:         sed -i "s|<BACKEND_BUCKET_NAME>|${BUCKET_NAME}|g" "$BACKEND_FILE"
461:         sed -i "s|<APPLICATION_PREFIX>|${APPLICATION_PREFIX}|g" "$BACKEND_FILE"
462:         sed -i "s|<AWS_REGION>|${AWS_REGION}|g" "$BACKEND_FILE"
463:     fi
464: 
465:     print_success "Created ${BACKEND_FILE}"
466: fi
467: 
468: print_success "Configuration files updated successfully!"
469: echo ""
470: print_info "Backend file: ${BACKEND_FILE}"
471: print_info "  - bucket: ${BUCKET_NAME}"
472: print_info "  - key: ${APPLICATION_PREFIX}"
473: print_info "  - region: ${AWS_REGION}"
474: echo ""
475: 
476: # Assume State Account role for backend operations
477: if ! assume_aws_role "$STATE_ROLE_ARN" "" "State Account role" "setup-application"; then
478:     exit 1
479: fi
480: 
481: echo ""
482: 
483: # Terraform workspace name (same as backend_infra)
484: WORKSPACE_NAME="${AWS_REGION}-${ENVIRONMENT}"
485: 
486: # Terraform init
487: print_info "Running terraform init with backend configuration..."
488: terraform init -backend-config="${BACKEND_FILE}"
489: 
490: # Terraform workspace (create/select before running mirror script)
491: print_info "Selecting or creating workspace: ${WORKSPACE_NAME}..."
492: terraform workspace select "${WORKSPACE_NAME}" 2>/dev/null || terraform workspace new "${WORKSPACE_NAME}"
493: 
494: echo ""
495: 
496: # Mirror third-party images to ECR (if not already present)
497: print_info "Checking if Docker images need to be mirrored to ECR..."
498: if [ ! -f "mirror-images-to-ecr.sh" ]; then
499:     print_error "mirror-images-to-ecr.sh not found."
500:     exit 1
501: fi
502: 
503: 
504: chmod +x ./mirror-images-to-ecr.sh
505: 
506: 
507: if ./mirror-images-to-ecr.sh; then
508:     print_success "ECR image mirroring completed"
509: else
510:     print_error "ECR image mirroring failed"
511:     exit 1
512: fi
513: 
514: 
515: print_info "Running terraform validate..."
516: terraform validate
517: 
518: 
519: print_info "Setting Kubernetes environment variables..."
520: if [ ! -f "set-k8s-env.sh" ]; then
521:     print_error "set-k8s-env.sh not found."
522:     exit 1
523: fi
524: 
525: 
526: chmod +x ./set-k8s-env.sh
527: 
528: 
529: 
530: source ./set-k8s-env.sh
531: 
532: if [ -z "$KUBERNETES_MASTER" ]; then
533:     print_error "Failed to set KUBERNETES_MASTER environment variable."
534:     exit 1
535: fi
536: 
537: print_success "Kubernetes environment variables set"
538: print_info "  - KUBERNETES_MASTER: ${KUBERNETES_MASTER}"
539: print_info "  - KUBE_CONFIG_PATH: ${KUBE_CONFIG_PATH}"
540: 
541: 
542: export TF_VAR_kubernetes_master="$KUBERNETES_MASTER"
543: export TF_VAR_kube_config_path="$KUBE_CONFIG_PATH"
544: print_info "  - TF_VAR_kubernetes_master: ${TF_VAR_kubernetes_master}"
545: print_info "  - TF_VAR_kube_config_path: ${TF_VAR_kube_config_path}"
546: echo ""
547: 
548: # Assume State Account role for backend operations
549: if ! assume_aws_role "$STATE_ROLE_ARN" "" "State Account role" "setup-application"; then
550:     exit 1
551: fi
552: 
553: echo ""
554: 
555: # Terraform plan
556: print_info "Running terraform plan..."
557: terraform plan -var-file="${VARIABLES_FILE}" -out terraform.tfplan
558: 
559: # Terraform apply
560: print_info "Running terraform apply..."
561: terraform apply -auto-approve terraform.tfplan
562: 
563: echo ""
564: print_success "Script completed successfully!"
````

## File: application/PRD-ALB.md
````markdown
  1: # Single ALB multiple Ingresses
  2: 
  3: Goal:
  4: Single internet-facing ALB on EKS, managed by **EKS Auto Mode** (built-in load
  5: balancer driver), using:
  6: 
  7: - Domain: `talorlik.com`
  8: - HTTPS on port 443
  9: - ACM certificate (Public ACM certificate requested in Deployment Account, validated
 10: via DNS in State Account Route53, already validated)
 11: - Multiple Ingresses from `helm-openldap` (phpLDAPadmin + ltb-passwd) sharing
 12: that ALB via IngressGroup.
 13: 
 14: > [!NOTE]
 15: >
 16: > **Certificate Architecture**: ACM certificates are **Public ACM certificates**
 17: > (Amazon-issued) requested in each deployment account (development, production)
 18: > and validated via DNS records in the State Account's Route53 hosted zone.
 19: > Each deployment account has its own certificate stored in its respective
 20: > account. This architecture eliminates cross-account certificate access
 21: > complexity and is compatible with EKS Auto Mode ALB controller requirements.
 22: > Certificates are automatically renewed by ACM. See
 23: > [Cross-Account Access Documentation](./CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 24: > for Public ACM certificate setup instructions.
 25: 
 26: > [!NOTE]
 27: >
 28: > This implementation uses **EKS Auto Mode** (`eks.amazonaws.com/alb`
 29: > controller), not the AWS Load Balancer Controller. EKS Auto Mode:
 30: >
 31: > - Has its own built-in load balancer driver (no need to install AWS Load
 32: > Balancer Controller)
 33: > - Automatically handles IAM permissions (no need to attach
 34: > AWSLoadBalancerControllerIAMPolicy)
 35: > - Uses a different API group (`eks.amazonaws.com`) for IngressClassParams
 36: 
 37: Below are the adjusted `values.yaml` snippets.
 38: 
 39: ## Option A - Separate hosts, same ALB, HTTPS 443 with ACM
 40: 
 41: Use two hostnames on the configured domain, one per app, on a single ALB:
 42: 
 43: - `${phpldapadmin_host}` (e.g., `phpldapadmin.talorlik.com`)  phpLDAPadmin
 44: - `${ltb_passwd_host}` (e.g., `passwd.talorlik.com`)  ltb-passwd
 45: 
 46: `values.yaml`:
 47: 
 48: ```yaml
 49: ltb-passwd:
 50:   enabled: true
 51:   image:
 52:     tag: 5.2.3
 53:   podLabels:
 54:     app: "${app_name}"
 55:   ingress:
 56:     enabled: true
 57:     ingressClassName: "${ingress_class_name}"
 58:     annotations:
 59:       # Note: group.name and certificate-arn are configured in IngressClassParams (cluster-wide)
 60:       # Only per-Ingress settings are specified here
 61:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
 62:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
 63:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
 64:       alb.ingress.kubernetes.io/ssl-redirect: "443"
 65:       # Note: scheme, ipAddressType, group.name, and certificateARNs are inherited from IngressClassParams
 66:     path: /
 67:     pathType: Prefix
 68:     hosts:
 69:       - "${ltb_passwd_host}"
 70: 
 71: phpldapadmin:
 72:   enabled: true
 73:   podLabels:
 74:     app: "${app_name}"
 75:   ingress:
 76:     enabled: true
 77:     ingressClassName: "${ingress_class_name}"
 78:     annotations:
 79:       # Same annotations as ltb-passwd - group.name and certificate-arn are in IngressClassParams
 80:       alb.ingress.kubernetes.io/load-balancer-name: "${alb_load_balancer_name}"
 81:       alb.ingress.kubernetes.io/target-type: "${alb_target_type}"
 82:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80},{"HTTPS":443}]'
 83:       alb.ingress.kubernetes.io/ssl-redirect: "443"
 84:     path: /
 85:     pathType: Prefix
 86:     hosts:
 87:       - "${phpldapadmin_host}"
 88: ```
 89: 
 90: What this does:
 91: 
 92: **Annotation Strategy**:
 93: 
 94: - **IngressClassParams** (cluster-wide defaults): Configured once at the cluster
 95: level:
 96:   - `scheme` (internet-facing)
 97:   - `ipAddressType` (ipv4)
 98:   - `group.name` (ALB group name for grouping multiple Ingresses)
 99:   - `certificateARNs` (ACM certificate ARNs for TLS termination)
100: - **Ingress annotations**: Each Ingress specifies per-Ingress settings:
101:   - `alb.ingress.kubernetes.io/load-balancer-name` (custom ALB name, max 32
102:   characters)
103:   - `alb.ingress.kubernetes.io/target-type` (ip vs instance)
104:   - `alb.ingress.kubernetes.io/listen-ports` (HTTP 80 and HTTPS 443)
105:   - `alb.ingress.kubernetes.io/ssl-redirect` (redirect HTTP to HTTPS)
106:   - Note: `group.name` and `certificate-arn` are configured in
107:   IngressClassParams, not in annotations
108: 
109: **How it works**:
110: 
111: - Both Ingresses use the same `group.name` (configured in IngressClassParams),
112: so the controller provisions a single ALB
113: - Certificate ARN is configured once in IngressClassParams and applies to all
114: Ingresses using this IngressClass
115: - All Ingresses share the same ALB configuration from IngressClassParams
116: (scheme, ipAddressType, group.name, certificateARNs)
117: - Each Ingress only needs to specify per-Ingress settings (load-balancer-name,
118: target-type, listen-ports, ssl-redirect)
119: - Route 53: create A (alias) records pointing to the ALB using the dedicated
120:   `route53_record` module (separate module calls for phpldapadmin, ltb_passwd,
121:   and twofa_app subdomains):
122:   - `${phpldapadmin_host}`  this ALB
123:   - `${ltb_passwd_host}`  same ALB
124: 
125: **Result**: A single internet-facing ALB with a custom name, TLS on 443,
126: separate hostnames for each UI, with minimal annotation duplication and
127: centralized certificate/group configuration.
128: 
129: The Helm chart can create `Ingress` objects, but it cannot magically tell
130: Kubernetes *which controller should act on them* or *what ALB defaults to use*.
131: That's exactly what `IngressClass` and `IngressClassParams` are for.
132: 
133: Breakdown:
134: 
135: 1. What the Ingress actually is
136: 
137:    - An `Ingress` is just a generic API object: "for host X and path Y, send
138:    traffic to Service Z".
139:    - It does not say:
140: 
141:      - which controller should implement it, or
142:      - which type of load balancer to create, or
143:      - what global LB settings (scheme, IP type, tags, etc.) to apply.
144:    - Something (an ingress controller) must watch those Ingresses and create
145:    real cloud resources (ALB, listeners, target groups).
146: 
147: 2. Why you need an IngressClass
148: 
149:    - Modern Kubernetes: the old `kubernetes.io/ingress.class` annotation is
150:    deprecated.
151:    - `IngressClass` is now the official way to bind an Ingress to a specific
152:    controller.
153:    - Example:
154: 
155:      ```yaml
156:      kind: IngressClass
157:      metadata:
158:        name: ic-alb-ldap
159:        annotations:
160:          ingressclass.kubernetes.io/is-default-class: "true"
161:      spec:
162:        controller: eks.amazonaws.com/alb
163:        parameters:
164:          apiGroup: eks.amazonaws.com
165:          kind: IngressClassParams
166:          name: icp-alb-ldap
167:      ```
168: 
169:    - Your `Ingress` then says:
170: 
171:      ```yaml
172:      spec:
173:        ingressClassName: ic-alb-ldap
174:      ```
175: 
176:    - This is the piece that tells EKS Auto Mode:
177:      "You are responsible for this Ingress. Create/manage an ALB for it."
178: 
179:    Without an IngressClass, either:
180: 
181:    - nothing watches the Ingress, or
182:    - you fall back to legacy behavior (controller-specific annotations), which
183:    AWS now documents as legacy.
184: 
185: 3. Why you need IngressClassParams
186: 
187:    - `IngressClassParams` is an EKS Auto Mode-specific CRD that holds ALB
188:    configuration shared across many Ingresses.
189:    - It lets you centralize things that should not be repeated in every Helm
190:    chart.
191:    - **EKS Auto Mode IngressClassParams supports**:
192:      - `scheme` (internet-facing vs internal)
193:      - `ipAddressType` (ipv4 / dualstack)
194:      - `group.name` (ALB group name for grouping multiple Ingresses)
195:      - `certificateARNs` (ACM certificate ARNs for TLS termination)
196:    - **Note**: EKS Auto Mode IngressClassParams does NOT support subnets,
197:    security groups, or tags (unlike AWS Load Balancer Controller's
198:    IngressClassParams).
199:    - Roughly: Ingress = routing rules; IngressClassParams = ALB profile.
200: 
201:    Helm charts like `openldap-stack-ha` only deal with routing rules. They don't
202:    know:
203: 
204:    - whether the ALB is internet-facing or internal
205:    - whether the ALB uses IPv4 or dual-stack
206:    - per-Ingress settings like target-type (ip vs instance) are still configured
207:    via annotations
208: 
209:    **Annotation Strategy**:
210:    - **IngressClassParams** (cluster-wide): Define `scheme`, `ipAddressType`,
211:    `group.name`, and `certificateARNs` once at the cluster level
212:    - **Ingress annotations**: Only need per-Ingress settings:
213:      - `load-balancer-name`: AWS ALB name (max 32 characters)
214:      - `target-type`: IP or instance mode
215:      - `listen-ports`: HTTP/HTTPS ports
216:      - `ssl-redirect`: HTTPS redirect configuration
217:      - Note: `group.name` and `certificate-arn` are now configured in
218:      IngressClassParams, not in Ingress annotations
219: 
220:    IngressClassParams is where you define cluster-wide defaults once, and then
221:    every Ingress that uses that IngressClass inherits them automatically.
222: 
223: 4. Why you still "need" them even though ALB is auto-provisioned
224: 
225:    - "ALB is auto-provisioned" = EKS Auto Mode automatically creates an ALB
226:    *when it sees an Ingress that belongs to it*.
227:    - How does it know the Ingress "belongs to it"? Through:
228: 
229:      - `spec.ingressClassName` that references an `IngressClass` with
230:      `controller: eks.amazonaws.com/alb`.
231:    - How does it know what defaults to apply to that ALB? Through:
232: 
233:      - The `parameters` reference from the IngressClass to an
234:      `IngressClassParams` object.
235: 
236:    So the chain is:
237: 
238:    `Ingress`
239:     `ingressClassName: ic-alb-ldap`
240:     `IngressClass` (`controller: eks.amazonaws.com/alb`)
241:     `parameters: IngressClassParams` (ALB config profile: scheme,
242:    ipAddressType)
243:     EKS Auto Mode
244:     Creates/updates ALB, listeners, target groups, rules.
245: 
246: 5. What would happen without them
247: 
248:    - If you skip IngressClass and IngressClassParams and rely only on
249:    annotations:
250: 
251:      - You're using deprecated/legacy patterns.
252:      - It's ambiguous which controller should act if you ever introduce more
253:      than one.
254:      - You repeat provider-specific config on every Ingress (in every chart).
255:    - With them:
256: 
257:      - The chart stays provider-agnostic: it just specifies `ingressClassName`.
258:      - The cluster owner decides at cluster level how ALBs are created and
259:      configured.
260: 
261: 6. In Helm chart terms
262: 
263:    - The OpenLDAP Helm chart's job:
264: 
265:      - Create `Ingress` objects with host/path/service rules.
266:    - Your cluster's job:
267: 
268:      - Provide an `IngressClass` (e.g., `ic-alb-ldap`) with `controller:
269:      eks.amazonaws.com/alb`.
270:      - Provide an associated `IngressClassParams` (e.g., `icp-alb-ldap`) that
271:      encodes "use EKS Auto Mode ALB with these defaults" (scheme,
272:      ipAddressType).
273: 
274:    That separation is why you still need IngressClass and IngressClassParams
275:    even though the ALB provisioning is "automatic". The automation needs a
276:    target profile and a controller binding, and those are exactly those two
277:    objects.
278: 
279: ## Implementation Details
280: 
281: **Terraform creates**:
282: 
283: - `IngressClass` resource using `kubernetes_ingress_class_v1` resource
284: - `IngressClassParams` using `null_resource` with `kubectl apply` (because
285: Terraform doesn't have native support for EKS Auto Mode's IngressClassParams
286: CRD)
287:   - Contains cluster-wide defaults:
288:     - `scheme` (internet-facing/internal)
289:     - `ipAddressType` (ipv4/dualstack)
290:     - `group.name` (ALB group name for grouping multiple Ingresses)
291:     - `certificateARNs` (ACM certificate ARNs for TLS termination)
292: 
293: **Helm chart creates**:
294: 
295: - `Ingress` objects with host/path/service rules
296: - Uses `ingressClassName` to reference the IngressClass
297: - **Annotation strategy**:
298:   - All Ingresses use the same annotations (no leader/secondary distinction
299:   needed):
300:     - `load-balancer-name`: AWS ALB name (max 32 characters)
301:     - `target-type`: IP or instance mode
302:     - `listen-ports`: HTTP/HTTPS ports (e.g., `[{"HTTP":80},{"HTTPS":443}]`)
303:     - `ssl-redirect`: HTTPS redirect configuration
304:   - Note: `group.name` and `certificate-arn` are configured in
305:   IngressClassParams (cluster-wide), not in Ingress annotations
306: 
307: **IngressClass is set as default**:
308: 
309: - Uses annotation `ingressclass.kubernetes.io/is-default-class: "true"`
310: - Allows Ingresses to omit `ingressClassName` if desired
311: 
312: **Why this strategy**:
313: 
314: - Treats IngressClassParams as cluster-wide defaults (scheme, ipAddressType,
315: group.name, certificateARNs)
316: - Minimizes annotation duplication across multiple Ingresses in the same group
317: - Certificate ARN and group name are configured once in IngressClassParams, not
318: repeated in each Ingress
319: - Each Ingress only needs to specify per-Ingress settings (load-balancer-name,
320: target-type, listen-ports, ssl-redirect)
321: - Each Ingress still defines its own routing rules (hosts, paths) in the
322: `spec.rules` section
323: 
324: ## Key Differences: EKS Auto Mode vs AWS Load Balancer Controller
325: 
326: | Feature | EKS Auto Mode | AWS Load Balancer Controller |
327: | --------- | --------------- | ------------------------------ |
328: | Controller | `eks.amazonaws.com/alb` | `alb.ingress.kubernetes.io` |
329: | API Group | `eks.amazonaws.com` | `elbv2.k8s.aws` |
330: | IAM Setup | Automatic (no manual setup) | Requires IAM policy attachment |
331: | Installation | Built-in to EKS | Requires separate Helm chart |
332: | IngressClassParams fields | `scheme`, `ipAddressType` only | `scheme`, `ipAddressType`, `subnets`, `securityGroups`, `tags`, etc. |
333: | Terraform support | Partial (IngressClassParams via kubectl) | Full (via `kubernetes_manifest`) |
````

## File: application/PRD-SMS-MAN.md
````markdown
  1: # SMS OTP Management with Redis - Product Requirements Document
  2: 
  3: ## Overview
  4: 
  5: This document defines the requirements for implementing Redis-based SMS OTP code
  6: management to replace the current in-memory storage mechanism in the 2FA backend
  7: application.
  8: 
  9: ### Problem Statement
 10: 
 11: The current SMS OTP implementation in [`routes.py`](backend/src/app/api/routes.py)
 12: uses in-memory Python dictionaries for storing verification codes:
 13: 
 14: ```python
 15: # Current implementation (problematic)
 16: _sms_codes: dict[str, dict] = {}
 17: # Structure: {username: {"code": "...", "expires_at": timestamp, "phone_number": "..."}}
 18: ```
 19: 
 20: This approach has several critical limitations:
 21: 
 22: | Problem | Impact |
 23: | --------- | -------- |
 24: | **Data loss on restart** | All pending OTP codes are lost when pods restart or scale |
 25: | **No automatic cleanup** | Expired codes only cleaned when accessed, leading to memory growth |
 26: | **Not horizontally scalable** | Each backend replica has its own in-memory store |
 27: | **No code sharing** | User must hit the same pod that generated the code |
 28: 
 29: ### Solution Overview
 30: 
 31: Deploy Redis as a centralized, TTL-aware cache for SMS OTP codes, enabling:
 32: 
 33: - Automatic expiration of codes via Redis TTL
 34: - Shared state across all backend replicas
 35: - Persistence across pod restarts (RDB snapshots)
 36: - Native support for atomic operations
 37: 
 38: ## Goals and Non-Goals
 39: 
 40: ### Goals
 41: 
 42: | ID | Goal |
 43: | ---- | ------ |
 44: | G-01 | Deploy Bitnami Redis Helm chart via Terraform |
 45: | G-02 | Replace in-memory `_sms_codes` dict with Redis client |
 46: | G-03 | Leverage Redis TTL for automatic code expiration |
 47: | G-04 | Enable horizontal scaling of backend pods |
 48: | G-05 | Maintain data across pod restarts via persistence |
 49: | G-06 | Secure Redis with password authentication |
 50: | G-07 | Restrict network access to backend pods only |
 51: 
 52: ### Non-Goals
 53: 
 54: | ID | Non-Goal |
 55: | ---- | ---------- |
 56: | NG-01 | High availability Redis (Sentinel/Cluster) - standalone is sufficient for OTP cache |
 57: | NG-02 | Migrating TOTP secrets to Redis - they remain in-memory (stateless by design) |
 58: | NG-03 | Redis as a general-purpose cache - scoped to SMS OTP only |
 59: | NG-04 | External Redis access - internal cluster use only |
 60: 
 61: ## Technical Architecture
 62: 
 63: ### Architecture Diagram
 64: 
 65: ```text
 66: 
 67:                     Kubernetes Cluster                         
 68:                                                                
 69:     
 70:                 twofa-backend namespace                      
 71:                                                              
 72:                              
 73:        Backend                Backend                    
 74:        Pod 1                  Pod 2                      
 75:                                                          
 76:       redis-py               redis-py                    
 77:                              
 78:                                                            
 79:     
 80:                                                              
 81:                  SETEX/GET/DEL                               
 82:                  (with TTL)                                  
 83:                                      
 84:                                                               
 85:                                                               
 86:     
 87:                      redis namespace                         
 88:                                                              
 89:          
 90:                    Redis Standalone                        
 91:                                                            
 92:                  
 93:          Redis Master     PersistentVolume         
 94:          (Port 6379)          (RDB Snapshots)          
 95:                  
 96:                                                            
 97:          
 98:                                                              
 99:     
100:                                                                
101: 
102: ```
103: 
104: ### Data Flow
105: 
106: ```text
107: 1. User requests SMS code
108:     Backend receives request
109:         Generate 6-digit code
110:             SETEX sms_otp:{username} {ttl} {code_data}
111:                 Redis stores with automatic TTL expiration
112: 
113: 2. User submits verification code
114:     Backend receives login request
115:         GET sms_otp:{username}
116:             Key exists: Validate code, DEL on success
117:             Key expired/missing: Return error
118: ```
119: 
120: ### Redis Key Schema
121: 
122: | Key Pattern | Value | TTL | Description |
123: | ------------- | ------- | ----- | ------------- |
124: | `sms_otp:{username}` | JSON: `{"code": "123456", "phone_number": "+1..."}` | 300s (configurable) | SMS verification code |
125: 
126: ## Redis Deployment Specifications
127: 
128: ### Helm Chart Configuration
129: 
130: | Setting | Value | Rationale |
131: | --------- | ------- | ----------- |
132: | **Chart** | `bitnami/redis` | Official, well-maintained, production-ready |
133: | **Version** | Latest stable (19.x+) | Security patches, bug fixes |
134: | **Architecture** | Standalone | Sufficient for OTP cache, simpler operations |
135: | **Namespace** | `redis` | Dedicated namespace for isolation |
136: | **Image Source** | ECR (not Docker Hub) | Eliminates rate limiting, uses `redis-latest` tag |
137: 
138: > [!NOTE]
139: >
140: > **ECR Image Support**: Redis uses ECR images instead of Docker Hub.
141: > The image `bitnami/redis:8.4.0-debian-12-r6` is automatically mirrored to ECR
142: > with tag `redis-latest` by the `mirror-images-to-ecr.sh` script before
143: > Terraform operations. The ECR registry and repository are computed from
144: > `backend_infra` Terraform state.
145: 
146: ### Resource Requirements
147: 
148: | Resource | Request | Limit | Rationale |
149: | ---------- | --------- | ------- | ----------- |
150: | CPU | 100m | 500m | OTP operations are lightweight |
151: | Memory | 128Mi | 256Mi | Small dataset (active OTPs only) |
152: 
153: ### Persistence Configuration
154: 
155: | Setting | Value | Rationale |
156: | --------- | ------- | ----------- |
157: | **Enabled** | `true` | Survive pod restarts |
158: | **Storage Class** | Existing EBS CSI class | Consistent with cluster storage |
159: | **Size** | 1Gi | OTP data is small |
160: | **RDB** | Enabled | Point-in-time snapshots |
161: | **AOF** | Disabled | Not needed for OTP cache |
162: 
163: ### Network Configuration
164: 
165: | Setting | Value |
166: | --------- | ------- |
167: | **Service Type** | ClusterIP |
168: | **Port** | 6379 |
169: | **Service Name** | `redis-master.redis.svc.cluster.local` |
170: 
171: ## Backend Code Changes
172: 
173: ### New Files
174: 
175: | File | Purpose |
176: | ------ | --------- |
177: | `app/redis/__init__.py` | Redis module initialization |
178: | `app/redis/client.py` | Redis client wrapper for OTP operations |
179: 
180: ### Modified Files
181: 
182: | File | Changes |
183: | ------ | --------- |
184: | [`app/config.py`](backend/src/app/config.py) | Add Redis configuration settings |
185: | [`app/api/routes.py`](backend/src/app/api/routes.py) | Replace `_sms_codes` dict with Redis calls |
186: | [`requirements.txt`](backend/src/app/requirements.txt) | Add `redis` package |
187: 
188: ### Configuration Settings
189: 
190: Add to [`config.py`](backend/src/app/config.py):
191: 
192: ```python
193: # Redis Configuration
194: redis_enabled: bool = os.getenv("REDIS_ENABLED", "false").lower() == "true"
195: redis_host: str = os.getenv("REDIS_HOST", "redis-master.redis.svc.cluster.local")
196: redis_port: int = int(os.getenv("REDIS_PORT", "6379"))
197: redis_password: str = os.getenv("REDIS_PASSWORD", "")
198: redis_db: int = int(os.getenv("REDIS_DB", "0"))
199: redis_ssl: bool = os.getenv("REDIS_SSL", "false").lower() == "true"
200: redis_key_prefix: str = os.getenv("REDIS_KEY_PREFIX", "sms_otp:")
201: ```
202: 
203: ### Redis Client Interface
204: 
205: ```python
206: class RedisOTPClient:
207:     """Redis client for SMS OTP operations."""
208: 
209:     def store_code(
210:         self,
211:         username: str,
212:         code: str,
213:         phone_number: str,
214:         ttl_seconds: int
215:     ) -> bool:
216:         """Store OTP code with automatic TTL expiration."""
217:         ...
218: 
219:     def get_code(self, username: str) -> Optional[dict]:
220:         """Retrieve OTP code data if not expired."""
221:         ...
222: 
223:     def delete_code(self, username: str) -> bool:
224:         """Delete OTP code after successful verification."""
225:         ...
226: 
227:     def code_exists(self, username: str) -> bool:
228:         """Check if valid OTP code exists for user."""
229:         ...
230: ```
231: 
232: ### Backward Compatibility
233: 
234: The implementation must support graceful fallback:
235: 
236: | Scenario | Behavior |
237: | ---------- | ---------- |
238: | `REDIS_ENABLED=true` | Use Redis for OTP storage |
239: | `REDIS_ENABLED=false` | Fall back to in-memory storage |
240: | Redis connection failure | Log error, return 503 Service Unavailable |
241: 
242: ## Infrastructure Changes
243: 
244: ### Directory Structure
245: 
246: ```text
247: application/
248:  modules/
249:     redis/                    # New Terraform module
250:         main.tf
251:         variables.tf
252:         outputs.tf
253:         README.md
254:  helm/
255:     redis-values.tpl.yaml     # Redis Helm values template
256:  main.tf                       # Add Redis module invocation
257: ```
258: 
259: ### Terraform Module: Redis
260: 
261: #### Resources Created
262: 
263: | Resource | Description |
264: | ---------- | ------------- |
265: | `kubernetes_namespace` | Dedicated `redis` namespace |
266: | `kubernetes_secret` | Redis password secret (from GitHub Secrets) |
267: | `helm_release` | Bitnami Redis deployment |
268: 
269: > **Note**: The Redis password is **not** randomly generated. It is sourced from
270: > GitHub Secrets and passed through Terraform variables, consistent with the
271: > existing LDAP admin password pattern.
272: 
273: #### Module Inputs
274: 
275: | Variable | Type | Default | Description |
276: | ---------- | ------ | --------- | ------------- |
277: | `enable_redis` | bool | `false` | Enable Redis deployment |
278: | `namespace` | string | `"redis"` | Kubernetes namespace |
279: | `redis_version` | string | `"19.6.4"` | Bitnami Redis chart version |
280: | `storage_class_name` | string | `""` | Storage class for PVC |
281: | `storage_size` | string | `"1Gi"` | PVC size |
282: | `redis_password` | string | **required** | Redis password (from GitHub Secrets via TF_VAR) |
283: | `replica_count` | number | `0` | Number of replicas (0 for standalone) |
284: 
285: #### Module Outputs
286: 
287: | Output | Description |
288: | -------- | ------------- |
289: | `redis_host` | Redis service hostname |
290: | `redis_port` | Redis service port |
291: | `redis_password_secret_name` | Name of K8s secret containing password |
292: | `redis_password_secret_key` | Key in secret for password |
293: 
294: ### Backend Helm Chart Updates
295: 
296: Add to [`values.yaml`](backend/helm/ldap-2fa-backend/values.yaml):
297: 
298: ```yaml
299: # Redis Configuration
300: redis:
301:   # Enable Redis for SMS OTP storage
302:   enabled: false
303:   # Redis service hostname
304:   host: "redis-master.redis.svc.cluster.local"
305:   # Redis service port
306:   port: 6379
307:   # Redis database number
308:   db: 0
309:   # Enable SSL/TLS
310:   ssl: false
311:   # Key prefix for OTP storage
312:   keyPrefix: "sms_otp:"
313:   # External secret for Redis password
314:   existingSecret:
315:     name: ""
316:     key: "redis-password"
317: ```
318: 
319: ### Network Policy Updates
320: 
321: Add to [`modules/network-policies/`](modules/network-policies/):
322: 
323: ```yaml
324: # Allow backend pods to connect to Redis
325: apiVersion: networking.k8s.io/v1
326: kind: NetworkPolicy
327: metadata:
328:   name: allow-backend-to-redis
329:   namespace: redis
330: spec:
331:   podSelector:
332:     matchLabels:
333:       app.kubernetes.io/name: redis
334:   policyTypes:
335:     - Ingress
336:   ingress:
337:     - from:
338:         - namespaceSelector:
339:             matchLabels:
340:               name: twofa-backend
341:         - podSelector:
342:             matchLabels:
343:               app.kubernetes.io/name: ldap-2fa-backend
344:       ports:
345:         - protocol: TCP
346:           port: 6379
347: ```
348: 
349: ## Security Requirements
350: 
351: | ID | Requirement | Implementation |
352: | ---- | ------------- | ---------------- |
353: | SEC-R01 | Redis must require password authentication | `auth.enabled=true` in Helm values |
354: | SEC-R02 | Redis password stored in Kubernetes Secret | `kubernetes_secret` resource via Terraform |
355: | SEC-R03 | Redis password sourced from GitHub Secrets | `TF_VAR_redis_password` environment variable (from GitHub Secret `TF_VAR_REDIS_PASSWORD`) |
356: | SEC-R04 | Redis not exposed outside cluster | `service.type=ClusterIP` |
357: | SEC-R05 | Network policy restricts access to backend only | NetworkPolicy with namespace/pod selector |
358: | SEC-R06 | Redis runs as non-root user | `securityContext` in Helm values |
359: | SEC-R07 | No public Ingress for Redis | No Ingress resource created |
360: | SEC-R08 | TLS for Redis connections (optional) | `tls.enabled=true` if required |
361: 
362: ### Secret Management Flow
363: 
364: The Redis password follows the same pattern as the LDAP admin password:
365: 
366: ```text
367: 
368:                             Secret Management Flow                            
369: 
370:                                                                               
371:   GitHub Secrets              GitHub Actions            Terraform             
372:                   
373:    TF_VAR_REDIS_     env:              var.redis_          
374:    PASSWORD                   TF_VAR_redis_         password            
375:                               password                                  
376:                   
377:                                                                              
378:                                                                              
379:   Kubernetes                  Bitnami Redis Helm        Terraform K8s Secret  
380:                   
381:    Backend Pod              auth:                   kubernetes_         
382:                               existingSecret: secret.redis_       
383:    REDIS_PASSWORD        redis-secret        password            
384:    (from secret)                                                        
385:                   
386:                                                                               
387: 
388: ```
389: 
390: ### GitHub Secrets Configuration
391: 
392: > [!NOTE]
393: >
394: > For complete secrets setup instructions, see [Secrets Requirements](../SECRETS_REQUIREMENTS.md).
395: 
396: Add the following secret to your GitHub repository:
397: 
398: | Secret Name | Description | Example |
399: | ------------- | ------------- | --------- |
400: | `TF_VAR_REDIS_PASSWORD` | Redis authentication password | Strong password (min 8 chars, exported as `TF_VAR_redis_password`) |
401: 
402: ### Terraform Secret Resource
403: 
404: ```hcl
405: # Create Kubernetes secret for Redis password
406: resource "kubernetes_secret" "redis_password" {
407:   count = var.enable_redis ? 1 : 0
408: 
409:   metadata {
410:     name      = "redis-secret"
411:     namespace = kubernetes_namespace.redis[0].metadata[0].name
412:   }
413: 
414:   data = {
415:     "redis-password" = var.redis_password
416:   }
417: 
418:   type = "Opaque"
419: }
420: ```
421: 
422: ### Bitnami Redis Helm Configuration
423: 
424: ```yaml
425: auth:
426:   enabled: true
427:   existingSecret: "redis-secret"
428:   existingSecretPasswordKey: "redis-password"
429: ```
430: 
431: ### Backend Deployment Secret Reference
432: 
433: ```yaml
434: # In deployment.yaml - reference the same secret
435: - name: REDIS_PASSWORD
436:   valueFrom:
437:     secretKeyRef:
438:       name: redis-secret
439:       key: redis-password
440: ```
441: 
442: ## Configuration Reference
443: 
444: ### Environment Variables
445: 
446: | Variable | Default | Description |
447: | ---------- | --------- | ------------- |
448: | `REDIS_ENABLED` | `false` | Enable Redis for OTP storage |
449: | `REDIS_HOST` | `redis-master.redis.svc.cluster.local` | Redis hostname |
450: | `REDIS_PORT` | `6379` | Redis port |
451: | `REDIS_PASSWORD` | `` | Redis password (from Secret) |
452: | `REDIS_DB` | `0` | Redis database number |
453: | `REDIS_SSL` | `false` | Enable SSL/TLS |
454: | `REDIS_KEY_PREFIX` | `sms_otp:` | Key prefix for OTP storage |
455: 
456: ### Terraform Variables
457: 
458: Add to [`variables.tf`](variables.tf):
459: 
460: ```hcl
461: variable "enable_redis" {
462:   description = "Enable Redis deployment for SMS OTP storage"
463:   type        = bool
464:   default     = false
465: }
466: 
467: variable "redis_password" {
468:   description = "Redis authentication password (from GitHub Secrets via TF_VAR_redis_password environment variable, sourced from TF_VAR_REDIS_PASSWORD secret)"
469:   type        = string
470:   sensitive   = true
471:   default     = ""
472: 
473:   validation {
474:     condition     = var.enable_redis == false || length(var.redis_password) >= 8
475:     error_message = "Redis password must be at least 8 characters when Redis is enabled."
476:   }
477: }
478: 
479: variable "redis_storage_size" {
480:   description = "Redis PVC storage size"
481:   type        = string
482:   default     = "1Gi"
483: }
484: 
485: variable "redis_chart_version" {
486:   description = "Bitnami Redis Helm chart version"
487:   type        = string
488:   default     = "19.6.4"
489: }
490: ```
491: 
492: ### GitHub Actions Workflow Updates
493: 
494: Update [`.github/workflows/application_infra_provisioning.yaml`](.github/workflows/application_infra_provisioning.yaml):
495: 
496: ```yaml
497: jobs:
498:   InfraProvision:
499:     # ... existing configuration ...
500:     env:
501:       AWS_REGION: ${{ needs.SetRegion.outputs.region_code }}
502:       # Note: TF_VAR environment variables are case-sensitive and must match variable names in variables.tf
503:       TF_VAR_openldap_admin_password: ${{ secrets.TF_VAR_OPENLDAP_ADMIN_PASSWORD }}
504:       TF_VAR_openldap_config_password: ${{ secrets.TF_VAR_OPENLDAP_CONFIG_PASSWORD }}
505:       # Add Redis password from GitHub Secrets
506:       TF_VAR_redis_password: ${{ secrets.TF_VAR_REDIS_PASSWORD }}
507: ```
508: 
509: ### Required GitHub Secrets
510: 
511: > [!NOTE]
512: >
513: > See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for complete setup instructions.
514: 
515: | Secret | Purpose | Requirements |
516: | -------- | --------- | -------------- |
517: | `TF_VAR_REDIS_PASSWORD` | Redis authentication | Min 8 chars, alphanumeric + special (exported as `TF_VAR_redis_password`) |
518: 
519: ### Password Generation Recommendation
520: 
521: Generate a secure password using:
522: 
523: ```bash
524: # Option 1: OpenSSL
525: openssl rand -base64 24
526: 
527: # Option 2: Python
528: python3 -c "import secrets; print(secrets.token_urlsafe(24))"
529: 
530: # Option 3: pwgen (if installed)
531: pwgen -s 24 1
532: ```
533: 
534: ## Testing Strategy
535: 
536: ### Unit Tests
537: 
538: | Test Case | Description |
539: | ----------- | ------------- |
540: | `test_store_code` | Verify code stored with correct TTL |
541: | `test_get_code_valid` | Retrieve valid (non-expired) code |
542: | `test_get_code_expired` | Verify expired code returns None |
543: | `test_delete_code` | Verify code deletion |
544: | `test_fallback_inmemory` | Verify fallback when Redis disabled |
545: | `test_connection_failure` | Verify graceful handling of Redis failure |
546: 
547: ### Integration Tests
548: 
549: | Test Case | Description |
550: | ----------- | ------------- |
551: | `test_sms_enrollment_redis` | Full enrollment flow with Redis |
552: | `test_sms_login_redis` | Full login flow with Redis |
553: | `test_code_expiration` | Verify automatic TTL expiration |
554: | `test_multi_replica` | Verify code sharing across pods |
555: 
556: ### Manual Verification
557: 
558: | Step | Expected Result |
559: | ------ | ----------------- |
560: | 1. Deploy Redis via Terraform | `helm_release.redis` successful |
561: | 2. Verify Redis pod running | `kubectl get pods -n redis` shows Ready |
562: | 3. Test Redis connectivity | `redis-cli ping` returns PONG |
563: | 4. Enroll user with SMS | Code stored in Redis |
564: | 5. Wait for TTL expiration | Code automatically deleted |
565: | 6. Login with expired code | Returns "code expired" error |
566: | 7. Restart backend pod | Pending codes preserved |
567: | 8. Scale backend to 2 replicas | Code accessible from both pods |
568: 
569: ## Rollout Plan
570: 
571: ### Phase 0: GitHub Secrets Setup
572: 
573: > [!NOTE]
574: >
575: > See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for complete secrets
576: > configuration instructions.
577: 
578: 1. Generate a secure Redis password (minimum 8 characters)
579: 2. Add `TF_VAR_REDIS_PASSWORD` to GitHub repository secrets (or AWS Secrets Manager
580: for local scripts)
581: 3. Update GitHub Actions workflow to include the new secret
582: 
583: ### Phase 1: Infrastructure (No Application Changes)
584: 
585: 1. Create Redis Terraform module
586: 2. Update `.github/workflows/application_infra_provisioning.yaml`
587: 3. Deploy Redis to cluster with `enable_redis = true`
588: 4. Verify Redis pod health and connectivity
589: 5. Create network policies
590: 
591: ### Phase 2: Backend Changes (Feature Flag)
592: 
593: 1. Add Redis client code to backend
594: 2. Add `REDIS_ENABLED` feature flag (default: false)
595: 3. Deploy backend with Redis disabled
596: 4. Verify no regression in existing functionality
597: 
598: ### Phase 3: Enable Redis
599: 
600: 1. Update backend Helm values: `redis.enabled = true`
601: 2. Deploy backend with Redis enabled
602: 3. Monitor logs for Redis connection success
603: 4. Verify SMS OTP flow end-to-end
604: 
605: ### Phase 4: Cleanup
606: 
607: 1. Remove in-memory storage code (optional)
608: 2. Update documentation
609: 3. Close tracking issues
610: 
611: ## Dependencies
612: 
613: ### Prerequisites
614: 
615: | Dependency | Status | Notes |
616: | ------------ | -------- | ------- |
617: | EKS cluster | Existing | Auto Mode enabled |
618: | EBS CSI driver | Existing | For PersistentVolume |
619: | StorageClass | Existing | GP3 encrypted |
620: | SMS 2FA enabled | Existing | `enable_sms_2fa = true` |
621: 
622: ### New Dependencies
623: 
624: | Dependency | Version | Purpose |
625: | ------------ | --------- | --------- |
626: | Bitnami Redis Helm chart | 19.6.4+ | Redis deployment |
627: | `redis` Python package | 5.0.0+ | Redis client library |
628: 
629: ## Implementation Checklist
630: 
631: ### GitHub Secrets Setup
632: 
633: > [!NOTE]
634: >
635: > See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for complete setup instructions.
636: 
637: - [ ] Generate secure Redis password (min 8 characters)
638: - [ ] Add `TF_VAR_REDIS_PASSWORD` to GitHub repository secrets
639: (or AWS Secrets Manager for local scripts)
640: - [ ] Verify secret is accessible in Actions workflow
641: 
642: ### Infrastructure
643: 
644: - [ ] Create `application/modules/redis/` Terraform module
645:   - [ ] `main.tf` with namespace, kubernetes_secret, and helm_release
646:   - [ ] `variables.tf` with module inputs (including `redis_password`)
647:   - [ ] `outputs.tf` with connection details
648:   - [ ] `README.md` with usage documentation
649: - [ ] Create `application/helm/redis-values.tpl.yaml` template
650: - [ ] Add Redis module invocation to `application/main.tf`
651: - [ ] Add Redis variables to `application/variables.tf`
652: - [ ] Update `.github/workflows/application_infra_provisioning.yaml` with `TF_VAR_REDIS_PASSWORD`
653: - [ ] Update network policies for Redis access
654: 
655: ### Backend Application
656: 
657: - [ ] Add `redis` to `requirements.txt`
658: - [ ] Create `app/redis/__init__.py`
659: - [ ] Create `app/redis/client.py` with RedisOTPClient
660: - [ ] Add Redis configuration to `app/config.py`
661: - [ ] Update `app/api/routes.py` to use Redis client
662: - [ ] Add Redis environment variables to ConfigMap template
663: - [ ] Add Redis secret reference to deployment template
664: - [ ] Update `values.yaml` with Redis configuration section
665: 
666: ### Testing
667: 
668: - [ ] Write unit tests for RedisOTPClient
669: - [ ] Write integration tests for SMS flow with Redis
670: - [ ] Manual end-to-end verification
671: - [ ] Multi-replica verification
672: 
673: ### Documentation
674: 
675: - [ ] Update `README.md` with Redis configuration
676: - [ ] Update `CHANGELOG.md` with feature entry
677: - [ ] Add Redis troubleshooting guide
678: 
679: ## Appendix
680: 
681: ### Redis CLI Commands for Debugging
682: 
683: ```bash
684: # Connect to Redis
685: kubectl exec -it -n redis redis-master-0 -- redis-cli -a $REDIS_PASSWORD
686: 
687: # View all OTP keys
688: KEYS sms_otp:*
689: 
690: # Get specific OTP data
691: GET sms_otp:username
692: 
693: # Check TTL remaining
694: TTL sms_otp:username
695: 
696: # Manually delete a key
697: DEL sms_otp:username
698: 
699: # Monitor real-time commands
700: MONITOR
701: ```
702: 
703: ### Helm Values Reference (Bitnami Redis)
704: 
705: ```yaml
706: # Minimal standalone configuration with external secret
707: architecture: standalone
708: 
709: auth:
710:   enabled: true
711:   # Reference Kubernetes secret created by Terraform
712:   # (password sourced from GitHub Secrets  TF_VAR_redis_password environment variable)
713:   existingSecret: "redis-secret"
714:   existingSecretPasswordKey: "redis-password"
715: 
716: master:
717:   persistence:
718:     enabled: true
719:     storageClass: "${storage_class_name}"
720:     size: 1Gi
721: 
722:   resources:
723:     requests:
724:       cpu: 100m
725:       memory: 128Mi
726:     limits:
727:       cpu: 500m
728:       memory: 256Mi
729: 
730:   securityContext:
731:     enabled: true
732:     runAsUser: 1001
733:     runAsNonRoot: true
734: 
735: replica:
736:   replicaCount: 0  # Standalone mode
737: 
738: metrics:
739:   enabled: false  # Enable for production monitoring
740: ```
741: 
742: ### Comparison with LDAP Secret Pattern
743: 
744: | Aspect | LDAP Admin Password | Redis Password |
745: | -------- | --------------------- | ---------------- |
746: | GitHub Secret | `TF_VAR_OPENLDAP_ADMIN_PASSWORD` | `TF_VAR_REDIS_PASSWORD` |
747: | Terraform Variable | `var.openldap_admin_password` | `var.redis_password` |
748: | K8s Secret Name | `ldap-admin-secret` | `redis-secret` |
749: | K8s Secret Key | `LDAP_ADMIN_PASSWORD` | `redis-password` |
750: | Helm Reference | `externalSecret.secretName` | `auth.existingSecret` |
````

## File: application/SECURITY-IMPROVEMENTS.md
````markdown
  1: # Security Improvements Summary
  2: 
  3: This document outlines the security enhancements made to ensure fully secured
  4: communication both from the internet (HTTPS on port 443) and internally within
  5: the Kubernetes cluster.
  6: 
  7: ## Changes Made
  8: 
  9: ### 1. External HTTPS Security (Internet to ALB)
 10: 
 11: ####  HTTP to HTTPS Redirect
 12: 
 13: - **Added**: HTTP (port 80) to HTTPS (port 443) redirect on all ALB ingress
 14: resources
 15: - **Location**: `application/helm/openldap-values.tpl.yaml`
 16: - **Implementation**:
 17:   - Added `alb.ingress.kubernetes.io/listen-ports:
 18:   '[{"HTTP":80},{"HTTPS":443}]'` to listen on both ports
 19:   - Added `alb.ingress.kubernetes.io/ssl-redirect: "443"` to automatically
 20:   redirect HTTP to HTTPS
 21:   - Added `alb.ingress.kubernetes.io/ssl-policy:
 22:   "ELBSecurityPolicy-TLS13-1-0-PQ-2025-09"` for modern TLS security with post-quantum cryptography support
 23: 
 24: ####  ALB Module HTTPS Configuration
 25: 
 26: - **Updated**: `application/modules/alb/main.tf` to support optional HTTPS
 27: configuration
 28: - **Added**:
 29:   - Certificate ARN parameter support
 30:   - Listen-ports configuration for HTTP and HTTPS
 31:   - SSL redirect annotation
 32:   - SSL policy annotation
 33: - **New Variable**: `acm_certificate_arn` in
 34: `application/modules/alb/variables.tf`
 35: 
 36: **Result**: All external traffic is now forced to use HTTPS on port 443, with
 37: automatic redirection from HTTP to HTTPS.
 38: 
 39: ### 2. Internal Cluster Security
 40: 
 41: ####  Network Policies for Pod-to-Pod Communication
 42: 
 43: - **Created**: New module `application/modules/network-policies/` with generic,
 44: service-agnostic network policies
 45: - **Generic Approach**: Any service can communicate with any service, but only
 46: on secure ports
 47: - **Cross-Namespace Communication**: Services in other namespaces can access the
 48: LDAP service on secure ports
 49: - **Policies Created**:
 50:   1. **Namespace Secure Communication Policy**: Applies to ALL pods, allows
 51:   secure inter-service communication
 52:      - Allows HTTPS (port 443) between any services (same namespace and
 53:      cross-namespace)
 54:      - Allows LDAPS (port 636) between any services (same namespace and
 55:      cross-namespace)
 56:      - Allows alternative HTTPS (port 8443) between any services (same namespace
 57:      and cross-namespace)
 58:      - Allows DNS resolution (port 53)
 59:      - Allows external HTTPS/HTTP for API calls (2FA providers, etc.)
 60: 
 61: **Key Security Features**:
 62: 
 63: - **Generic and Future-Proof**: Works with any service (PhpLdapAdmin,
 64: LTB-passwd, 2FA website, future services) without policy changes
 65: - **Encrypted Internal Communication**: Only secure ports (HTTPS 443, LDAPS 636)
 66: are allowed
 67: - **Cross-Namespace Access**: Services in other namespaces can securely access
 68: the LDAP service using LDAPS (port 636)
 69: - **Service-Agnostic**: No need to create new policies when adding services like
 70: your 2FA website
 71: - **Secure by Default**: Unencrypted ports (LDAP 389, HTTP 80) are blocked
 72: 
 73: ### 3. TLS Security Policy
 74: 
 75: ####  Modern TLS Configuration
 76: 
 77: - **SSL Policy**: `ELBSecurityPolicy-TLS13-1-0-PQ-2025-09` - Supports TLS 1.3 with post-quantum cryptography
 78: - **Applied to**: All ALB ingress resources (PhpLdapAdmin, LTB-passwd, and 2FA application)
 79: 
 80: **Result**: Only modern, secure TLS protocols are used for external
 81: communication.
 82: 
 83: ## Security Architecture
 84: 
 85: ### External Communication Flow
 86: 
 87: ```bash
 88: Internet (HTTP/HTTPS)
 89:     
 90: ALB (Port 80  Redirects to 443)
 91:     
 92: ALB (Port 443 - HTTPS with TLS 1.2/1.3)
 93:     
 94: Kubernetes Service (ClusterIP)
 95:     
 96: Pod (PhpLdapAdmin or LTB-passwd)
 97: ```
 98: 
 99: ### Internal Communication Flow
100: 
101: ```bash
102: Any Service Pod (PhpLdapAdmin, LTB-passwd, 2FA Website, etc.)
103:      (Secure ports only: HTTPS 443, LDAPS 636)
104: Network Policy Enforcement
105:     
106: Any Service Pod (OpenLDAP, APIs, etc.)
107:      (Secure ports only)
108: External APIs (HTTPS 443) - 2FA providers, etc.
109: ```
110: 
111: **Cross-Namespace Communication Flow**:
112: 
113: ```bash
114: Service Pod (Other Namespace, e.g., production)
115:      LDAPS (636)  Allowed by Network Policy
116: LDAP Service (ldap namespace)
117: ```
118: 
119: **Key Points**:
120: 
121: - Any service can communicate with any service (same namespace or
122: cross-namespace)
123: - Only secure/encrypted ports are allowed (443, 636, 8443)
124: - Cross-namespace communication is enabled for LDAP service access
125: - Your 2FA website will work automatically without policy changes
126: 
127: ## Files Modified
128: 
129: 1. **application/helm/openldap-values.tpl.yaml**
130: 
131:    - Added HTTP to HTTPS redirect
132:    - Added SSL policy configuration
133:    - Updated listen-ports to include both HTTP and HTTPS
134: 
135: 2. **application/modules/alb/main.tf**
136: 
137:    - Added HTTPS configuration support
138:    - Added SSL redirect and SSL policy annotations
139: 
140: 3. **application/modules/alb/variables.tf**
141: 
142:    - Added `acm_certificate_arn` variable
143: 
144: 4. **application/main.tf**
145: 
146:    - Added network policies module
147:    - Updated ALB module to pass certificate ARN
148: 
149: ## Files Created
150: 
151: 1. **application/modules/network-policies/main.tf**
152: 
153:    - Network policies for OpenLDAP ingress
154:    - Network policies for PhpLdapAdmin egress
155:    - Network policies for LTB-passwd egress
156:    - Default deny policy for the namespace
157: 
158: 2. **application/modules/network-policies/variables.tf**
159: 
160:    - Namespace variable for network policies
161: 
162: 3. **application/modules/network-policies/README.md**
163: 
164:    - Comprehensive documentation for network policies
165: 
166: ## Deployment Notes
167: 
168: ### Prerequisites
169: 
170: - EKS cluster must support Network Policies (CNI plugin must support Network
171: Policies)
172: - Helm chart must create pods with labels matching the network policy selectors
173: 
174: ### Important Considerations
175: 
176: 1. **Generic Policy Approach**: The network policies are **service-agnostic**
177: and apply to ALL pods in the namespace:
178: 
179:    - No label selectors needed - works with any service
180:    - Cross-namespace communication enabled for LDAP service access
181:    - Your 2FA website will work automatically
182:    - Future services will work without policy changes
183: 
184: 2. **Secure Ports Only**: Services must use secure ports:
185: 
186:    - **HTTPS** (port 443) for web services - not HTTP (port 80)
187:    - **LDAPS** (port 636) for LDAP - not LDAP (port 389)
188:    - **Alternative HTTPS** (port 8443) if needed
189:    - Unencrypted ports are blocked by the policy
190: 
191: 3. **Service Configuration**: Ensure your services are configured correctly:
192: 
193:    - OpenLDAP must listen on LDAPS port 636
194:    - PhpLdapAdmin and LTB-passwd must use `ldaps://` instead of `ldap://`
195:    - Your 2FA website must use HTTPS for internal APIs
196:    - All inter-service communication must use secure ports
197: 
198: 4. **Network Policy Enforcement**: Network policies are enforced by the CNI
199: plugin. If your cluster uses a CNI that doesn't support Network Policies (e.g.,
200: older versions of Flannel), the policies will be ignored.
201: 
202: ## Testing
203: 
204: After deployment, verify:
205: 
206: 1. **External HTTPS**:
207: 
208:    ```bash
209:    # Test HTTP redirect
210:    curl -I http://phpldapadmin.talorlik.com
211:    # Should return 301/302 redirect to HTTPS
212: 
213:    # Test HTTPS
214:    curl -I https://phpldapadmin.talorlik.com
215:    # Should return 200 OK
216:    ```
217: 
218: 2. **Network Policies**:
219: 
220:    ```bash
221:    # Check network policies
222:    kubectl get networkpolicies -n ldap
223: 
224:    # Verify pod labels match policy selectors
225:    kubectl get pods -n ldap --show-labels
226:    ```
227: 
228: 3. **LDAPS Communication**:
229: 
230:    ```bash
231:    # Test LDAPS connectivity from PhpLdapAdmin pod
232:    kubectl exec -n ldap <phpldapadmin-pod> -- nc -zv <openldap-service> 636
233:    # Should succeed
234: 
235:    # Test LDAP (should fail due to network policy)
236:    kubectl exec -n ldap <phpldapadmin-pod> -- nc -zv <openldap-service> 389
237:    # Should fail or timeout
238:    ```
239: 
240: ### 4. Cross-Account Role Assumption Security
241: 
242: ####  ExternalId for Role Assumption
243: 
244: - **Added**: ExternalId requirement for cross-account role assumption between
245: state account (Account A) and deployment accounts (Account B)
246: - **Location**: `application/providers.tf`, `backend_infra/providers.tf`
247: - **Implementation**:
248:   - ExternalId retrieved from AWS Secrets Manager (secret: `external-id`) for
249:   local deployment
250:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
251:   for GitHub Actions
252:   - ExternalId passed to Terraform provider's `assume_role` block
253:   - Deployment account roles must have ExternalId condition in Trust Relationship
254: 
255: **Key Security Features**:
256: 
257: - **Prevents Confused Deputy Attacks**: ExternalId ensures only authorized
258: callers can assume deployment account roles
259: - **Secret-Based Management**: ExternalId stored securely in AWS Secrets Manager
260: and GitHub secrets (never hardcoded)
261: - **Consistent Value**: Same ExternalId used across both local and CI/CD
262: deployments
263: - **Trust Relationship Condition**: Deployment account roles require ExternalId
264: match in Trust Relationship policy
265: 
266: **Trust Relationship Configuration**:
267: 
268: The deployment account role's Trust Relationship must include:
269: 
270: ```json
271: {
272:   "Effect": "Allow",
273:   "Principal": {
274:     "AWS": "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
275:   },
276:   "Action": "sts:AssumeRole",
277:   "Condition": {
278:     "StringEquals": {
279:       "sts:ExternalId": "<generated-external-id>"
280:     }
281:   }
282: }
283: ```
284: 
285: **State Account Role Trust Relationship (Reverse Direction)**:
286: 
287: In addition to deployment account roles trusting the state account role, the
288: state account role's Trust Relationship must also be updated to allow the
289: deployment account roles. This bidirectional trust is required for proper
290: cross-account role assumption.
291: 
292: > [!IMPORTANT]
293: >
294: > **ExternalId Still Required**: The ExternalId security mechanism is still
295: > required when the state account role assumes deployment account roles. The
296: > ExternalId condition must be present in the deployment account roles' Trust
297: > Relationships (as shown above), and the state account role must provide the
298: > ExternalId when assuming those roles. The ExternalId is retrieved from
299: > `AWS_ASSUME_EXTERNAL_ID` secret (for GitHub Actions) or AWS Secrets Manager
300: > (for local deployment).
301: 
302: Update the state account role's Trust Relationship to include the deployment
303: account role ARNs:
304: 
305: ```json
306: {
307:   "Version": "2012-10-17",
308:   "Statement": [
309:     {
310:       "Effect": "Allow",
311:       "Principal": {
312:         "Federated": "arn:aws:iam::STATE_ACCOUNT_ID:oidc-provider/token.actions.githubusercontent.com"
313:       },
314:       "Action": "sts:AssumeRoleWithWebIdentity",
315:       "Condition": {
316:         "StringLike": {
317:           "token.actions.githubusercontent.com:sub": "repo:YOUR_ORG/YOUR_REPO:*"
318:         }
319:       }
320:     },
321:     {
322:       "Effect": "Allow",
323:       "Principal": {
324:         "AWS": [
325:           "arn:aws:iam::PRODUCTION_ACCOUNT_ID:role/github-role",
326:           "arn:aws:iam::DEVELOPMENT_ACCOUNT_ID:role/github-role",
327:           "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
328:         ]
329:       },
330:       "Action": "sts:AssumeRole"
331:     }
332:   ]
333: }
334: ```
335: 
336: Replace `PRODUCTION_ACCOUNT_ID` and `DEVELOPMENT_ACCOUNT_ID` with your actual
337: account IDs, and `github-role` with your actual deployment role names.
338: 
339: > [!IMPORTANT]
340: >
341: > **Self-Assumption Statement**: The last statement allows the role to assume itself.
342: > This is required when:
343: >
344: > - The State Account role is used for both backend state operations and
345: > Route53/ACM access (when `state_account_role_arn` points to the same role)
346: > - Terraform providers need to assume the same role that was already assumed by
347: > the initial authentication
348: > - You encounter errors like "User: arn:aws:sts::ACCOUNT_ID:assumed-role/github-role/SESSION
349: > is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::ACCOUNT_ID:role/github-role"
350: >
351: > Without this statement, if a session is already running under `github-role` and
352: > Terraform tries to assume the same role again (via `assume_role` in `providers.tf`),
353: > the operation will fail with an `AccessDenied` error.
354: 
355: **ExternalId Generation**:
356: 
357: - Generate using: `openssl rand -hex 32`
358: - Must match in:
359:   - AWS Secrets Manager secret `external-id` (plain text)
360:   - GitHub repository secret `AWS_ASSUME_EXTERNAL_ID`
361:   - Deployment account role Trust Relationship condition
362: 
363: **Result**: Enhanced security for cross-account role assumption, preventing
364: unauthorized role assumption attempts. Both the deployment account roles and the
365: state account role must trust each other in their respective Trust
366: Relationships for proper bidirectional cross-account access.
367: 
368: ####  Route53 Cross-Account Access
369: 
370: - **Added**: Support for accessing Route53 hosted zones from State Account
371: - **Location**: `application/providers.tf`, `application/main.tf`, `application/modules/route53_record/`,
372: `application/modules/ses/`
373: - **Implementation**:
374:   - State account provider alias (`aws.state_account`) configured in `providers.tf`
375:   - Route53 hosted zone data source queries from State Account when `state_account_role_arn`
376:   is provided
377:   - All Route53 record resources use state account provider for creating records
378:   in State Account
379:   - Scripts automatically inject `state_account_role_arn` into `variables.tfvars`
380:   - No ExternalId required for state account role assumption (by design)
381: 
382: ####  ACM Certificate Architecture (EKS Auto Mode)
383: 
384: - **Important**: EKS Auto Mode ALB controller **CANNOT** access cross-account
385: ACM certificates
386: - **Requirement**: ACM certificate **MUST** be in the Deployment Account
387: (same account as EKS cluster)
388: - **Architecture**: Public ACM certificates with DNS validation via Route53
389: - **Location**: `application/main.tf`
390: - **Implementation**:
391:   - Public ACM certificates are requested in each deployment account (development, production)
392:   - DNS validation records are created in Route53 hosted zone in State Account
393:   - Each deployment account has its own public ACM certificate
394:   - ACM certificate data source uses default provider (deployment account),
395:   NOT `aws.state_account`
396:   - Certificate must exist in Deployment Account before ALB creation
397:   - Certificate must be validated and in `ISSUED` status
398:   - Certificate must be in the same region as the EKS cluster
399:   - No cross-account certificate access needed (each account uses its own certificate)
400:   - Certificates are automatically renewed by ACM
401: 
402: **Key Security Features**:
403: 
404: - **Public ACM Certificate Architecture**: Public ACM certificates requested in each deployment account
405: - **Browser-Trusted Certificates**: Public ACM certificates are trusted by browsers without warnings
406: - **No Cross-Account Certificate Access**: Each deployment account has its own
407: certificate, eliminating cross-account certificate access needs
408: - **Cross-Account Resource Access**: Route53 hosted zones reside in State Account
409: while ALB is deployed in Deployment Account
410: - **Automatic Provider Selection**: Terraform automatically uses state account
411: provider when `state_account_role_arn` is configured
412: - **No ExternalId Required**: State account role assumption does not require
413: ExternalId (by design, different security model)
414: - **Automatic Renewal**: ACM automatically renews certificates before expiration
415: - **Comprehensive Documentation**: See `CROSS-ACCOUNT-ACCESS.md` for complete
416: configuration details, including step-by-step AWS CLI commands for public ACM certificate setup
417: and DNS validation.
418: 
419: **State Account Role Permissions**:
420: 
421: The State Account role must have the following permissions (Route53 only, ACM
422: certificate access not needed since each account has its own certificate):
423: 
424: ```json
425: {
426:   "Version": "2012-10-17",
427:   "Statement": [
428:     {
429:       "Effect": "Allow",
430:       "Action": [
431:         "route53:GetHostedZone",
432:         "route53:ListHostedZones",
433:         "route53:ChangeResourceRecordSets",
434:         "route53:GetChange"
435:       ],
436:       "Resource": "*"
437:     }
438:   ]
439: }
440: ```
441: 
442: **Deployment Account Role Permissions (for ACM Certificate):**
443: 
444: The Deployment Account role (or default credentials) must have ACM permissions:
445: 
446: ```json
447: {
448:   "Version": "2012-10-17",
449:   "Statement": [
450:     {
451:       "Effect": "Allow",
452:       "Action": [
453:         "acm:RequestCertificate",
454:         "acm:ListCertificates",
455:         "acm:DescribeCertificate"
456:       ],
457:       "Resource": "*"
458:     }
459:   ]
460: }
461: ```
462: 
463: **State Account Role Trust Relationship**:
464: 
465: The State Account role must trust the Deployment Account role (or GitHub Actions
466: OIDC provider):
467: 
468: ```json
469: {
470:   "Version": "2012-10-17",
471:   "Statement": [
472:     {
473:       "Effect": "Allow",
474:       "Principal": {
475:         "AWS": [
476:           "arn:aws:iam::DEPLOYMENT_ACCOUNT_ID:role/github-role",
477:           "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
478:         ]
479:       },
480:       "Action": "sts:AssumeRole"
481:     }
482:   ]
483: }
484: ```
485: 
486: **Note**: ExternalId is **not required** for State Account role assumption (by design).
487: 
488: > [!IMPORTANT]
489: >
490: > **Self-Assumption Statement**: The second statement allows the role to assume
491: > itself. This is required when the State Account role is used for both backend
492: > state operations and Route53/ACM access (when `state_account_role_arn` points
493: > to the same role). Without this statement, if a session is already running under
494: > `github-role` and Terraform tries to assume the same role again via `assume_role`
495: > in `providers.tf`, the operation will fail with an `AccessDenied` error.
496: 
497: **Result**: Enables secure cross-account access to Route53 hosted zones while maintaining
498: separation between state storage and resource deployment accounts. ACM certificates
499: must be in the Deployment Account due to EKS Auto Mode ALB controller limitations.
500: 
501: ## Security Compliance
502: 
503: These changes ensure:
504: 
505:  **End-to-End Encryption**: All external traffic uses HTTPS (TLS 1.2/1.3)
506:  **Internal Encryption**: All internal LDAP communication uses LDAPS
507: (encrypted)
508:  **Network Segmentation**: Services can only communicate with explicitly
509: allowed services
510:  **Default Deny**: All traffic is denied by default, with explicit allow rules
511:  **Principle of Least Privilege**: Each service has minimal required network
512: access
513:  **Modern TLS**: Only secure TLS protocols are used
514:  **Cross-Account Security**: ExternalId prevents confused deputy attacks in
515: multi-account deployments
516: 
517: ## Next Steps (Optional Enhancements)
518: 
519: 1. **Service Mesh**: Consider implementing a service mesh (Istio, Linkerd) for
520: mTLS between all services
521: 2. **Certificate Rotation**: Implement automated certificate rotation for ACM
522: certificates
523: 3. **Monitoring**: Set up monitoring and alerting for security events
524: 4. **Audit Logging**: Enable Kubernetes audit logging for security compliance
525: 5. **Pod Security Standards**: Implement Pod Security Standards for additional
526: security
527: 
528: ## References
529: 
530: - [Kubernetes Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)
531: - [AWS ALB Ingress Annotations](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/ingress/annotations/)
532: - [AWS EKS Network Policies](https://docs.aws.amazon.com/eks/latest/userguide/network-policy.html)
533: - [TLS Security Policies](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html#describe-ssl-policies)
````

## File: backend_infra/CHANGELOG.md
````markdown
  1: # Changelog
  2: 
  3: All notable changes to the backend infrastructure will be documented in this
  4: file.
  5: 
  6: The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
  7: and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
  8: 
  9: ## [2026-01-15] - ExternalId Security and Infrastructure Improvements
 10: 
 11: ### Added
 12: 
 13: - **ExternalId Support for Cross-Account Role Assumption**
 14:   - Added ExternalId requirement for enhanced security when assuming deployment
 15:   account roles
 16:   - ExternalId retrieved from AWS Secrets Manager (secret: `external-id`) for
 17:   local deployment
 18:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
 19:   for GitHub Actions
 20:   - ExternalId passed to Terraform provider's `assume_role` block
 21:   - New variable `deployment_account_external_id` added to `variables.tf`
 22:   - Setup script (`setup-backend.sh`) automatically retrieves ExternalId from
 23:   AWS Secrets Manager
 24:   - GitHub Actions workflow (`backend_infra_provisioning.yaml`) updated to use
 25:   `AWS_ASSUME_EXTERNAL_ID` secret
 26:   - Deployment account roles must have ExternalId condition in Trust Relationship
 27:   - **Bidirectional Trust Relationships**: Both deployment account roles and state
 28:     account role must trust each other in their respective Trust Relationships
 29:   - State account role's Trust Relationship must include deployment account role
 30:     ARNs to enable proper cross-account role assumption
 31:   - Prevents confused deputy attacks in multi-account deployments
 32:   - ExternalId generation: `openssl rand -hex 32`
 33: 
 34: - **Destroy Script for Backend Infrastructure**
 35:   - Created `destroy-backend.sh` script for destroying backend infrastructure
 36:   - Interactive region and environment selection
 37:   - Automatic retrieval of role ARNs and ExternalId from AWS Secrets Manager
 38:   - Automatic backend configuration and variables.tfvars updates
 39:   - Safety confirmations required before destruction (type 'yes' then 'DESTROY')
 40:   - Comprehensive error handling and user guidance
 41:   - Updated GitHub Actions destroying workflow with ExternalId support
 42: 
 43: ### Changed
 44: 
 45: - **Setup Script Improvements**
 46:   - Enhanced `setup-backend.sh` with improved error handling and ExternalId
 47:   support
 48:   - Automatic ExternalId retrieval from AWS Secrets Manager
 49:   - Improved role assumption logic with better error messages
 50:   - Enhanced secret retrieval with validation and error handling
 51:   - Better integration with GitHub repository variables and secrets
 52:   - Improved user guidance and confirmation prompts
 53: 
 54: - **GitHub Actions Workflow Updates**
 55:   - Updated `backend_infra_provisioning.yaml` with ExternalId support and
 56:   improved error handling
 57:   - Updated `backend_infra_destroying.yaml` with ExternalId support and
 58:   improved error handling
 59:   - Workflows now use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations
 60:   - Workflows now use `AWS_ASSUME_EXTERNAL_ID` for cross-account role assumption
 61:   security
 62:   - Improved environment variable handling
 63: 
 64: - **Documentation Improvements**
 65:   - Removed duplication by replacing detailed module descriptions with links
 66:   to module READMEs
 67:   - Enhanced cross-references to VPC Endpoints and ECR module documentation
 68:   - Updated component descriptions to be more concise with links to detailed documentation
 69: 
 70: ## [2025-12-18] - VPC Endpoints for IRSA and SMS 2FA Support
 71: 
 72: ### Added
 73: 
 74: - **STS VPC Endpoint for IRSA (IAM Roles for Service Accounts)**
 75:   - Added optional STS VPC endpoint (`com.amazonaws.${region}.sts`)
 76:   - Required for pods to assume IAM roles via web identity (IRSA)
 77:   - Controlled by `enable_sts_endpoint` variable (default: `true`)
 78:   - Enables secure internal communication for IAM role assumption
 79: 
 80: - **SNS VPC Endpoint for SMS 2FA functionality**
 81:   - Added optional SNS VPC endpoint (`com.amazonaws.${region}.sns`)
 82:   - Required for pods to send SMS verification codes via SNS
 83:   - Controlled by `enable_sns_endpoint` variable (default: `false`)
 84:   - Enables secure internal communication for SMS 2FA
 85: 
 86: - **IRSA (IAM Roles for Service Accounts) support**
 87:   - Enabled OIDC provider on EKS cluster with `enable_irsa = true`
 88:   - Allows pods to assume IAM roles for AWS service access
 89:   - Required for secure SNS access from application pods
 90: 
 91: - **New outputs for IRSA and VPC endpoints**
 92:   - Added `oidc_provider_arn`: OIDC provider ARN for creating IAM roles
 93:   - Added `oidc_provider_url`: OIDC provider URL (without `https://`)
 94:   - Added `vpc_endpoint_sts_id`: VPC endpoint ID for STS
 95:   - Added `vpc_endpoint_sns_id`: VPC endpoint ID for SNS
 96: 
 97: - **VPC CIDR security group rule**
 98:   - Added ingress rule allowing VPC CIDR to access VPC endpoints
 99:   - Supports pods that may not use node security group
100:   - Ensures all pods can reach VPC endpoints regardless of network policy
101: 
102: ### Changed
103: 
104: - **VPC Endpoints module configuration**
105:   - Added `vpc_cidr` variable for security group rules
106:   - Added `enable_sts_endpoint` variable (default: `true`)
107:   - Added `enable_sns_endpoint` variable (default: `false`)
108:   - Updated `vpc_endpoint_ids` output to include optional STS and SNS endpoints
109:   - Added description and Name tag to endpoint security group
110: 
111: - **Root module variables**
112:   - Added `enable_sts_endpoint` variable to control STS endpoint creation
113:   - Added `enable_sns_endpoint` variable to control SNS endpoint creation
114:   - Variables passed through to endpoints module
115: 
116: ## [2025-12-15] - Provider Profile Cleanup
117: 
118: ### Changed
119: 
120: - **Removed provider_profile variable dependency**
121:   - Removed `provider_profile` variable from `variables.tf` and
122:   `variables.tfvars`
123:   - Removed `profile = var.provider_profile` from `providers.tf`
124:   - Provider now uses role assumption via `deployment_account_role_arn` variable
125:   instead of AWS profiles
126:   - Aligns with multi-account architecture and environment-based role selection
127: 
128: - **Updated setup script for multi-account architecture**
129:   - `setup-backend.sh` now retrieves deployment account role ARN from GitHub
130:   repository secrets
131:   - Script automatically selects appropriate role ARN based on environment
132:   (`prod` or `dev`)
133:   - Removed dependency on AWS profiles for role assumption
134:   - Improved error handling and user guidance
135: 
136: ### Removed
137: 
138: - **Removed `setup-backend-api.sh` script**
139:   - Consolidated functionality into `setup-backend.sh`
140:   - Eliminated duplicate script maintenance
141:   - Improved script organization and maintainability
142: 
143: ## [2025-12-14] - Deployment Versatility and Security Improvements
144: 
145: ### Added
146: 
147: - **Multi-account role assumption support**
148:   - Added `deployment_account_role_arn` variable to support role assumption in
149:   deployment accounts
150:   - Variable automatically injected by GitHub Actions workflows based on
151:   environment
152:   - Supports separate production and development account deployments
153:   - Provider configuration updated to use `assume_role` when
154:   `deployment_account_role_arn` is provided
155: 
156: - **Enhanced setup script automation**
157:   - `setup-backend.sh` now automatically retrieves deployment account role ARN
158:   from GitHub secrets
159:   - Script handles environment-based role selection
160:   (`AWS_PRODUCTION_ACCOUNT_ROLE_ARN` or `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`)
161:   - Improved error messages and validation
162:   - Better integration with GitHub repository secrets and variables
163: 
164: ### Changed
165: 
166: - **Provider configuration for multi-account support**
167:   - Updated `providers.tf` to conditionally use `assume_role` when
168:   `deployment_account_role_arn` is provided
169:   - Maintains backward compatibility for single-account deployments
170:   - Supports both local execution and GitHub Actions workflows
171: 
172: - **Setup script consolidation**
173:   - Enhanced `setup-backend.sh` with comprehensive role assumption logic
174:   - Removed `setup-backend-api.sh` (functionality merged into
175:   `setup-backend.sh`)
176:   - Improved script structure and error handling
177:   - Better user feedback and guidance
178: 
179: - **Documentation updates**
180:   - Updated `README.md` to reflect multi-account architecture
181:   - Clarified role assumption workflow
182:   - Updated prerequisites and setup instructions
183: 
184: ### Removed
185: 
186: - **Removed `setup-backend-api.sh` script**
187:   - Functionality consolidated into unified `setup-backend.sh`
188:   - Reduces script maintenance overhead
189:   - Simplifies deployment workflow
190: 
191: ## [2025-12-14] - Terraform State Deployment Automation
192: 
193: ### Added
194: 
195: - **Automated Terraform state management**
196:   - Setup script now automatically handles Terraform workspace
197:   creation/selection
198:   - Automatic Terraform initialization with backend configuration
199:   - Automated validation, planning, and application of infrastructure changes
200:   - Eliminates need for manual Terraform command execution
201: 
202: - **Backend configuration automation**
203:   - `setup-backend.sh` automatically creates `backend.hcl` from template if it
204:   doesn't exist
205:   - Script retrieves backend state information from GitHub repository variables
206:   - Prevents overwriting existing backend configuration
207: 
208: - **Environment-based workspace management**
209:   - Workspaces automatically created/selected based on `${region}-${env}`
210:   pattern
211:   - Ensures proper state isolation between environments and regions
212: 
213: ### Changed
214: 
215: - **Provider configuration enhancements**
216:   - Added conditional backend configuration support
217:   - Improved error handling for missing backend state information
218:   - Better integration with GitHub repository variables
219: 
220: - **Variable management**
221:   - Added variables for backend state configuration
222:   - Improved variable descriptions and documentation
223:   - Better default value handling
224: 
225: ## [2025-12-10] - Output Enhancements
226: 
227: ### Added
228: 
229: - **Comprehensive VPC Endpoints outputs**
230:   - Added `vpc_endpoint_sg_id`: Security group ID for VPC endpoints
231:   - Added `vpc_endpoint_ssm_id`: VPC endpoint ID for SSM
232:   - Added `vpc_endpoint_ssmmessages_id`: VPC endpoint ID for SSM Messages
233:   - Added `vpc_endpoint_ec2messages_id`: VPC endpoint ID for EC2 Messages
234:   - Added `vpc_endpoint_ids`: List of all VPC endpoint IDs
235:   - All outputs properly documented with descriptions
236: 
237: - **ECR repository outputs**
238:   - Added `ecr_name`: ECR repository name
239:   - Added `ecr_arn`: ECR repository ARN
240:   - Added `ecr_url`: ECR repository URL for Docker image push/pull operations
241: 
242: - **Enhanced module outputs**
243:   - VPC endpoints module now exports all endpoint IDs and security group
244:   information
245:   - Improved output organization and documentation
246: 
247: ### Changed
248: 
249: - **Output structure improvements**
250:   - Reorganized outputs by component (VPC, EKS, Endpoints, ECR, EBS)
251:   - Added consistent descriptions to all outputs
252:   - Improved output naming conventions
253: 
254: ## [2025-12-08] - Documentation Updates
255: 
256: ### Changed
257: 
258: - **Comprehensive README updates**
259:   - Expanded architecture documentation with ASCII diagrams
260:   - Added detailed component descriptions (VPC, EKS, VPC Endpoints, ECR)
261:   - Enhanced security considerations section
262:   - Added cost optimization notes
263:   - Improved troubleshooting guide with useful commands
264:   - Added module structure documentation
265:   - Clarified prerequisites and setup requirements
266: 
267: ## [2025-12-02] - EBS Module Deprecation
268: 
269: ### Changed
270: 
271: - **EBS module commented out in main.tf**
272:   - EBS module usage commented out as OpenLDAP creates storage per pod
273:   - Module definition remains for future use if needed
274:   - EBS outputs commented out to match module status
275:   - Updated documentation to reflect current state
276: 
277: ### Added
278: 
279: - **EBS module outputs (commented)**
280:   - Added `ebs_pvc_name` output (commented)
281:   - Added `ebs_storage_class_name` output (commented)
282:   - Preserved for potential future reactivation
283: 
284: ## [2025-12-01] - Circular Dependency Resolution
285: 
286: ### Fixed
287: 
288: - **Resolved circular dependency in EKS module providers**
289:   - Fixed provider configuration to prevent circular dependencies
290:   - Updated provider initialization order
291:   - Improved module dependency management
292: 
293: ### Changed
294: 
295: - **Provider configuration updates**
296:   - Refactored provider setup to eliminate circular references
297:   - Improved provider initialization sequence
298:   - Updated setup scripts to reflect provider changes
299: 
300: ## [2025-11-27] - EBS Module Outputs
301: 
302: ### Added
303: 
304: - **EBS module outputs**
305:   - Added `ebs_pvc_name` output to get the name of the PVC for later use in the
306:   application
307:   - Added `ebs_storage_class_name` output
308:   - Enables application infrastructure to reference EBS resources
309: 
310: ## [2025-11-26] - VPC Endpoints, Storage, and ECR
311: 
312: ### Added
313: 
314: - **VPC Endpoints module**
315:   - Created new `modules/endpoints/` module for VPC endpoint management
316:   - Implements PrivateLink endpoints for SSM Session Manager access
317:   - Enables secure node access without public IPs
318:   - Creates endpoints for:
319:     - SSM (Systems Manager)
320:     - SSM Messages
321:     - EC2 Messages
322:   - Comprehensive README documentation
323: 
324: - **EBS Storage module**
325:   - Created new `modules/ebs/` module for EBS storage management
326:   - Implements Kubernetes StorageClass and PersistentVolumeClaim
327:   - Configurable storage class with gp3 volume type
328:   - Supports ReadWriteOnce access mode
329:   - Comprehensive README documentation
330: 
331: - **ECR Repository module**
332:   - Created new `modules/ecr/` module for container registry
333:   - Implements private Docker registry for application images
334:   - Configurable lifecycle policies for cost management
335:   - Image tag mutability settings
336:   - Comprehensive README documentation
337: 
338: - **Module integration**
339:   - All three modules integrated into `main.tf`
340:   - Proper dependency management between modules
341:   - Consistent naming conventions across modules
342: 
343: ### Changed
344: 
345: - **Provider updates**
346:   - Updated Terraform provider versions
347:   - Added Kubernetes provider for EBS module
348:   - Improved provider configuration
349: 
350: - **Documentation**
351:   - Added comprehensive README for each new module
352:   - Updated main README with module information
353:   - Added architecture diagrams and usage examples
354: 
355: ## [2025-11-26] - CloudWatch Logging and Kubernetes Upgrade
356: 
357: ### Added
358: 
359: - **CloudWatch logging for EKS cluster**
360:   - Enabled comprehensive logging for:
361:     - API server logs
362:     - Audit logs
363:     - Authenticator logs
364:     - Controller manager logs
365:     - Scheduler logs
366:   - Automatic CloudWatch log group creation
367:   - Improved observability and troubleshooting capabilities
368: 
369: ### Changed
370: 
371: - **Kubernetes version upgrade**
372:   - Upgraded Kubernetes version to 1.34
373:   - Updated EKS module configuration
374:   - Improved cluster stability and features
375: 
376: - **Provider version updates**
377:   - Updated Terraform AWS provider versions
378:   - Updated EKS module version
379:   - Improved compatibility and feature support
380: 
381: ## [2025-11-25] - EKS Auto Mode Cluster
382: 
383: ### Added
384: 
385: - **EKS Auto Mode cluster deployment**
386:   - Deployed Amazon EKS cluster using Auto Mode
387:   - Automatic node provisioning with "general-purpose" node pool
388:   - Elastic Load Balancing automatically enabled
389:   - Public API endpoint for kubectl access
390:   - Cluster creator admin permissions enabled
391:   - Nodes deployed in private subnets
392: 
393: - **EKS module integration**
394:   - Integrated `terraform-aws-modules/eks/aws` module (version 21.9.0)
395:   - Proper VPC and subnet integration
396:   - Kubernetes-specific subnet tagging
397:   - Security group configuration
398: 
399: - **Node IAM policies**
400:   - Added `AmazonSSMManagedInstanceCore` policy for SSM access
401:   - Enables Session Manager access to nodes without public IPs
402: 
403: ## [2025-11-25] - Provider Profile Removal
404: 
405: ### Removed
406: 
407: - **Removed AWS profile dependency**
408:   - Removed `provider_profile` variable from `variables.tf`
409:   - Removed `profile = var.provider_profile` from `providers.tf`
410:   - Removed profile configuration from `variables.tfvars`
411:   - Transitioned to role assumption for authentication
412: 
413: ### Changed
414: 
415: - **Provider authentication method**
416:   - Moved from AWS profile-based authentication to role assumption
417:   - Improved security and multi-account support
418:   - Better alignment with CI/CD workflows
419: 
420: ## [2025-11-25] - Initial Backend Infrastructure
421: 
422: ### Added
423: 
424: - **VPC infrastructure**
425:   - Created VPC with public and private subnets across two availability zones
426:   - Internet Gateway for public subnet internet access
427:   - NAT Gateway for private subnet internet access (single NAT for cost
428:   optimization)
429:   - Proper route table configuration
430:   - DNS support and DHCP options configured
431:   - Kubernetes-specific subnet tagging for EKS integration
432: 
433: - **Terraform configuration**
434:   - Main Terraform configuration files (`main.tf`, `variables.tf`, `outputs.tf`,
435:   `providers.tf`)
436:   - Variable definitions and default values
437:   - Comprehensive output definitions
438:   - Provider configuration for AWS
439: 
440: - **Setup scripts**
441:   - `setup-backend.sh`: Local setup script with interactive region and
442:   environment selection
443:   - `setup-backend-api.sh`: API-based setup script (later removed)
444:   - Both scripts support interactive region and environment selection
445:   - Backend configuration template (`tfstate-backend-values-template.hcl`)
446: 
447: - **GitHub Actions workflows**
448:   - Remote setup with GitHub workflows
449:   - Interactive region and environment selection in workflows
450:   - Automated infrastructure provisioning
451: 
452: - **Documentation**
453:   - Initial README with setup instructions
454:   - Backend configuration documentation
455: 
456: ### Configuration Details
457: 
458: - **VPC Module**: Uses `terraform-aws-modules/vpc/aws` module (version 6.5.1)
459: - **Naming Convention**: Resources follow `${prefix}-${region}-${name}-${env}`
460: pattern
461: - **Workspace Management**: Uses Terraform workspaces named `${region}-${env}`
462: - **Subnet Configuration**:
463:   - Public subnets tagged with `kubernetes.io/role/elb = 1`
464:   - Private subnets tagged with `kubernetes.io/role/internal-elb = 1`
465:   - All subnets tagged with `kubernetes.io/cluster/${cluster_name} = "shared"`
466: 
467: ## Architecture Overview
468: 
469: The backend infrastructure provides the foundational AWS resources for deploying
470: containerized applications on Kubernetes:
471: 
472: - **VPC**: Network isolation and segmentation
473: - **EKS Cluster**: Kubernetes orchestration platform
474: - **VPC Endpoints**: Secure access to AWS services without internet exposure
475: - **ECR Repository**: Container image storage and management
476: - **EBS Module**: Storage provisioning (currently commented out)
477: 
478: ### Key Components
479: 
480: 1. **VPC Module** (`terraform-aws-modules/vpc/aws`)
481:    - Public and private subnets
482:    - Internet Gateway and NAT Gateway
483:    - Route tables and DNS configuration
484: 
485: 2. **EKS Module** (`terraform-aws-modules/eks/aws`)
486:    - EKS Auto Mode cluster
487:    - Automatic node provisioning
488:    - CloudWatch logging
489: 
490: 3. **VPC Endpoints Module** (`modules/endpoints/`)
491:    - SSM, SSM Messages, EC2 Messages endpoints
492:    - Security group configuration
493: 
494: 4. **ECR Module** (`modules/ecr/`)
495:    - Private container registry
496:    - Lifecycle policies
497:    - Image tag mutability
498: 
499: 5. **EBS Module** (`modules/ebs/`) - Currently commented out
500:    - StorageClass and PersistentVolumeClaim
501:    - gp3 storage configuration
502: 
503: ## Notes
504: 
505: ### Multi-Account Architecture
506: 
507: The backend infrastructure supports multi-account deployments:
508: 
509: - **State Account (Account A)**: Stores Terraform state in S3
510: - **Deployment Accounts (Account B)**: Contains infrastructure resources (VPC,
511: EKS, etc.)
512:   - Production environment: Uses `AWS_PRODUCTION_ACCOUNT_ROLE_ARN`
513:   - Development environment: Uses `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
514: 
515: ### Role Assumption
516: 
517: The provider uses role assumption when `deployment_account_role_arn` is
518: provided:
519: 
520: - Automatically injected by GitHub Actions workflows
521: - Can be set manually for local execution
522: - Supports environment-based role selection
523: 
524: ### Setup Script Behavior
525: 
526: The `setup-backend.sh` script:
527: 
528: 1. Retrieves backend state information from GitHub repository variables
529: 2. Retrieves deployment account role ARN from GitHub secrets based on
530: environment
531: 3. Creates `backend.hcl` if it doesn't exist
532: 4. Updates `variables.tfvars` with region, environment, and deployment account
533: role ARN
534: 5. Runs Terraform commands automatically (init, workspace, validate, plan,
535: apply)
536: 
537: ### EBS Module Status
538: 
539: The EBS module is currently commented out in `main.tf` because:
540: 
541: - OpenLDAP creates EBS volumes per pod automatically
542: - Storage classes and PVCs are managed by the application infrastructure
543: - Module definition remains for potential future use
544: 
545: ## References
546: 
547: - [Keep a Changelog](https://keepachangelog.com/)
548: - [Semantic Versioning](https://semver.org/)
549: - [AWS EKS Documentation](https://docs.aws.amazon.com/eks/)
550: - [Terraform AWS VPC Module](https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws)
551: - [Terraform AWS EKS Module](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws)
````

## File: backend_infra/providers.tf
````hcl
 1: terraform {
 2:   required_providers {
 3:     aws = {
 4:       source  = "hashicorp/aws"
 5:       version = ">= 6.21.0"
 6:     }
 7:     kubernetes = {
 8:       source  = "hashicorp/kubernetes"
 9:       version = "~> 2.0"
10:     }
11:   }
12: 
13:   backend "s3" {
14:     # Backend configuration provided via backend.hcl file
15:     encrypt      = true
16:     use_lockfile = true
17:   }
18: 
19:   required_version = "~> 1.14.0"
20: }
21: 
22: provider "aws" {
23:   region = var.region
24: 
25:   # Assume role in deployment account (Account B) if role ARN is provided
26:   # This allows GitHub Actions to authenticate with Account A (for state)
27:   # while Terraform provider uses Account B (for resource deployment)
28:   # ExternalId is required for security when assuming cross-account roles
29:   dynamic "assume_role" {
30:     for_each = var.deployment_account_role_arn != null ? [1] : []
31:     content {
32:       role_arn    = var.deployment_account_role_arn
33:       external_id = var.deployment_account_external_id
34:     }
35:   }
36: }
37: 
38: provider "kubernetes" {
39:   host                   = module.eks.cluster_endpoint
40:   cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)
41:   token                  = data.aws_eks_cluster_auth.cluster.token
42: }
43: 
44: data "aws_eks_cluster_auth" "cluster" {
45:   name = module.eks.cluster_name
46: }
````

## File: application/PRD.md
````markdown
  1: # Application Requirements
  2: 
  3: ## 1. What you want the chart to do
  4: 
  5: Target state:
  6: 
  7: - `openldap` StatefulSet with EBS backed PVC inside the cluster only.
  8: - PhpLdapAdmin UI exposed via ALB.
  9: - LTB-passwd UI exposed via ALB (self-service password).
 10: - No external exposure of the LDAP ports themselves.
 11: - **ECR Image Support**: Container images are pulled from ECR (not Docker Hub)
 12: to eliminate rate limiting and external dependencies.
 13: 
 14: The chart already supports:
 15: 
 16: - Global LDAP config: `global.ldapDomain`, `adminPassword`, `configPassword`,
 17: ports. ([GitHub][1])
 18: - Built in PhpLdapAdmin and LTB-passwd, each with an `ingress` block you can
 19: customize. ([GitHub][1])
 20: 
 21: EKS Auto Mode already supports ALB if `elastic_load_balancing.enabled = true` in
 22: the cluster `kubernetes_network_config`. ([j-labs][2])
 23: ALB creation is driven by Kubernetes `Ingress` with AWS Load Balancer Controller
 24: annotations. ([Kubernetes SIGs][3])
 25: 
 26: So you only need:
 27: 
 28: - Correct `values.yaml` overrides.
 29: - A `helm_release` in Terraform that applies those values.
 30: 
 31: No separate AWS `aws_lb` resource is required.
 32: 
 33: ## 2. Minimal values changes
 34: 
 35: Key sections from your `values-openldap-stack-ha (1).yaml` that must be
 36: adjusted.
 37: 
 38: ### 2.1 Global LDAP and credentials
 39: 
 40: > [!NOTE]
 41: >
 42: > **ECR Image Configuration**: The current implementation uses ECR images instead
 43: > of Docker Hub.
 44: > The `imageRegistry` and `repository` fields in the Helm values template are automatically
 45: > configured to use ECR. Images are automatically mirrored from Docker Hub to ECR
 46: > by the `mirror-images-to-ecr.sh` script before Terraform operations.
 47: > See [ECR Image Mirroring](#ecr-image-mirroring) section for details.
 48: 
 49: Defaults you currently have:
 50: 
 51: ```yaml
 52: global:
 53:   imageRegistry: ""
 54:   imagePullSecrets: [""]
 55:   storageClass: ""
 56:   ldapDomain: "example.org"
 57:   adminPassword:  Not@SecurePassw0rd
 58:   configPassword: Not@SecurePassw0rd
 59:   ldapPort: 1389
 60:   sslLdapPort: 1636
 61: ```
 62: 
 63: Change to something like:
 64: 
 65: ```yaml
 66: global:
 67:   imageRegistry: "${ecr_registry}"        # ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)
 68:   imagePullSecrets: []
 69:   storageClass: ""                        # leave empty, use persistence.storageClass instead
 70:   ldapDomain: "ldap.talorlik.internal"     # or whatever LDAP base you want
 71:   adminPassword:  "${TF_VAR_openldap_admin_password}"
 72:   configPassword: "${TF_VAR_openldap_config_password}"
 73:   ldapPort: 389                           # standard LDAP
 74:   sslLdapPort: 636                        # standard LDAPS
 75: 
 76: # Image configuration for ECR
 77: image:
 78:   registry: "${ecr_registry}"
 79:   repository: "${ecr_repository}"
 80:   tag: "${openldap_image_tag}"            # e.g., "openldap-1.5.0"
 81: ```
 82: 
 83: In Terraform you will not literally hardcode `${TF_VAR_openldap_admin_password}`
 84: (from GitHub Secret `TF_VAR_OPENLDAP_ADMIN_PASSWORD` or AWS Secrets Manager);
 85: you will template these from variables or inject via `global.existingSecret`.
 86: The important part is:
 87: 
 88: - Do not keep `Not@SecurePassw0rd`.
 89: - Set `ldapDomain` to the real domain you will use for DNs. ([GitHub][1])
 90: 
 91: If you prefer secrets instead of cleartext in values:
 92: 
 93: - Use `global.existingSecret` (documented in the chart README) which expects
 94: keys `LDAP_ADMIN_PASSWORD` and `LDAP_CONFIG_ADMIN_PASSWORD`, and remove
 95: `adminPassword` / `configPassword` from the file. ([GitHub][1])
 96: 
 97: > [!NOTE]
 98: >
 99: > For complete secrets configuration, see [Secrets Requirements](../SECRETS_REQUIREMENTS.md).
100: 
101: ### 2.2 Persistence on your EBS StorageClass / PVC
102: 
103: Your current persistence block:
104: 
105: ```yaml
106: persistence:
107:   enabled: true
108:   # storageClass: "standard-singlewriter"
109:   # existingClaim: openldap-pvc
110:   accessModes:
111:     - ReadWriteOnce
112:   size: 8Gi
113: ```
114: 
115: > [!NOTE]
116: >
117: > In the current implementation (pattern 2) the code creates a StorageClass resource
118: > and the Helm chart creates a new PVC using that StorageClass.
119: > The `existingClaim` option (pattern 1) is not used.
120: 
121: You can use one of these two patterns:
122: 
123: 1. Reuse the existing PVC (not currently used):
124: 
125:     ```yaml
126:     persistence:
127:       enabled: true
128:       existingClaim: "openldap-pvc"   # must match your PVC name
129:       accessModes:
130:         - ReadWriteOnce
131:       size: 8Gi                       # ignored when existingClaim is used, but harmless
132:     ```
133: 
134: 2. Let the chart create a PVC with your StorageClass (current implementation):
135: 
136:     ```yaml
137:     persistence:
138:       enabled: true
139:       storageClass: "your-ebs-sc-name"
140:       accessModes:
141:         - ReadWriteOnce
142:       size: 8Gi
143:     ```
144: 
145: The current implementation uses pattern 2: a StorageClass is created by
146: Terraform (`kubernetes_storage_class_v1` resource), and the Helm chart creates a
147: new PVC using that StorageClass.
148: 
149: ### 2.3 Keep LDAP service internal
150: 
151: Your current service block:
152: 
153: ```yaml
154: service:
155:   annotations: {}
156:   externalIPs: []
157:   #loadBalancerIP:
158:   #loadBalancerSourceRanges: []
159:   type: ClusterIP
160:   sessionAffinity: None
161: ```
162: 
163: Leave `type: ClusterIP`. Do not change to `LoadBalancer` or `NodePort`. This
164: keeps LDAP itself strictly internal.
165: 
166: ### 2.4 Externalize only the UIs via ALB
167: 
168: From your file:
169: 
170: ```yaml
171: ltb-passwd:
172:   enabled : true
173:   image:
174:     tag: 5.2.3
175:   ingress:
176:     enabled: true
177:     annotations: {}
178:     path: /
179:     pathType: Prefix
180:     hosts:
181:     - "ssl-ldap2.example"
182:   ldap:
183:     bindPWKey: LDAP_ADMIN_PASSWORD
184: 
185: phpldapadmin:
186:   enabled: true
187:   env:
188:     PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "never"
189:   ingress:
190:     enabled: true
191:     annotations: {}
192:     path: /
193:     pathType: Prefix
194:     hosts:
195:     - phpldapadmin.example
196: ```
197: 
198: You want these two to be the only exposed pieces, via AWS ALB. For AWS Load
199: Balancer Controller you add the ALB annotations on the Ingress. ([Kubernetes
200: SIGs][3])
201: 
202: Example for private (internal) ALB, TLS terminated at ALB:
203: 
204: ```yaml
205: ltb-passwd:
206:   enabled: true
207:   image:
208:     tag: 5.2.3
209:   ingress:
210:     enabled: true
211:     annotations:
212:       kubernetes.io/ingress.class: alb
213:       alb.ingress.kubernetes.io/scheme: internal
214:       alb.ingress.kubernetes.io/target-type: ip
215:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
216:       alb.ingress.kubernetes.io/certificate-arn: "arn:aws:acm:eu-west-1:ACCOUNT:certificate/XXXXXXXX"
217:     path: /
218:     pathType: Prefix
219:     hosts:
220:       - "passwd.ldap.talorlik.internal"
221:   ldap:
222:     bindPWKey: LDAP_ADMIN_PASSWORD
223: 
224: phpldapadmin:
225:   enabled: true
226:   env:
227:     PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "never"
228:   ingress:
229:     enabled: true
230:     annotations:
231:       kubernetes.io/ingress.class: alb
232:       alb.ingress.kubernetes.io/scheme: internal
233:       alb.ingress.kubernetes.io/target-type: ip
234:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
235:       alb.ingress.kubernetes.io/certificate-arn: "arn:aws:acm:eu-west-1:ACCOUNT:certificate/XXXXXXXX"
236:     path: /
237:     pathType: Prefix
238:     hosts:
239:       - "phpldapadmin.ldap.talorlik.internal"
240: ```
241: 
242: Points:
243: 
244: - `scheme: internal` ensures ALB is only reachable inside the VPC.
245: ([enterprise-k8s.arcgis.com][4])
246: - `target-type: ip` is typical with CNI mode and avoids NodePort. ([Kubernetes
247: SIGs][3])
248: - `listen-ports` plus `certificate-arn` ensures HTTPS listener with ACM cert.
249: ([Kubernetes SIGs][3])
250: 
251: LDAP service remains `ClusterIP`; only these UIs have Ingress, hence only these
252: UIs are reachable via ALB.
253: 
254: ## 3. Helm from Terraform
255: 
256: Assume:
257: 
258: - You already have an `aws_eks_cluster` resource and `data
259: "aws_eks_cluster_auth"` for the token.
260: - You are running this inside `backend_infra`.
261: 
262: ### 3.1 Providers
263: 
264: Pattern consistent with EKS docs:
265: 
266: ```hcl
267: provider "kubernetes" {
268:   host                   = aws_eks_cluster.main.endpoint
269:   cluster_ca_certificate = base64decode(aws_eks_cluster.main.certificate_authority[0].data)
270:   token                  = data.aws_eks_cluster_auth.main.token
271: }
272: 
273: provider "helm" {
274:   kubernetes {
275:     host                   = aws_eks_cluster.main.endpoint
276:     cluster_ca_certificate = base64decode(aws_eks_cluster.main.certificate_authority[0].data)
277:     token                  = data.aws_eks_cluster_auth.main.token
278:   }
279: }
280: ```
281: 
282: This matches the pattern used in EKS Auto Mode articles and Terraform examples.
283: ([j-labs][2])
284: 
285: ### 3.2 Variables for sensitive bits
286: 
287: In `variables.tf`:
288: 
289: ```hcl
290: variable "openldap_admin_password" {
291:   type      = string
292:   sensitive = true
293: }
294: 
295: variable "openldap_config_password" {
296:   type      = string
297:   sensitive = true
298: }
299: 
300: variable "openldap_ldap_domain" {
301:   type = string
302: }
303: 
304: # ACM certificate is a Public ACM certificate (Amazon-issued) requested in Deployment Account
305: # Certificate is validated via DNS records in State Account's Route53 hosted zone
306: # See CROSS-ACCOUNT-ACCESS.md for Public ACM certificate setup instructions
307: # ACM certificate is a Public ACM certificate (Amazon-issued) requested in Deployment Account
308: # Certificate is validated via DNS records in State Account's Route53 hosted zone
309: # See CROSS-ACCOUNT-ACCESS.md for Public ACM certificate setup instructions
310: variable "acm_cert_arn" {
311:   type = string
312: }
313: 
314: variable "phpldapadmin_host" {
315:   type = string
316: }
317: 
318: variable "ltb_passwd_host" {
319:   type = string
320: }
321: ```
322: 
323: Values go into `variables.tfvars` or GitHub Actions env/vars.
324: 
325: ### 3.3 Template the values file
326: 
327: Create `application/helm/openldap-values.tpl.yaml` and move your adjusted YAML
328: there, replacing literal values with interpolation placeholders:
329: 
330: > [!NOTE]
331: >
332: > **ECR Image Configuration**: The template includes ECR registry and repository
333: > configuration. These values are automatically computed from `backend_infra`
334: > Terraform state. Images must be mirrored to ECR before deployment
335: > (handled automatically by `mirror-images-to-ecr.sh`).
336: 
337: ```yaml
338: global:
339:   imageRegistry: "${ecr_registry}"        # ECR registry URL
340:   imagePullSecrets: []
341:   storageClass: ""
342:   ldapDomain: "${openldap_ldap_domain}"
343:   adminPassword:  "${openldap_admin_password}"
344:   configPassword: "${openldap_config_password}"
345:   ldapPort: 389
346:   sslLdapPort: 636
347: 
348: # ECR image configuration for OpenLDAP
349: image:
350:   registry: "${ecr_registry}"
351:   repository: "${ecr_repository}"
352:   tag: "${openldap_image_tag}"            # e.g., "openldap-1.5.0"
353: 
354: persistence:
355:   enabled: true
356:   accessModes:
357:     - ReadWriteOnce
358:   size: 8Gi
359: 
360: service:
361:   annotations: {}
362:   externalIPs: []
363:   type: ClusterIP
364:   sessionAffinity: None
365: 
366: ltb-passwd:
367:   enabled: true
368:   image:
369:     tag: 5.2.3
370:   ingress:
371:     enabled: true
372:     annotations:
373:       kubernetes.io/ingress.class: alb
374:       alb.ingress.kubernetes.io/scheme: internal
375:       alb.ingress.kubernetes.io/target-type: ip
376:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
377:       alb.ingress.kubernetes.io/certificate-arn: "${acm_cert_arn}"
378:     path: /
379:     pathType: Prefix
380:     hosts:
381:       - "${ltb_passwd_host}"
382:   ldap:
383:     bindPWKey: LDAP_ADMIN_PASSWORD
384: 
385: phpldapadmin:
386:   enabled: true
387:   env:
388:     PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT: "never"
389:   ingress:
390:     enabled: true
391:     annotations:
392:       kubernetes.io/ingress.class: alb
393:       alb.ingress.kubernetes.io/scheme: internal
394:       alb.ingress.kubernetes.io/target-type: ip
395:       alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
396:       alb.ingress.kubernetes.io/certificate-arn: "${acm_cert_arn}"
397:     path: /
398:     pathType: Prefix
399:     hosts:
400:       - "${phpldapadmin_host}"
401: ```
402: 
403: ### 3.4 Helm release resource
404: 
405: In `application/main.tf` or a dedicated module:
406: 
407: > [!NOTE]
408: >
409: > **ECR Configuration**: The template includes ECR registry, repository, and
410: > image tag variables. These are computed from `backend_infra` Terraform state.
411: > Ensure images are mirrored to ECR before deployment.
412: 
413: ```hcl
414: locals {
415:   # Compute ECR registry and repository from backend_infra state
416:   ecr_registry   = replace(data.terraform_remote_state.backend_infra.outputs.ecr_url, "/^https?://([^/]+).*$/", "$1")
417:   ecr_repository = replace(data.terraform_remote_state.backend_infra.outputs.ecr_url, "/^https?://[^/]+/(.+)$/", "$1")
418: 
419:   openldap_values = templatefile(
420:     "${path.module}/helm/openldap-values.tpl.yaml",
421:     {
422:       openldap_admin_password  = var.openldap_admin_password
423:       openldap_config_password = var.openldap_config_password
424:       openldap_ldap_domain     = var.openldap_ldap_domain
425:       acm_cert_arn             = var.acm_cert_arn
426:       phpldapadmin_host        = var.phpldapadmin_host
427:       ltb_passwd_host          = var.ltb_passwd_host
428:       ecr_registry             = local.ecr_registry
429:       ecr_repository           = local.ecr_repository
430:       openldap_image_tag       = var.openldap_image_tag
431:     }
432:   )
433: }
434: 
435: resource "helm_release" "openldap" {
436:   name       = "openldap-stack-ha"
437:   repository = "https://jp-gouin.github.io/helm-openldap"
438:   chart      = "openldap-stack-ha"
439:   version    = "4.0.1"
440: 
441:   namespace        = "ldap"
442:   create_namespace = true
443: 
444:   values = [local.openldap_values]
445: 
446:   depends_on = [
447:     aws_eks_cluster.main,
448:     # optionally your EBS StorageClass / PVC resources if you manage them here
449:   ]
450: }
451: ```
452: 
453: Execution order:
454: 
455: 1. EKS cluster and its EKS Auto Mode settings applied
456: (`elastic_load_balancing.enabled = true`). ([j-labs][2])
457: 2. StorageClass / PVC resources applied.
458: 3. `helm_release.openldap` applied.
459: 
460: On apply:
461: 
462: - Helm installs OpenLDAP StatefulSet, Service, and the two UI Deployments plus
463: Services.
464: - The two Ingress resources for `phpldapadmin` and `ltb-passwd` are created with
465: ALB annotations.
466: - AWS Load Balancer Controller in EKS Auto Mode detects these Ingresses and
467: provisions an internal ALB with HTTPS, ACM cert, and targets pointing at the
468: pods. ([Kubernetes SIGs][3])
469: 
470: You now have:
471: 
472: - LDAP reachable only inside the cluster via ClusterIP service.
473: - Two GUIs reachable via ALB on the hostnames you specified, for manual
474: management and self service.
475: 
476: ## ECR Image Mirroring
477: 
478: ### Overview
479: 
480: The application infrastructure uses **ECR (Elastic Container Registry)** images
481: instead of Docker Hub to eliminate rate limiting and external dependencies.
482: All third-party container images are automatically mirrored from Docker Hub to
483: ECR before deployment.
484: 
485: ### Supported Images
486: 
487: The following images are automatically mirrored to ECR:
488: 
489: | Docker Hub Image | ECR Tag | Purpose |
490: | ----------------- | --------- | --------- |
491: | `osixia/openldap:1.5.0` | `openldap-1.5.0` | OpenLDAP directory service |
492: | `bitnami/postgresql:latest` | `postgresql-latest` | PostgreSQL database |
493: | `bitnami/redis:latest` | `redis-latest` | Redis cache |
494: 
495: ### Automatic Mirroring Process
496: 
497: The `mirror-images-to-ecr.sh` script automatically:
498: 
499: 1. **Checks ECR**: Verifies if images already exist in ECR (skips if present)
500: 2. **Fetches ECR URL**: Uses State Account credentials to retrieve ECR URL from
501: `backend_infra` Terraform state
502: 3. **Assumes Deployment Role**: Assumes Deployment Account role (with ExternalId)
503: for ECR operations
504: 4. **Authenticates Docker**: Authenticates Docker to ECR using `aws ecr get-login-password`
505: 5. **Pulls Images**: Pulls images from Docker Hub
506: 6. **Tags and Pushes**: Tags images with standardized tags and pushes to ECR
507: 7. **Cleans Up**: Removes local images after pushing to save disk space
508: 8. **Verifies**: Lists all images in ECR repository after completion
509: 
510: ### Integration
511: 
512: - **Local Deployment**: Automatically executed by `setup-application.sh` before
513: Terraform operations
514: - **GitHub Actions**: Automatically executed in workflow after Terraform validate,
515: before `set-k8s-env.sh`
516: 
517: ### Requirements
518: 
519: - Docker must be installed and running
520: - `jq` command-line tool (with fallback to sed for compatibility)
521: - AWS credentials configured (State Account for S3, Deployment Account for ECR)
522: - ECR repository must exist (created by `backend_infra`)
523: 
524: ### Configuration
525: 
526: ECR registry and repository are automatically computed from `backend_infra`
527: Terraform state (`ecr_url`). The Helm values template uses these values:
528: 
529: ```yaml
530: global:
531:   imageRegistry: "${ecr_registry}"    # e.g., account.dkr.ecr.region.amazonaws.com
532: 
533: image:
534:   registry: "${ecr_registry}"
535:   repository: "${ecr_repository}"
536:   tag: "${openldap_image_tag}"       # e.g., "openldap-1.5.0"
537: ```
538: 
539: > [!NOTE]
540: >
541: > For detailed information about ECR image mirroring,
542: > see the [Application Infrastructure README](README.md#ecr-image-mirroring-automatic).
543: 
544: ## Future Improvements
545: 
546: ### cert-manager Integration
547: 
548: **Current Status**: The cert-manager module exists in the codebase (`modules/cert-manager/`)
549: but is **not currently used** by the OpenLDAP module. OpenLDAP currently uses auto-generated
550: self-signed certificates from the osixia/openldap image.
551: 
552: **Future Enhancement**: Integrating cert-manager would provide:
553: 
554: - Automatic certificate generation and renewal for OpenLDAP TLS certificates
555: - Better certificate lifecycle management (renewal, rotation)
556: - Integration with Let's Encrypt or other certificate authorities for trusted certificates
557: - Consistent certificate management across all services
558: - Reduced manual certificate management overhead
559: 
560: **Implementation Notes**:
561: 
562: - The cert-manager module is already available and can be enabled
563: - Integration would require updating the OpenLDAP Helm values to reference cert-manager-issued
564: certificates
565: - Certificates would be stored in Kubernetes secrets and mounted into the
566: OpenLDAP pods
567: - This would replace the current auto-generated self-signed certificates
568: 
569: [1]: https://github.com/jp-gouin/helm-openldap "GitHub - jp-gouin/helm-openldap:
570: Helm chart of Openldap in High availability with multi-master replication and
571: PhpLdapAdmin and Ltb-Passwd"
572: [2]:
573: https://www.j-labs.pl/en/tech-blog/aws-eks-auto-mode/?utm_source=chatgpt.com
574: "AWS EKS Auto Mode with Terraform. Guidebook"
575: [3]:
576: https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/ingress/annotations/?utm_source=chatgpt.com
577: "Ingress annotations - AWS Load Balancer Controller"
578: [4]:
579: https://enterprise-k8s.arcgis.com/en/latest/deploy/use-a-cluster-level-ingress-controller-with-eks.htm?utm_source=chatgpt.com
580: "Use application load balancing on Amazon Elastic ..."
````

## File: .github/workflows/application_infra_provisioning.yaml
````yaml
  1: name: Application Infra Provisioning
  2: 
  3: 
  4: 
  5: 
  6: 
  7: 
  8: 
  9: 
 10: 
 11: 
 12: 
 13: 
 14: 
 15: 
 16: on:
 17:   workflow_dispatch:
 18:     inputs:
 19:       region:
 20:         description: 'Select AWS Region'
 21:         required: true
 22:         type: choice
 23:         default: 'us-east-1: N. Virginia'
 24:         options:
 25:           - 'us-east-1: N. Virginia'
 26:           - 'us-east-2: Ohio'
 27:       environment:
 28:         description: 'Select Environment'
 29:         required: true
 30:         type: choice
 31:         default: prod
 32:         options:
 33:           - prod
 34:           - dev
 35: 
 36: jobs:
 37:   SetRegion:
 38:     runs-on: ubuntu-latest
 39:     permissions:
 40:       contents: read
 41:     outputs:
 42:       region_code: ${{ steps.set_region.outputs.region_code }}
 43:     steps:
 44:       - name: Set Region
 45:         id: set_region
 46:         run: |
 47:           SELECTED_REGION="${{ inputs.region }}"
 48:           echo "region_code=${SELECTED_REGION%%:*}" >> $GITHUB_OUTPUT
 49: 
 50:   InfraProvision:
 51:     runs-on: ubuntu-latest
 52:     needs:
 53:       - SetRegion
 54:     permissions:
 55:       contents: write
 56:       actions: write
 57:       id-token: write
 58:     env:
 59:       AWS_REGION: ${{ needs.SetRegion.outputs.region_code }}
 60: 
 61: 
 62:       TF_VAR_openldap_admin_password: ${{ secrets.TF_VAR_OPENLDAP_ADMIN_PASSWORD }}
 63:       TF_VAR_openldap_config_password: ${{ secrets.TF_VAR_OPENLDAP_CONFIG_PASSWORD }}
 64: 
 65:       TF_VAR_redis_password: ${{ secrets.TF_VAR_REDIS_PASSWORD }}
 66: 
 67:       TF_VAR_postgresql_database_password: ${{ secrets.TF_VAR_POSTGRESQL_PASSWORD }}
 68:     defaults:
 69:       run:
 70:         working-directory: ./application
 71:     steps:
 72:       - name: Checkout the repo code
 73:         uses: actions/checkout@v4
 74: 
 75:       - name: Setup terraform
 76:         uses: hashicorp/setup-terraform@v3
 77:         with:
 78:           terraform_version: 1.14.0
 79: 
 80:       - name: Export environment variables for set-k8s-env.sh
 81:         run: |
 82: 
 83:           echo "BACKEND_FILE=backend.hcl" >> $GITHUB_ENV
 84:           echo "VARIABLES_FILE=variables.tfvars" >> $GITHUB_ENV
 85:           echo "ENVIRONMENT=${{ inputs.environment }}" >> $GITHUB_ENV
 86: 
 87:           if [ "${{ inputs.environment }}" = "prod" ]; then
 88:             echo "DEPLOYMENT_ROLE_ARN=${{ secrets.AWS_PRODUCTION_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 89:           else
 90:             echo "DEPLOYMENT_ROLE_ARN=${{ secrets.AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 91:           fi
 92:           echo "EXTERNAL_ID=${{ secrets.AWS_ASSUME_EXTERNAL_ID }}" >> $GITHUB_ENV
 93: 
 94:           echo "STATE_ACCOUNT_ROLE_ARN=${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}" >> $GITHUB_ENV
 95: 
 96:       - name: Setup Docker Buildx
 97:         uses: docker/setup-buildx-action@v3
 98: 
 99:       - name: Configure AWS credentials (State Account)
100:         uses: aws-actions/configure-aws-credentials@v4
101:         with:
102:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
103:           role-session-name: GitHubActions-ApplicationInfraProvision-State
104:           aws-region: ${{ env.AWS_REGION }}
105: 
106:       - name: Create backend.hcl from placeholder
107:         run: |
108: 
109:           if [ ! -f "backend.hcl" ]; then
110:             cp tfstate-backend-values-template.hcl backend.hcl
111:             sed -i -e "s|<BACKEND_BUCKET_NAME>|${{ vars.BACKEND_BUCKET_NAME }}|g" \
112:             -e "s|<APPLICATION_PREFIX>|${{ vars.APPLICATION_PREFIX }}|g" \
113:             -e "s|<AWS_REGION>|${{ env.AWS_REGION }}|g" \
114:             backend.hcl
115:             echo "Created backend.hcl:"
116:             cat backend.hcl
117:           else
118:             echo "backend.hcl already exists. Skipping creation."
119:           fi
120: 
121:       - name: Terraform init
122:         run: terraform init -backend-config=backend.hcl
123: 
124:       - name: Terraform workspace
125:         run: |
126:           WORKSPACE="${{ env.AWS_REGION }}-${{ inputs.environment }}"
127:           terraform workspace select $WORKSPACE || terraform workspace new $WORKSPACE
128: 
129:       - name: Terraform validate
130:         run: terraform validate
131: 
132:       - name: Mirror Docker images to ECR
133:         run: |
134: 
135: 
136: 
137: 
138: 
139:           chmod +x ./mirror-images-to-ecr.sh
140:           ./mirror-images-to-ecr.sh
141: 
142:       - name: Set Kubernetes environment variables
143:         run: |
144: 
145: 
146:           chmod +x ./set-k8s-env.sh
147:           source ./set-k8s-env.sh
148: 
149:           echo "TF_VAR_kubernetes_master=$KUBERNETES_MASTER" >> $GITHUB_ENV
150:           echo "TF_VAR_kube_config_path=$KUBE_CONFIG_PATH" >> $GITHUB_ENV
151: 
152:       - name: Configure AWS credentials (State Account for Terraform)
153:         uses: aws-actions/configure-aws-credentials@v4
154:         with:
155:           role-to-assume: ${{ secrets.AWS_STATE_ACCOUNT_ROLE_ARN }}
156:           role-session-name: GitHubActions-ApplicationInfraProvision-Terraform
157:           aws-region: ${{ env.AWS_REGION }}
158: 
159:       - name: Terraform plan
160:         run: terraform plan -var-file="variables.tfvars" -out terraform.tfplan
161: 
162:       - name: Provision application infrastructure
163:         run: terraform apply -auto-approve terraform.tfplan
````

## File: backend_infra/README.md
````markdown
  1: # Backend Infrastructure
  2: 
  3: This Terraform configuration creates the core AWS infrastructure required for
  4: deploying the LDAP 2FA application on Kubernetes.
  5: 
  6: ## Overview
  7: 
  8: The backend infrastructure provisions:
  9: 
 10: - **VPC** with public and private subnets across two availability zones
 11: - **EKS Cluster** (Auto Mode) for running Kubernetes workloads
 12: - **IRSA** (IAM Roles for Service Accounts) for secure AWS API access from pods
 13: - **VPC Endpoints** for secure access to AWS services (SSM, STS, SNS)
 14: - **ECR Repository** for container image storage with lifecycle policies
 15: 
 16: > [!NOTE]
 17: >
 18: > The EBS module exists but is currently commented out in `main.tf`.
 19: > Storage classes and PVCs are created by the application infrastructure instead.
 20: 
 21: ## Architecture
 22: 
 23: ```ascii
 24: 
 25:                               VPC                               
 26:                                                                 
 27:                         
 28:    Public Subnet 1                       Public Subnet 2    
 29:                                                             
 30:                         
 31:                                                               
 32:             IGW             
 33:                                                                 
 34:                         
 35:    Private Subnet 1                      Private Subnet 2   
 36:                                                             
 37:                                 
 38:      EKS Nodes                           EKS Nodes      
 39:                                                         
 40:                                               
 41:       Pods                                            
 42:       (IRSA)                                          
 43:                                               
 44:                                 
 45:                                                             
 46:                                 
 47:      VPC                                 VPC            
 48:      Endpoints                           Endpoints      
 49:      SSM/STS/                            SSM/STS/       
 50:      SNS                                 SNS            
 51:                                 
 52:                         
 53:                                                               
 54:             NAT Gateway             
 55: 
 56: ```
 57: 
 58: ## Components
 59: 
 60: ### 1. VPC Module
 61: 
 62: Creates a Virtual Private Cloud with:
 63: 
 64: - **Public Subnets**: For internet-facing resources (Load Balancers)
 65:   - Tagged with `kubernetes.io/role/elb = 1` for ALB placement
 66: - **Private Subnets**: For EKS nodes and application workloads
 67:   - Tagged with `kubernetes.io/role/internal-elb = 1` for internal load
 68:   balancers
 69: - **NAT Gateway**: Single NAT gateway for cost optimization (private subnet
 70: internet access)
 71: - **Internet Gateway**: For public subnet internet access
 72: - **Route Tables**: Properly configured for public and private subnets
 73: - **DNS Support**: Enabled for service discovery (`enable_dns_hostnames = true`,
 74: `enable_dns_support = true`)
 75: - **DHCP Options**: Configured with domain name `ec2.internal`
 76: 
 77: **Key Configuration:**
 78: 
 79: - Uses `terraform-aws-modules/vpc/aws` module (version 6.5.1)
 80: - Kubernetes-specific tags for EKS integration:
 81:   - `kubernetes.io/cluster/${cluster_name} = "shared"` on all subnets
 82:   - `kubernetes.io/role/elb = 1` on public subnets
 83:   - `kubernetes.io/role/internal-elb = 1` on private subnets
 84: - Two availability zones for high availability
 85: - Subnets automatically named: `${vpc_name}-public-subnet-{1,2}` and
 86: `${vpc_name}-private-subnet-{1,2}`
 87: 
 88: ### 2. EKS Cluster
 89: 
 90: Deploys an Amazon EKS cluster in Auto Mode:
 91: 
 92: - **Auto Mode**: Simplified cluster management with automatic node provisioning
 93:   - Enabled via `compute_config.enabled = true`
 94:   - Uses "general-purpose" node pool
 95: - **IRSA (IAM Roles for Service Accounts)**: Enabled via `enable_irsa = true`
 96:   - Creates OIDC provider for the cluster
 97:   - Allows pods to assume IAM roles for AWS service access
 98:   - Required for secure SNS access for SMS 2FA
 99:   - ExternalId support for enhanced cross-account role assumption security
100: - **Elastic Load Balancing**: Automatically enabled by default with Auto Mode
101:   - No explicit configuration needed - `elastic_load_balancing` capability is
102:   enabled by default
103:   - Supports ALB provisioning via EKS Auto Mode Ingress
104: - **Public Endpoint**: API server accessible from internet
105: (`endpoint_public_access = true` for kubectl access)
106: - **Logging**: CloudWatch logging enabled for:
107:   - API server
108:   - Audit logs
109:   - Authenticator
110:   - Controller manager
111:   - Scheduler
112: - **Node IAM Policies**: Includes SSM access for Session Manager
113: (`AmazonSSMManagedInstanceCore`)
114: 
115: **Key Configuration:**
116: 
117: - Uses `terraform-aws-modules/eks/aws` module (version 21.9.0)
118: - Kubernetes version specified via `k8s_version` variable
119: - Compute config with "general-purpose" node pool
120: - Cluster creator has admin permissions
121: (`enable_cluster_creator_admin_permissions = true`)
122: - Nodes deployed in private subnets
123: - CloudWatch log group created automatically
124: 
125: ### 3. VPC Endpoints Module
126: 
127: The VPC Endpoints module creates PrivateLink endpoints for secure access to
128: AWS services from EKS nodes without requiring internet gateway access.
129: It creates SSM endpoints (always enabled), STS endpoint (optional, default: enabled)
130: for IRSA, and SNS endpoint (optional, default: disabled) for SMS 2FA.
131: 
132: > [!NOTE]
133: >
134: > For detailed VPC endpoints configuration, security setup, IRSA integration,
135: > cost considerations, and usage examples, see the [VPC Endpoints Module Documentation](modules/endpoints/README.md).
136: 
137: ### 4. ECR Module
138: 
139: The ECR module creates a private Docker registry for application images with
140: configurable lifecycle policies and image tag mutability settings.
141: 
142: > [!NOTE]
143: >
144: > For detailed ECR configuration, lifecycle policies, and usage examples,
145: > see the [ECR Module Documentation](modules/ecr/README.md).
146: 
147: ## Module Structure
148: 
149: ```bash
150: backend_infra/
151:  main.tf                        # Main infrastructure configuration
152:  variables.tf                   # Variable definitions
153:  variables.tfvars               # Variable values (customize for your environment)
154:  outputs.tf                     # Output values
155:  providers.tf                   # Provider configuration (AWS, Kubernetes)
156:  backend.hcl                    # Terraform backend configuration (generated)
157:  tfstate-backend-values-template.hcl  # Backend config template
158:  CHANGELOG.md                   # Change log for this module
159:  setup-backend.sh               # Backend setup script (GitHub CLI)
160:  modules/
161:      ebs/                       # EBS storage resources (currently commented out in main.tf)
162:         main.tf
163:         variables.tf
164:         outputs.tf
165:         README.md
166:      ecr/                       # ECR repository
167:         main.tf
168:         variables.tf
169:         outputs.tf
170:         README.md
171:      endpoints/                 # VPC endpoints (SSM, STS, SNS)
172:          main.tf
173:          variables.tf
174:          outputs.tf
175:          README.md
176: ```
177: 
178: ## Destroying Infrastructure
179: 
180: > [!WARNING]
181: >
182: > Destroying infrastructure is a **destructive operation** that permanently
183: > deletes all resources. This action **cannot be undone**. Always ensure you have
184: > backups and understand the consequences before proceeding.
185: 
186: ### Option 1: Using Destroy Script (Local)
187: 
188: ```bash
189: cd backend_infra
190: ./destroy-backend.sh
191: ```
192: 
193: The script will:
194: 
195: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
196: - Retrieve repository variables from GitHub
197: - Retrieve role ARNs and ExternalId from AWS Secrets Manager
198: - Generate `backend.hcl` from template (if it doesn't exist)
199: - Update `variables.tfvars` with selected region, environment, deployment account
200:   role ARN, and ExternalId
201: - Run Terraform destroy commands (init, workspace, validate, plan destroy, apply
202:   destroy) automatically
203: - **Requires confirmation**: Type 'yes' to confirm, then 'DESTROY' to proceed
204: 
205: ### Option 2: Using GitHub Actions Workflow
206: 
207: 1. Go to GitHub  Actions tab
208: 2. Select "Backend Infrastructure Destroying" workflow
209: 3. Click "Run workflow"
210: 4. Select environment (prod or dev) and region
211: 5. Click "Run workflow"
212: 
213: The workflow will:
214: 
215: - Use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations
216: - Use environment-specific deployment account role ARN
217: - Use `AWS_ASSUME_EXTERNAL_ID` for cross-account role assumption
218: - Run Terraform destroy operations automatically
219: 
220: > [!IMPORTANT]
221: >
222: > **Destroy Order**: Backend infrastructure should be destroyed after application
223: > infrastructure. Ensure all application resources are destroyed first before
224: > destroying the backend infrastructure.
225: 
226: ## Prerequisites
227: 
228: 1. **Terraform Backend**: The Terraform state backend must be provisioned first
229: (see [tf_backend_state/README.md](../tf_backend_state/README.md))
230: 2. **Multi-Account Setup**:
231:    - **Account A (State Account)**: Stores Terraform state in S3
232:      - GitHub Actions uses `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state
233:      operations
234:    - **Account B (Production/Development Accounts)**: Contains infrastructure
235:    resources (VPC, EKS, etc.)
236:      - Terraform provider assumes deployment account role via `assume_role`
237:      configuration
238:      - Role selection based on environment:
239:        - `prod` environment  uses `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` (set in
240:        `deployment_account_role_arn` variable)
241:        - `dev` environment  uses `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` (set in
242:        `deployment_account_role_arn` variable)
243: 3. **AWS SSO/OIDC**: Configured GitHub OIDC provider and IAM roles (see main
244: [README.md](../README.md))
245: 4. **Backend Configuration**: Generate `backend.hcl` using the setup scripts
246: (see main [README.md](../README.md))
247: 5. **GitHub Secrets**: Ensure `AWS_STATE_ACCOUNT_ROLE_ARN`,
248: `AWS_PRODUCTION_ACCOUNT_ROLE_ARN`, `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`, and
249: `AWS_ASSUME_EXTERNAL_ID` are configured in repository secrets
250: 
251: ## Key Variables
252: 
253: ### Required Variables
254: 
255: | Variable | Description | Type |
256: | ---------- | ------------- | ------ |
257: | `env` | Deployment environment (prod, dev) | `string` |
258: | `region` | AWS region (us-east-1, us-east-2) | `string` |
259: | `prefix` | Prefix for all resource names | `string` |
260: | `vpc_cidr` | CIDR block for VPC | `string` |
261: | `k8s_version` | Kubernetes version for EKS cluster | `string` |
262: 
263: ### Optional Variables
264: 
265: | Variable | Description | Default |
266: | ---------- | ------------- | --------- |
267: | `deployment_account_role_arn` | ARN of IAM role in Account B to assume for resource deployment | `null` |
268: | `deployment_account_external_id` | ExternalId for cross-account role assumption security (must match Trust Relationship) | `null` |
269: | `enable_sts_endpoint` | Whether to create STS VPC endpoint (required for IRSA) | `true` |
270: | `enable_sns_endpoint` | Whether to create SNS VPC endpoint (required for SMS 2FA) | `false` |
271: 
272: ### ExternalId Configuration
273: 
274: ExternalId is required for enhanced security when assuming deployment account roles:
275: 
276: - **Purpose**: Prevents confused deputy attacks in multi-account deployments
277: - **Generation**: `openssl rand -hex 32`
278: - **Storage**:
279:   - AWS Secrets Manager: Plain text secret named `external-id` (for local scripts)
280:   - GitHub: Repository secret `AWS_ASSUME_EXTERNAL_ID` (for GitHub Actions)
281: - **Requirement**: Must match the ExternalId configured in deployment account role
282: Trust Relationships
283: - **Bidirectional Trust**: Both deployment account roles and state account role
284: must trust each other
285: 
286: ### Important Configuration
287: 
288: - **Naming Convention**: All resources follow the pattern
289: `${prefix}-${region}-${name}-${env}`
290: - **Workspace-based State**: Uses Terraform workspaces named `${region}-${env}`
291: - **Single NAT Gateway**: Configured for cost optimization (can be changed to
292: `false` for HA)
293: - **IRSA**: Enabled by default with STS endpoint for secure AWS API access from
294: pods
295: - **ExternalId Security**: ExternalId required for cross-account role assumption
296:   (retrieved from AWS Secrets Manager or GitHub secrets)
297: 
298: ## Outputs
299: 
300: The infrastructure provides outputs for:
301: 
302: ### AWS Account & Region
303: 
304: | Output | Description |
305: | -------- | ------------- |
306: | `aws_account` | AWS Account ID |
307: | `region` | AWS region |
308: | `env` | Deployment environment |
309: | `prefix` | Resource name prefix |
310: 
311: ### VPC
312: 
313: | Output | Description |
314: | -------- | ------------- |
315: | `vpc_id` | VPC ID |
316: | `default_security_group_id` | Default VPC security group ID |
317: | `public_subnets` | List of public subnet IDs |
318: | `private_subnets` | List of private subnet IDs |
319: | `igw_id` | Internet Gateway ID |
320: 
321: ### EKS Cluster
322: 
323: | Output | Description |
324: | -------- | ------------- |
325: | `cluster_name` | EKS cluster name (format: `${prefix}-${region}-${cluster_name}-${env}`) |
326: | `cluster_endpoint` | EKS Cluster API endpoint |
327: | `cluster_arn` | EKS Cluster ARN |
328: | `oidc_provider_arn` | OIDC provider ARN for creating IRSA IAM roles |
329: | `oidc_provider_url` | OIDC provider URL (without `https://`) |
330: 
331: ### VPC Endpoints
332: 
333: | Output | Description |
334: | -------- | ------------- |
335: | `vpc_endpoint_sg_id` | Security group ID for VPC endpoints |
336: | `vpc_endpoint_ssm_id` | VPC endpoint ID for SSM |
337: | `vpc_endpoint_ssmmessages_id` | VPC endpoint ID for SSM Messages |
338: | `vpc_endpoint_ec2messages_id` | VPC endpoint ID for EC2 Messages |
339: | `vpc_endpoint_sts_id` | VPC endpoint ID for STS (null if disabled) |
340: | `vpc_endpoint_sns_id` | VPC endpoint ID for SNS (null if disabled) |
341: | `vpc_endpoint_ids` | List of all enabled VPC endpoint IDs |
342: 
343: ### ECR
344: 
345: | Output | Description |
346: | -------- | ------------- |
347: | `ecr_name` | ECR repository name |
348: | `ecr_arn` | ECR repository ARN |
349: | `ecr_url` | ECR repository URL for Docker image push/pull operations |
350: 
351: > [!NOTE]
352: >
353: > EBS outputs are commented out since the EBS module is not currently active.
354: 
355: Use `terraform output` to view all available outputs.
356: 
357: ## IRSA (IAM Roles for Service Accounts)
358: 
359: The backend infrastructure enables IRSA for secure AWS API access from
360: Kubernetes pods:
361: 
362: ### How IRSA Works
363: 
364: 1. EKS cluster has an OIDC provider (`enable_irsa = true`)
365: 2. STS VPC endpoint allows pods to call `sts:AssumeRoleWithWebIdentity`
366: 3. Pods use Kubernetes service accounts annotated with IAM role ARNs
367: 4. AWS SDK automatically assumes the IAM role using the service account token
368: 
369: ### Using IRSA in Application Infrastructure
370: 
371: To use IRSA in your application:
372: 
373: 1. Reference the OIDC provider outputs from this module:
374: 
375:    ```hcl
376:    data "terraform_remote_state" "backend_infra" {
377:      backend = "s3"
378:      # ... configuration
379:    }
380: 
381:    # Create IAM role with OIDC trust policy
382:    resource "aws_iam_role" "app_role" {
383:      name = "app-role"
384:      assume_role_policy = jsonencode({
385:        Version = "2012-10-17"
386:        Statement = [{
387:          Effect = "Allow"
388:          Principal = {
389:            Federated = data.terraform_remote_state.backend_infra.outputs.oidc_provider_arn
390:          }
391:          Action = "sts:AssumeRoleWithWebIdentity"
392:          Condition = {
393:            StringEquals = {
394:              "${data.terraform_remote_state.backend_infra.outputs.oidc_provider_url}:sub" = "system:serviceaccount:NAMESPACE:SERVICE_ACCOUNT_NAME"
395:            }
396:          }
397:        }]
398:      })
399:    }
400:    ```
401: 
402: 2. Create a Kubernetes service account with the IAM role annotation:
403: 
404:    ```yaml
405:    apiVersion: v1
406:    kind: ServiceAccount
407:    metadata:
408:      name: my-app
409:      namespace: my-namespace
410:      annotations:
411:        eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/app-role
412:    ```
413: 
414: 3. Use the service account in your pod/deployment
415: 
416: ### SMS 2FA with SNS
417: 
418: To enable SMS 2FA functionality:
419: 
420: 1. Set `enable_sns_endpoint = true` in your variables
421: 2. Create an IAM role with SNS publish permissions using IRSA
422: 3. Annotate your backend service account with the IAM role ARN
423: 4. The backend can call `sns.publish()` to send SMS verification codes
424: 
425: ## Security Considerations
426: 
427: 1. **Private Subnets**: EKS nodes are deployed in private subnets (no public
428: IPs)
429: 2. **VPC Endpoints**: Enable secure access to AWS services without internet
430: exposure
431:    - SSM endpoints for node access
432:    - STS endpoint for IRSA (IAM role assumption)
433:    - SNS endpoint for SMS 2FA (optional)
434: 3. **IRSA**: Pods assume IAM roles via OIDC, not long-lived credentials
435: 4. **Public API Endpoint**: EKS API server is publicly accessible (required for
436: kubectl access)
437: 5. **IAM Permissions**:
438:    - Cluster creator has admin permissions
439:    - Nodes have SSM access via `AmazonSSMManagedInstanceCore` policy
440:    - Pods assume minimal IAM roles via IRSA
441: 6. **Network Isolation**: Proper security group rules restrict access
442:    - VPC endpoints accept traffic only from node security group and VPC CIDR
443: 7. **Kubernetes Tags**: Subnets are properly tagged for Kubernetes integration
444: 8. **CloudWatch Logging**: Comprehensive logging enabled for audit and security
445: monitoring
446: 
447: ## Cost Optimization
448: 
449: - **Single NAT Gateway**: Reduces NAT gateway costs (trade-off: single point of
450: failure)
451: - **EKS Auto Mode**: Simplified and cost-effective node management
452: - **Lifecycle Policies**: ECR lifecycle policies help manage storage costs
453: - **VPC Endpoints**: Consider which endpoints you need:
454:   - SSM endpoints: Required for node access without bastion hosts (always enabled)
455:   - STS endpoint: Required for IRSA (enabled by default)
456:   - SNS endpoint: Only enable if using SMS 2FA (disabled by default)
457:   - Estimated cost per endpoint: ~$7-10/month per availability zone
458: - **ExternalId Security**: ExternalId required for cross-account role assumption
459:   to prevent confused deputy attacks
460: 
461: ## Troubleshooting
462: 
463: ### Common Issues
464: 
465: 1. **Cluster Not Accessible**: Ensure `backend.hcl` is configured correctly and
466: remote state is accessible
467: 2. **SSM Access**: Ensure VPC endpoints are fully created and security groups
468: allow traffic
469: 3. **Node Access**: Use `aws ssm start-session` instead of SSH for private nodes
470: (no public IPs)
471: 4. **Kubectl Connection**: Ensure kubeconfig is updated: `aws eks
472: update-kubeconfig --name <cluster-name> --region <region>`
473: 5. **IRSA Not Working**:
474:    - Verify STS endpoint is enabled (`enable_sts_endpoint = true`)
475:    - Check service account has correct annotation
476:    - Verify IAM role trust policy references correct OIDC provider
477:    - Check pod logs for AWS SDK errors
478: 6. **SNS SMS Failing**:
479:    - Verify SNS endpoint is enabled (`enable_sns_endpoint = true`)
480:    - Check IAM role has SNS publish permissions
481:    - Verify service account annotation is correct
482: 
483: ### Useful Commands
484: 
485: ```bash
486: # Check cluster status
487: aws eks describe-cluster --name <cluster-name> --region <region>
488: 
489: # View cluster outputs
490: terraform output
491: 
492: # Update kubeconfig
493: aws eks update-kubeconfig --name $(terraform output -raw cluster_name) --region $(terraform output -raw region)
494: 
495: # Access node via SSM (get instance ID from EKS console or AWS CLI)
496: aws ssm start-session --target <instance-id>
497: 
498: # Check VPC endpoints
499: aws ec2 describe-vpc-endpoints --filters "Name=vpc-id,Values=$(terraform output -raw vpc_id)"
500: 
501: # View CloudWatch logs
502: aws logs describe-log-groups --log-group-name-prefix /aws/eks/$(terraform output -raw cluster_name)
503: 
504: # Verify OIDC provider
505: aws iam list-open-id-connect-providers
506: 
507: # Check OIDC provider details
508: aws eks describe-cluster --name $(terraform output -raw cluster_name) --query "cluster.identity.oidc.issuer"
509: ```
510: 
511: ## Related Documentation
512: 
513: - [Application Infrastructure](../application/README.md) - OpenLDAP, 2FA app,
514: PostgreSQL, Redis, SES, and ArgoCD deployment
515: - [Terraform Backend State](../tf_backend_state/README.md) - S3 state management
516: - [Main README](../README.md) - Project overview and quick start
517: 
518: ## References
519: 
520: - [AWS EKS Documentation](https://docs.aws.amazon.com/eks/)
521: - [Terraform AWS VPC Module](https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws)
522: - [Terraform AWS EKS Module](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws)
523: - [IRSA Documentation](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html)
524: - [AWS VPC Endpoints](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html)
525: - [AWS SNS SMS](https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html)
526: - [AWS SES](https://docs.aws.amazon.com/ses/latest/dg/Welcome.html)
````

## File: docs/index.html
````html
   1: <!DOCTYPE html>
   2: <html lang="en">
   3: <head>
   4:     <meta charset="UTF-8">
   5:     <meta name="viewport" content="width=device-width, initial-scale=1.0">
   6:     <title>LDAP 2FA on Kubernetes - Documentation</title>
   7:     <link rel="icon" type="image/x-icon" href="favicon.ico">
   8:     <link rel="stylesheet" href="light-theme.css" id="theme-stylesheet">
   9: </head>
  10: <body>
  11: 
  12:     <nav class="navbar">
  13:         <div class="nav-container">
  14:             <a href="#hero" class="nav-logo">LDAP 2FA on K8s</a>
  15:             <button class="mobile-menu-toggle" id="mobileMenuToggle"></button>
  16:             <ul class="nav-menu" id="navMenu">
  17:                 <li><a href="#content-index">Content Index</a></li>
  18:                 <li><a href="#overview">Overview</a></li>
  19:                 <li><a href="#getting-started">Getting Started</a></li>
  20:                 <li><a href="#architecture">Architecture</a></li>
  21:                 <li><a href="#documentation">Documentation</a></li>
  22:                 <li><a href="#access">Access</a></li>
  23:                 <li><a href="#security">Security</a></li>
  24:                 <li><a href="#support">Support</a></li>
  25:                 <li>
  26:                     <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
  27:                         <span class="icon" id="sunIcon" title="Switch to light theme"></span>
  28:                         <span class="icon hidden" id="moonIcon" title="Switch to dark theme"></span>
  29:                     </button>
  30:                 </li>
  31:             </ul>
  32:         </div>
  33:     </nav>
  34: 
  35:     <section id="hero" class="hero">
  36:         <div class="hero-content">
  37:             <h1>LDAP Authentication with 2FA on Kubernetes</h1>
  38:             <p>Complete LDAP authentication solution with two-factor authentication, self-service password management, and GitOps capabilities on Amazon EKS</p>
  39:             <img src="header_banner.png" alt="Project Banner" class="hero-banner">
  40:         </div>
  41:     </section>
  42: 
  43:     <section id="content-index">
  44:         <h2>Content Index</h2>
  45:         <div class="card">
  46:             <ul>
  47:                 <li><a href="#overview">Project Overview</a>
  48:                     <ul>
  49:                         <li><a href="#core-infrastructure">Core Infrastructure</a></li>
  50:                         <li><a href="#ldap-stack">LDAP Stack</a></li>
  51:                         <li><a href="#2fa-application">2FA Application</a></li>
  52:                         <li><a href="#supporting-infrastructure">Supporting Infrastructure</a></li>
  53:                         <li><a href="#devops-security">DevOps & Security</a></li>
  54:                         <li><a href="#key-features">Key Features</a></li>
  55:                     </ul>
  56:                 </li>
  57:                 <li><a href="#getting-started">Getting Started</a>
  58:                     <ul>
  59:                         <li><a href="#prerequisites">Prerequisites</a></li>
  60:                         <li><a href="#deployment-options">Deployment Options</a>
  61:                             <ul>
  62:                                 <li><a href="#local-deployment">Local Deployment</a>
  63:                                     <ul>
  64:                                         <li><a href="#local-step-1">Step 1: Deploy Terraform Backend State Infrastructure</a></li>
  65:                                         <li><a href="#local-step-2">Step 2: Deploy Backend Infrastructure</a></li>
  66:                                         <li><a href="#local-step-3">Step 3: Deploy Application Infrastructure</a></li>
  67:                                         <li><a href="#local-destroy">Destroying Infrastructure (Local)</a></li>
  68:                                     </ul>
  69:                                 </li>
  70:                                 <li><a href="#github-actions-deployment">GitHub Actions Deployment</a>
  71:                                     <ul>
  72:                                         <li><a href="#github-step-1">Step 1: Deploy Terraform Backend State Infrastructure</a></li>
  73:                                         <li><a href="#github-step-2">Step 2: Deploy Backend Infrastructure</a></li>
  74:                                         <li><a href="#github-step-3">Step 3: Deploy Application Infrastructure</a></li>
  75:                                         <li><a href="#github-destroy">Destroying Infrastructure (GitHub Actions)</a></li>
  76:                                     </ul>
  77:                                 </li>
  78:                             </ul>
  79:                         </li>
  80:                         <li><a href="#deployment-comparison">Deployment Comparison</a></li>
  81:                         <li><a href="#deployment-order">Deployment Order</a></li>
  82:                     </ul>
  83:                 </li>
  84:                 <li><a href="#architecture">Architecture</a>
  85:                     <ul>
  86:                         <li><a href="#multi-account-architecture">Multi-Account Architecture</a></li>
  87:                         <li><a href="#how-it-works">How It Works</a></li>
  88:                         <li><a href="#project-structure">Project Structure</a></li>
  89:                         <li><a href="#backend-infrastructure-components">Backend Infrastructure Components</a></li>
  90:                         <li><a href="#application-infrastructure-components">Application Infrastructure Components</a></li>
  91:                     </ul>
  92:                 </li>
  93:                 <li><a href="#documentation">Documentation</a>
  94:                     <ul>
  95:                         <li><a href="#infrastructure-documentation">Infrastructure Documentation</a></li>
  96:                         <li><a href="#application-documentation">Application Documentation</a></li>
  97:                         <li><a href="#module-documentation">Module Documentation</a></li>
  98:                         <li><a href="#configuration-documentation">Configuration Documentation</a></li>
  99:                         <li><a href="#security-operations">Security & Operations</a></li>
 100:                     </ul>
 101:                 </li>
 102:                 <li><a href="#access">Accessing the Services</a>
 103:                     <ul>
 104:                         <li><a href="#2fa-application-access">2FA Application</a></li>
 105:                         <li><a href="#phpldapadmin-access">PhpLdapAdmin</a></li>
 106:                         <li><a href="#ltb-passwd-access">LTB-passwd</a></li>
 107:                         <li><a href="#argocd-access">ArgoCD</a></li>
 108:                         <li><a href="#ldap-service-access">LDAP Service</a></li>
 109:                         <li><a href="#mfa-methods">MFA Methods</a></li>
 110:                     </ul>
 111:                 </li>
 112:                 <li><a href="#security">Security Considerations</a>
 113:                     <ul>
 114:                         <li><a href="#key-security-features">Key Security Features</a></li>
 115:                     </ul>
 116:                 </li>
 117:                 <li><a href="#support">Contributing & Support</a>
 118:                     <ul>
 119:                         <li><a href="#troubleshooting">Troubleshooting</a></li>
 120:                         <li><a href="#repository">Repository</a></li>
 121:                         <li><a href="#license">License</a></li>
 122:                     </ul>
 123:                 </li>
 124:             </ul>
 125:         </div>
 126:     </section>
 127: 
 128:     <section id="overview">
 129:         <h2>Project Overview</h2>
 130:         <div class="card">
 131:             <p>This project deploys a complete LDAP authentication solution with two-factor authentication (2FA), self-service password management, and GitOps capabilities on Amazon EKS using Terraform.</p>
 132:         </div>
 133:         <h3 id="core-infrastructure">Core Infrastructure</h3>
 134:         <div class="card">
 135:             <ul>
 136:                 <li><strong>EKS Cluster</strong> (Auto Mode) with IRSA for secure pod-to-AWS-service authentication</li>
 137:                 <li><strong>VPC</strong> with public/private subnets and VPC endpoints for private AWS service access</li>
 138:                 <li><strong>Application Load Balancer (ALB)</strong> via EKS Auto Mode for internet-facing access</li>
 139:                 <li><strong>Route53 DNS</strong> integration for domain management</li>
 140:                 <li><strong>ACM Certificates</strong> for HTTPS/TLS termination</li>
 141:             </ul>
 142:         </div>
 143:         <h3 id="ldap-stack">LDAP Stack</h3>
 144:         <div class="card">
 145:             <ul>
 146:                 <li><strong>OpenLDAP Stack</strong> with high availability and multi-master replication</li>
 147:                 <li><strong>PhpLdapAdmin</strong> web interface for LDAP administration</li>
 148:                 <li><strong>LTB-passwd</strong> self-service password management UI</li>
 149:             </ul>
 150:         </div>
 151:         <h3 id="2fa-application">2FA Application</h3>
 152:         <div class="card">
 153:             <ul>
 154:                 <li><strong>Full-stack 2FA application</strong> with Python FastAPI backend and static HTML/JS/CSS frontend</li>
 155:                 <li><strong>Dual MFA methods</strong>: TOTP (authenticator apps) and SMS (AWS SNS)</li>
 156:                 <li><strong>LDAP integration</strong> for centralized user authentication</li>
 157:                 <li><strong>Self-service user registration</strong> with email/phone verification and profile state management</li>
 158:                 <li><strong>Admin dashboard</strong> for user management, group CRUD operations, and approval workflows</li>
 159:                 <li><strong>User profile management</strong> with edit restrictions for verified fields</li>
 160:                 <li><strong>Interactive API documentation</strong> via Swagger UI and ReDoc (always enabled)</li>
 161:             </ul>
 162:         </div>
 163:         <h3 id="supporting-infrastructure">Supporting Infrastructure</h3>
 164:         <div class="card">
 165:             <ul>
 166:                 <li><strong>PostgreSQL</strong> (Bitnami Helm chart, OCI registry) for user registration data and email verification token storage with persistent EBS-backed storage</li>
 167:                 <li><strong>Redis</strong> (Bitnami Helm chart) for SMS OTP code storage with TTL-based automatic expiration and shared state across replicas</li>
 168:                 <li><strong>AWS SES</strong> for email verification and notifications with IRSA-based access (no hardcoded credentials)</li>
 169:                 <li><strong>AWS SNS</strong> for SMS-based 2FA verification (optional, requires SNS VPC endpoint enabled in backend infrastructure)</li>
 170:             </ul>
 171:         </div>
 172:         <h3 id="devops-security">DevOps & Security</h3>
 173:         <div class="card">
 174:             <ul>
 175:                 <li><strong>ArgoCD</strong> (AWS EKS managed service) for GitOps deployments with AWS Identity Center authentication</li>
 176:                 <li><strong>cert-manager</strong> for automatic TLS certificate management</li>
 177:                 <li><strong>Network Policies</strong> for securing pod-to-pod communication with cross-namespace support</li>
 178:                 <li><strong>IRSA</strong> (IAM Roles for Service Accounts) for secure AWS API access from pods without credentials</li>
 179:                 <li><strong>VPC Endpoints</strong> for private AWS service access (SSM, STS, SNS) without internet exposure</li>
 180:                 <li><strong>Multi-Account Architecture</strong> with separated state storage and deployment accounts</li>
 181:                 <li><strong>S3 File-Based Locking</strong> for Terraform state management (migrated from DynamoDB)</li>
 182:             </ul>
 183:         </div>
 184:         <h3 id="key-features">Key Features</h3>
 185:         <div class="card">
 186:             <ul>
 187:                 <li><strong>EKS Auto Mode</strong>: Simplified cluster management with automatic load balancer provisioning and built-in EBS CSI driver</li>
 188:                 <li><strong>Two-Factor Authentication</strong>: Full-stack 2FA application with dual MFA methods (TOTP and SMS)</li>
 189:                 <li><strong>Self-Service User Registration</strong>: Email and phone verification with profile state management (PENDING  COMPLETE  ACTIVE)</li>
 190:                 <li><strong>Admin Dashboard</strong>: User management, group CRUD operations, approval workflows, and user profile management</li>
 191:                 <li><strong>IRSA Integration</strong>: Secure AWS API access from pods without hardcoded credentials via OIDC</li>
 192:                 <li><strong>High Availability</strong>: Multi-master OpenLDAP replication with persistent storage</li>
 193:                 <li><strong>GitOps Ready</strong>: ArgoCD (AWS managed service) for declarative, Git-driven deployments</li>
 194:                 <li><strong>Multi-Account Architecture</strong>: Separation of state storage (Account A) and resource deployment (Account B) for enhanced security</li>
 195:                 <li><strong>API Documentation</strong>: Interactive Swagger UI and ReDoc always available at <code>/api/docs</code> and <code>/api/redoc</code> (always enabled, not just in debug mode)</li>
 196:                 <li><strong>Secrets Management</strong>: Passwords managed via GitHub repository secrets (for CI/CD) or AWS Secrets Manager (for local deployment) with automated retrieval</li>
 197:                 <li><strong>Public ACM Certificates</strong>: Uses public ACM certificates (Amazon-issued) with DNS validation for browser-trusted certificates (no security warnings)</li>
 198:                 <li><strong>Route53 Record Module</strong>: Dedicated module for Route53 A (alias) records with cross-account support and ALB zone_id mapping</li>
 199:             </ul>
 200:         </div>
 201:     </section>
 202: 
 203:     <section id="getting-started">
 204:         <h2>Getting Started</h2>
 205:         <h3 id="prerequisites">Prerequisites</h3>
 206:         <div class="card">
 207:             <ul>
 208:                 <li><strong>AWS Account(s)</strong> with appropriate permissions
 209:                     <ul>
 210:                         <li><strong>State Account (Account A)</strong>: For Terraform state storage (S3)</li>
 211:                         <li><strong>Deployment Account (Account B)</strong>: For infrastructure resources (EKS, ALB, Route53, etc.)</li>
 212:                     </ul>
 213:                 </li>
 214:                 <li><strong>GitHub Account</strong> and repository fork: <a href="https://github.com/talorlik/ldap-2fa-on-k8s.git" target="_blank">ldap-2fa-on-k8s</a></li>
 215:                 <li><strong>AWS SSO/OIDC</strong> configured (see <a href="../README.md#github-repository-configuration">GitHub Repository Configuration</a>)</li>
 216:                 <li><strong>Route53 hosted zone</strong> must already exist (or create it manually)
 217:                     <ul>
 218:                         <li>Can be in State Account (different from deployment account) - automatically accessed via <code>state_account_role_arn</code></li>
 219:                         <li>See <a href="../application/CROSS-ACCOUNT-ACCESS.md">Cross-Account Access Documentation</a> for details</li>
 220:                     </ul>
 221:                 </li>
 222:                 <li><strong>Public ACM Certificate Setup</strong>: Public ACM certificates must be requested in each deployment account and validated using DNS records in the State Account's Route53 hosted zone
 223:                     <ul>
 224:                         <li>See <a href="../application/CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation">Public ACM Certificate Setup and DNS Validation</a> for detailed setup instructions</li>
 225:                         <li>Includes step-by-step AWS CLI commands for requesting certificates, creating DNS validation records, and verifying certificate status</li>
 226:                         <li>Each deployment account (development, production) has its own public ACM certificate</li>
 227:                         <li>Certificates are automatically renewed by ACM</li>
 228:                     </ul>
 229:                 </li>
 230:                 <li><strong>ACM certificate</strong> must already exist and be validated in the same region as the EKS cluster
 231:                     <ul>
 232:                         <li>Certificate must be a public ACM certificate (Amazon-issued) requested in the Deployment Account</li>
 233:                         <li>Certificate must exist in the Deployment Account (not State Account)</li>
 234:                         <li>Certificate must be validated and in <code>ISSUED</code> status</li>
 235:                         <li>DNS validation records must be created in Route53 hosted zone in the State Account</li>
 236:                         <li>See <a href="../application/CROSS-ACCOUNT-ACCESS.md">Cross-Account Access Documentation</a> for details</li>
 237:                     </ul>
 238:                 </li>
 239:                 <li><strong>GitHub Secrets and Variables</strong> configured (see <a href="../SECRETS_REQUIREMENTS.md">Secrets Requirements</a> for complete details):
 240:                     <ul>
 241:                         <li><strong>Required Secrets:</strong>
 242:                             <ul>
 243:                                 <li><code>AWS_STATE_ACCOUNT_ROLE_ARN</code></li>
 244:                                 <li><code>AWS_PRODUCTION_ACCOUNT_ROLE_ARN</code></li>
 245:                                 <li><code>AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN</code></li>
 246:                                 <li><code>AWS_ASSUME_EXTERNAL_ID</code></li>
 247:                                 <li><code>TF_VAR_OPENLDAP_ADMIN_PASSWORD</code></li>
 248:                                 <li><code>TF_VAR_OPENLDAP_CONFIG_PASSWORD</code></li>
 249:                                 <li><code>TF_VAR_REDIS_PASSWORD</code></li>
 250:                                 <li><code>TF_VAR_POSTGRESQL_PASSWORD</code></li>
 251:                                 <li><code>GH_TOKEN</code></li>
 252:                             </ul>
 253:                         </li>
 254:                         <li><strong>Required Variables:</strong>
 255:                             <ul>
 256:                                 <li><code>AWS_REGION</code></li>
 257:                                 <li><code>BACKEND_PREFIX</code></li>
 258:                                 <li><code>APPLICATION_PREFIX</code></li>
 259:                             </ul>
 260:                         </li>
 261:                     </ul>
 262:                 </li>
 263:                 <li><strong>For Local Deployment:</strong> GitHub CLI (<code>gh</code>), AWS CLI, Terraform, kubectl, and <code>jq</code> installed and configured</li>
 264:                 <li><strong>For Local Deployment:</strong> <strong>Docker</strong> must be installed and running for ECR image mirroring. The <code>mirror-images-to-ecr.sh</code> script requires Docker to pull images from Docker Hub and push them to ECR. This step is automatically executed by <code>setup-application.sh</code> before Terraform operations.</li>
 265:                 <li><strong>For Local Deployment:</strong> AWS Secrets Manager configured with <code>github-role</code>, <code>tf-vars</code>, and <code>external-id</code> secrets (see <a href="../SECRETS_REQUIREMENTS.md">Secrets Requirements</a>)</li>
 266:             </ul>
 267:             <p><strong>For detailed prerequisites and setup:</strong> <a href="../README.md#prerequisites">Prerequisites</a> | <a href="../README.md#secrets-configuration">Secrets Configuration</a> | <a href="../SECRETS_REQUIREMENTS.md">Secrets Requirements</a></p>
 268:         </div>
 269:         <h3 id="deployment-options">Deployment Options</h3>
 270:         <div class="deployment-options">
 271:             <div class="deployment-card">
 272:                 <h4 id="local-deployment">Local Deployment</h4>
 273:                 <p><strong>Recommended for:</strong> Development, testing, and local experimentation</p>
 274:                 <h5 id="local-step-1">Step 1: Deploy Terraform Backend State Infrastructure</h5>
 275:                 <p>Deploy the S3 bucket for Terraform state storage:</p>
 276:                 <pre><code>cd tf_backend_state
 277: ./set-state.sh</code></pre>
 278:                 <p><strong>What the script does:</strong></p>
 279:                 <ul>
 280:                     <li>Retrieves <code>AWS_STATE_ACCOUNT_ROLE_ARN</code> from AWS Secrets Manager</li>
 281:                     <li>Retrieves <code>AWS_REGION</code> and <code>BACKEND_PREFIX</code> from GitHub repository variables</li>
 282:                     <li>Assumes the IAM role and verifies credentials</li>
 283:                     <li>Checks if infrastructure exists (via <code>BACKEND_BUCKET_NAME</code> variable)</li>
 284:                     <li>If new: Runs Terraform init, validate, plan, and apply to create S3 bucket</li>
 285:                     <li>If exists: Downloads existing state file from S3 (if available)</li>
 286:                     <li>Saves/updates <code>BACKEND_BUCKET_NAME</code> to GitHub repository variables</li>
 287:                     <li>Uploads state file to S3</li>
 288:                 </ul>
 289:                 <p><strong>Alternative:</strong> Use <code>./get-state.sh</code> to download existing state file without provisioning</p>
 290:                 <h5 id="local-step-2">Step 2: Deploy Backend Infrastructure</h5>
 291:                 <p>Deploy VPC, EKS cluster, VPC endpoints, IRSA, and ECR:</p>
 292:                 <pre><code>cd backend_infra
 293: ./setup-backend.sh</code></pre>
 294:                 <p><strong>What the script does:</strong></p>
 295:                 <ul>
 296:                     <li>Prompts for AWS region (us-east-1 or us-east-2) and environment (prod or dev)</li>
 297:                     <li>Retrieves repository variables from GitHub (<code>BACKEND_BUCKET_NAME</code>, <code>BACKEND_PREFIX</code>)</li>
 298:                     <li>Retrieves role ARNs from AWS Secrets Manager (<code>github-role</code> secret)</li>
 299:                     <li>Retrieves ExternalId from AWS Secrets Manager (<code>external-id</code> secret)</li>
 300:                     <li>Assumes State Account role for backend operations</li>
 301:                     <li>Generates <code>backend.hcl</code> from template (if it doesn't exist)</li>
 302:                     <li>Updates <code>variables.tfvars</code> with selected region, environment, deployment account role ARN, and ExternalId</li>
 303:                     <li>Runs Terraform init, workspace select/new, validate, plan, and apply</li>
 304:                 </ul>
 305:                 <h5 id="local-step-3">Step 3: Deploy Application Infrastructure</h5>
 306:                 <p>Deploy OpenLDAP stack, 2FA application, ALB, Route53 records, and supporting services:</p>
 307:                 <pre><code>cd application
 308: ./setup-application.sh</code></pre>
 309:                 <p><strong>What the script does:</strong></p>
 310:                 <ul>
 311:                     <li>Prompts for AWS region (us-east-1 or us-east-2) and environment (prod or dev)</li>
 312:                     <li>Retrieves repository variables from GitHub (<code>BACKEND_BUCKET_NAME</code>, <code>APPLICATION_PREFIX</code>)</li>
 313:                     <li><strong>Mirrors Docker images to ECR</strong> (runs <code>mirror-images-to-ecr.sh</code> before Terraform operations):
 314:                         <ul>
 315:                             <li>Checks if images exist in ECR before mirroring (skips if already present)</li>
 316:                             <li>Pulls images from Docker Hub: <code>bitnami/redis:8.4.0-debian-12-r6</code>, <code>bitnami/postgresql:18.1.0-debian-12-r4</code>, <code>osixia/openldap:1.5.0</code></li>
 317:                             <li>Pushes images to ECR with tags: <code>redis-latest</code>, <code>postgresql-latest</code>, <code>openldap-1.5.0</code></li>
 318:                             <li>Uses State Account credentials to fetch ECR URL from backend_infra state</li>
 319:                             <li>Assumes Deployment Account role for ECR operations (with ExternalId)</li>
 320:                             <li>Authenticates Docker to ECR automatically</li>
 321:                             <li>Cleans up local images after pushing to save disk space</li>
 322:                             <li>Requires Docker to be installed and running</li>
 323:                             <li>Requires <code>jq</code> for JSON parsing (with fallback to sed for compatibility)</li>
 324:                         </ul>
 325:                     </li>
 326:                     <li>Retrieves role ARNs and ExternalId from AWS Secrets Manager</li>
 327:                     <li>Retrieves password secrets from AWS Secrets Manager (<code>tf-vars</code> secret) and exports as environment variables:
 328:                         <ul>
 329:                             <li><code>TF_VAR_openldap_admin_password</code></li>
 330:                             <li><code>TF_VAR_openldap_config_password</code></li>
 331:                             <li><code>TF_VAR_postgresql_database_password</code></li>
 332:                             <li><code>TF_VAR_redis_password</code></li>
 333:                         </ul>
 334:                     </li>
 335:                     <li>Assumes State Account role for backend operations</li>
 336:                     <li>Generates <code>backend.hcl</code> from template (if it doesn't exist)</li>
 337:                     <li>Updates <code>variables.tfvars</code> with selected values</li>
 338:                     <li>Sets Kubernetes environment variables using <code>set-k8s-env.sh</code></li>
 339:                     <li>Runs Terraform init, workspace select/new, validate, plan, and apply</li>
 340:                 </ul>
 341:                 <h5 id="local-destroy">Destroying Infrastructure (Local)</h5>
 342:                 <p><strong> Warning:</strong> Destroy operations are permanent and cannot be undone. Always destroy in reverse order.</p>
 343:                 <ol>
 344:                     <li><strong>Destroy Application Infrastructure:</strong>
 345:                         <pre><code>cd application
 346: ./destroy-application.sh</code></pre>
 347:                         <p>Script will prompt for region and environment, then require confirmation ('yes', then 'DESTROY')</p>
 348:                     </li>
 349:                     <li><strong>Destroy Backend Infrastructure:</strong>
 350:                         <pre><code>cd backend_infra
 351: ./destroy-backend.sh</code></pre>
 352:                         <p>Script will prompt for region and environment, then require confirmation ('yes', then 'DESTROY')</p>
 353:                     </li>
 354:                     <li><strong>Destroy State Backend (if needed):</strong>
 355:                         <pre><code>cd tf_backend_state
 356: ./get-state.sh  # Download state file first
 357: terraform plan -var-file="variables.tfvars" -destroy -out terraform.tfplan
 358: terraform apply -auto-approve terraform.tfplan</code></pre>
 359:                     </li>
 360:                 </ol>
 361:                 <p><strong>For detailed local setup instructions:</strong> <a href="../README.md#method-2-local-development">Local Development Setup</a> | <a href="../tf_backend_state/README.md#option-2-local-execution">Terraform Backend State Local Execution</a></p>
 362:             </div>
 363:             <div class="deployment-card">
 364:                 <h4 id="github-actions-deployment">GitHub Actions Deployment</h4>
 365:                 <p><strong>Recommended for:</strong> Production deployments, CI/CD pipelines, automated workflows</p>
 366:                 <h5 id="github-step-1">Step 1: Deploy Terraform Backend State Infrastructure</h5>
 367:                 <ol>
 368:                     <li>Go to GitHub  <strong>Actions</strong> tab</li>
 369:                     <li>Select <strong>"TF Backend State Provisioning"</strong> workflow</li>
 370:                     <li>Click <strong>"Run workflow"</strong>  <strong>"Run workflow"</strong></li>
 371:                     <li>Monitor the workflow execution</li>
 372:                 </ol>
 373:                 <p><strong>What the workflow does:</strong></p>
 374:                 <ul>
 375:                     <li>Uses <code>AWS_STATE_ACCOUNT_ROLE_ARN</code> secret for OIDC authentication</li>
 376:                     <li>Validates Terraform configuration</li>
 377:                     <li>Creates S3 bucket with versioning and encryption</li>
 378:                     <li>Saves bucket name as <code>BACKEND_BUCKET_NAME</code> repository variable</li>
 379:                     <li>Uploads state file to S3</li>
 380:                 </ul>
 381:                 <h5 id="github-step-2">Step 2: Deploy Backend Infrastructure</h5>
 382:                 <ol>
 383:                     <li>Go to GitHub  <strong>Actions</strong> tab</li>
 384:                     <li>Select <strong>"Backend Infra Provisioning"</strong> workflow</li>
 385:                     <li>Click <strong>"Run workflow"</strong></li>
 386:                     <li>Select <strong>region</strong> (us-east-1: N. Virginia or us-east-2: Ohio)</li>
 387:                     <li>Select <strong>environment</strong> (prod or dev)</li>
 388:                     <li>Click <strong>"Run workflow"</strong></li>
 389:                     <li>Monitor the workflow execution</li>
 390:                 </ol>
 391:                 <p><strong>What the workflow does:</strong></p>
 392:                 <ul>
 393:                     <li>Uses <code>AWS_STATE_ACCOUNT_ROLE_ARN</code> for backend state operations</li>
 394:                     <li>Uses environment-specific deployment account role ARN (<code>AWS_PRODUCTION_ACCOUNT_ROLE_ARN</code> or <code>AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN</code>)</li>
 395:                     <li>Uses <code>AWS_ASSUME_EXTERNAL_ID</code> for cross-account role assumption</li>
 396:                     <li>Runs Terraform operations to deploy VPC, EKS, VPC endpoints, IRSA, and ECR</li>
 397:                 </ul>
 398:                 <h5 id="github-step-3">Step 3: Deploy Application Infrastructure</h5>
 399:                 <ol>
 400:                     <li>Go to GitHub  <strong>Actions</strong> tab</li>
 401:                     <li>Select <strong>"Application Infra Provisioning"</strong> workflow</li>
 402:                     <li>Click <strong>"Run workflow"</strong></li>
 403:                     <li>Select <strong>region</strong> (us-east-1: N. Virginia or us-east-2: Ohio)</li>
 404:                     <li>Select <strong>environment</strong> (prod or dev)</li>
 405:                     <li>Click <strong>"Run workflow"</strong></li>
 406:                     <li>Monitor the workflow execution</li>
 407:                 </ol>
 408:                 <p><strong>What the workflow does:</strong></p>
 409:                 <ul>
 410:                     <li>Uses <code>AWS_STATE_ACCOUNT_ROLE_ARN</code> for backend state operations</li>
 411:                     <li>Uses environment-specific deployment account role ARN</li>
 412:                     <li>Uses <code>AWS_ASSUME_EXTERNAL_ID</code> for cross-account role assumption</li>
 413:                     <li>Retrieves password secrets from GitHub repository secrets</li>
 414:                     <li>Runs Terraform operations to deploy OpenLDAP, 2FA app, ALB, Route53, and supporting services</li>
 415:                 </ul>
 416:                 <h5 id="github-destroy">Destroying Infrastructure (GitHub Actions)</h5>
 417:                 <p><strong> Warning:</strong> Destroy operations are permanent and cannot be undone. Always destroy in reverse order.</p>
 418:                 <ol>
 419:                     <li><strong>Destroy Application Infrastructure:</strong>
 420:                         <ul>
 421:                             <li>Go to GitHub  <strong>Actions</strong> tab</li>
 422:                             <li>Select <strong>"Application Infra Destroying"</strong> workflow</li>
 423:                             <li>Click <strong>"Run workflow"</strong></li>
 424:                             <li>Select environment (prod or dev) and region</li>
 425:                             <li>Click <strong>"Run workflow"</strong></li>
 426:                         </ul>
 427:                     </li>
 428:                     <li><strong>Destroy Backend Infrastructure:</strong>
 429:                         <ul>
 430:                             <li>Go to GitHub  <strong>Actions</strong> tab</li>
 431:                             <li>Select <strong>"Backend Infra Destroying"</strong> workflow</li>
 432:                             <li>Click <strong>"Run workflow"</strong></li>
 433:                             <li>Select environment (prod or dev) and region</li>
 434:                             <li>Click <strong>"Run workflow"</strong></li>
 435:                         </ul>
 436:                     </li>
 437:                     <li><strong>Destroy State Backend (if needed):</strong>
 438:                         <ul>
 439:                             <li>Go to GitHub  <strong>Actions</strong> tab</li>
 440:                             <li>Select <strong>"TF Backend State Destroying"</strong> workflow</li>
 441:                             <li>Click <strong>"Run workflow"</strong>  <strong>"Run workflow"</strong></li>
 442:                         </ul>
 443:                     </li>
 444:                 </ol>
 445:                 <p><strong>For detailed GitHub Actions setup:</strong> <a href="../README.md#github-repository-configuration">GitHub Repository Configuration</a> | <a href="../README.md#method-1-github-actions-cicd">GitHub Actions Deployment</a></p>
 446:             </div>
 447:         </div>
 448:         <h3 id="deployment-comparison">Deployment Comparison</h3>
 449:         <table>
 450:             <thead>
 451:                 <tr>
 452:                     <th>Feature</th>
 453:                     <th>Local Deployment</th>
 454:                     <th>GitHub Actions</th>
 455:                 </tr>
 456:             </thead>
 457:             <tbody>
 458:                 <tr>
 459:                     <td>Setup Complexity</td>
 460:                     <td>Medium (requires local tools)</td>
 461:                     <td>Low (web-based)</td>
 462:                 </tr>
 463:                 <tr>
 464:                     <td>Best For</td>
 465:                     <td>Development, testing</td>
 466:                     <td>Production, CI/CD</td>
 467:                 </tr>
 468:                 <tr>
 469:                     <td>Requires GitHub CLI</td>
 470:                     <td>Yes</td>
 471:                     <td>No</td>
 472:                 </tr>
 473:                 <tr>
 474:                     <td>Requires GitHub Secrets</td>
 475:                     <td>Optional (can use env vars)</td>
 476:                     <td>Required</td>
 477:                 </tr>
 478:                 <tr>
 479:                     <td>Automation Level</td>
 480:                     <td>Script-based</td>
 481:                     <td>Fully automated</td>
 482:                 </tr>
 483:             </tbody>
 484:         </table>
 485:         <h3 id="deployment-order">Deployment Order</h3>
 486:         <div class="card">
 487:             <p>The deployment follows a <strong>three-tier approach</strong> that must be executed in order. Each tier depends on the previous one:</p>
 488:             <ol>
 489:                 <li><strong>Deploy Terraform Backend State Infrastructure</strong>
 490:                     <ul>
 491:                         <li><strong>Purpose:</strong> Creates S3 bucket for storing Terraform state files</li>
 492:                         <li><strong>Components:</strong> S3 bucket with versioning, encryption, and file-based locking</li>
 493:                         <li><strong>Account:</strong> State Account (Account A)</li>
 494:                         <li><strong>Local:</strong> <code>cd tf_backend_state && ./set-state.sh</code></li>
 495:                         <li><strong>GitHub Actions:</strong> "TF Backend State Provisioning" workflow</li>
 496:                         <li><strong>See:</strong> <a href="../tf_backend_state/README.md">Terraform Backend State README</a></li>
 497:                     </ul>
 498:                 </li>
 499:                 <li><strong>Deploy Backend Infrastructure</strong>
 500:                     <ul>
 501:                         <li><strong>Purpose:</strong> Creates foundational AWS infrastructure for Kubernetes workloads</li>
 502:                         <li><strong>Components:</strong> VPC with public/private subnets, EKS cluster (Auto Mode), VPC endpoints (SSM, STS, SNS), IRSA (OIDC provider), ECR repository</li>
 503:                         <li><strong>Account:</strong> Deployment Account (Account B)</li>
 504:                         <li><strong>Prerequisites:</strong> Terraform backend state must be deployed first</li>
 505:                         <li><strong>Local:</strong> <code>cd backend_infra && ./setup-backend.sh</code></li>
 506:                         <li><strong>GitHub Actions:</strong> "Backend Infra Provisioning" workflow</li>
 507:                         <li><strong>See:</strong> <a href="../backend_infra/README.md">Backend Infrastructure README</a></li>
 508:                     </ul>
 509:                 </li>
 510:                 <li><strong>Deploy Application Infrastructure</strong>
 511:                     <ul>
 512:                         <li><strong>Purpose:</strong> Deploys LDAP stack, 2FA application, and supporting services on the EKS cluster</li>
 513:                         <li><strong>Components:</strong> OpenLDAP stack (HA), PhpLdapAdmin, LTB-passwd, 2FA application (backend + frontend), ALB, Route53 records, PostgreSQL, Redis, SES, SNS (optional), ArgoCD (optional)</li>
 514:                         <li><strong>Account:</strong> Deployment Account (Account B)</li>
 515:                         <li><strong>Prerequisites:</strong> Backend infrastructure (EKS cluster) must be deployed first</li>
 516:                         <li><strong>Additional Requirements:</strong> Route53 hosted zone and ACM certificate must exist
 517:                             <ul>
 518:                                 <li>Route53 hosted zone and ACM certificate can be in State Account (different from deployment account)</li>
 519:                                 <li>Automatically accessed via <code>state_account_role_arn</code> (injected by scripts/workflows)</li>
 520:                                 <li>See <a href="../application/CROSS-ACCOUNT-ACCESS.md">Cross-Account Access Documentation</a> for configuration details</li>
 521:                             </ul>
 522:                         </li>
 523:                         <li><strong>Local:</strong> <code>cd application && ./setup-application.sh</code></li>
 524:                         <li><strong>GitHub Actions:</strong> "Application Infra Provisioning" workflow</li>
 525:                         <li><strong>See:</strong> <a href="../application/README.md">Application Infrastructure README</a></li>
 526:                     </ul>
 527:                 </li>
 528:             </ol>
 529:             <p><strong>Destroy Order:</strong> Always destroy in <strong>reverse order</strong>: Application  Backend  State</p>
 530:             <p><strong>For detailed deployment information:</strong> <a href="../README.md#deployment-methods">Deployment Methods</a> | <a href="../README.md#deployment-overview">Deployment Overview</a></p>
 531:         </div>
 532:     </section>
 533: 
 534:     <section id="architecture">
 535:         <h2>Architecture</h2>
 536:         <h3 id="multi-account-architecture">Multi-Account Architecture</h3>
 537:         <div class="card">
 538:             <p>This project uses a <strong>multi-account architecture</strong> for enhanced security:</p>
 539:             <ul>
 540:                 <li><strong>Account A (State Account)</strong>: Stores Terraform state files in S3
 541:                     <ul>
 542:                         <li>S3 bucket with versioning and server-side encryption (AES256)</li>
 543:                         <li>S3 file-based locking (<code>use_lockfile = true</code>) for state concurrency control</li>
 544:                         <li>GitHub Actions authenticates with Account A via OIDC for backend operations</li>
 545:                         <li>Provides isolation between state storage and resource deployment</li>
 546:                         <li>IAM-based access control with OIDC authentication (no access keys required)</li>
 547:                     </ul>
 548:                 </li>
 549:                 <li><strong>Account B (Deployment Account)</strong>: Contains all infrastructure resources
 550:                     <ul>
 551:                         <li>EKS cluster, VPC, ALB, Route53, and other AWS resources</li>
 552:                         <li>Separate roles for production and development environments</li>
 553:                         <li>Terraform provider assumes Account B role via cross-account role assumption</li>
 554:                         <li>Provides isolation and separation of concerns</li>
 555:                     </ul>
 556:                 </li>
 557:             </ul>
 558:             <p><strong>For detailed architecture documentation:</strong> <a href="../README.md#multi-account-architecture">Multi-Account Architecture</a> | <a href="../tf_backend_state/README.md">Terraform Backend State README</a></p>
 559:         </div>
 560:         <h3 id="how-it-works">How It Works</h3>
 561:         <div class="card">
 562:             <p>The multi-account architecture enables secure separation of concerns:</p>
 563:             <ol>
 564:                 <li><strong>GitHub Actions</strong> authenticates with Account A via OIDC (no access keys required) for Terraform backend access</li>
 565:                 <li><strong>Terraform backend</strong> uses Account A credentials to read/write state files in S3</li>
 566:                 <li><strong>Terraform AWS provider</strong> assumes Account B role (via <code>assume_role</code> with ExternalId) for resource deployment</li>
 567:                 <li><strong>Remote state</strong> data sources use Account A credentials to read state from Account A, enabling cross-tier dependencies</li>
 568:             </ol>
 569:             <p>This architecture ensures state files are isolated in a dedicated account while resource deployment uses separate credentials, providing enhanced security and better compliance capabilities.</p>
 570:         </div>
 571:         <h3 id="project-structure">Project Structure</h3>
 572:         <pre><code>ldap-2fa-on-k8s/
 573:  SECRETS_REQUIREMENTS.md  # Secrets management documentation (AWS Secrets Manager & GitHub Secrets)
 574:  tf_backend_state/      # Terraform state backend infrastructure (S3) - Account A
 575:  backend_infra/         # Core AWS infrastructure (VPC, EKS, VPC endpoints, IRSA) - Account B
 576:  application/           # Application infrastructure and deployments - Account B
 577:     backend/           # 2FA Backend (Python FastAPI)
 578:     frontend/          # 2FA Frontend (HTML/JS/CSS + nginx)
 579:     helm/              # Helm values for OpenLDAP stack
 580:     modules/           # Terraform modules (ALB, ArgoCD, SNS, cert-manager, etc.)
 581:  .github/workflows/     # GitHub Actions workflows for CI/CD</code></pre>
 582:         <h3 id="backend-infrastructure-components">Backend Infrastructure Components</h3>
 583:         <div class="card">
 584:             <ul>
 585:                 <li><strong>VPC</strong> with public and private subnets across multiple availability zones</li>
 586:                 <li><strong>EKS Cluster</strong> in Auto Mode with automatic node provisioning and CloudWatch logging</li>
 587:                 <li><strong>IRSA (IAM Roles for Service Accounts)</strong> for secure pod-to-AWS-service authentication via OIDC</li>
 588:                 <li><strong>VPC Endpoints</strong> for private AWS service access:
 589:                     <ul>
 590:                         <li>SSM endpoints for secure node access (Session Manager)</li>
 591:                         <li>STS endpoint for IRSA (IAM role assumption) - enabled by default</li>
 592:                         <li>SNS endpoint for SMS 2FA (optional, requires <code>enable_sns_endpoint = true</code>)</li>
 593:                     </ul>
 594:                 </li>
 595:                 <li><strong>ECR Repository</strong> for container image storage with lifecycle policies</li>
 596:                 <li><strong>Terraform State Backend</strong> using S3 with file-based locking for state concurrency control (migrated from DynamoDB for simplicity and cost efficiency)</li>
 597:             </ul>
 598:         </div>
 599:         <h3 id="application-infrastructure-components">Application Infrastructure Components</h3>
 600:         <div class="card">
 601:             <ul>
 602:                 <li><strong>OpenLDAP Stack HA</strong> deployed via Helm chart with:
 603:                     <ul>
 604:                         <li>OpenLDAP StatefulSet (3 replicas for high availability)</li>
 605:                         <li>PhpLdapAdmin web interface</li>
 606:                         <li>LTB-passwd self-service password management</li>
 607:                     </ul>
 608:                 </li>
 609:                 <li><strong>2FA Application</strong> with LDAP authentication integration:
 610:                     <ul>
 611:                         <li>Python FastAPI backend with TOTP and SMS MFA support</li>
 612:                         <li>Static HTML/JS/CSS frontend with modern UI</li>
 613:                         <li>Single domain routing (<code>app.&lt;domain&gt;</code>) with path-based access</li>
 614:                         <li>Self-service user registration with email/phone verification</li>
 615:                         <li>Admin dashboard for user management and group operations</li>
 616:                         <li>Interactive API documentation (Swagger UI and ReDoc)</li>
 617:                     </ul>
 618:                 </li>
 619:                 <li><strong>Application Load Balancer (ALB)</strong> via EKS Auto Mode:
 620:                     <ul>
 621:                         <li>Internet-facing ALB with HTTPS/TLS termination</li>
 622:                         <li>Single ALB handles multiple Ingresses via host-based routing</li>
 623:                         <li>Automatic provisioning via IngressClass and IngressClassParams</li>
 624:                         <li>Certificate ARN and group name configured at cluster level</li>
 625:                     </ul>
 626:                 </li>
 627:                 <li><strong>PostgreSQL</strong> (Bitnami Helm chart) for user registration and verification token storage</li>
 628:                 <li><strong>Redis</strong> (Bitnami Helm chart) for SMS OTP code storage with TTL-based expiration</li>
 629:                 <li><strong>AWS SES</strong> integration for email verification and notifications (IRSA-based)</li>
 630:                 <li><strong>ArgoCD</strong> (AWS EKS managed service) for GitOps deployments with AWS Identity Center</li>
 631:                 <li><strong>cert-manager</strong> for automatic TLS certificate management</li>
 632:                 <li><strong>Network Policies</strong> for securing pod-to-pod communication with cross-namespace support</li>
 633:                 <li><strong>SNS Integration</strong> for SMS-based 2FA verification (optional, requires VPC endpoint)</li>
 634:                 <li><strong>Route53 DNS</strong> records for subdomains pointing to ALB</li>
 635:                 <li><strong>Persistent Storage</strong> using EBS-backed StorageClass</li>
 636:             </ul>
 637:             <p><strong>For detailed architecture documentation:</strong> <a href="../backend_infra/README.md">Backend Infrastructure README</a> | <a href="../application/README.md">Application Infrastructure README</a></p>
 638:         </div>
 639:     </section>
 640: 
 641:     <section id="documentation">
 642:         <h2>Documentation</h2>
 643:         <h3 id="infrastructure-documentation">Infrastructure Documentation</h3>
 644:         <div class="doc-grid">
 645:             <div class="doc-item">
 646:                 <a href="../tf_backend_state/README.md">Terraform Backend State</a>
 647:                 <p>S3 state management and GitHub variable configuration</p>
 648:             </div>
 649:             <div class="doc-item">
 650:                 <a href="../backend_infra/README.md">Backend Infrastructure</a>
 651:                 <p>VPC, EKS, IRSA, VPC endpoints, and ECR documentation</p>
 652:             </div>
 653:             <div class="doc-item">
 654:                 <a href="../application/README.md">Application Infrastructure</a>
 655:                 <p>OpenLDAP, 2FA app, ALB, ArgoCD, and deployment instructions</p>
 656:             </div>
 657:         </div>
 658:         <h3 id="application-documentation">Application Documentation</h3>
 659:         <div class="doc-grid">
 660:             <div class="doc-item">
 661:                 <a href="../application/PRD-2FA-APP.md">2FA Application PRD</a>
 662:                 <p>Product requirements for the 2FA application (API specs, frontend architecture, Swagger UI)</p>
 663:             </div>
 664:             <div class="doc-item">
 665:                 <a href="../application/PRD-SIGNUP-MAN.md">User Signup Management PRD</a>
 666:                 <p>Self-service user registration with email/phone verification and profile state management</p>
 667:             </div>
 668:             <div class="doc-item">
 669:                 <a href="../application/PRD-ADMIN-FUNCS.md">Admin Functions PRD</a>
 670:                 <p>Admin dashboard, group CRUD operations, user management, and approval workflows</p>
 671:             </div>
 672:             <div class="doc-item">
 673:                 <a href="../application/PRD-SMS-MAN.md">SMS OTP Management PRD</a>
 674:                 <p>Redis-based SMS OTP storage with TTL-based automatic expiration</p>
 675:             </div>
 676:             <div class="doc-item">
 677:                 <a href="../application/OPENLDAP-README.md">OpenLDAP README</a>
 678:                 <p>OpenLDAP configuration and TLS setup</p>
 679:             </div>
 680:             <div class="doc-item">
 681:                 <a href="../SECRETS_REQUIREMENTS.md">Secrets Requirements</a>
 682:                 <p>Complete guide for managing secrets via GitHub and AWS Secrets Manager</p>
 683:             </div>
 684:         </div>
 685:         <h3 id="module-documentation">Module Documentation</h3>
 686:         <div class="doc-grid">
 687:             <div class="doc-item">
 688:                 <a href="../application/modules/alb/README.md">ALB Module</a>
 689:                 <p>EKS Auto Mode ALB configuration</p>
 690:             </div>
 691:             <div class="doc-item">
 692:                 <a href="../application/modules/argocd/README.md">ArgoCD Module</a>
 693:                 <p>AWS managed ArgoCD setup</p>
 694:             </div>
 695:             <div class="doc-item">
 696:                 <a href="../application/modules/argocd_app/README.md">ArgoCD Application Module</a>
 697:                 <p>GitOps application deployment</p>
 698:             </div>
 699:             <div class="doc-item">
 700:                 <a href="../application/modules/cert-manager/README.md">cert-manager Module</a>
 701:                 <p>TLS certificate management</p>
 702:             </div>
 703:             <div class="doc-item">
 704:                 <a href="../application/modules/network-policies/README.md">Network Policies Module</a>
 705:                 <p>Pod-to-pod security</p>
 706:             </div>
 707:             <div class="doc-item">
 708:                 <a href="../application/modules/postgresql/README.md">PostgreSQL Module</a>
 709:                 <p>User data and verification token storage</p>
 710:             </div>
 711:             <div class="doc-item">
 712:                 <a href="../application/modules/redis/README.md">Redis Module</a>
 713:                 <p>SMS OTP code storage</p>
 714:             </div>
 715:             <div class="doc-item">
 716:                 <a href="../application/modules/ses/README.md">SES Module</a>
 717:                 <p>Email verification and notifications</p>
 718:             </div>
 719:             <div class="doc-item">
 720:                 <a href="../application/modules/sns/README.md">SNS Module</a>
 721:                 <p>SMS 2FA integration</p>
 722:             </div>
 723:             <div class="doc-item">
 724:                 <a href="../application/modules/route53_record/README.md">Route53 Record Module</a>
 725:                 <p>Route53 A (alias) records for ALB</p>
 726:             </div>
 727:             <div class="doc-item">
 728:                 <a href="../backend_infra/modules/endpoints/README.md">VPC Endpoints Module</a>
 729:                 <p>Private AWS service access</p>
 730:             </div>
 731:             <div class="doc-item">
 732:                 <a href="../backend_infra/modules/ecr/README.md">ECR Module</a>
 733:                 <p>Container registry setup</p>
 734:             </div>
 735:             <div class="doc-item">
 736:                 <a href="../backend_infra/modules/ebs/README.md">EBS Module</a>
 737:                 <p>EBS storage configuration</p>
 738:             </div>
 739:         </div>
 740:         <h3 id="configuration-documentation">Configuration Documentation</h3>
 741:         <div class="doc-grid">
 742:             <div class="doc-item">
 743:                 <a href="../application/PRD-ALB.md">ALB Configuration PRD</a>
 744:                 <p>Application Load Balancer configuration details</p>
 745:             </div>
 746:             <div class="doc-item">
 747:                 <a href="../application/PRD-ArgoCD.md">ArgoCD Configuration PRD</a>
 748:                 <p>GitOps deployment configuration</p>
 749:             </div>
 750:             <div class="doc-item">
 751:                 <a href="../application/PRD-DOMAIN.md">Domain Configuration PRD</a>
 752:                 <p>Route53 and domain setup</p>
 753:             </div>
 754:             <div class="doc-item">
 755:                 <a href="../application/PRD.md">Main PRD</a>
 756:                 <p>Application requirements document</p>
 757:             </div>
 758:         </div>
 759:         <h3 id="security-operations">Security & Operations</h3>
 760:         <div class="doc-grid">
 761:             <div class="doc-item">
 762:                 <a href="../application/SECURITY-IMPROVEMENTS.md">Security Improvements</a>
 763:                 <p>Security enhancements and best practices</p>
 764:             </div>
 765:             <div class="doc-item">
 766:                 <a href="../CHANGELOG.md">Project Changelog</a>
 767:                 <p>All project changes including latest features and improvements</p>
 768:             </div>
 769:             <div class="doc-item">
 770:                 <a href="../backend_infra/CHANGELOG.md">Backend Infrastructure Changelog</a>
 771:                 <p>Backend infrastructure changes (VPC, EKS, IRSA, VPC endpoints)</p>
 772:             </div>
 773:             <div class="doc-item">
 774:                 <a href="../application/CHANGELOG.md">Application Infrastructure Changelog</a>
 775:                 <p>Application infrastructure changes (2FA app, OpenLDAP, supporting services)</p>
 776:             </div>
 777:             <div class="doc-item">
 778:                 <a href="../tf_backend_state/CHANGELOG.md">Terraform Backend State Changelog</a>
 779:                 <p>S3 state management changes (v1.0.0 with file-based locking)</p>
 780:             </div>
 781:         </div>
 782:     </section>
 783: 
 784:     <section id="access">
 785:         <h2>Accessing the Services</h2>
 786:         <p>After deployment, the following services are available:</p>
 787:         <h3 id="2fa-application-access">2FA Application</h3>
 788:         <div class="card">
 789:             <p><strong>URL:</strong> <code>https://app.&lt;your-domain&gt;</code> (e.g., <code>https://app.example.com</code>)</p>
 790:             <p>The full-stack 2FA application provides:</p>
 791:             <ul>
 792:                 <li>Self-service user registration with email/phone verification and profile state management (PENDING  COMPLETE  ACTIVE)</li>
 793:                 <li>Two-factor authentication enrollment and login with dual MFA methods (TOTP and SMS)</li>
 794:                 <li>TOTP setup with QR code generation for authenticator apps</li>
 795:                 <li>SMS verification with 6-digit OTP codes sent via AWS SNS</li>
 796:                 <li>User profile management with edit restrictions for verified fields</li>
 797:                 <li>Admin dashboard for user management, group CRUD operations, and approval workflows (visible to LDAP admin group members only)</li>
 798:                 <li><strong>Interactive API Documentation</strong> (always enabled):
 799:                     <ul>
 800:                         <li><code>/api/docs</code> - Swagger UI for interactive API exploration and testing</li>
 801:                         <li><code>/api/redoc</code> - ReDoc alternative API documentation interface</li>
 802:                         <li><code>/api/openapi.json</code> - OpenAPI schema in JSON format</li>
 803:                     </ul>
 804:                 </li>
 805:             </ul>
 806:         </div>
 807:         <h3 id="phpldapadmin-access">PhpLdapAdmin</h3>
 808:         <div class="card">
 809:             <p><strong>URL:</strong> <code>https://phpldapadmin.&lt;your-domain&gt;</code> (e.g., <code>https://phpldapadmin.example.com</code>)</p>
 810:             <ul>
 811:                 <li>Web-based LDAP administration interface for managing directory entries</li>
 812:                 <li>Internet-facing access via Application Load Balancer with HTTPS/TLS termination</li>
 813:                 <li>Requires OpenLDAP admin credentials for authentication</li>
 814:             </ul>
 815:         </div>
 816:         <h3 id="ltb-passwd-access">LTB-passwd</h3>
 817:         <div class="card">
 818:             <p><strong>URL:</strong> <code>https://passwd.&lt;your-domain&gt;</code> (e.g., <code>https://passwd.example.com</code>)</p>
 819:             <ul>
 820:                 <li>Self-service password management UI for LDAP users</li>
 821:                 <li>Allows users to reset their LDAP passwords without administrator intervention</li>
 822:                 <li>Internet-facing access via Application Load Balancer with HTTPS/TLS termination</li>
 823:             </ul>
 824:         </div>
 825:         <h3 id="argocd-access">ArgoCD</h3>
 826:         <div class="card">
 827:             <p><strong>URL:</strong> Retrieved from Terraform output <code>argocd_server_url</code> (if ArgoCD is enabled)</p>
 828:             <ul>
 829:                 <li>AWS EKS managed ArgoCD service for GitOps deployments</li>
 830:                 <li>Declarative, Git-driven application deployments</li>
 831:                 <li>AWS Identity Center (SSO) authentication for secure access</li>
 832:                 <li>Automatic synchronization and self-healing capabilities</li>
 833:             </ul>
 834:         </div>
 835:         <h3 id="ldap-service-access">LDAP Service</h3>
 836:         <div class="card">
 837:             <p><strong>Access:</strong> Cluster-internal only (ClusterIP service)</p>
 838:             <ul>
 839:                 <li><strong>Port:</strong> 389 (LDAP), 636 (LDAPS)</li>
 840:                 <li><strong>Not Exposed:</strong> LDAP ports are not accessible outside the cluster</li>
 841:             </ul>
 842:         </div>
 843:         <h3 id="mfa-methods">MFA Methods</h3>
 844:         <table>
 845:             <thead>
 846:                 <tr>
 847:                     <th>Method</th>
 848:                     <th>Description</th>
 849:                     <th>Infrastructure Required</th>
 850:                 </tr>
 851:             </thead>
 852:             <tbody>
 853:                 <tr>
 854:                     <td><strong>TOTP</strong></td>
 855:                     <td>Time-based One-Time Password using authenticator apps (Google Authenticator, Authy, etc.)</td>
 856:                     <td>None (codes generated locally)</td>
 857:                 </tr>
 858:                 <tr>
 859:                     <td><strong>SMS</strong></td>
 860:                     <td>Verification codes sent via AWS SNS to user's phone</td>
 861:                     <td>SNS VPC endpoint, IRSA role</td>
 862:                 </tr>
 863:             </tbody>
 864:         </table>
 865:     </section>
 866: 
 867:     <section id="security">
 868:         <h2>Security Considerations</h2>
 869:         <h3 id="key-security-features">Key Security Features</h3>
 870:         <div class="card">
 871:             <p>This project implements defense-in-depth security across multiple layers:</p>
 872:             <ul>
 873:                 <li><strong>Secrets Management</strong>: Passwords managed via GitHub repository secrets (CI/CD) or AWS Secrets Manager (local) with automated retrievalnever committed to version control</li>
 874:                 <li><strong>IRSA (IAM Roles for Service Accounts)</strong>: Pods assume IAM roles via OIDCno long-lived AWS credentials stored in containers or environment variables</li>
 875:                 <li><strong>VPC Endpoints</strong>: AWS service access (SSM, STS, SNS) routed through private endpointsno public internet exposure for sensitive operations</li>
 876:                 <li><strong>TLS/HTTPS</strong>: TLS termination at ALB using ACM certificates; internal cluster communication secured via cert-manager</li>
 877:                 <li><strong>LDAP Security</strong>: ClusterIP service only (not exposed externally); cross-namespace access restricted to secure ports (443, 636, 8443)</li>
 878:                 <li><strong>Network Policies</strong>: Kubernetes Network Policies restrict pod-to-pod communication to encrypted ports with cross-namespace support for authorized services</li>
 879:                 <li><strong>Storage Encryption</strong>: EBS volumes encrypted by default; S3 state files encrypted with AES256 server-side encryption</li>
 880:                 <li><strong>Network Isolation</strong>: EKS nodes deployed in private subnets with no public IPs; access via SSM Session Manager</li>
 881:                 <li><strong>Multi-Account Architecture</strong>: State storage (Account A) isolated from resource deployment (Account B) for enhanced security and compliance</li>
 882:                 <li><strong>State Locking</strong>: S3 file-based locking prevents concurrent Terraform operations and state corruption</li>
 883:                 <li><strong>OIDC Authentication</strong>: GitHub Actions authenticates with AWS via OIDCno access keys required</li>
 884:                 <li><strong>Cross-Account Security</strong>: ExternalId required for cross-account role assumption to prevent confused deputy attacks; bidirectional trust relationships</li>
 885:                 <li><strong>Helm Release Safety</strong>: Comprehensive Helm release attributes (atomic, force_update, replace, cleanup_on_fail, recreate_pods, wait, wait_for_jobs, upgrade_install) for safer deployments</li>
 886:                 <li><strong>ECR Image Support</strong>: All modules (OpenLDAP, PostgreSQL, Redis) use ECR images instead of Docker Hub to prevent rate limiting</li>
 887:                 <li><strong>Kubeconfig Auto-Update</strong>: Automatic kubeconfig updates prevent stale cluster endpoints and DNS lookup errors</li>
 888:             </ul>
 889:             <p><strong>For detailed security documentation:</strong> <a href="../application/SECURITY-IMPROVEMENTS.md">Security Improvements</a></p>
 890:         </div>
 891:     </section>
 892: 
 893:     <section id="support">
 894:         <h2>Contributing & Support</h2>
 895:         <h3 id="troubleshooting">Troubleshooting</h3>
 896:         <div class="card">
 897:             <p>For troubleshooting guides, see:</p>
 898:             <ul>
 899:                 <li><a href="../backend_infra/README.md#troubleshooting">Backend Infrastructure Troubleshooting</a></li>
 900:                 <li><a href="../application/README.md#troubleshooting">Application Infrastructure Troubleshooting</a></li>
 901:             </ul>
 902:         </div>
 903:         <h3 id="repository">Repository</h3>
 904:         <div class="card">
 905:             <p>GitHub Repository: <a href="https://github.com/talorlik/ldap-2fa-on-k8s" target="_blank">ldap-2fa-on-k8s</a></p>
 906:         </div>
 907:         <h3 id="license">License</h3>
 908:         <div class="card">
 909:             <p>This project is licensed under the <strong>MIT License</strong>.</p>
 910:             <p>See the <a href="../LICENSE">LICENSE</a> file for details.</p>
 911:             <p>Copyright (c) 2025 Tal Orlik</p>
 912:         </div>
 913:     </section>
 914: 
 915:     <footer>
 916:         <p>&copy; 2025 Tal Orlik. Licensed under MIT License.</p>
 917:         <p>LDAP Authentication with 2FA on Kubernetes (EKS)</p>
 918:     </footer>
 919:     <script>
 920:         // Theme management
 921:         const themeStylesheet = document.getElementById('theme-stylesheet');
 922:         const themeToggle = document.getElementById('themeToggle');
 923:         const sunIcon = document.getElementById('sunIcon');
 924:         const moonIcon = document.getElementById('moonIcon');
 925:         // Get saved theme or default to light
 926:         const currentTheme = localStorage.getItem('theme') || 'light';
 927:         function setTheme(theme) {
 928:             if (theme === 'dark') {
 929:                 themeStylesheet.href = 'dark-theme.css';
 930:                 // Show sun icon (to switch to light theme)
 931:                 sunIcon.classList.remove('hidden');
 932:                 moonIcon.classList.add('hidden');
 933:                 themeToggle.setAttribute('aria-label', 'Switch to light theme');
 934:                 themeToggle.setAttribute('title', 'Switch to light theme');
 935:                 localStorage.setItem('theme', 'dark');
 936:             } else {
 937:                 themeStylesheet.href = 'light-theme.css';
 938:                 // Show moon icon (to switch to dark theme)
 939:                 sunIcon.classList.add('hidden');
 940:                 moonIcon.classList.remove('hidden');
 941:                 themeToggle.setAttribute('aria-label', 'Switch to dark theme');
 942:                 themeToggle.setAttribute('title', 'Switch to dark theme');
 943:                 localStorage.setItem('theme', 'light');
 944:             }
 945:         }
 946:         // Initialize theme on page load
 947:         setTheme(currentTheme);
 948:         // Toggle theme on button click
 949:         themeToggle.addEventListener('click', () => {
 950:             const newTheme = themeStylesheet.href.includes('dark-theme.css') ? 'light' : 'dark';
 951:             setTheme(newTheme);
 952:         });
 953:         // Mobile menu toggle
 954:         const mobileMenuToggle = document.getElementById('mobileMenuToggle');
 955:         const navMenu = document.getElementById('navMenu');
 956:         mobileMenuToggle.addEventListener('click', () => {
 957:             navMenu.classList.toggle('active');
 958:         });
 959:         // Close mobile menu when clicking on a link
 960:         const navLinks = document.querySelectorAll('.nav-menu a');
 961:         navLinks.forEach(link => {
 962:             link.addEventListener('click', () => {
 963:                 navMenu.classList.remove('active');
 964:             });
 965:         });
 966:         // Active section highlighting
 967:         const sections = document.querySelectorAll('section[id]');
 968:         const navLinksArray = Array.from(navLinks);
 969:         function highlightActiveSection() {
 970:             const scrollY = window.pageYOffset;
 971:             sections.forEach(section => {
 972:                 const sectionHeight = section.offsetHeight;
 973:                 const sectionTop = section.offsetTop - 150;
 974:                 const sectionId = section.getAttribute('id');
 975:                 if (scrollY > sectionTop && scrollY <= sectionTop + sectionHeight) {
 976:                     navLinksArray.forEach(link => {
 977:                         link.classList.remove('active');
 978:                         if (link.getAttribute('href') === `#${sectionId}`) {
 979:                             link.classList.add('active');
 980:                         }
 981:                     });
 982:                 }
 983:             });
 984:         }
 985:         window.addEventListener('scroll', highlightActiveSection);
 986:         window.addEventListener('load', highlightActiveSection);
 987:     </script>
 988: 
 989:     <button id="scrollToTopButton" class="scroll-to-top" aria-label="Scroll to top" title="Scroll to top">
 990:         <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round">
 991:             <circle cx="12" cy="12" r="10"></circle>
 992:             <polyline points="16 12 12 8 8 12"></polyline>
 993:             <line x1="12" y1="8" x2="12" y2="16"></line>
 994:         </svg>
 995:     </button>
 996:     <script>
 997:         // Initialize scroll to top button after DOM is ready
 998:         function initScrollToTop() {
 999:             const scrollToTopButton = document.getElementById('scrollToTopButton');
1000:             if (!scrollToTopButton) {
1001:                 console.error('Scroll to top button not found');
1002:                 return;
1003:             }
1004:             // Check scroll position on load
1005:             function checkScroll() {
1006:                 if (window.pageYOffset > 100 || document.documentElement.scrollTop > 100) {
1007:                     scrollToTopButton.classList.add('visible');
1008:                 } else {
1009:                     scrollToTopButton.classList.remove('visible');
1010:                 }
1011:             }
1012:             // Initial check
1013:             checkScroll();
1014:             // Handle scroll events
1015:             window.addEventListener('scroll', checkScroll);
1016:             // Handle click
1017:             scrollToTopButton.addEventListener('click', (e) => {
1018:                 e.preventDefault();
1019:                 window.scrollTo({
1020:                     top: 0,
1021:                     behavior: 'smooth'
1022:                 });
1023:             });
1024:         }
1025:         // Initialize when DOM is ready
1026:         if (document.readyState === 'loading') {
1027:             document.addEventListener('DOMContentLoaded', initScrollToTop);
1028:         } else {
1029:             initScrollToTop();
1030:         }
1031:         // Smooth scroll for anchor links
1032:         document.querySelectorAll('a[href^="#"]').forEach(anchor => {
1033:             anchor.addEventListener('click', function (e) {
1034:                 e.preventDefault();
1035:                 const target = document.querySelector(this.getAttribute('href'));
1036:                 if (target) {
1037:                     target.scrollIntoView({
1038:                         behavior: 'smooth',
1039:                         block: 'start'
1040:                     });
1041:                 }
1042:             });
1043:         });
1044:     </script>
1045: </body>
1046: </html>
````

## File: tf_backend_state/README.md
````markdown
  1: # Terraform Backend State Infrastructure
  2: 
  3: This directory contains Terraform configuration to provision the AWS
  4: infrastructure needed to store Terraform state files remotely. This includes an
  5: S3 bucket for state storage with file-based locking.
  6: 
  7: ## Overview
  8: 
  9: This infrastructure creates:
 10: 
 11: - **S3 Bucket**: Stores Terraform state files with versioning enabled and
 12: file-based locking
 13: - **Security**: Encrypted storage, private access, and IAM-based access control
 14: 
 15: The bucket name is dynamically generated based on your prefix and AWS account ID
 16: to ensure global uniqueness.
 17: 
 18: ## Prerequisites
 19: 
 20: - **AWS Account A (State Account)** with appropriate permissions for S3 bucket
 21: creation
 22: - GitHub repository with Actions enabled
 23: - AWS SSO/OIDC configured (see AWS IAM Setup section)
 24: - Terraform >= 1.2.0 (for local execution)
 25: - AWS Cli V2
 26: - **For local execution**: AWS Secrets Manager secret named `github-role` containing
 27: role ARNs (see [Local Execution](#option-2-local-execution) section)
 28: 
 29: ## GitHub Repository Configuration
 30: 
 31: Before running the workflows, you need to configure the following in your GitHub
 32: repository:
 33: 
 34: ### Required Secrets
 35: 
 36: Secrets are sensitive values that are encrypted and only accessible to
 37: workflows. Configure them at:
 38: **Repository  Settings  Secrets and variables  Actions  Secrets**
 39: 
 40: 1. `AWS_STATE_ACCOUNT_ROLE_ARN`
 41: 
 42:     - **Type**: Secret
 43:     - **Description**: ARN of the IAM role in Account A (State Account) that
 44:     trusts GitHub OIDC provider
 45:     - **Format**: `arn:aws:iam::ACCOUNT_A_ID:role/github-actions-state-role`
 46:     - **How to set it up**:
 47:       1. Create an OIDC Identity Provider in AWS IAM:
 48:          - Provider URL: `https://token.actions.githubusercontent.com`
 49:          - Audience: `sts.amazonaws.com`
 50:       2. Create an IAM Role that trusts the GitHub OIDC provider (see AWS IAM
 51:       Setup below)
 52:       3. Attach permissions policy with S3 access to state bucket
 53:       4. Copy the role ARN and set it as this secret
 54:     - **Used for**:
 55:       - **GitHub Actions workflows**: Authenticating AWS API calls in GitHub Actions
 56:       via OIDC (no access keys needed)
 57:       - **Local scripts**: Not used directly - local scripts retrieve the role
 58:       ARN from AWS Secrets Manager instead (see [Local Execution](#option-2-local-execution)
 59:       section)
 60:     - **Permissions needed**: S3 access to create/manage state bucket
 61:     - ** Note**: For local script execution, ensure the same role ARN is
 62:       stored in AWS Secrets Manager secret 'github-role' with key
 63:       'AWS_STATE_ACCOUNT_ROLE_ARN'. See [Secrets
 64:       Requirements](../SECRETS_REQUIREMENTS.md) for complete setup
 65:       instructions.
 66: 
 67: 2. `GH_TOKEN`
 68: 
 69:     - **Type**: Secret
 70:     - **Description**: GitHub Personal Access Token (PAT) with `repo` scope
 71:     - **How to create it**:
 72:       1. Go to GitHub  Settings  Developer settings  Personal access tokens 
 73:       Tokens (classic)
 74:       2. Click "Generate new token (classic)"
 75:       3. Give it a descriptive name (e.g., "Terraform Backend State")
 76:       4. Select scope: **`repo`** (Full control of private repositories)
 77:       5. Click "Generate token" and copy it immediately
 78:       6. Store it as a repository secret named `GH_TOKEN`
 79:     - **Used for**: Creating/updating the `BACKEND_BUCKET_NAME` repository
 80:     variable after provisioning
 81:     - **Why needed**: The default `GITHUB_TOKEN` may not have permissions to
 82:     write repository variables
 83: 
 84: ### Required Variables
 85: 
 86: Variables are non-sensitive values that can be accessed by workflows. Configure
 87: them at:
 88: **Repository  Settings  Secrets and variables  Actions  Variables**
 89: 
 90: 1. `AWS_REGION`
 91: 
 92:     - **Type**: Variable
 93:     - **Description**: AWS region where resources will be created
 94:     - **Example values**: `us-east-1`, `us-west-2`, `eu-west-1`
 95:     - **Used for**: Setting the AWS region for all operations
 96:     - ** Important**: This should match the region in your `variables.tfvars`
 97:     file
 98: 
 99: 2. `BACKEND_PREFIX`
100: 
101:     - **Type**: Variable
102:     - **Description**: The prefix that will be created once the state file is
103:     saved in the bucket
104:     - **Example values**: `backend_state/terraform.tfstate`
105:     - **Used for**: Setting the bucket prefix for all operations
106: 
107: 3. `BACKEND_BUCKET_NAME` (Auto-generated)
108: 
109:     - **Type**: Variable
110:     - **Description**: The dynamically generated S3 bucket name
111:     - **How it's created**: Automatically set by the provisioning workflow after
112:     the bucket is created
113:     - **Used for**: Other workflows that need to know the bucket name (e.g.,
114:     destroying workflow)
115:     - ** Note**: You don't need to create this manually - it's created
116:     automatically
117: 
118: ## Terraform Variables
119: 
120: Configure these **required** variables in `variables.tfvars` before running:
121: 
122: 1. `env`
123: 
124:     - **Type**: `string`
125:     - **Description**: Deployment environment identifier
126:     - **Example**: `"prod"`, `"dev"`, `"staging"`
127:     - **Used for**: Tagging resources and organizing by environment
128: 
129: 2. `region`
130: 
131:     - **Type**: `string`
132:     - **Description**: AWS region for resource deployment
133:     - **Example**: `"us-east-1"`, `"us-west-2"`
134:     - **Used for**: Specifying where AWS resources are created
135:     - ** Important**: Should match `AWS_REGION` GitHub variable
136: 
137: 3. `prefix`
138: 
139:     - **Type**: `string`
140:     - **Description**: Prefix added to all resource names for identification
141:     - **Example**: `"mycompany-tf"`, `"project-name"`
142:     - **Used for**: Creating unique names for all resources
143:     - ** Important**: Choose a unique prefix to avoid naming conflicts
144: 
145: ## How to Run
146: 
147: ### Option 1: GitHub Actions (Recommended)
148: 
149: This is the recommended approach as it handles state file upload automatically.
150: 
151: > [!NOTE]
152: >
153: > GitHub Actions workflows retrieve the role ARN directly from
154: > **GitHub repository secrets** (`AWS_STATE_ACCOUNT_ROLE_ARN`).
155: > This differs from local script execution, which uses AWS Secrets Manager.
156: 
157: #### Provisioning 1 (Create Infrastructure)
158: 
159: 1. **Configure your variables**:
160:    - Edit `variables.tfvars` with your values
161:    - Commit and push the changes
162: 
163: 2. **Run the workflow**:
164:    - Go to GitHub  Actions tab
165:    - Select "TF Backend State Provisioning" workflow
166:    - Click "Run workflow"  "Run workflow"
167:    - The workflow will:
168:      - Validate Terraform configuration
169:      - Create the S3 bucket
170:      - Save the bucket name as a repository variable
171:      - Upload the state file to S3
172: 
173: #### Destroying (Remove Infrastructure)
174: 
175: 1. **Run the destroying workflow**:
176:    - Go to GitHub  Actions tab
177:    - Select "TF Backend State Destroying" workflow
178:    - Click "Run workflow"  "Run workflow"
179:    - The workflow will:
180:      - Download the state file from S3
181:      - Destroy all resources
182:      -  **Warning**: This permanently deletes the S3 bucket
183: 
184: ### Option 2: Local Execution
185: 
186: For local development or testing, use the provided automation scripts. These
187: scripts handle role assumption, Terraform operations, state file management, and
188: repository variable updates automatically.
189: 
190: > [!IMPORTANT]
191: >
192: > - **Secret Retrieval**: The local bash scripts (`get-state.sh` and `set-state.sh`)
193: > retrieve the role ARN from **AWS Secrets Manager** (secret named 'github-role'
194: > with key 'AWS_STATE_ACCOUNT_ROLE_ARN'), not from GitHub repository secrets.
195: > - **GitHub Actions**: The GitHub Actions workflows retrieve the role ARN directly
196: > from **GitHub repository secrets** (`AWS_STATE_ACCOUNT_ROLE_ARN`).
197: > - **Role Assumption**: The scripts automatically assume the IAM role retrieved
198: > from AWS Secrets Manager. The S3 bucket policy grants access to the role ARN
199: > (used by GitHub Actions), not your local user ARN. Terraform will automatically
200: > detect and use the assumed role's ARN.
201: 
202: #### Prerequisites for Local Execution
203: 
204: Before running the scripts, ensure you have:
205: 
206: 1. **GitHub CLI installed and authenticated**:
207: 
208:    ```bash
209:    # Install GitHub CLI (if not already installed)
210:    # macOS: brew install gh
211:    # Linux: See https://cli.github.com/manual/installation
212: 
213:    # Authenticate with GitHub
214:    gh auth login
215:    ```
216: 
217: 2. **Required tools installed**:
218:    - AWS CLI V2
219:    - Terraform >= 1.2.0
220:    - GitHub CLI (`gh`)
221:    - `jq` (for JSON parsing)
222: 
223: 3. **AWS Secrets Manager configured**:
224:    - Secret named `github-role` must exist in AWS Secrets Manager
225:    - Secret must contain JSON with key `AWS_STATE_ACCOUNT_ROLE_ARN`
226:    (and optionally other role ARNs)
227:    - Your AWS credentials must have `secretsmanager:GetSecretValue` permission
228:    for the `github-role` secret
229:    - Example secret JSON structure:
230: 
231:      ```json
232:      {
233:        "AWS_STATE_ACCOUNT_ROLE_ARN": "arn:aws:iam::<account-id>:role/<role-name>"
234:      }
235:      ```
236: 
237: 4. **GitHub repository configured**:
238:    - `AWS_STATE_ACCOUNT_ROLE_ARN` secret set (used by GitHub Actions workflows,
239:    not local scripts)
240:    - `AWS_REGION` variable set (defaults to `us-east-1` if not set)
241:    - `BACKEND_PREFIX` variable set
242:    - `variables.tfvars` file configured with required variables
243: 
244: #### Provisioning 2 (Create Infrastructure)
245: 
246: Use the `set-state.sh` script to provision infrastructure and upload the state
247: file:
248: 
249: ```bash
250: cd tf_backend_state
251: ./set-state.sh
252: ```
253: 
254: > [!NOTE]
255: >
256: > The script intelligently detects whether infrastructure needs to be provisioned
257: > by checking for the `BACKEND_BUCKET_NAME` repository variable. If the variable
258: > exists, it assumes infrastructure is already provisioned and will download the
259: > existing state file from S3 (if available) before uploading any updates.
260: 
261: **What the script does automatically**:
262: 
263: 1. Retrieves `AWS_STATE_ACCOUNT_ROLE_ARN` from **AWS Secrets Manager**
264: (secret 'github-role', key 'AWS_STATE_ACCOUNT_ROLE_ARN')
265: 2. Retrieves `AWS_REGION` from GitHub repository variables (defaults to
266: `us-east-1`)
267: 3. Retrieves `BACKEND_PREFIX` from GitHub repository variables
268: 4. Assumes the IAM role with temporary credentials and verifies credentials
269: 5. Checks if infrastructure already exists:
270:    - **If not exists**: Runs `terraform init`, `validate`, `plan`, and `apply`
271:      to provision infrastructure
272:    - **If exists**: Downloads existing state file from S3 (if available) or
273:      uses local state file
274: 6. Verifies bucket name consistency between repository variable and Terraform
275:    output
276: 7. **Always** saves/updates bucket name to GitHub repository variable
277:    `BACKEND_BUCKET_NAME`
278: 8. **Always** uploads `terraform.tfstate` to S3 (ensures state file is
279:    synchronized with latest changes)
280: 
281: #### Downloading Existing State File
282: 
283: If you need to download the state file from S3 (e.g., after running via GitHub
284: Actions), use the `get-state.sh` script:
285: 
286: ```bash
287: cd tf_backend_state
288: ./get-state.sh
289: ```
290: 
291: **What the script does automatically**:
292: 
293: 1. Retrieves `AWS_STATE_ACCOUNT_ROLE_ARN` from **AWS Secrets Manager**
294: (secret 'github-role', key 'AWS_STATE_ACCOUNT_ROLE_ARN')
295: 2. Retrieves `AWS_REGION` from GitHub repository variables (defaults to
296: `us-east-1`)
297: 3. Assumes the IAM role with temporary credentials
298: 4. Retrieves `BACKEND_BUCKET_NAME` and `BACKEND_PREFIX` from GitHub repository
299: variables
300: 5. Downloads `terraform.tfstate` from S3 if it exists
301: 
302: #### Destroying Infrastructure
303: 
304: To destroy the infrastructure, use Terraform directly (after downloading the
305: state file if needed):
306: 
307: ```bash
308: cd tf_backend_state
309: 
310: # Download state file if needed
311: ./get-state.sh
312: 
313: # Destroy infrastructure
314: terraform plan -var-file="variables.tfvars" -destroy -out terraform.tfplan
315: terraform apply -auto-approve terraform.tfplan
316: ```
317: 
318: > [!WARNING]
319: >
320: > This permanently deletes the S3 bucket and all resources.
321: 
322: ## What Gets Created
323: 
324: ### S3 Bucket
325: 
326: - **Name**: `{prefix}-{account-id}-s3-tfstate`
327: - **Features**:
328:   - Versioning enabled (allows recovery of previous state versions)
329:   - Encryption at rest (AES256)
330:   - Private access (no public access)
331:   - IAM-based access control
332:   - Force destroy enabled (allows bucket deletion even if not empty)
333: 
334: ### State Locking
335: 
336: - **Method**: File-based locking using `use_lockfile = true` in the backend
337: configuration
338: - **Location**: Lock file is stored in the same S3 bucket as the state file
339: - **Benefits**: Simpler setup, lower cost, lock file stored alongside state in
340: S3
341: 
342: ### Security Features
343: 
344: - **S3 Bucket Policy**: Automatically uses current caller's ARN via
345:   `data.aws_caller_identity.current.arn` (no manual configuration needed)
346: - **Public Access Block**: Prevents any public access to the S3 bucket
347: - **Encryption**: All data encrypted at rest
348: 
349: ## State File Management
350: 
351: ### After Provisioning
352: 
353: - The state file is automatically uploaded to: `s3://{bucket-name}/{prefix}`
354: - The bucket name is saved as `BACKEND_BUCKET_NAME` repository variable
355: - The variable is accessible to all workflows via `${{ vars.BACKEND_BUCKET_NAME}}`
356: 
357: ### State File Location
358: 
359: - **Path in S3**: `{prefix}`
360: - **Versioning**: Enabled, so you can recover previous versions if needed
361: 
362: ## Troubleshooting
363: 
364: ### "Resource not accessible by integration" error
365: 
366: - **Cause**: `GH_TOKEN` doesn't have proper permissions or doesn't exist
367: - **Solution**: Create a PAT with `repo` scope and store it as `GH_TOKEN` secret
368: 
369: ### "Access Denied" when accessing S3
370: 
371: - **Cause**: The IAM principal doesn't have S3 permissions, or there's a
372: mismatch between the caller and the bucket policy
373: - **Solution**:
374:   - The bucket policy automatically uses the current caller's ARN via
375:   `data.aws_caller_identity.current.arn`. Verify this matches your expectations:
376:     - Run `aws sts get-caller-identity` to see your current ARN
377:     - Ensure the caller has S3 permissions for the state bucket
378:   - For GitHub Actions: Verify the IAM role ARN used in `AWS_STATE_ACCOUNT_ROLE_ARN`
379:   secret matches the assumed role
380:   - Check that the OIDC trust relationship is correctly configured (for GitHub
381:   Actions)
382: 
383: ### OIDC Authentication Issues
384: 
385: - **Cause**: GitHub OIDC provider not configured correctly or role trust policy
386: incorrect
387: - **Solution**:
388:   - Verify OIDC Identity Provider exists in Account A
389:   - Check role trust policy includes correct repository name
390:   - Ensure `AWS_STATE_ACCOUNT_ROLE_ARN` secret contains the correct role ARN
391:   (for GitHub Actions)
392: 
393: ### AWS Secrets Manager Issues (Local Scripts)
394: 
395: - **Cause**: Local scripts cannot retrieve secret from AWS Secrets Manager
396: - **Common issues and solutions**:
397:   - **Secret doesn't exist**: Ensure secret named `github-role` exists in
398:   AWS Secrets Manager
399:   - **Access denied**: Your AWS credentials must have `secretsmanager:GetSecretValue`
400:   permission for the `github-role` secret
401:   - **Key not found**: Ensure the secret JSON contains key `AWS_STATE_ACCOUNT_ROLE_ARN`
402:   - **Invalid JSON**: Verify the secret value is valid JSON format
403:   - **Wrong region**: Ensure your AWS CLI is configured to the correct region
404:   where the secret exists
405: - **Verification**:
406: 
407:   ```bash
408:   # Test secret retrieval manually
409:   aws secretsmanager get-secret-value --secret-id github-role --query SecretString --output text | jq .
410:   ```
411: 
412: ### Bucket name conflicts
413: 
414: - **Cause**: Another account is using the same prefix
415: - **Solution**: Use a more unique prefix in `variables.tfvars`
416: 
417: ### State file not found during destroy
418: 
419: - **Cause**: The state file wasn't uploaded or the bucket name variable is
420: incorrect
421: - **Solution**: Verify `BACKEND_BUCKET_NAME` variable exists and contains the
422: correct bucket name
423: 
424: ## Important Notes
425: 
426: 1. **State File**: The state file contains sensitive information. Never commit
427: it to version control (it's in `.gitignore`).
428: 
429: 2. **Bucket Deletion**: The bucket has `force_destroy = true`, meaning it can be
430: deleted even if it contains files. Use with caution.
431: 
432: 3. **Costs**:
433:    - S3: Minimal cost for storage (typically < $1/month for small projects)
434:    - No additional costs for state locking (uses file-based locking in S3)
435: 
436: 4. **Backup**: State file versioning is enabled, so you can recover previous
437: versions from the S3 console if needed.
438: 
439: 5. **Multiple Environments**: If you need multiple environments (dev, staging,
440: prod), you can:
441:    - Use different prefixes in `variables.tfvars`
442:    - Or create separate Terraform workspaces
443:    - Or use separate repositories/variables for each environment
444: 
445: ## AWS IAM Setup
446: 
447: ### Account A (State Account) - OIDC Configuration
448: 
449: This infrastructure uses **AWS SSO via GitHub OIDC** for authentication instead
450: of access keys.
451: 
452: #### Step 1: Create OIDC Identity Provider
453: 
454: The OIDC Identity Provider establishes trust between GitHub Actions and AWS,
455: allowing GitHub to authenticate without access keys.
456: 
457: 1. **Navigate to IAM Console**:
458:    - Go to AWS IAM Console  **Identity providers** (left sidebar)
459:    - Click **Add provider**
460: 
461: 2. **Configure Provider**:
462:    - Select **OpenID Connect**
463:    - **Provider URL**: `https://token.actions.githubusercontent.com`
464:    - Click **Get thumbprint** (AWS will automatically fetch GitHub's certificate
465:    thumbprint for security)
466:    - **Audience**: `sts.amazonaws.com`
467:    - Click **Add provider**
468: 
469: 3. **Verify Creation**:
470:    - You should see the provider listed with ARN format:
471:    `arn:aws:iam::ACCOUNT_A_ID:oidc-provider/token.actions.githubusercontent.com`
472:    - Note this ARN - it will be used in the role trust policy
473: 
474: **What this does:**
475: 
476: - Establishes GitHub as a trusted identity provider for AWS
477: - Allows GitHub Actions to request temporary AWS credentials via OIDC tokens
478: - No access keys needed - authentication happens through OIDC tokens
479: 
480: #### Step 2: Create IAM Role and Assign to Identity Provider
481: 
482: Now create an IAM Role that uses this Identity Provider for authentication. The
483: role will be "assigned" to the Identity Provider through its trust policy.
484: 
485: 1. **Navigate to IAM Roles**:
486:    - Go to AWS IAM Console  **Roles** (left sidebar)
487:    - Click **Create role**
488: 
489: 2. **Select Trusted Entity Type**:
490:    - Under **Trusted entity type**, select **Web identity**
491:    - Under **Web identity**, select the Identity Provider you just created:
492:    `token.actions.githubusercontent.com`
493:    - **Audience**: Select `sts.amazonaws.com` from the dropdown
494:    - Click **Next**
495: 
496: 3. **Configure Trust Policy Conditions** (Recommended for Security):
497:    - Click **Add condition** to restrict which repositories can assume this role
498:    - **Condition key**: `token.actions.githubusercontent.com:sub`
499:    - **Operator**: `StringLike`
500:    - **Value**: `repo:YOUR_ORG/YOUR_REPO:*` (replace `YOUR_ORG/YOUR_REPO` with
501:    your GitHub organization and repository name)
502:      - Example: `repo:talorlik/ldap-2fa-on-k8s:*`
503:    - This ensures only workflows from your specific repository can assume the
504:    role
505:    - Click **Next**
506: 
507: 4. **Add Permissions**:
508:    - Create or attach a policy with S3 permissions for the state bucket
509:    - **Minimum required permissions**:
510: 
511:      ```json
512:      {
513:        "Version": "2012-10-17",
514:        "Statement": [
515:          {
516:            "Effect": "Allow",
517:            "Action": [
518:              "s3:GetObject",
519:              "s3:PutObject",
520:              "s3:DeleteObject",
521:              "s3:ListBucket"
522:            ],
523:            "Resource": [
524:              "arn:aws:s3:::your-state-bucket-name",
525:              "arn:aws:s3:::your-state-bucket-name/*"
526:            ]
527:          }
528:        ]
529:      }
530:      ```
531: 
532:    - **Note**: For initial setup, you may want to use a broader policy (e.g.,
533:    `s3:*` on all buckets) and restrict it later once you know the exact
534:    bucket name
535:    - Click **Next**
536: 
537: 5. **Name and Create Role**:
538:    - **Role name**: `github-actions-state-role` (or your preferred name)
539:    - **Description**: "Role for GitHub Actions to access Terraform state bucket
540:    via OIDC"
541:    - Click **Create role**
542: 
543: 6. **Verify Role Configuration**:
544:    - After creation, click on the role name to view details
545:    - Under **Trust relationships**, you should see:
546:      - **Type**: Web identity
547:      - **Identity provider**: `token.actions.githubusercontent.com`
548:      - **Audience**: `sts.amazonaws.com`
549:      - **Condition**: `token.actions.githubusercontent.com:sub` equals
550:      `repo:YOUR_ORG/YOUR_REPO:*`
551:    - This confirms the role is properly assigned to the Identity Provider
552: 
553: 7. **Copy Role ARN**:
554:    - The **Role ARN** is displayed at the top of the role details page
555:    - Format: `arn:aws:iam::ACCOUNT_A_ID:role/github-actions-state-role`
556:    - Copy this ARN  Set as `AWS_STATE_ACCOUNT_ROLE_ARN` GitHub secret
557: 
558: 8. **Update Trust Relationship for Deployment Accounts** (Required for
559:    Multi-Account Setup):
560:    - After creating deployment account roles (see main [README.md](../README.md)),
561:    you must update the state account role's Trust Relationship to allow the
562:    deployment account roles
563:    - **Important:** The ExternalId security mechanism is still required when the
564:      state account role assumes deployment account roles. The deployment account
565:      roles' Trust Relationships must include the ExternalId condition, and the
566:      state account role must provide the ExternalId when assuming those roles
567:    - Navigate to the state account role in IAM Console
568:    - Go to **Trust relationships** tab
569:    - Click **Edit trust policy**
570:    - Add the deployment account role ARNs to the trust policy:
571: 
572:      ```json
573:      {
574:        "Version": "2012-10-17",
575:        "Statement": [
576:          {
577:            "Effect": "Allow",
578:            "Principal": {
579:              "Federated": "arn:aws:iam::STATE_ACCOUNT_ID:oidc-provider/token.actions.githubusercontent.com"
580:            },
581:            "Action": "sts:AssumeRoleWithWebIdentity",
582:            "Condition": {
583:              "StringLike": {
584:                "token.actions.githubusercontent.com:sub": "repo:YOUR_ORG/YOUR_REPO:*"
585:              }
586:            }
587:          },
588:          {
589:            "Effect": "Allow",
590:            "Principal": {
591:              "AWS": [
592:                "arn:aws:iam::PRODUCTION_ACCOUNT_ID:role/github-role",
593:                "arn:aws:iam::DEVELOPMENT_ACCOUNT_ID:role/github-role"
594:              ]
595:            },
596:            "Action": "sts:AssumeRole"
597:          }
598:        ]
599:      }
600:      ```
601: 
602:    - Replace `PRODUCTION_ACCOUNT_ID` and `DEVELOPMENT_ACCOUNT_ID` with your actual
603:    account IDs, and `github-role` with your actual deployment role names
604:    - Click **Update policy**
605: 
606: **Understanding the Relationship:**
607: 
608: - **Identity Provider**: Establishes trust with GitHub (created first)
609: - **IAM Role**: Uses the Identity Provider for authentication (created second)
610: - **Assignment**: The role is "assigned" to the Identity Provider through its
611: trust policy, which references the Identity Provider's ARN
612: - When GitHub Actions runs, it presents an OIDC token, which AWS validates
613: against the Identity Provider, then allows assuming the role
614: - **Bidirectional Trust**: For multi-account setups, both the deployment account
615: roles and the state account role must trust each other in their respective Trust
616: Relationships
617: 
618: **Important Notes:**
619: 
620: - The Identity Provider must be created **before** the IAM Role
621: - The IAM Role's trust policy automatically references the Identity Provider you
622: selected during role creation
623: - The condition on `token.actions.githubusercontent.com:sub` restricts access to
624: your specific repository for security
625: - You can update the trust policy later to add more repositories or adjust
626: conditions
627: - The role ARN is what you'll use in GitHub Secrets, not the Identity Provider
628: ARN
629: - **For multi-account setups**: The state account role's Trust Relationship must
630: also include the deployment account role ARNs to enable bidirectional trust
631: 
632: #### Step 3: S3 Bucket Policy (Automatic)
633: 
634: The bucket policy in `main.tf` automatically uses the current caller's ARN via
635: `data.aws_caller_identity.current.arn`. **No configuration needed!**
636: 
637: - **Automatic Detection**: The bucket policy automatically detects and uses the
638:   current caller's ARN, whether it's:
639:   - GitHub Actions OIDC-assumed role
640:   - Locally assumed role (via scripts)
641:   - Direct AWS credentials
642: - **No Manual Configuration**: The `principal_arn` variable has been removed
643:   - Bucket policy always grants access to the current caller
644:   - Eliminates the need for manual ARN configuration
645:   - Works seamlessly with both GitHub Actions and local execution
646: - **Security**: Access is automatically restricted to the caller that creates the
647:   bucket, ensuring proper access control
648: 
649: > [!NOTE]
650: >
651: > For multi-account setups, Account A stores state, and Account B
652: > deploys resources. The workflows and scripts handle this automatically via role
653: > assumption, and the principal ARN is automatically detected.
654: 
655: ## Related Documentation
656: 
657: - [Main README](../README.md) - Project overview and quick start
658: - [Backend Infrastructure](../backend_infra/README.md) - VPC, EKS, IRSA, and VPC
659: endpoints
660: - [Application Infrastructure](../application/README.md) - OpenLDAP, 2FA app,
661: and supporting services
````

## File: application/main.tf
````hcl
  1: locals {
  2:   storage_class_name = "${var.prefix}-${var.region}-${var.storage_class_name}-${var.env}"
  3: 
  4:   # Retrieve ECR information from backend_infra state
  5:   ecr_registry   = try(data.terraform_remote_state.backend_infra[0].outputs.ecr_registry, "")
  6:   ecr_repository = try(data.terraform_remote_state.backend_infra[0].outputs.ecr_repository, "")
  7: 
  8:   tags = {
  9:     Env       = "${var.env}"
 10:     Terraform = "true"
 11:   }
 12: }
 13: 
 14: data "aws_route53_zone" "this" {
 15:   provider     = aws.state_account
 16:   name         = var.domain_name
 17:   private_zone = false
 18: }
 19: 
 20: # ACM Certificate must be in the deployment account (not state account)
 21: # EKS Auto Mode ALB controller cannot access cross-account certificates
 22: # The certificate must exist in the same account where the ALB is created
 23: # Certificate is issued from Private CA in State Account but stored in Deployment Account
 24: # Each deployment account (development, production) has its own certificate
 25: data "aws_acm_certificate" "this" {
 26:   # Use default provider (deployment account) instead of state_account
 27:   # EKS Auto Mode ALB controller requires certificate in the same account
 28:   # Certificate is issued from Private CA in State Account but stored here
 29:   domain      = var.domain_name
 30:   most_recent = true
 31:   statuses    = ["ISSUED"]
 32: }
 33: 
 34: # Create StorageClass for OpenLDAP PVC
 35: resource "kubernetes_storage_class_v1" "this" {
 36:   metadata {
 37:     name = local.storage_class_name
 38:     annotations = var.storage_class_is_default ? {
 39:       "storageclass.kubernetes.io/is-default-class" = "true"
 40:     } : {}
 41:   }
 42: 
 43:   storage_provisioner    = "ebs.csi.eks.amazonaws.com"
 44:   reclaim_policy         = "Delete"
 45:   volume_binding_mode    = "Immediate" # Changed from WaitForFirstConsumer to prevent PVC binding deadlocks
 46:   allow_volume_expansion = true
 47: 
 48:   parameters = {
 49:     type      = var.storage_class_type
 50:     encrypted = tostring(var.storage_class_encrypted)
 51:   }
 52: 
 53:   depends_on = [data.aws_eks_cluster.cluster]
 54: 
 55:   lifecycle {
 56:     # Prevent Terraform from trying to recreate if the resource already exists
 57:     # This helps when the resource exists but isn't in state
 58:     ignore_changes = [
 59:       metadata[0].annotations,
 60:     ]
 61:     # Allow replacement if needed
 62:     replace_triggered_by = []
 63:   }
 64: }
 65: 
 66: # module "route53" {
 67: #   source = "./modules/route53"
 68: 
 69: #   use_existing_route53_zone = var.use_existing_route53_zone
 70: #   env                       = var.env
 71: #   region                    = var.region
 72: #   prefix                    = var.prefix
 73: #   domain_name               = var.domain_name
 74: #   subject_alternative_names = var.subject_alternative_names
 75: #   tags                      = local.tags
 76: # }
 77: 
 78: locals {
 79:   app_name = "${var.prefix}-${var.region}-${var.app_name}-${var.env}"
 80: 
 81:   # ALB group name: Kubernetes identifier (max 63 chars) used to group Ingresses
 82:   # If alb_group_name is set, concatenate with prefix, region, and env (truncate to 63 chars if needed)
 83:   # If not set, use app_name (truncate to 63 chars if needed)
 84:   alb_group_name = var.alb_group_name != null ? (
 85:     length("${var.prefix}-${var.region}-${var.alb_group_name}-${var.env}") > 63 ?
 86:     substr("${var.prefix}-${var.region}-${var.alb_group_name}-${var.env}", 0, 63) :
 87:     "${var.prefix}-${var.region}-${var.alb_group_name}-${var.env}"
 88:     ) : (
 89:     length(local.app_name) > 63 ? substr(local.app_name, 0, 63) : local.app_name
 90:   )
 91: 
 92:   # ALB load balancer name: AWS resource name (max 32 chars per AWS constraints)
 93:   # If alb_load_balancer_name is set, concatenate with prefix, region, and env (truncate to 32 chars if needed)
 94:   # If not set, use alb_group_name (truncate to 32 chars if needed)
 95:   alb_load_balancer_name = var.alb_load_balancer_name != null ? (
 96:     length("${var.prefix}-${var.region}-${var.alb_load_balancer_name}-${var.env}") > 32 ?
 97:     substr("${var.prefix}-${var.region}-${var.alb_load_balancer_name}-${var.env}", 0, 32) :
 98:     "${var.prefix}-${var.region}-${var.alb_load_balancer_name}-${var.env}"
 99:     ) : (
100:     length(local.alb_group_name) > 32 ? substr(local.alb_group_name, 0, 32) : local.alb_group_name
101:   )
102: 
103:   # ALB zone_id mapping by region (for Route53 alias records)
104:   # These are the canonical hosted zone IDs for Application Load Balancers
105:   alb_zone_ids = {
106:     "us-east-1"      = "Z35SXDOTRQ7X7K"
107:     "us-east-2"      = "Z3AADJGX6KTTL2"
108:     "us-west-1"      = "Z1M58G0W56PQJA"
109:     "us-west-2"      = "Z33MTJ483K6KNU"
110:     "eu-west-1"      = "Z3DZXE0Q2N3XK0"
111:     "eu-west-2"      = "Z3GKZC51ZF0DB4"
112:     "eu-west-3"      = "Z3Q77PNBUNY4FR"
113:     "eu-central-1"   = "Z215JYRZR1TBD5"
114:     "ap-southeast-1" = "Z1LMS91P8CMLE5"
115:     "ap-southeast-2" = "Z1GM3OXH4ZPM65"
116:     "ap-northeast-1" = "Z14GRHDCWA56QT"
117:     "ap-northeast-2" = "Z1W9GUF3Q8Z8BZ"
118:     "sa-east-1"      = "Z2P70J7HTTTPLU"
119:   }
120:   alb_zone_id = lookup(local.alb_zone_ids, var.region, "Z35SXDOTRQ7X7K")
121: 
122:   # ALB DNS name: Query AWS directly using the ALB name.
123:   # While this is the preferred approach, we are reliant on the OpenLDAP module
124:   # being fully deployed as this guarantees that an Ingress resource exists, which triggers ALB creation.
125:   # The ALB must exist before this can be queried.
126:   alb_dns_name = var.use_alb ? data.aws_lb.alb[0].dns_name : null
127: 
128:   # Derive hostnames from domain_name if not explicitly provided
129:   # These are used for Route53 records and must be non-null
130:   # Note: domain_name is a required variable (not a resource), so no depends_on is needed
131:   # The coalesce ensures we always have a value - either from the variable or derived from domain_name
132:   phpldapadmin_host = coalesce(var.phpldapadmin_host, "phpldapadmin.${var.domain_name}")
133:   ltb_passwd_host   = coalesce(var.ltb_passwd_host, "passwd.${var.domain_name}")
134:   twofa_app_host    = coalesce(var.twofa_app_host, "app.${var.domain_name}")
135: }
136: 
137: # ALB module creates IngressClass and IngressClassParams for EKS Auto Mode
138: # The Ingress/Service resources in the module are commented out (not needed)
139: module "alb" {
140:   source = "./modules/alb"
141: 
142:   count = var.use_alb ? 1 : 0
143: 
144:   env          = var.env
145:   region       = var.region
146:   prefix       = var.prefix
147:   app_name     = local.app_name
148:   cluster_name = local.cluster_name
149:   # ingress_alb_name            = var.ingress_alb_name
150:   # service_alb_name            = var.service_alb_name
151:   ingressclass_alb_name       = var.ingressclass_alb_name
152:   ingressclassparams_alb_name = var.ingressclassparams_alb_name
153:   acm_certificate_arn         = try(data.aws_acm_certificate.this.arn, null)
154:   alb_scheme                  = var.alb_scheme
155:   alb_ip_address_type         = var.alb_ip_address_type
156:   alb_group_name              = local.alb_group_name
157: 
158:   wait_for_crd = var.wait_for_crd
159: }
160: 
161: ##################### OpenLDAP ##########################
162: 
163: # OpenLDAP Module
164: module "openldap" {
165:   source = "./modules/openldap"
166: 
167:   env    = var.env
168:   region = var.region
169:   prefix = var.prefix
170: 
171:   app_name                 = local.app_name
172:   openldap_ldap_domain     = var.openldap_ldap_domain
173:   openldap_admin_password  = var.openldap_admin_password
174:   openldap_config_password = var.openldap_config_password
175:   openldap_secret_name     = var.openldap_secret_name
176:   storage_class_name       = local.storage_class_name
177: 
178:   # ECR image configuration
179:   ecr_registry       = local.ecr_registry
180:   ecr_repository     = local.ecr_repository
181:   openldap_image_tag = var.openldap_image_tag
182: 
183:   # Use derived values from locals to ensure non-null values
184:   # These are derived from domain_name if not explicitly provided
185:   phpldapadmin_host = local.phpldapadmin_host
186:   ltb_passwd_host   = local.ltb_passwd_host
187: 
188:   use_alb                = var.use_alb
189:   ingress_class_name     = var.use_alb ? module.alb[0].ingress_class_name : null
190:   alb_load_balancer_name = local.alb_load_balancer_name
191:   alb_target_type        = var.alb_target_type
192:   alb_ssl_policy         = var.alb_ssl_policy
193:   acm_cert_arn           = data.aws_acm_certificate.this.arn
194: 
195:   tags = local.tags
196: 
197:   depends_on = [
198:     kubernetes_storage_class_v1.this,
199:     module.alb,
200:   ]
201: }
202: 
203: # Query AWS for ALB DNS name using the load balancer name.
204: # While querying AWS directly is the preferred approach, we are reliant on the OpenLDAP module
205: # being fully deployed as this guarantees that an Ingress resource exists, which triggers ALB creation.
206: data "aws_lb" "alb" {
207:   count = var.use_alb ? 1 : 0
208:   name  = local.alb_load_balancer_name
209: 
210:   # Ensure OpenLDAP module is fully deployed (creates Ingress which triggers ALB creation)
211:   depends_on = [module.openldap]
212: }
213: 
214: ##################### Route53 Records ##########################
215: 
216: # Route53 A (alias) records for all subdomains pointing to ALB
217: # All records use consistent ALB data source approach to avoid timing issues
218: 
219: # Route53 record for phpLDAPadmin
220: module "route53_record_phpldapadmin" {
221:   source = "./modules/route53_record"
222: 
223:   count = var.use_alb && local.phpldapadmin_host != "" ? 1 : 0
224: 
225:   zone_id      = data.aws_route53_zone.this.zone_id
226:   name         = local.phpldapadmin_host
227:   alb_dns_name = data.aws_lb.alb[0].dns_name
228:   alb_zone_id  = local.alb_zone_id
229: 
230:   depends_on = [
231:     module.openldap, # Ensures Ingress is created (which triggers ALB creation)
232:     data.aws_lb.alb, # Ensures ALB exists before creating record
233:   ]
234: 
235:   providers = {
236:     aws.state_account = aws.state_account
237:   }
238: }
239: 
240: # Route53 record for ltb-passwd
241: module "route53_record_ltb_passwd" {
242:   source = "./modules/route53_record"
243: 
244:   count = var.use_alb && local.ltb_passwd_host != "" ? 1 : 0
245: 
246:   zone_id      = data.aws_route53_zone.this.zone_id
247:   name         = local.ltb_passwd_host
248:   alb_dns_name = data.aws_lb.alb[0].dns_name
249:   alb_zone_id  = local.alb_zone_id
250: 
251:   depends_on = [
252:     module.openldap, # Ensures Ingress is created (which triggers ALB creation)
253:     data.aws_lb.alb, # Ensures ALB exists before creating record
254:   ]
255: 
256:   providers = {
257:     aws.state_account = aws.state_account
258:   }
259: }
260: 
261: # Route53 record for 2FA application
262: module "route53_record_twofa_app" {
263:   source = "./modules/route53_record"
264: 
265:   count = var.use_alb && local.twofa_app_host != "" ? 1 : 0
266: 
267:   zone_id      = data.aws_route53_zone.this.zone_id
268:   name         = local.twofa_app_host
269:   alb_dns_name = data.aws_lb.alb[0].dns_name
270:   alb_zone_id  = local.alb_zone_id
271: 
272:   depends_on = [
273:     module.openldap, # Ensures Ingress is created (which triggers ALB creation)
274:     data.aws_lb.alb, # Ensures ALB exists before creating record
275:   ]
276: 
277:   providers = {
278:     aws.state_account = aws.state_account
279:   }
280: }
281: 
282: ##################### ArgoCD ##########################
283: 
284: # ArgoCD Capability Module
285: # Deployed early to allow other modules to depend on it
286: module "argocd" {
287:   source = "./modules/argocd"
288: 
289:   count = var.enable_argocd ? 1 : 0
290: 
291:   env    = var.env
292:   region = var.region
293:   prefix = var.prefix
294: 
295:   cluster_name = local.cluster_name
296: 
297:   argocd_role_name_component       = var.argocd_role_name_component
298:   argocd_capability_name_component = var.argocd_capability_name_component
299:   argocd_namespace                 = var.argocd_namespace
300:   argocd_project_name              = var.argocd_project_name
301: 
302:   idc_instance_arn = var.idc_instance_arn
303:   idc_region       = var.idc_region
304: 
305:   rbac_role_mappings        = var.argocd_rbac_role_mappings
306:   argocd_vpce_ids           = var.argocd_vpce_ids
307:   delete_propagation_policy = var.argocd_delete_propagation_policy
308: }
309: 
310: # Wait for ArgoCD capability to be fully deployed and ACTIVE
311: # This ensures proper deployment ordering when ArgoCD is enabled
312: resource "time_sleep" "wait_for_argocd" {
313:   count = var.enable_argocd ? 1 : 0
314: 
315:   create_duration = "3m" # Wait 60 seconds for ArgoCD capability to be ready
316: 
317:   depends_on = [module.argocd]
318: }
319: 
320: ##################### PostgreSQL for User Storage ##########################
321: 
322: # PostgreSQL Module for user signup data storage
323: module "postgresql" {
324:   source = "./modules/postgresql"
325: 
326:   count = var.enable_postgresql ? 1 : 0
327: 
328:   env    = var.env
329:   region = var.region
330:   prefix = var.prefix
331: 
332:   namespace         = var.postgresql_namespace
333:   secret_name       = var.postgresql_secret_name
334:   database_name     = var.postgresql_database_name
335:   database_username = var.postgresql_database_username
336:   database_password = var.postgresql_database_password
337:   storage_class     = local.storage_class_name
338:   storage_size      = var.postgresql_storage_size
339: 
340:   # ECR image configuration
341:   ecr_registry   = local.ecr_registry
342:   ecr_repository = local.ecr_repository
343:   image_tag      = var.postgresql_image_tag
344: 
345:   tags = local.tags
346: 
347:   # Static list: always depends on OpenLDAP
348:   # ArgoCD dependency is handled implicitly through module ordering (ArgoCD is defined before this module)
349:   depends_on = [
350:     module.openldap,
351:     data.aws_lb.alb
352:   ]
353: }
354: 
355: ##################### Redis for SMS OTP Storage ##########################
356: 
357: # Redis Module for centralized SMS OTP code storage with TTL-based expiration
358: module "redis" {
359:   source = "./modules/redis"
360: 
361:   count = var.enable_redis ? 1 : 0
362: 
363:   env    = var.env
364:   region = var.region
365:   prefix = var.prefix
366: 
367:   enable_redis       = var.enable_redis
368:   namespace          = var.redis_namespace
369:   secret_name        = var.redis_secret_name
370:   redis_password     = var.redis_password
371:   storage_class_name = local.storage_class_name
372:   storage_size       = var.redis_storage_size
373:   chart_version      = var.redis_chart_version
374: 
375:   # ECR image configuration
376:   ecr_registry   = local.ecr_registry
377:   ecr_repository = local.ecr_repository
378:   image_tag      = var.redis_image_tag
379: 
380:   # Network policy configuration
381:   backend_namespace = var.argocd_app_backend_namespace
382: 
383:   tags = local.tags
384: 
385:   # Static list: always depends on OpenLDAP
386:   # ArgoCD dependency is handled implicitly through module ordering (ArgoCD is defined before this module)
387:   depends_on = [
388:     module.openldap,
389:     data.aws_lb.alb
390:   ]
391: }
392: 
393: ##################### SES for Email Verification ##########################
394: 
395: # SES Module for email verification
396: module "ses" {
397:   source = "./modules/ses"
398: 
399:   count = var.enable_email_verification ? 1 : 0
400: 
401:   env          = var.env
402:   region       = var.region
403:   prefix       = var.prefix
404:   cluster_name = local.cluster_name
405: 
406:   sender_email              = var.ses_sender_email
407:   sender_domain             = var.ses_sender_domain
408:   iam_role_name             = var.ses_iam_role_name
409:   service_account_namespace = var.argocd_app_backend_namespace
410:   service_account_name      = "ldap-2fa-backend"
411:   route53_zone_id           = var.ses_route53_zone_id != null ? var.ses_route53_zone_id : data.aws_route53_zone.this.zone_id
412: 
413:   tags = local.tags
414: 
415:   # Pass state account provider for Route53 resources
416:   # If state_account_role_arn is null, state_account provider uses default credentials
417:   # Note: ses module needs both aws and aws.state_account
418:   providers = {
419:     aws               = aws
420:     aws.state_account = aws.state_account
421:   }
422: }
423: 
424: ##################### SNS for SMS 2FA ##########################
425: 
426: # SNS Module for SMS-based 2FA verification
427: module "sns" {
428:   source = "./modules/sns"
429: 
430:   count = var.enable_sms_2fa ? 1 : 0
431: 
432:   env          = var.env
433:   region       = var.region
434:   prefix       = var.prefix
435:   cluster_name = local.cluster_name
436: 
437:   sns_topic_name            = var.sns_topic_name
438:   sns_display_name          = var.sns_display_name
439:   iam_role_name             = var.sns_iam_role_name
440:   service_account_namespace = var.argocd_app_backend_namespace
441:   service_account_name      = "ldap-2fa-backend"
442: 
443:   configure_sms_preferences = var.configure_sms_preferences
444:   sms_sender_id             = var.sms_sender_id
445:   sms_type                  = var.sms_type
446:   sms_monthly_spend_limit   = var.sms_monthly_spend_limit
447: 
448:   tags = local.tags
449: }
450: 
451: ##################### ArgoCD Application - Backend
452: module "argocd_app_backend" {
453:   source = "./modules/argocd_app"
454: 
455:   count = var.enable_argocd_apps && var.enable_argocd && var.argocd_app_repo_url != null && var.argocd_app_backend_path != null ? 1 : 0
456: 
457:   app_name              = var.argocd_app_backend_name
458:   argocd_namespace      = var.argocd_namespace
459:   argocd_project_name   = var.argocd_project_name
460:   cluster_name_in_argo  = module.argocd[0].local_cluster_secret_name
461:   repo_url              = var.argocd_app_repo_url
462:   target_revision       = var.argocd_app_target_revision
463:   repo_path             = var.argocd_app_backend_path
464:   destination_namespace = var.argocd_app_backend_namespace
465: 
466:   sync_policy = var.argocd_app_sync_policy_automated ? {
467:     automated = {
468:       prune       = var.argocd_app_sync_policy_prune
469:       self_heal   = var.argocd_app_sync_policy_self_heal
470:       allow_empty = false
471:     }
472:     sync_options = ["CreateNamespace=true"]
473:   } : null
474: }
475: 
476: # ArgoCD Application - Frontend
477: module "argocd_app_frontend" {
478:   source = "./modules/argocd_app"
479: 
480:   count = var.enable_argocd_apps && var.enable_argocd && var.argocd_app_repo_url != null && var.argocd_app_frontend_path != null ? 1 : 0
481: 
482:   app_name              = var.argocd_app_frontend_name
483:   argocd_namespace      = var.argocd_namespace
484:   argocd_project_name   = var.argocd_project_name
485:   cluster_name_in_argo  = module.argocd[0].local_cluster_secret_name
486:   repo_url              = var.argocd_app_repo_url
487:   target_revision       = var.argocd_app_target_revision
488:   repo_path             = var.argocd_app_frontend_path
489:   destination_namespace = var.argocd_app_frontend_namespace
490: 
491:   sync_policy = var.argocd_app_sync_policy_automated ? {
492:     automated = {
493:       prune       = var.argocd_app_sync_policy_prune
494:       self_heal   = var.argocd_app_sync_policy_self_heal
495:       allow_empty = false
496:     }
497:     sync_options = ["CreateNamespace=true"]
498:   } : null
499: }
````

## File: application/variables.tf
````hcl
  1: variable "env" {
  2:   description = "Deployment environment"
  3:   type        = string
  4: }
  5: 
  6: variable "region" {
  7:   description = "Deployment region"
  8:   type        = string
  9: }
 10: 
 11: variable "prefix" {
 12:   description = "Name added to all resources"
 13:   type        = string
 14: }
 15: 
 16: variable "deployment_account_role_arn" {
 17:   description = "ARN of the IAM role to assume in the deployment account (Account B). Required when using GitHub Actions with multi-account setup."
 18:   type        = string
 19:   default     = null
 20:   nullable    = true
 21: }
 22: 
 23: variable "deployment_account_external_id" {
 24:   description = "ExternalId for cross-account role assumption security. Required when assuming roles in deployment accounts. Must match the ExternalId configured in the deployment account role's Trust Relationship. Retrieved from AWS Secrets Manager (secret: 'external-id') for local deployment or GitHub secret (AWS_ASSUME_EXTERNAL_ID) for GitHub Actions."
 25:   type        = string
 26:   default     = null
 27:   nullable    = true
 28:   sensitive   = true
 29: }
 30: 
 31: variable "state_account_role_arn" {
 32:   description = "ARN of the IAM role to assume in the state account (where Route53 hosted zone and ACM certificate reside). Required when Route53 and ACM resources are in a different account than the deployment account."
 33:   type        = string
 34:   default     = null
 35:   nullable    = true
 36: }
 37: 
 38: ##################### OpenLDAP ##########################
 39: variable "app_name" {
 40:   description = "Application name"
 41:   type        = string
 42: }
 43: 
 44: variable "openldap_ldap_domain" {
 45:   description = "OpenLDAP domain (e.g., ldap.talorlik.internal)"
 46:   type        = string
 47: }
 48: 
 49: variable "openldap_admin_password" {
 50:   description = "OpenLDAP admin password. MUST be set via TF_VAR_OPENLDAP_ADMIN_PASSWORD environment variable, .env file, or GitHub Secret. Do NOT set in variables.tfvars."
 51:   type        = string
 52:   sensitive   = true
 53:   # No default - must be provided via environment variable or .env file
 54: }
 55: 
 56: variable "openldap_config_password" {
 57:   description = "OpenLDAP config password. MUST be set via TF_VAR_OPENLDAP_CONFIG_PASSWORD environment variable, .env file, or GitHub Secret. Do NOT set in variables.tfvars."
 58:   type        = string
 59:   sensitive   = true
 60:   # No default - must be provided via environment variable or .env file
 61: }
 62: 
 63: variable "openldap_secret_name" {
 64:   description = "Name of the Kubernetes secret for OpenLDAP passwords"
 65:   type        = string
 66:   default     = "openldap-secret"
 67: }
 68: 
 69: variable "openldap_image_tag" {
 70:   description = "OpenLDAP image tag in ECR. Corresponds to the tag created by mirror-images-to-ecr.sh"
 71:   type        = string
 72:   default     = "openldap-1.5.0"
 73: }
 74: 
 75: variable "postgresql_image_tag" {
 76:   description = "PostgreSQL image tag in ECR. Corresponds to the tag created by mirror-images-to-ecr.sh"
 77:   type        = string
 78:   default     = "postgresql-latest"
 79: }
 80: 
 81: variable "redis_image_tag" {
 82:   description = "Redis image tag in ECR. Corresponds to the tag created by mirror-images-to-ecr.sh"
 83:   type        = string
 84:   default     = "redis-latest"
 85: }
 86: 
 87: ##################### Storage ##########################
 88: 
 89: variable "storage_class_name" {
 90:   description = "Name of the Kubernetes StorageClass to create and use for OpenLDAP PVC"
 91:   type        = string
 92: }
 93: 
 94: variable "storage_class_type" {
 95:   description = "EBS volume type for the StorageClass (gp2, gp3, io1, io2, etc.)"
 96:   type        = string
 97: }
 98: 
 99: variable "storage_class_encrypted" {
100:   description = "Whether to encrypt EBS volumes created by the StorageClass"
101:   type        = bool
102: }
103: 
104: variable "storage_class_is_default" {
105:   description = "Whether to mark this StorageClass as the default for the cluster"
106:   type        = bool
107: }
108: 
109: ##################### Route53 ##########################
110: 
111: variable "domain_name" {
112:   description = "Root domain name for Route53 hosted zone and ACM certificate (e.g., talorlik.com)"
113:   type        = string
114: }
115: 
116: # variable "subject_alternative_names" {
117: #   description = "List of subject alternative names for the ACM certificate (e.g., [\"*.talorlik.com\"])"
118: #   type        = list(string)
119: #   default     = []
120: # }
121: 
122: # variable "use_existing_route53_zone" {
123: #   description = "Whether to use an existing Route53 zone"
124: #   type        = bool
125: #   default     = false
126: # }
127: 
128: # Use ALB - can set this to false for to get NLB
129: ### NLB not yet implemented. If false you get no load balancer
130: variable "use_alb" {
131:   description = "When true, uses AWS Auto to create ALB. When false an NLB is created"
132:   type        = bool
133:   default     = true
134: }
135: 
136: # variable "ingress_alb_name" {
137: #   description = "Name component for ingress ALB resource (between prefix and env)"
138: #   type        = string
139: # }
140: 
141: # variable "service_alb_name" {
142: #   description = "Name component for service ALB resource (between prefix and env)"
143: #   type        = string
144: # }
145: 
146: variable "ingressclass_alb_name" {
147:   description = "Name component for ingressclass ALB resource (between prefix and env)"
148:   type        = string
149: }
150: 
151: variable "ingressclassparams_alb_name" {
152:   description = "Name component for ingressclassparams ALB resource (between prefix and env)"
153:   type        = string
154: }
155: 
156: ##################### ALB Configuration ##########################
157: 
158: variable "alb_group_name" {
159:   description = "ALB group name for grouping multiple Ingress resources to share a single ALB. This is an internal Kubernetes identifier (max 63 characters)."
160:   type        = string
161:   default     = null # If null, will be derived from app_name
162: }
163: 
164: variable "alb_load_balancer_name" {
165:   description = "Custom name for the AWS ALB (appears in AWS console). Must be  32 characters per AWS constraints. If null, defaults to alb_group_name (truncated to 32 chars if needed)."
166:   type        = string
167:   default     = null
168: }
169: 
170: variable "phpldapadmin_host" {
171:   description = "Hostname for phpLDAPadmin ingress (e.g., phpldapadmin.talorlik.com). If null, will be derived from domain_name"
172:   type        = string
173:   default     = null
174:   nullable    = true
175: }
176: 
177: variable "ltb_passwd_host" {
178:   description = "Hostname for ltb-passwd ingress (e.g., passwd.talorlik.com). If null, will be derived from domain_name"
179:   type        = string
180:   default     = null
181:   nullable    = true
182: }
183: 
184: variable "twofa_app_host" {
185:   description = "Hostname for 2FA application ingress (e.g., app.talorlik.com). If null, will be derived from domain_name"
186:   type        = string
187:   default     = null
188: }
189: 
190: variable "alb_scheme" {
191:   description = "ALB scheme: internet-facing or internal"
192:   type        = string
193:   default     = "internet-facing"
194:   validation {
195:     condition     = contains(["internet-facing", "internal"], var.alb_scheme)
196:     error_message = "ALB scheme must be either 'internet-facing' or 'internal'"
197:   }
198: }
199: 
200: variable "alb_target_type" {
201:   description = "ALB target type: ip or instance"
202:   type        = string
203:   default     = "ip"
204:   validation {
205:     condition     = contains(["ip", "instance"], var.alb_target_type)
206:     error_message = "ALB target type must be either 'ip' or 'instance'"
207:   }
208: }
209: 
210: variable "alb_ssl_policy" {
211:   description = "ALB SSL policy for HTTPS listeners"
212:   type        = string
213:   default     = "ELBSecurityPolicy-TLS13-1-0-PQ-2025-09"
214: }
215: 
216: variable "alb_ip_address_type" {
217:   description = "ALB IP address type: ipv4 or dualstack"
218:   type        = string
219:   default     = "ipv4"
220:   validation {
221:     condition     = contains(["ipv4", "dualstack"], var.alb_ip_address_type)
222:     error_message = "ALB IP address type must be either 'ipv4' or 'dualstack'"
223:   }
224: }
225: 
226: variable "cluster_name" {
227:   description = "Full name of the EKS cluster (will be retrieved from backend_infra remote state if backend.hcl exists, otherwise must be provided)"
228:   type        = string
229:   default     = null
230: }
231: 
232: variable "cluster_name_component" {
233:   description = "Name component for cluster (used only if cluster_name not provided and remote state unavailable). Full name format: prefix-region-cluster_name_component-env"
234:   type        = string
235:   default     = "kc"
236: }
237: 
238: variable "terraform_workspace" {
239:   description = "Terraform workspace name for remote state lookup. If null, will be derived from region and env as 'region-env'. This ensures the correct workspace state is used when fetching ECR registry information from backend_infra."
240:   type        = string
241:   default     = null
242:   nullable    = true
243: }
244: 
245: variable "kubernetes_master" {
246:   description = "Kubernetes API server endpoint (KUBERNETES_MASTER environment variable). Set by set-k8s-env.sh or GitHub workflow. Can be set via TF_VAR_kubernetes_master."
247:   type        = string
248:   default     = null
249:   nullable    = true
250: }
251: 
252: variable "kube_config_path" {
253:   description = "Path to kubeconfig file (KUBE_CONFIG_PATH environment variable). Set by set-k8s-env.sh or GitHub workflow. Can be set via TF_VAR_kube_config_path."
254:   type        = string
255:   default     = null
256:   nullable    = true
257: }
258: 
259: variable "wait_for_crd" {
260:   description = "Whether to wait for EKS Auto Mode CRD to be available before creating IngressClassParams. Set to true for initial cluster deployments, false after cluster is established."
261:   type        = bool
262:   default     = false
263: }
264: 
265: ##################### PostgreSQL User Storage ##########################
266: 
267: variable "enable_postgresql" {
268:   description = "Whether to deploy PostgreSQL for user storage"
269:   type        = bool
270:   default     = true
271: }
272: 
273: variable "postgresql_namespace" {
274:   description = "Kubernetes namespace for PostgreSQL"
275:   type        = string
276:   default     = "ldap-2fa"
277: }
278: 
279: variable "postgresql_database_name" {
280:   description = "PostgreSQL database name"
281:   type        = string
282:   default     = "ldap2fa"
283: }
284: 
285: variable "postgresql_database_username" {
286:   description = "PostgreSQL database username"
287:   type        = string
288:   default     = "ldap2fa"
289: }
290: 
291: variable "postgresql_database_password" {
292:   description = "PostgreSQL database password. MUST be set via TF_VAR_POSTGRESQL_PASSWORD environment variable or GitHub Secret."
293:   type        = string
294:   sensitive   = true
295: }
296: 
297: variable "postgresql_secret_name" {
298:   description = "Name of the Kubernetes secret for PostgreSQL password"
299:   type        = string
300:   default     = "postgresql-secret"
301: }
302: 
303: variable "postgresql_storage_size" {
304:   description = "PostgreSQL storage size"
305:   type        = string
306:   default     = "8Gi"
307: }
308: 
309: ##################### SES Email Verification ##########################
310: 
311: variable "enable_email_verification" {
312:   description = "Whether to enable email verification using SES"
313:   type        = bool
314:   default     = true
315: }
316: 
317: variable "ses_sender_email" {
318:   description = "Email address to send verification emails from"
319:   type        = string
320:   default     = "noreply@example.com"
321: }
322: 
323: variable "ses_sender_domain" {
324:   description = "Domain to verify in SES (optional, for domain-level verification)"
325:   type        = string
326:   default     = null
327: }
328: 
329: variable "ses_iam_role_name" {
330:   description = "Name component for the SES IAM role"
331:   type        = string
332:   default     = "ses-sender"
333: }
334: 
335: variable "ses_route53_zone_id" {
336:   description = "Route53 zone ID for SES domain verification (optional, defaults to main domain zone)"
337:   type        = string
338:   default     = null
339: }
340: 
341: ##################### SNS SMS 2FA ##########################
342: 
343: variable "enable_sms_2fa" {
344:   description = "Whether to enable SMS-based 2FA using SNS"
345:   type        = bool
346:   default     = false
347: }
348: 
349: variable "sns_topic_name" {
350:   description = "Name component for the SNS topic"
351:   type        = string
352: }
353: 
354: variable "sns_display_name" {
355:   description = "Display name for the SNS topic (appears in SMS sender)"
356:   type        = string
357: }
358: 
359: variable "sns_iam_role_name" {
360:   description = "Name component for the SNS IAM role"
361:   type        = string
362: }
363: 
364: variable "configure_sms_preferences" {
365:   description = "Whether to configure account-level SMS preferences"
366:   type        = bool
367:   default     = false
368: }
369: 
370: variable "sms_sender_id" {
371:   description = "Default sender ID for SMS messages (max 11 alphanumeric characters)"
372:   type        = string
373: }
374: 
375: variable "sms_type" {
376:   description = "Default SMS type: Promotional or Transactional"
377:   type        = string
378:   validation {
379:     condition     = contains(["Promotional", "Transactional"], var.sms_type)
380:     error_message = "SMS type must be either 'Promotional' or 'Transactional'"
381:   }
382: }
383: 
384: variable "sms_monthly_spend_limit" {
385:   description = "Monthly spend limit for SMS in USD"
386:   type        = number
387: }
388: 
389: ##################### Redis SMS OTP Storage ##########################
390: 
391: variable "enable_redis" {
392:   description = "Enable Redis deployment for SMS OTP storage"
393:   type        = bool
394:   default     = false
395: }
396: 
397: variable "redis_password" {
398:   description = "Redis authentication password (from GitHub Secrets via TF_VAR_REDIS_PASSWORD)"
399:   type        = string
400:   sensitive   = true
401:   default     = ""
402: 
403:   validation {
404:     condition     = var.enable_redis == false || length(var.redis_password) >= 8
405:     error_message = "Redis password must be at least 8 characters when Redis is enabled."
406:   }
407: }
408: 
409: variable "redis_secret_name" {
410:   description = "Name of the Kubernetes secret for Redis password"
411:   type        = string
412:   default     = "redis-secret"
413: }
414: 
415: variable "redis_namespace" {
416:   description = "Kubernetes namespace for Redis"
417:   type        = string
418:   default     = "redis"
419: }
420: 
421: variable "redis_storage_size" {
422:   description = "Redis PVC storage size"
423:   type        = string
424:   default     = "1Gi"
425: }
426: 
427: variable "redis_chart_version" {
428:   description = "Bitnami Redis Helm chart version"
429:   type        = string
430:   default     = "19.6.4"
431: }
432: 
433: ##################### ArgoCD ##########################
434: 
435: variable "enable_argocd" {
436:   description = "Whether to enable ArgoCD capability deployment"
437:   type        = bool
438:   default     = false
439: }
440: 
441: variable "argocd_role_name_component" {
442:   description = "Name component for ArgoCD IAM role (between prefix and env)"
443:   type        = string
444: }
445: 
446: variable "argocd_capability_name_component" {
447:   description = "Name component for ArgoCD capability (between prefix and env)"
448:   type        = string
449: }
450: 
451: variable "argocd_namespace" {
452:   description = "Kubernetes namespace for ArgoCD resources"
453:   type        = string
454: }
455: 
456: variable "argocd_project_name" {
457:   description = "ArgoCD project name for cluster registration"
458:   type        = string
459: }
460: 
461: variable "idc_instance_arn" {
462:   description = "ARN of the AWS Identity Center instance used for Argo CD auth"
463:   type        = string
464:   default     = null
465:   nullable    = true
466: }
467: 
468: variable "idc_region" {
469:   description = "Region of the Identity Center instance"
470:   type        = string
471:   default     = null
472:   nullable    = true
473: }
474: 
475: variable "argocd_rbac_role_mappings" {
476:   description = "List of RBAC role mappings for Identity Center groups/users"
477:   type = list(object({
478:     role = string
479:     identities = list(object({
480:       id   = string
481:       type = string # SSO_GROUP or SSO_USER
482:     }))
483:   }))
484:   default = []
485: }
486: 
487: variable "argocd_vpce_ids" {
488:   description = "Optional list of VPC endpoint IDs for private access to Argo CD"
489:   type        = list(string)
490:   default     = []
491: }
492: 
493: variable "argocd_delete_propagation_policy" {
494:   description = "Delete propagation policy for ArgoCD capability (RETAIN or DELETE)"
495:   type        = string
496:   validation {
497:     condition     = contains(["RETAIN", "DELETE"], var.argocd_delete_propagation_policy)
498:     error_message = "Delete propagation policy must be either 'RETAIN' or 'DELETE'"
499:   }
500: }
501: 
502: ##################### ArgoCD Applications ##########################
503: 
504: variable "enable_argocd_apps" {
505:   description = "Whether to enable ArgoCD Application deployments"
506:   type        = bool
507:   default     = false
508: }
509: 
510: variable "argocd_app_repo_url" {
511:   description = "Git repository URL containing application manifests. Supports both HTTPS (https://github.com/user/repo.git) and SSH (git@github.com:user/repo.git) URLs. SSH URLs require SSH key credentials to be configured via a Kubernetes Secret with label 'argocd.argoproj.io/secret-type: repository'"
512:   type        = string
513:   default     = null
514:   nullable    = true
515: }
516: 
517: variable "argocd_app_target_revision" {
518:   description = "Git branch, tag, or commit to sync (default: HEAD)"
519:   type        = string
520:   default     = "HEAD"
521: }
522: 
523: # Backend App Configuration
524: variable "argocd_app_backend_name" {
525:   description = "Name of the ArgoCD Application for backend"
526:   type        = string
527: }
528: 
529: variable "argocd_app_backend_path" {
530:   description = "Path within the repository to the backend application manifests"
531:   type        = string
532:   default     = null
533:   nullable    = true
534: }
535: 
536: variable "argocd_app_backend_namespace" {
537:   description = "Target Kubernetes namespace for the backend application"
538:   type        = string
539: }
540: 
541: # Frontend App Configuration
542: variable "argocd_app_frontend_name" {
543:   description = "Name of the ArgoCD Application for frontend"
544:   type        = string
545: }
546: 
547: variable "argocd_app_frontend_path" {
548:   description = "Path within the repository to the frontend application manifests"
549:   type        = string
550:   default     = null
551:   nullable    = true
552: }
553: 
554: variable "argocd_app_frontend_namespace" {
555:   description = "Target Kubernetes namespace for the frontend application"
556:   type        = string
557: }
558: 
559: variable "argocd_app_sync_policy_automated" {
560:   description = "Enable automated sync policy for ArgoCD Applications"
561:   type        = bool
562:   default     = true
563: }
564: 
565: variable "argocd_app_sync_policy_prune" {
566:   description = "Enable prune for automated sync (delete resources not in Git)"
567:   type        = bool
568:   default     = true
569: }
570: 
571: variable "argocd_app_sync_policy_self_heal" {
572:   description = "Enable self-heal for automated sync (auto-sync on drift detection)"
573:   type        = bool
574:   default     = true
575: }
````

## File: CHANGELOG.md
````markdown
  1: # Changelog
  2: 
  3: All notable changes to this project will be documented in this file.
  4: 
  5: The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
  6: and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
  7: 
  8: ## [2026-01-18] - Documentation Updates and Certificate Architecture Migration
  9: 
 10: ### Changed
 11: 
 12: - **Certificate Architecture Migration to Public ACM**
 13:   - Migrated from Private CA-based certificates to Public ACM certificates
 14:     (Amazon-issued) for browser-trusted certificates
 15:   - Public ACM certificates are requested in each deployment account and
 16:     validated via DNS records in State Account's Route53 hosted zone
 17:   - Certificates are automatically renewed by ACM (no manual intervention
 18:     required)
 19:   - Eliminates browser security warnings and simplifies certificate management
 20:   - Updated all documentation to reflect Public ACM certificate architecture
 21:   - Comprehensive Public ACM certificate setup documentation in
 22:     `application/CROSS-ACCOUNT-ACCESS.md` with step-by-step AWS CLI commands
 23:   - Private CA setup moved to "Legacy" section (deprecated for public-facing
 24:     applications)
 25: 
 26: - **Image Tag Standardization Update**
 27:   - Updated Redis and PostgreSQL image tags to use 'latest' tag instead of
 28:     version-specific tags
 29:   - Redis default image tag changed from `redis-8.4.0` to `redis-latest`
 30:   - PostgreSQL default image tag changed from `postgresql-18.1.0` to
 31:     `postgresql-latest`
 32:   - OpenLDAP continues to use specific version tag: `openldap-1.5.0`
 33:   - Updated ECR image mirroring script to use 'latest' tags
 34:   - Updated all documentation to reflect new image tag naming convention
 35: 
 36: - **Comprehensive Documentation Updates**
 37:   - Updated `docs/index.html` with latest features and information
 38:   - Updated main `README.md` with Public ACM certificate prerequisites
 39:   - Updated `application/README.md` with latest features and certificate
 40:     architecture
 41:   - Updated `backend_infra/README.md` with ExternalId and latest changes
 42:   - Updated `tf_backend_state/README.md` with automatic ARN detection
 43:   - All documentation now reflects Public ACM certificates as the recommended
 44:     approach
 45:   - Updated API documentation references to clarify always-enabled status
 46:   - Added Helm release safety, ECR image support, and Kubeconfig auto-update
 47:     documentation
 48: 
 49: ### Fixed
 50: 
 51: - **Documentation Consistency**
 52:   - Fixed inconsistent references to Private CA vs Public ACM certificates
 53:   - Updated all prerequisites to reference Public ACM certificate setup
 54:   - Corrected image tag references across all documentation files
 55:   - Ensured all documentation reflects current implementation state
 56: 
 57: ## [2026-01-15] - Helm Release Safety, ECR Image Support, and Infrastructure Improvements
 58: 
 59: ### Added
 60: 
 61: - **Helm Release Attributes for Safer Deployments**
 62:   - Added comprehensive Helm release attributes to all application modules
 63:   (OpenLDAP, PostgreSQL, Redis, cert-manager) for safer and more reliable deployments
 64:   - Attributes include: atomic, force_update, replace, cleanup_on_fail,
 65:   recreate_pods, wait, wait_for_jobs, upgrade_install
 66:   - Prevents partial deployments, enables proper rollbacks, and ensures resource
 67:   readiness
 68:   - OpenLDAP module timeout set to 5 minutes, PostgreSQL and Redis modules set
 69:   to 10 minutes
 70: 
 71: - **Standardized Helm Values Passing**
 72:   - Standardized how Helm values are passed through to all modules using consistent
 73:   `templatefile()` approach
 74:   - All modules now support `values_template_path` variable for custom template
 75:   paths
 76:   - Created comprehensive Helm values templates for PostgreSQL and updated
 77:   Redis/OpenLDAP templates
 78:   - Improved maintainability and consistency across all Helm chart deployments
 79: 
 80: - **PostgreSQL Chart Repository Fix**
 81:   - Fixed PostgreSQL Helm chart download issue by changing to OCI registry format
 82:   - Changed repository from `https://charts.bitnami.com/bitnami` to `oci://registry-1.docker.io/bitnamicharts`
 83:   - Resolves chart download failures during deployment
 84: 
 85: - **Image Tag Standardization**
 86:   - Changed Redis and PostgreSQL image tags to use 'latest' tag instead of SHA digests
 87:   - Redis default image tag: `redis-latest`
 88:   - PostgreSQL default image tag: `postgresql-latest`
 89:   - OpenLDAP continues to use specific version tag: `openldap-1.5.0`
 90:   - Simplifies image management and updates while maintaining version control
 91: 
 92: - **Public ACM Certificate Architecture**
 93:   - Migrated to Public ACM certificates (Amazon-issued) for browser-trusted
 94:     certificates
 95:   - Public ACM certificates requested in each deployment account (development,
 96:     production)
 97:   - DNS validation records created in Route53 hosted zone in State Account
 98:   - Certificates stored in respective deployment accounts (not State Account)
 99:   - Eliminates cross-account certificate access complexity
100:   - Compatible with EKS Auto Mode ALB controller requirements (certificate must
101:     be in same account as ALB)
102:   - Comprehensive Public ACM certificate setup documentation in
103:     `application/CROSS-ACCOUNT-ACCESS.md` with step-by-step AWS CLI commands
104:   - Certificate validation workflow documented for both production and development
105:     accounts
106:   - Certificates automatically renewed by ACM (no manual intervention required)
107:   - Browser-trusted certificates (no security warnings)
108: 
109: - **State Account Role ARN Support for Route53 Cross-Account Access**
110:   - Added support for querying Route53 hosted zones from State Account
111:   - New variable `state_account_role_arn` in `application/variables.tf` for
112:     assuming role in State Account
113:   - State account provider alias (`aws.state_account`) configured in
114:     `application/providers.tf`
115:   - All Route53 data sources and resources use state account provider when
116:     configured
117:   - Route53 records created in State Account while ALB deployed in Deployment
118:     Account
119:   - Route53 DNS validation records for Public ACM certificates created in State
120:     Account
121:   - ACM certificates are Public ACM certificates (Amazon-issued) requested in
122:     Deployment Account (not State Account)
123:   - Scripts automatically inject `state_account_role_arn`:
124:     - `application/setup-application.sh` exports `STATE_ACCOUNT_ROLE_ARN`
125:     - `application/set-k8s-env.sh` injects into `variables.tfvars`
126:   - GitHub Actions workflows export `STATE_ACCOUNT_ROLE_ARN` for automatic
127:     injection
128:   - No ExternalId required for state account role assumption (by design)
129:   - Comprehensive cross-account access documentation in
130:     `application/CROSS-ACCOUNT-ACCESS.md`
131:   - Updated ALB module to handle null certificate ARN and include in triggers
132: 
133: - **ExternalId Support for Cross-Account Role Assumption**
134:   - Added ExternalId requirement for enhanced security when assuming deployment
135:   account roles
136:   - ExternalId retrieved from AWS Secrets Manager (secret: `external-id`) for
137:   local deployment
138:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
139:   for GitHub Actions
140:   - ExternalId passed to Terraform provider's `assume_role` block in both
141:   `application` and `backend_infra`
142:   - New variable `deployment_account_external_id` added to `application/variables.tf`
143:   and `backend_infra/variables.tf`
144:   - Setup scripts (`setup-application.sh` and `setup-backend.sh`) automatically
145:   retrieve ExternalId from AWS Secrets Manager
146:   - GitHub Actions workflows updated to use `AWS_ASSUME_EXTERNAL_ID` secret
147:   - Deployment account roles must have ExternalId condition in Trust Relationship
148:   - **Bidirectional Trust Relationships**: Both deployment account roles and state
149:     account role must trust each other in their respective Trust Relationships
150:   - State account role's Trust Relationship must include deployment account role
151:     ARNs to enable proper cross-account role assumption
152:   - Prevents confused deputy attacks in multi-account deployments
153:   - ExternalId generation: `openssl rand -hex 32`
154:   - Comprehensive documentation updates across all README files,
155:   SECURITY-IMPROVEMENTS.md, and docs/index.html
156: 
157: - **Destroy Scripts for Infrastructure Cleanup**
158:   - Created `application/destroy-application.sh` script for destroying application
159:   infrastructure
160:   - Created `backend_infra/destroy-backend.sh` script for destroying backend
161:   infrastructure
162:   - Both scripts support interactive region and environment selection
163:   - Automatic retrieval of role ARNs, ExternalId, and secrets from AWS Secrets
164:   Manager
165:   - Automatic backend configuration and variables.tfvars updates
166:   - Kubernetes environment setup for application destroy script
167:   - Safety confirmations required before destruction (type 'yes' then 'DESTROY')
168:   - Comprehensive error handling and user guidance
169:   - Updated GitHub Actions destroying workflows with ExternalId support
170:   - Documentation updates in README files and docs/index.html
171: 
172: - **Route53 Record Module Separation**
173:   - Separated Route53 record creation from OpenLDAP module into dedicated
174:     `route53_record` module
175:   - New module located at `application/modules/route53_record/` for per-record
176:     creation
177:   - Module uses state account provider for cross-account access (Route53 records
178:     created in State Account)
179:   - Three separate module calls: `route53_record_phpldapadmin`,
180:     `route53_record_ltb_passwd`, `route53_record_twofa_app`
181:   - Module outputs: `record_name`, `record_fqdn`, `record_id`
182:   - Precondition ensures ALB DNS name is available before record creation
183:   - Comprehensive ALB zone_id mapping by region (13 AWS regions supported)
184:   - Proper dependency chain: OpenLDAP module  ALB data source  Route53 records
185:   - All records use consistent ALB data source approach to avoid timing issues
186:   - Comprehensive module documentation in `application/modules/route53_record/README.md`
187: 
188: - **ECR Image Mirroring Script**
189:   - Created `application/mirror-images-to-ecr.sh` script to eliminate Docker Hub
190:     rate limiting and external dependencies
191:   - Automatically mirrors third-party container images from Docker Hub to ECR:
192:     - `bitnami/redis:8.4.0-debian-12-r6`  `redis-latest`
193:     - `bitnami/postgresql:18.1.0-debian-12-r4`  `postgresql-latest`
194:     - `osixia/openldap:1.5.0`  `openldap-1.5.0`
195:   - Checks if images exist in ECR before mirroring (skips if already present)
196:   - Uses State Account credentials to fetch ECR URL from backend_infra state
197:   - Assumes Deployment Account role for ECR operations (with ExternalId)
198:   - Authenticates Docker to ECR automatically
199:   - Cleans up local images after pushing to save space
200:   - Lists all images in ECR repository after completion
201:   - Integrated into `application/setup-application.sh` (runs before Terraform
202:     operations)
203:   - Integrated into GitHub Actions workflow (runs after Terraform validate, before
204:     set-k8s-env.sh)
205:   - Requires Docker to be installed and running
206:   - Requires `jq` for JSON parsing
207:   - Prevents Docker Hub rate limiting and external dependencies during deployments
208: 
209: - **ECR Image Support for Modules**
210:   - OpenLDAP, PostgreSQL, and Redis modules now use ECR images instead of
211:   Docker Hub
212:   - New variables in `application/variables.tf`:
213:     - `openldap_image_tag` (default: "openldap-1.5.0")
214:     - `postgresql_image_tag` (default: "postgresql-latest")
215:     - `redis_image_tag` (default: "redis-latest")
216:   - ECR registry and repository computed from backend_infra state (`ecr_url`)
217:   - All modules updated with ECR configuration variables:
218:     - `ecr_registry`: ECR registry URL
219:     - `ecr_repository`: ECR repository name
220:     - `image_tag` or module-specific tag variable
221:   - Helm values templates updated to use ECR images
222:   - Image tags correspond to tags created by `mirror-images-to-ecr.sh`
223: 
224: ### Changed
225: 
226: - **Module Documentation Updates**
227:   - Updated all module READMEs with standardized Helm values passing documentation
228:   - Enhanced PostgreSQL, Redis, OpenLDAP, ALB, cert-manager, and ArgoCD module documentation
229:   - Added comprehensive Route53 module README documentation
230:   - Improved consistency and clarity across all module documentation
231: 
232: - **Helm Values Template Organization**
233:   - Standardized Helm values template structure across all modules
234:   - Improved template variable naming and organization
235:   - Enhanced template documentation and comments
236: 
237: - **Kubeconfig Auto-Update to Prevent Stale Cluster Endpoints**
238:   - Fixed issue where kubeconfig could contain stale cluster endpoints after
239:     cluster recreation or endpoint changes
240:   - `set-k8s-env.sh` now automatically updates kubeconfig on every run using
241:     `aws eks update-kubeconfig`
242:   - Ensures kubeconfig always contains the latest cluster endpoint before any
243:     kubectl commands are executed
244:   - Prevents DNS lookup errors like: `dial tcp: lookup
245:     26A3426590C00FBB5A84A506D1F8B14A.gr7.us-east-1.eks.amazonaws.com: no such host`
246:   - Uses deployment account credentials (already assumed by the script) for
247:     kubeconfig update
248:   - Automatically creates kubeconfig directory if it doesn't exist
249:   - Script exits with error if kubeconfig update fails, preventing deployment
250:     with incorrect configuration
251:   - Fixes issues with Terraform provisioners (e.g., ALB IngressClassParams) that
252:     use kubectl commands
253: 
254: - **Documentation Improvements**
255:   - Removed duplication across README files by replacing detailed content with
256:   links to module documentation
257:   - Enhanced cross-references between main README, application README,
258:   and module READMEs
259:   - Updated architecture overview sections to be more concise with links to
260:   detailed documentation
261:   - Improved module documentation references in application and backend
262:   infrastructure READMEs
263:   - Added links to PRD documents for detailed feature specifications
264:   - Updated changelog references in main README
265: 
266: - **Setup Script Improvements**
267:   - Enhanced `backend_infra/setup-backend.sh` with improved error handling and
268:   ExternalId support
269:   - Enhanced `application/setup-application.sh` with improved error handling,
270:   ExternalId support, and Kubernetes environment setup
271:   - Both scripts now automatically retrieve ExternalId from AWS Secrets Manager
272:   - Improved role assumption logic with better error messages
273:   - Enhanced secret retrieval with validation and error handling
274:   - Better integration with GitHub repository variables and secrets
275:   - Improved user guidance and confirmation prompts
276:   - Improved credential handling to prevent conflicts between different AWS
277:     credentials
278:   - Better dependency chain organization to prevent failures
279:   - Enhanced script error handling in destroy scripts
280: 
281: - **GitHub Actions Workflow Updates**
282:   - Updated `application_infra_provisioning.yaml` with new environment variables
283:   for Redis, PostgreSQL, and SES
284:   - Added Docker Buildx setup step for image operations
285:   - Added "Mirror Docker images to ECR" step (runs after Terraform validate, before
286:     set-k8s-env.sh)
287:   - Workflow now handles image mirroring automatically
288:   - Improved credential handling to prevent conflicts between different AWS
289:     credentials
290:   - Updated `application_infra_destroying.yaml` with ExternalId support and
291:   improved error handling
292:   - Updated `backend_infra_provisioning.yaml` with ExternalId support
293:   - Updated `backend_infra_destroying.yaml` with ExternalId support and
294:   improved error handling
295:   - Workflows now pass Redis password via `TF_VAR_redis_password` environment
296:   variable (from GitHub Secret `TF_VAR_REDIS_PASSWORD`)
297:   - Workflows now pass PostgreSQL password via `TF_VAR_postgresql_database_password`
298:   environment variable (from GitHub Secret `TF_VAR_POSTGRES_PASSWORD`)
299:   - All workflows now use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state
300:   operations
301:   - All workflows now use `AWS_ASSUME_EXTERNAL_ID` for cross-account role
302:   assumption security
303:   - Maintains backward compatibility with existing OpenLDAP password secrets
304: 
305: - **Comprehensive Product Requirements Documents**
306:   - Added `PRD-SIGNUP-MAN.md` for user signup management system
307:   - Added `PRD-ADMIN-FUNCS.md` for admin functions and profile management
308:   - Added `PRD-SMS-MAN.md` for SMS OTP management with Redis
309: 
310: - **Documentation and linting improvements**
311:   - All documentation files updated for Markdown lint compliance
312:   - Added `.markdownlint.json` for consistent formatting across the project
313:   - Improved formatting consistency across CHANGELOG, README, and PRD files
314: 
315: - **Enhanced Network Policies**
316:   - Added cross-namespace communication rules for LDAP service access
317:   - Allows services in other namespaces to access LDAP on secure
318:   ports (443, 636, 8443)
319:   - Maintains security by only allowing encrypted ports
320: 
321: - **VPC Endpoints module enhancements**
322:   - Added `enable_sts_endpoint` and `enable_sns_endpoint` configuration options
323:   - Added `vpc_cidr` variable for security group rules
324:   - New outputs for STS and SNS endpoint IDs
325: 
326: - **Password management approach**
327:   - OpenLDAP passwords are now managed exclusively through GitHub repository
328:   secrets
329:   - Removed dependency on local password files or environment-specific
330:   configurations
331:   - Setup scripts automatically retrieve passwords from GitHub secrets
332:   - Updated documentation to reflect new password management workflow
333:   - Improved security by eliminating password storage in local files
334: 
335: - **Setup script consolidation**
336:   - Replaced `setup-backend.sh` and `setup-backend-api.sh` with unified
337:   `setup-application.sh`
338:   - New script provides complete end-to-end deployment automation
339:   - Improved error messages and user guidance
340:   - Better integration with GitHub repository secrets and variables
341: 
342: - **Documentation updates**
343:   - Updated `README.md` with comprehensive password management instructions and
344:   three-role architecture documentation
345:   - Updated `WARP.md` with latest setup procedures and password handling
346:   - Updated `application/README.md` to reflect new setup script workflow
347:   - Updated `backend_infra/README.md` to reflect environment-based role
348:   selection
349:   - Clarified local vs. GitHub Actions execution differences
350:   - Clarified the separation between backend state operations and deployment
351:   operations
352:   - Updated AWS IAM setup instructions to reflect the new role structure
353: 
354: - **Multi-account architecture clarification**
355:   - Separated backend state operations from deployment operations
356:   - Backend state operations now use `AWS_STATE_ACCOUNT_ROLE_ARN` (State
357:   Account)
358:   - Deployment operations use environment-specific role ARNs
359:   (`AWS_PRODUCTION_ACCOUNT_ROLE_ARN` or `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`)
360:   - Updated all workflows to use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend
361:   operations
362:   - Updated workflows to set `deployment_account_role_arn` variable based on
363:   selected environment
364: 
365: - **Workflow updates**
366:   - `backend_infra_provisioning.yaml`: Uses `AWS_STATE_ACCOUNT_ROLE_ARN` for
367:   backend, sets environment-based deployment role
368:   - `backend_infra_destroying.yaml`: Uses `AWS_STATE_ACCOUNT_ROLE_ARN` for
369:   backend, sets environment-based deployment role
370:   - `application_infra_provisioning.yaml`: Uses `AWS_STATE_ACCOUNT_ROLE_ARN` for
371:   backend, sets environment-based deployment role
372:   - `application_infra_destroying.yaml`: Uses `AWS_STATE_ACCOUNT_ROLE_ARN` for
373:   backend, sets environment-based deployment role
374: 
375: ## [2025-12-20] - User Signup, Admin Functions, and Infrastructure Modules
376: 
377: ### Added
378: 
379: - **API Documentation (Swagger UI)**
380:   - FastAPI Swagger UI now always enabled at `/api/docs` (previously only available
381:   in debug mode)
382:   - ReDoc UI always available at `/api/redoc`
383:   - OpenAPI schema accessible at `/api/openapi.json`
384:   - Interactive API documentation automatically updates when endpoints change
385:   - Accessible at `https://app.<domain>/api/docs` for API exploration and testing
386: 
387: - **User Signup Management System**
388:   - Self-service user registration with profile fields (first name, last name,
389:   username, email, phone, password, MFA method)
390:   - Email verification via AWS SES with token-based verification links
391:   - Phone verification via AWS SNS with 6-digit OTP codes
392:   - Profile state management (PENDING  COMPLETE  ACTIVE)
393:   - PostgreSQL database for storing user data before LDAP activation
394:   - Administrator user management interface for approval workflow
395:   - Login restrictions based on verification status
396: 
397: - **Admin Functions and User Profile Management**
398:   - User profile page with viewable and editable fields
399:   - Edit restrictions for verified email/phone (read-only after verification)
400:   - Admin dashboard (only visible to LDAP admin group members)
401:   - Group CRUD operations (create, read, update, delete)
402:   - User-group assignment and management
403:   - Approve/Revoke workflow for user activation
404:   - List features with sorting, filtering, and searching
405:   - Admin email notifications on new user signup
406:   - Top navigation bar with user menu after login
407: 
408: - **PostgreSQL Module (`application/modules/postgresql/`)**
409:   - Bitnami PostgreSQL Helm chart deployment via Terraform
410:   - Database for storing user registrations and verification tokens
411:   - Password authentication via Kubernetes Secret (from GitHub Secrets)
412:   - PersistentVolume storage for data durability
413: 
414: - **SES Module (`application/modules/ses/`)**
415:   - AWS SES email identity verification
416:   - IAM Role configured for IRSA
417:   - Email sending capabilities for verification and notifications
418:   - Welcome email on user activation
419: 
420: - **Redis Module for SMS OTP Storage (`application/modules/redis/`)**
421:   - Bitnami Redis Helm chart deployment via Terraform
422:   - Replaces in-memory storage for SMS OTP codes
423:   - TTL-based automatic expiration for OTP codes
424:   - Network policy restricting Redis access to backend pods only
425:   - Password authentication via Kubernetes Secret
426: 
427: - **Two-Factor Authentication (2FA) Application**
428:   - Full-stack 2FA solution with Python FastAPI backend and static HTML/JS/CSS
429:   frontend
430:   - Dual MFA methods: TOTP (authenticator apps) and SMS (AWS SNS)
431:   - Single domain routing with path-based access (`/` for frontend, `/api/*` for
432:   backend)
433:   - Complete Helm charts, Dockerfiles, and Kubernetes resources for deployment
434:   - Comprehensive PRD documentation (`PRD-2FA-APP.md`)
435: 
436: - **ArgoCD GitOps Integration**
437:   - AWS EKS managed ArgoCD service deployment
438:   - ArgoCD Application module for GitOps-driven deployments
439:   - Support for Kubernetes manifests, Helm charts, and Kustomize
440:   - AWS Identity Center (IdC) authentication and RBAC mappings
441:   - ECR and CodeCommit access policy configuration
442: 
443: - **IRSA (IAM Roles for Service Accounts) Support**
444:   - Enabled OIDC provider on EKS cluster for secure pod-to-AWS-service
445:   authentication
446:   - New outputs: `oidc_provider_arn` and `oidc_provider_url`
447:   - Required for secure SNS access from application pods
448: 
449: - **VPC Endpoints for Private AWS Service Access**
450:   - STS VPC endpoint for IRSA/web identity role assumption
451:   - SNS VPC endpoint for SMS 2FA functionality
452:   - VPC CIDR security group rule for pod access to endpoints
453: 
454: - **SNS Module for SMS-based 2FA**
455:   - SNS Topic for centralized SMS notifications
456:   - IAM Role configured for IRSA
457:   - Direct SMS support with E.164 phone number format
458:   - Cost control via monthly spend limits
459: 
460: - **OpenLDAP password management via GitHub repository secrets**
461:   - `setup-application.sh` now automatically retrieves OpenLDAP passwords from
462:   GitHub repository secrets
463:   - New GitHub secrets: `TF_VAR_OPENLDAP_ADMIN_PASSWORD` and
464:   `TF_VAR_OPENLDAP_CONFIG_PASSWORD`
465:   - Script automatically exports passwords as environment variables for
466:   Terraform
467:   - Supports both GitHub Actions (automatic) and local execution (requires
468:   exported environment variables)
469:   - Eliminates need to manually manage password files or commit sensitive data
470: 
471: - **Consolidated application setup script**
472:   - New unified `setup-application.sh` script replaces `setup-backend.sh` and
473:   `setup-backend-api.sh`
474:   - Handles complete application deployment workflow: role assumption, backend
475:   configuration, Terraform operations, and Kubernetes environment setup
476:   - Automatically retrieves all required secrets and variables from GitHub
477:   - Includes comprehensive error handling and user-friendly output
478: 
479: - **Environment-based AWS role ARN selection**
480:   - Added support for separate role ARNs for production and development
481:   environments
482:   - New GitHub secrets: `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` and
483:   `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
484:   - Workflows and scripts automatically select the appropriate role ARN based on
485:   selected environment (`prod` or `dev`)
486:   - `setup-backend.sh` script now retrieves and uses environment-specific
487:   deployment account role ARNs
488: 
489: - **Automated Terraform execution in setup scripts**
490:   - `setup-backend.sh` now automatically runs Terraform commands (init,
491:   workspace, validate, plan, apply)
492:   - Eliminates the need for manual Terraform command execution after backend
493:   configuration
494:   - Script handles workspace creation/selection automatically
495: 
496: - **Automated backend.hcl creation**
497:   - `setup-backend.sh` now automatically creates `backend.hcl` from template if
498:   it doesn't exist
499:   - Skips creation if `backend.hcl` already exists (prevents overwriting
500:   existing configuration)
501: 
502: - **New GitHub Secrets for Infrastructure Components**
503:   - `TF_VAR_REDIS_PASSWORD`: Redis authentication password for SMS OTP storage
504:   (exported as `TF_VAR_redis_password`)
505:   - `TF_VAR_POSTGRES_PASSWORD`: PostgreSQL database password for user data
506:   (exported as `TF_VAR_postgresql_database_password`)
507:   - All secrets follow existing pattern (TF_VAR_ prefix for Terraform
508:   integration)
509:   - **Note:** Secret names in GitHub/AWS remain uppercase, but environment
510:   variables must be lowercase to match variable names in `variables.tf`
511: 
512: ### Removed
513: 
514: - **Removed legacy setup scripts**
515:   - Removed `application/setup-backend.sh` (replaced by `setup-application.sh`)
516:   - Removed `application/setup-backend-api.sh` (replaced by
517:   `setup-application.sh`)
518:   - Consolidated functionality into single unified script for better
519:   maintainability
520: 
521: - **Removed `provider_profile` variable**
522:   - Removed `provider_profile` variable from `backend_infra/variables.tf` and
523:   `application/variables.tf`
524:   - Removed `provider_profile` from `backend_infra/variables.tfvars` and
525:   `application/variables.tfvars`
526:   - Removed `profile = var.provider_profile` from `backend_infra/providers.tf`
527:   and `application/providers.tf`
528:   - No longer needed since role assumption is handled via setup scripts and
529:   workflows
530: 
531: ### Fixed
532: 
533: - **Corrected role ARN usage in workflows**
534:   - Fixed workflows to use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state
535:   operations
536:   - Fixed workflows to use environment-based role ARNs for deployment operations
537:   via `deployment_account_role_arn` variable
538: 
539: ## [2025-12-19] - Terraform Backend State Infrastructure v1.0.0
540: 
541: ### Changed
542: 
543: - **Terraform Backend State Infrastructure (v1.0.0)**
544:   - Migrated from DynamoDB-based state locking to S3 file-based locking
545:     (`use_lockfile = true`)
546:   - Updated AWS provider to version 6.21.0
547:   - Updated Terraform required version to 1.14.0
548:   - Improved automation scripts (`get-state.sh` and `set-state.sh`) to use
549:     AWS Secrets Manager instead of GitHub CLI for secret access
550:   - Enhanced documentation with detailed troubleshooting sections
551:   - Improved error handling and user feedback in automation scripts
552: 
553: ### Removed
554: 
555: - **Terraform Backend State Infrastructure (v1.0.0)**
556:   - Removed DynamoDB table and all related resources (deprecated in favor
557:     of S3 file-based locking)
558:   - Removed all references to DynamoDB from code and documentation
559: 
560: ## [2025-12-18] - 2FA Application and IRSA Infrastructure
561: 
562: ### Added
563: 
564: - Full-stack 2FA application with TOTP and SMS verification methods
565: - IRSA (IAM Roles for Service Accounts) support on EKS cluster
566: - VPC endpoints for STS and SNS for private AWS service access
567: - SNS module for SMS-based 2FA verification
568: 
569: ### Changed
570: 
571: - Enhanced network policies to support cross-namespace communication
572: - Updated VPC endpoints module with STS and SNS endpoint options
573: - Added new IRSA-related outputs to backend infrastructure
574: 
575: ## [2025-12-16] - ArgoCD GitOps Integration
576: 
577: ### Added
578: 
579: - ArgoCD capability module for EKS-managed ArgoCD service
580: - ArgoCD application module for GitOps-driven deployments
581: - Support for multiple deployment types (Kubernetes manifests, Helm, Kustomize)
582: - AWS Identity Center authentication and RBAC integration
583: 
584: ## [2025-12-15] - Documentation and Linting Improvements
585: 
586: ### Changed
587: 
588: - Comprehensive documentation updates for Markdown lint compliance
589: - Added `.markdownlint.json` configuration for consistent formatting
590: - Enhanced network policies module documentation
591: 
592: ## [2025-12-14] - Deployment Versatility and Security Improvements
593: 
594: ### Changed
595: 
596: - Made the deployment more versatile and secure
597: - Improved Terraform state deployment automation
598: - Updated documentation
599: 
600: ## [2025-12-10] - Output and Ingress Configuration Updates
601: 
602: ### Added
603: 
604: - Bubbled up outputs and added new ones
605: - Updated WARP.md documentation
606: 
607: ### Fixed
608: 
609: - Corrected attributes across IngressClass, IngressClassParams, and the two
610: Ingresses
611: - Updated documentation to reflect changes
612: 
613: ## [2025-12-08] - ALB, TLS, and Documentation Updates
614: 
615: ### Added
616: 
617: - Consolidated annotations
618: - Added naming logic for better resource identification
619: 
620: ### Changed
621: 
622: - Latest updates to resolve ALB and TLS issues (ALB issue still under
623: investigation)
624: - Updated documentation
625: 
626: ### Removed
627: 
628: - Removed any mention of DynamoDB as that functionality is deprecated in
629: managing TF state
630: 
631: ## [2025-12-03] - Backend Infrastructure Workflow Updates
632: 
633: ### Changed
634: 
635: - Updated backend infrastructure workflows
636: 
637: ## [2025-12-02] - Application Infrastructure and Storage
638: 
639: ### Added
640: 
641: - Main application infrastructure related to the OpenLDAP Helm deployment
642: 
643: ### Changed
644: 
645: - Commented out the use of the EBS module because OpenLDAP creates one per pod
646: already.
647: 
648: ## [2025-12-01] - Circular Dependency Resolution and Documentation
649: 
650: ### Fixed
651: 
652: - Resolved circular dependency issue with EKS module in the providers
653: 
654: ### Changed
655: 
656: - Updated names in code and documentation
657: - Added WARP.md file which works with the Warp Terminal Agent
658: 
659: ## [2025-11-27] - EBS Module Outputs
660: 
661: ### Added
662: 
663: - Added outputs for the EBS module to get the name of the PVC for later use in
664: the application
665: 
666: ## [2025-11-26] - VPC Endpoints, Storage, and ECR
667: 
668: ### Added
669: 
670: - Added 3 VPC Endpoints
671: - Added EBS Storage Class and Claim
672: - Added ECR (Elastic Container Registry)
673: - Added CloudWatch logs
674: - Upgraded Kubernetes version to 1.34
675: - Updated documentation with all the latest changes
676: 
677: ## [2025-11-25] - EKS Cluster and Backend Infrastructure
678: 
679: ### Added
680: 
681: - Added EKS Auto cluster
682: - Initial backend infrastructure (VPC)
683: - Local setup with bash files
684: - Remote setup with GitHub workflows
685: - Interactive Region and Environment selection in both local and remote setups
686: 
687: ### Changed
688: 
689: - Removed the use of profile in the provider
690: 
691: ### Fixed
692: 
693: - Fixed bucket prefix issue: the prefix cannot start with '/' when defining the
694: 'key' attribute for the backend state
695: 
696: ## [2025-11-24] - Backend State Management Improvements
697: 
698: ### Added
699: 
700: - Added backend state table name as an output
701: - Altered workflows to save and retrieve backend state table name
702: - Updated documentation
703: 
704: ### Fixed
705: 
706: - Updated provisioning workflow to pre-check for an already existing state to
707: prevent errors
708: 
709: ## [2025-11-23] - Backend State Infrastructure
710: 
711: ### Added
712: 
713: - Upgraded versions of AWS provider and Terraform
714: - Added files to begin with main infrastructure
715: - Added a README to the backend state that explains everything
716: - Added a link to backend state README in the main README
717: - Added missing GitHub Token
718: - Added a way to manage the backend state's state without having to commit it to
719: the repository
720: - Added a way to transfer the backend bucket name after its creation
721: - Added account number to bucket name to make it unique
722: 
723: ## [2025-11-22] - Initial Project Setup
724: 
725: ### Added
726: 
727: - Initial commit
728: - Added Terraform backend state and GitHub Actions to deploy and destroy it
729: 
730: ## Architecture Overview
731: 
732: This project uses a multi-account architecture:
733: 
734: - **State Account (Account A)**: Stores Terraform state files in S3
735: - **Production Account (Account B)**: Contains production infrastructure
736: resources
737: - **Development Account (Account B)**: Contains development infrastructure
738: resources
739: 
740: ### Key Components
741: 
742: - Terraform backend state infrastructure (`tf_backend_state/`)
743: - Backend infrastructure (VPC, EKS cluster, VPC endpoints, IRSA) (`backend_infra/`)
744: - Application infrastructure (OpenLDAP, 2FA app, ALB, Route53, ArgoCD)
745: (`application/`)
746: - 2FA Backend and Frontend applications (`application/backend/`,
747: `application/frontend/`)
748: - GitHub Actions workflows for CI/CD (`.github/workflows/`)
749: 
750: ### Supporting Infrastructure
751: 
752: - **PostgreSQL** (`application/modules/postgresql/`): User registration and
753: verification token storage
754: - **Redis** (`application/modules/redis/`): SMS OTP code storage with TTL
755: - **SES** (`application/modules/ses/`): Email verification and notifications
756: - **SNS** (`application/modules/sns/`): SMS-based 2FA verification
757: 
758: ### Required GitHub Secrets
759: 
760: | Secret | Purpose |
761: | -------- | --------- |
762: | `AWS_STATE_ACCOUNT_ROLE_ARN` | Role for Terraform state operations |
763: | `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` | Role for production deployments |
764: | `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` | Role for development deployments |
765: | `TF_VAR_OPENLDAP_ADMIN_PASSWORD` | OpenLDAP admin password (exported as `TF_VAR_openldap_admin_password`) |
766: | `TF_VAR_OPENLDAP_CONFIG_PASSWORD` | OpenLDAP config password (exported as `TF_VAR_openldap_config_password`) |
767: | `TF_VAR_REDIS_PASSWORD` | Redis authentication password (exported as `TF_VAR_redis_password`) |
768: | `TF_VAR_POSTGRES_PASSWORD` | PostgreSQL database password (exported as `TF_VAR_postgresql_database_password`) |
769: 
770: ## Notes
771: 
772: ### Role ARN Selection Logic
773: 
774: The system automatically selects the appropriate role ARN based on the
775: environment:
776: 
777: - **Backend State Operations**: Always uses `AWS_STATE_ACCOUNT_ROLE_ARN`
778: - **Deployment Operations**:
779:   - `prod` environment  uses `AWS_PRODUCTION_ACCOUNT_ROLE_ARN`
780:   - `dev` environment  uses `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
781: 
782: ### Setup Script Behavior
783: 
784: The `setup-backend.sh` script:
785: 
786: 1. Assumes `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations
787: 2. Retrieves the appropriate deployment account role ARN based on selected
788: environment
789: 3. Creates `backend.hcl` if it doesn't exist
790: 4. Updates `variables.tfvars` with region, environment, and deployment account
791: role ARN
792: 5. Runs Terraform commands automatically (init, workspace, validate, plan,
793: apply)
794: 
795: ### Terraform State Management
796: 
797: - **S3 File-Based Locking**: The Terraform backend state infrastructure
798:   (v1.0.0) uses S3 file-based locking (`use_lockfile = true`) instead of
799:   DynamoDB
800: - **State Storage**: All Terraform state files are stored in S3 with
801:   versioning enabled and server-side encryption (AES256)
802: - **Access Control**: IAM-based access control with principal ARN support
803:   and OIDC-based authentication (no access keys required)
804: - **Automation**: Local automation scripts (`get-state.sh` and
805:   `set-state.sh`) use AWS Secrets Manager for role ARN retrieval
806: - **Security**: Private bucket ACL configuration, comprehensive public
807:   access blocking, and encryption at rest for all state files
808: - **Provider Versions**: AWS provider 6.21.0, Terraform 1.14.0
809: - All references to DynamoDB have been removed from code and
810:   documentation
811: 
812: ## References
813: 
814: - [Keep a Changelog](https://keepachangelog.com/)
815: - [Semantic Versioning](https://semver.org/)
````

## File: WARP.md
````markdown
   1: # WARP.md
   2: 
   3: This file provides guidance to WARP (warp.dev) when working with code in this
   4: repository.
   5: 
   6: ## Project Overview
   7: 
   8: This repository deploys LDAP authentication with 2FA on Kubernetes (EKS Auto
   9: Mode) using Terraform. The infrastructure is deployed on AWS using a
  10: **multi-account architecture** and consists of three main layers:
  11: 
  12: 1. **Terraform Backend State** (`tf_backend_state/`) - S3 bucket for storing
  13: Terraform state files (Account A - State Account)
  14: 2. **Backend Infrastructure** (`backend_infra/`) - Core AWS infrastructure (VPC,
  15: EKS cluster with IRSA, VPC endpoints, ECR) (Account B - Deployment Account)
  16: 3. **Application Layer** (`application/`) - OpenLDAP stack, 2FA application
  17: (backend + frontend), ArgoCD, SNS for SMS 2FA, using existing Route53 zone and
  18: ACM certificate (Account B - Deployment Account)
  19: 
  20: **Multi-Account Architecture:**
  21: 
  22: - **Account A (State Account)**: Stores Terraform state files in S3, Route53
  23: hosted zones, and ACM certificates
  24: - **Account B (Deployment Accounts)**: Contains all infrastructure resources
  25:   - **Production Account**: Separate account for production infrastructure
  26:   - **Development Account**: Separate account for development infrastructure
  27: - GitHub Actions uses OIDC to assume Account A role for backend state operations
  28: - Terraform provider assumes Account B role (prod or dev) via `assume_role` for
  29: resource deployment with ExternalId for enhanced security
  30: - **State Account provider** (`aws.state_account`) assumes Account A role for
  31: Route53 and ACM operations (no ExternalId required)
  32: - Environment-based role selection: workflows and scripts automatically select
  33: the appropriate deployment role ARN based on the selected environment (`prod` or
  34: `dev`)
  35: - **ExternalId Security**: Cross-account role assumption uses ExternalId to
  36: prevent confused deputy attacks (for deployment account roles only)
  37: 
  38: ## Architecture
  39: 
  40: ### Three-Phased Deployment Model
  41: 
  42: - **Phase 1**: Deploy Terraform backend state infrastructure first (prerequisite
  43: for all other deployments)
  44: - **Phase 2**: Deploy backend infrastructure (VPC, EKS, networking, EBS, ECR)
  45: using the remote state backend
  46: - **Phase 3**: Deploy application layer (OpenLDAP Helm chart, Route53 DNS
  47: records, network policies) on top of the EKS cluster
  48: 
  49: ### Infrastructure Components
  50: 
  51: - **VPC**: Custom VPC with public/private subnets across 2 availability zones
  52: - **EKS Auto Mode**: Simplified cluster management with automatic node
  53: provisioning and built-in EBS CSI driver (Kubernetes 1.34)
  54: - **IRSA (IAM Roles for Service Accounts)**: Enabled via OIDC provider for
  55: secure pod-to-AWS-service authentication
  56: - **Networking**: Single NAT gateway (cost optimization), IGW, VPC endpoints for
  57: SSM, STS (IRSA), and SNS (SMS 2FA) access
  58: - **Storage**: StorageClass created in application layer (gp3, encrypted), PVCs
  59: created by Helm chart
  60: - **Container Registry**: ECR repository for Docker images with lifecycle
  61: policies (immutable tags). All third-party images (Redis, PostgreSQL, OpenLDAP)
  62: are automatically mirrored from Docker Hub to ECR during deployment
  63: - **DNS & Certificates**: Uses existing Route53 hosted zone and validated ACM
  64: certificate (via data sources). Supports cross-account access when Route53/ACM
  65: are in State Account
  66: - **Load Balancer**: AWS ALB automatically created via Ingress resources for
  67: exposing web UIs (phpLdapAdmin, LTB-passwd, and 2FA application)
  68: - **IngressClass/IngressClassParams**: Created by ALB module to configure EKS
  69: Auto Mode ALB behavior (scheme, IP address type, certificate ARN, group name)
  70: - **Network Policies**: Kubernetes NetworkPolicies for secure internal cluster
  71: communication with cross-namespace access for LDAP service
  72: - **Container Image Management**: All third-party images (OpenLDAP, Redis,
  73: PostgreSQL) are mirrored to ECR to eliminate Docker Hub rate limits and external
  74: dependencies. Images are pulled from ECR during deployment
  75:   - OpenLDAP: osixia/openldap:1.5.0  ECR tag `openldap-1.5.0`
  76:   - Redis: bitnami/redis:8.4.0-debian-12-r6  ECR tag `redis-latest`
  77:   - PostgreSQL: bitnami/postgresql:18.1.0-debian-12-r4  ECR tag `postgresql-latest`
  78: - **2FA Application**: Full-stack application with Python FastAPI backend and
  79: static HTML/JS/CSS frontend, supporting TOTP and SMS MFA methods
  80: - **User Signup Management**: Self-service registration with email/phone
  81: verification and admin approval workflow
  82: - **PostgreSQL Database**: User registration data, verification tokens, and
  83: profile management
  84: - **Redis Cache**: SMS OTP code storage with automatic TTL expiration
  85: - **ArgoCD**: AWS EKS managed ArgoCD service for GitOps deployments (optional)
  86: - **SNS Integration**: AWS SNS for SMS-based 2FA verification codes (optional)
  87: - **SES Integration**: AWS SES for email verification and notifications
  88: 
  89: ### Naming Convention
  90: 
  91: All resources follow the pattern: `${prefix}-${region}-${name}-${env}`
  92: 
  93: ### Workspace Strategy
  94: 
  95: Terraform workspaces are named: `${region}-${env}` (e.g., `us-east-1-prod`,
  96: `us-east-2-dev`)
  97: 
  98: ## Project Directory Structure
  99: 
 100: ```text
 101: ldap-2fa-on-k8s/
 102:  SECRETS_REQUIREMENTS.md     # Secrets management documentation (root)
 103:  tf_backend_state/           # Terraform state backend (S3) - Account A
 104:  backend_infra/              # Core AWS infrastructure - Account B
 105:     modules/
 106:         ebs/                # EBS storage (commented out)
 107:         ecr/                # Container registry
 108:         endpoints/          # VPC endpoints (SSM, STS, SNS)
 109:  application/                # Application infrastructure - Account B
 110:     backend/                # 2FA Backend (Python FastAPI)
 111:        src/                # Source code
 112:        helm/               # Helm chart
 113:        Dockerfile
 114:     frontend/               # 2FA Frontend (HTML/JS/CSS)
 115:        src/                # Source code
 116:        helm/               # Helm chart
 117:        Dockerfile
 118:        nginx.conf
 119:     helm/                   # Helm values templates (OpenLDAP, Redis)
 120:     mirror-images-to-ecr.sh # ECR image mirroring script
 121:     modules/                # Terraform modules
 122:         alb/                # IngressClass and IngressClassParams
 123:         argocd/             # ArgoCD capability (AWS managed)
 124:         argocd_app/         # ArgoCD Application CRD
 125:         cert-manager/       # TLS certificate management
 126:         network-policies/   # Kubernetes NetworkPolicies
 127:         openldap/           # OpenLDAP Stack HA deployment module
 128:         postgresql/         # PostgreSQL database (Bitnami Helm)
 129:         redis/              # Redis cache for SMS OTP
 130:         route53/            # Route53 hosted zone (commented out)
 131:         route53_record/     # Route53 A (alias) record creation (NEW)
 132:         ses/                # SES for email verification
 133:         sns/                # SNS for SMS 2FA
 134:  .github/workflows/          # CI/CD workflows
 135:     tfstate_infra_*.yaml
 136:     backend_infra_*.yaml
 137:     application_infra_*.yaml
 138:     backend_build_push.yaml
 139:     frontend_build_push.yaml
 140:  docs/                       # GitHub Pages documentation
 141:      index.html              # Project documentation website
 142: ```
 143: 
 144: ## Common Commands
 145: 
 146: ### Terraform Backend State Setup
 147: 
 148: **Initial Backend Provisioning (GitHub Actions - Recommended):**
 149: 
 150: ```bash
 151: # Run via GitHub UI: Actions  "TF Backend State Provisioning" workflow
 152: # This automatically creates S3 bucket and saves state
 153: ```
 154: 
 155: **Local Backend Setup (Automated):**
 156: 
 157: ```bash
 158: cd tf_backend_state
 159: 
 160: # Provision infrastructure and upload state (all-in-one script)
 161: ./set-state.sh
 162: 
 163: # Or download existing state file from S3
 164: ./get-state.sh
 165: ```
 166: 
 167: The scripts automatically:
 168: 
 169: - Retrieve `AWS_STATE_ACCOUNT_ROLE_ARN` from AWS Secrets Manager (secret: 'github-role')
 170: - Retrieve `AWS_ASSUME_EXTERNAL_ID` from AWS Secrets Manager (secret: 'external-id')
 171: - Assume the IAM role with temporary credentials and ExternalId
 172: - Handle Terraform provisioning (if infrastructure doesn't exist)
 173: - Upload/download state files to/from S3
 174: - Update GitHub repository variables
 175: 
 176: **Manual Local Setup (if not using automated scripts):**
 177: 
 178: ```bash
 179: cd tf_backend_state
 180: 
 181: # IMPORTANT: Assume the IAM role first (required for local deployment)
 182: # The bucket policy grants access to the role ARN, not your user ARN
 183: aws sts assume-role \
 184:   --role-arn "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role" \
 185:   --role-session-name "local-deployment"
 186: 
 187: # Export the temporary credentials from the assume-role output
 188: export AWS_ACCESS_KEY_ID=<temporary-access-key>
 189: export AWS_SECRET_ACCESS_KEY=<temporary-secret-key>
 190: export AWS_SESSION_TOKEN=<session-token>
 191: 
 192: # If previously run via GitHub Actions, download state first:
 193: aws s3 cp s3://<bucket_name>/<prefix> ./terraform.tfstate
 194: 
 195: terraform init
 196: terraform plan -var-file="variables.tfvars" -out terraform.tfplan
 197: terraform apply -auto-approve terraform.tfplan
 198: ```
 199: 
 200: ### Backend Infrastructure Setup
 201: 
 202: **Configure Backend and Deploy (Automated):**
 203: 
 204: ```bash
 205: cd backend_infra
 206: 
 207: # Option 1: Using GitHub CLI (requires gh and jq)
 208: # This script will:
 209: # - Prompt for region and environment selection
 210: # - Retrieve AWS_STATE_ACCOUNT_ROLE_ARN and assume it for backend operations
 211: # - Retrieve ExternalId for secure cross-account role assumption
 212: # - Retrieve environment-specific deployment role ARN (prod or dev)
 213: # - Create backend.hcl from template if it doesn't exist
 214: # - Update variables.tfvars with selected values
 215: # - Run all Terraform commands automatically (init, workspace, validate, plan, apply)
 216: ./setup-backend.sh
 217: ```
 218: 
 219: **Manual Deployment (if not using automated script):**
 220: 
 221: ```bash
 222: cd backend_infra
 223: 
 224: # Initialize with backend configuration
 225: terraform init -backend-config="backend.hcl"
 226: 
 227: # Select or create workspace (format: region-environment)
 228: terraform workspace select us-east-1-prod || terraform workspace new us-east-1-prod
 229: 
 230: # Plan and apply
 231: terraform plan -var-file="variables.tfvars" -out "terraform.tfplan"
 232: terraform apply -auto-approve "terraform.tfplan"
 233: ```
 234: 
 235: **Destroy Backend Infrastructure:**
 236: 
 237: ```bash
 238: cd backend_infra
 239: 
 240: # Option 1: Automated destroy script (recommended)
 241: # This script will:
 242: # - Prompt for region and environment selection
 243: # - Retrieve role ARNs and ExternalId from AWS Secrets Manager
 244: # - Configure backend and variables automatically
 245: # - Require safety confirmations (type 'yes' then 'DESTROY')
 246: # - Run Terraform destroy commands
 247: ./destroy-backend.sh
 248: 
 249: # Option 2: Manual destroy
 250: terraform plan -var-file="variables.tfvars" -destroy -out "terraform.tfplan"
 251: terraform apply -auto-approve "terraform.tfplan"
 252: ```
 253: 
 254: ### Application Layer Deployment
 255: 
 256: **Prerequisites:**
 257: Ensure you have:
 258: 
 259: - A registered domain name (e.g., `talorlik.com`)
 260: - An existing Route53 hosted zone for your domain
 261: - **Public ACM certificates** requested in each deployment account and validated
 262: via DNS records in State Account's Route53 hosted zone
 263:   - See [Public ACM Certificate Setup and DNS Validation](application/CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 264:   for detailed setup instructions
 265:   - Certificates are browser-trusted (no security warnings) and automatically
 266:   renewed by ACM
 267: - **For local scripts**: AWS Secrets Manager secrets configured:
 268:   - `github-role`: Contains `AWS_STATE_ACCOUNT_ROLE_ARN` and deployment account
 269:   role ARNs
 270:   - `external-id`: Contains `AWS_ASSUME_EXTERNAL_ID`
 271:   - `tf-vars`: Contains OpenLDAP, PostgreSQL, and Redis passwords
 272:   - See `SECRETS_REQUIREMENTS.md` for detailed setup instructions
 273: 
 274: **Deploy OpenLDAP Application:**
 275: 
 276: ```bash
 277: cd application
 278: 
 279: # For local use: Export passwords as environment variables (script retrieves from GitHub secrets if available)
 280: export TF_VAR_OPENLDAP_ADMIN_PASSWORD="YourSecurePassword123!"
 281: export TF_VAR_OPENLDAP_CONFIG_PASSWORD="YourSecurePassword123!"
 282: 
 283: # Deploy application (handles all configuration and Terraform operations automatically)
 284: ./setup-application.sh
 285: ```
 286: 
 287: This script will:
 288: 
 289: - Prompt for region and environment selection
 290: - Retrieve AWS_STATE_ACCOUNT_ROLE_ARN and assume it for backend operations
 291: - Retrieve ExternalId for secure cross-account role assumption
 292: - Retrieve environment-specific deployment role ARN (prod or dev)
 293: - Retrieve OpenLDAP password secrets from repository secrets and export them as
 294: environment variables
 295: - Create backend.hcl from template if it doesn't exist
 296: - Update variables.tfvars with selected values
 297: - **Mirror third-party Docker images to ECR** (OpenLDAP, Redis, PostgreSQL)
 298:   - Checks which images already exist in ECR
 299:   - Only mirrors missing images from Docker Hub
 300:   - Uses Deployment Account credentials for ECR operations
 301: - Set Kubernetes environment variables using set-k8s-env.sh
 302: - Run all Terraform commands automatically (init, workspace, validate, plan,
 303: apply)
 304: 
 305: > [!NOTE]
 306: >
 307: > The script automatically retrieves OpenLDAP passwords from AWS Secrets Manager
 308: > (for local use). For GitHub Actions workflows, passwords are retrieved from
 309: > GitHub repository secrets.
 310: 
 311: **Destroy Application Infrastructure:**
 312: 
 313: ```bash
 314: cd application
 315: 
 316: # Automated destroy script with comprehensive safety checks
 317: # This script will:
 318: # - Prompt for region and environment selection
 319: # - Retrieve role ARNs, ExternalId, and passwords from AWS Secrets Manager
 320: # - Configure backend, variables, and Kubernetes environment automatically
 321: # - Require safety confirmations (type 'yes' then 'DESTROY')
 322: # - Run Terraform destroy commands
 323: ./destroy-application.sh
 324: ```
 325: 
 326: ### Kubernetes Operations
 327: 
 328: **Configure kubectl:**
 329: 
 330: ```bash
 331: aws eks update-kubeconfig --name <cluster-name> --region <region>
 332: ```
 333: 
 334: **Check cluster resources:**
 335: 
 336: ```bash
 337: kubectl get nodes
 338: kubectl get pods -n ldap
 339: kubectl get pvc -n ldap
 340: kubectl get ingress -n ldap
 341: ```
 342: 
 343: **Access EKS nodes via SSM (no SSH required):**
 344: 
 345: ```bash
 346: aws ssm start-session --target <instance-id>
 347: ```
 348: 
 349: ### ECR Operations
 350: 
 351: **Mirror Third-Party Images to ECR:**
 352: 
 353: The `mirror-images-to-ecr.sh` script automatically mirrors third-party images
 354: from Docker Hub to ECR. This eliminates Docker Hub rate limits and external
 355: dependencies.
 356: 
 357: ```bash
 358: cd application
 359: 
 360: # Run manually (if needed)
 361: ./mirror-images-to-ecr.sh
 362: ```
 363: 
 364: The script:
 365: 
 366: - Fetches ECR repository URL from backend_infra Terraform state
 367: - Assumes Deployment Account role for ECR operations
 368: - Checks which images already exist in ECR
 369: - Pulls missing images from Docker Hub
 370: - Tags and pushes them to ECR with consistent naming:
 371:   - `redis-latest` tag for Redis (bitnami/redis:latest)
 372:   - `postgresql-latest` tag for PostgreSQL (bitnami/postgresql:latest)
 373:   - `openldap-1.5.0` for OpenLDAP (osixia/openldap:1.5.0)
 374: 
 375: **Push Custom Docker Image to ECR:**
 376: 
 377: ```bash
 378: # Authenticate Docker to ECR
 379: aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <ecr_url>
 380: 
 381: # Tag and push image
 382: docker tag <image>:<tag> <ecr_url>:<tag>
 383: docker push <ecr_url>:<tag>
 384: ```
 385: 
 386: **Note**: The `setup-application.sh` script automatically runs the image
 387: mirroring script, so manual execution is typically not needed.
 388: 
 389: ## Key Configuration Files
 390: 
 391: ### Backend State
 392: 
 393: - `tf_backend_state/variables.tfvars` - Configure `env`, `region`, `prefix`
 394: (principal_arn automatically detected via `data.aws_caller_identity`)
 395: - `tf_backend_state/README.md` - Detailed setup instructions for GitHub
 396: secrets/variables and AWS Secrets Manager configuration
 397: - `tf_backend_state/set-state.sh` - Enhanced automated provisioning and state upload
 398: script with intelligent infrastructure detection
 399: - `tf_backend_state/get-state.sh` - Automated state download script
 400: - `tf_backend_state/CHANGELOG.md` - Detailed changelog for backend state infrastructure
 401: 
 402: ### Backend Infrastructure Layer
 403: 
 404: - `backend_infra/variables.tfvars` - Configure VPC CIDR, K8s version (1.34),
 405: resource names, ECR lifecycle policies, VPC endpoints (enable_sts_endpoint,
 406: enable_sns_endpoint)
 407: - `backend_infra/backend.hcl` - Generated file (do not commit) with S3 backend
 408: config
 409: - `backend_infra/tfstate-backend-values-template.hcl` - Template for backend.hcl
 410: - `backend_infra/modules/` - Reusable modules:
 411:   - `ecr/` - Container registry with lifecycle policies
 412:   - `endpoints/` - VPC endpoints for SSM, STS (IRSA), and SNS (SMS 2FA)
 413:   - `ebs/` - EBS storage (commented out in main.tf)
 414: - `backend_infra/main.tf` - Creates VPC, EKS cluster with Auto Mode and IRSA,
 415: VPC endpoints, ECR
 416: - `backend_infra/setup-backend.sh` - Automated setup script with role assumption
 417: and Terraform execution
 418: - `backend_infra/destroy-backend.sh` - Automated destroy script with safety
 419: confirmations
 420: 
 421: ### Application Layer
 422: 
 423: - `application/variables.tfvars` - Configure:
 424:   - Domain name, ALB settings, storage class
 425:   - ArgoCD configuration (enable_argocd, Identity Center settings)
 426:   - SNS/SMS 2FA configuration (enable_sms_2fa)
 427:   - Passwords retrieved automatically by setup-application.sh from AWS Secrets Manager
 428: - `application/setup-application.sh` - Unified setup script for application
 429: deployment (retrieves secrets from AWS Secrets Manager, mirrors ECR images)
 430: - `application/destroy-application.sh` - Automated destroy script with safety
 431: confirmations and Kubernetes environment setup
 432: - `application/set-k8s-env.sh` - Kubernetes environment variable configuration
 433: - `application/mirror-images-to-ecr.sh` - ECR image mirroring script (called by
 434: setup-application.sh)
 435: - `application/helm/openldap-values.tpl.yaml` - Helm chart values template
 436: configured to pull OpenLDAP image from ECR (openldap-1.5.0)
 437: - `application/helm/redis-values.tpl.yaml` - Redis Helm chart values template
 438: (image configuration in module, pulls from ECR)
 439: - `application/providers.tf` - Retrieves cluster name from backend_infra remote
 440: state (with fallback options)
 441: - `application/main.tf` - Creates:
 442:   - StorageClass for persistent storage
 443:   - OpenLDAP module invocation (Helm release, secrets, Ingress, Route53 records)
 444:   - 2FA backend Helm release (if ArgoCD not used)
 445:   - 2FA frontend Helm release (if ArgoCD not used)
 446:   - Route53 records for 2FA app subdomain
 447:   - ALB module (IngressClass and IngressClassParams)
 448:   - Network policies
 449:   - PostgreSQL module (with Kubernetes secrets)
 450:   - Redis module (with Kubernetes secrets)
 451:   - SES module
 452:   - SNS module (if SMS 2FA enabled)
 453:   - ArgoCD capability (if enabled)
 454:   - ArgoCD Applications (if enabled)
 455: - `application/modules/` - Terraform modules:
 456:   - `alb/` - IngressClass and IngressClassParams for EKS Auto Mode ALB
 457:   - `argocd/` - AWS EKS managed ArgoCD capability
 458:   - `argocd_app/` - ArgoCD Application CRD for GitOps
 459:   - `cert-manager/` - TLS certificate management (optional)
 460:   - `network-policies/` - Kubernetes NetworkPolicies with cross-namespace access
 461:   - `openldap/` - OpenLDAP Stack HA deployment with secrets, Ingress, and Route53
 462:   - `postgresql/` - PostgreSQL database with Kubernetes secrets
 463:   - `redis/` - Redis cache with Kubernetes secrets for SMS OTP storage
 464:   - `route53/` - Route53 hosted zone creation (commented out, uses data sources)
 465:   - `ses/` - AWS SES for email verification and notifications
 466:   - `sns/` - SNS resources for SMS 2FA with IRSA
 467: - `SECRETS_REQUIREMENTS.md` - Comprehensive secrets management documentation
 468:   - AWS Secrets Manager setup for local scripts (role ARNs, ExternalId, passwords)
 469:   - GitHub Repository Secrets setup for workflows
 470:   - ExternalId configuration for cross-account role assumption security
 471:   - Secret naming conventions and case sensitivity
 472: - `application/backend/` - 2FA backend application:
 473:   - `src/` - Python FastAPI source code
 474:   - `helm/` - Helm chart with Ingress for `/api/*`
 475:   - `Dockerfile` - Container image definition
 476: - `application/frontend/` - 2FA frontend application:
 477:   - `src/` - Static HTML/JS/CSS files
 478:   - `helm/` - Helm chart with Ingress for `/`
 479:   - `Dockerfile` - Container image definition (nginx)
 480:   - `nginx.conf` - nginx configuration
 481: - `application/CHANGELOG.md` - Detailed changelog documenting all application
 482: changes
 483: - `application/PRD-2FA-APP.md` - Product requirements document for 2FA
 484: application
 485: - `application/PRD-SIGNUP-MAN.md` - Product requirements document for signup
 486: management system
 487: - `application/PRD-ALB.md` - Comprehensive ALB implementation guide
 488: - `application/OPENLDAP-README.md` - OpenLDAP configuration and TLS setup
 489: - `application/OSIXIA-OPENLDAP-REQUIREMENTS.md` - OpenLDAP image requirements
 490: - `application/SECURITY-IMPROVEMENTS.md` - Security enhancements and best
 491: practices
 492: 
 493: ## Outputs
 494: 
 495: ### Backend Infrastructure Outputs
 496: 
 497: - **VPC**: `vpc_id`, `public_subnets`, `private_subnets`,
 498: `default_security_group_id`, `igw_id`
 499: - **EKS**: `cluster_name`, `cluster_endpoint`, `cluster_arn`, `oidc_provider_arn`
 500: (for IRSA)
 501: - **VPC Endpoints**: `vpc_endpoint_sg_id`, `vpc_endpoint_ssm_id`,
 502: `vpc_endpoint_ssmmessages_id`, `vpc_endpoint_ec2messages_id`,
 503: `vpc_endpoint_sts_id` (if enabled), `vpc_endpoint_sns_id` (if enabled),
 504: `vpc_endpoint_ids`
 505: - **ECR**: `ecr_name`, `ecr_arn`, `ecr_url`
 506: - **General**: `aws_account`, `region`, `env`, `prefix`
 507: 
 508: ### Application Infrastructure Outputs
 509: 
 510: - **ALB**: `alb_dns_name`, `alb_ingress_class_name`,
 511: `alb_ingress_class_params_name`, `alb_scheme`, `alb_ip_address_type`
 512: - **OpenLDAP**: `openldap_namespace`, `openldap_secret_name`,
 513: `openldap_helm_release_name`, `openldap_alb_dns_name`,
 514: `phpldapadmin_route53_record`, `ltb_passwd_route53_record`
 515: - **Route53**: `route53_acm_cert_arn`, `route53_domain_name`, `route53_zone_id`,
 516: `route53_name_servers`
 517: - **Network Policies**: `network_policy_name`, `network_policy_namespace`,
 518: `network_policy_uid`
 519: - **ArgoCD** (if enabled): `argocd_capability_arn`, `argocd_capability_id`,
 520: `argocd_server_url`
 521: - **SNS** (if enabled): `sns_topic_arn`, `sns_topic_name`, `sns_iam_role_arn`,
 522: `sns_iam_role_name`
 523: - **SES** (if enabled): `ses_iam_role_arn`, `ses_iam_role_name`,
 524: `ses_email_identity_arn`
 525: - **PostgreSQL** (if enabled): `postgresql_service_name`, `postgresql_port`
 526: - **Redis** (if enabled): `redis_service_name`, `redis_port`
 527: 
 528: ## Important Patterns
 529: 
 530: ### Terraform State Management
 531: 
 532: - **Never commit** `backend.hcl` or `terraform.tfstate` files (in `.gitignore`)
 533: - Always use remote state backend after initial provisioning
 534: - Use workspace naming convention: `${region}-${env}`
 535: - State is stored in S3 with file-based locking (no DynamoDB required)
 536: - **Local scripts** retrieve role ARNs from AWS Secrets Manager (secret: `github-role`)
 537: - **GitHub Actions** retrieve role ARNs from GitHub repository secrets
 538: 
 539: ### Security Considerations
 540: 
 541: - All EKS nodes are in private subnets (no public IPs)
 542: - VPC endpoints enable SSM access without internet gateway
 543: - EBS volumes are encrypted by default
 544: - Secrets should use `sensitive = true` in Terraform variables
 545: - OpenLDAP admin/config passwords should never be committed in plaintext
 546: - **ExternalId for Cross-Account Role Assumption**:
 547:   - Prevents confused deputy attacks in multi-account deployments
 548:   - ExternalId retrieved from AWS Secrets Manager (`external-id`) for local scripts
 549:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
 550:   for workflows
 551:   - Must be configured in deployment account role Trust Relationships
 552:   - Generated using: `openssl rand -hex 32`
 553: 
 554: ### EKS Auto Mode and IRSA
 555: 
 556: - **EKS Auto Mode**:
 557:   - Built-in EBS CSI driver - no manual installation needed
 558:   - Automatic IAM permissions for CSI driver
 559:   - Compute config uses "general-purpose" node pool
 560:   - ALB creation driven by Kubernetes Ingress with annotations (no separate AWS
 561:   ALB resource)
 562: - **IRSA (IAM Roles for Service Accounts)**:
 563:   - Enabled via `enable_irsa = true` in backend_infra
 564:   - Creates OIDC provider for the EKS cluster
 565:   - Allows pods to assume IAM roles for AWS service access
 566:   - Required for SMS 2FA (SNS access)
 567:   - No hardcoded AWS credentials needed in pods
 568: 
 569: ### Application Deployments
 570: 
 571: **OpenLDAP Stack (via OpenLDAP Module):**
 572: 
 573: - Deployed via `application/modules/openldap/` Terraform module
 574: - OpenLDAP chart version: 4.0.1 from `https://jp-gouin.github.io/helm-openldap`
 575: - Uses osixia/openldap:1.5.0 Docker image mirrored to ECR (chart's default
 576: bitnami image doesn't exist)
 577: - Image pulled from ECR with tag `openldap-1.5.0` instead of Docker Hub
 578: - **Multi-master replication**: 3 replicas for high availability
 579: - **Kubernetes secrets**: Admin and config passwords stored in Kubernetes secrets,
 580: not plain-text in Helm values
 581: - **Web UIs**: phpLDAPadmin and ltb-passwd exposed via ALB with separate Ingress
 582: resources
 583: - **LDAP service**: ClusterIP (internal only) for secure cluster-internal access
 584: - **Route53 DNS**: Module creates A (alias) records pointing to ALB
 585: - Hostnames configurable via variables:
 586:   - `phpldapadmin_host` (default: `phpldapadmin.talorlik.com`)
 587:   - `ltb_passwd_host` (default: `passwd.talorlik.com`)
 588:   - `twofa_app_host` (default: `app.talorlik.com`)
 589: - **TLS**: Auto-generated self-signed certificates from osixia/openldap image
 590: 
 591: **2FA Application (Helm Charts or ArgoCD):**
 592: 
 593: - Backend: Python FastAPI with comprehensive authentication features
 594:   - LDAP authentication and MFA support (TOTP and SMS)
 595:   - Self-service user signup with email/phone verification
 596:   - Admin dashboard for user and group management
 597:   - User profile management
 598:   - PostgreSQL for user registration and profile data (with Kubernetes secrets,
 599:   image pulled from ECR)
 600:   - Redis for SMS OTP code caching (with Kubernetes secrets, image pulled from
 601:   ECR)
 602:   - AWS SES for email verification and notifications (via IRSA)
 603:   - AWS SNS for SMS verification codes (via IRSA)
 604:   - Exposed at `/api/*` path on `app.<domain>`
 605:   - Uses IRSA for SNS, SES access (no hardcoded credentials)
 606:   - Swagger UI always enabled at `/api/docs` for interactive API documentation
 607:   - Helm chart includes: Deployment, Service, Ingress, ConfigMap, Secret,
 608:   ServiceAccount
 609: - Frontend: Static HTML/JS/CSS served by nginx
 610:   - Signup form with email/phone verification
 611:   - Admin dashboard (visible to admin group members)
 612:   - User profile page
 613:   - Top navigation bar with user menu
 614:   - Exposed at `/` path on `app.<domain>`
 615:   - Helm chart includes: Deployment, Service, Ingress
 616: - Deployment method:
 617:   - Direct Helm deployment via Terraform (default)
 618:   - Or via ArgoCD GitOps (if `enable_argocd = true`)
 619: 
 620: **ALB Configuration:**
 621: 
 622: - Uses EKS Auto Mode (`eks.amazonaws.com/alb` controller) instead of AWS Load
 623: Balancer Controller
 624: - IngressClassParams (cluster-wide) contains: `scheme`, `ipAddressType`,
 625: `group.name`, and `certificateARNs`
 626: - Ingress annotations (per-Ingress) contain: `load-balancer-name`,
 627: `target-type`, `listen-ports`, `ssl-redirect`
 628: - All Ingress resources use the same ALB with host-based routing via shared
 629: `group.name` in IngressClassParams
 630: - IngressClass created by ALB module references the IngressClassParams for
 631: cluster-wide ALB configuration
 632: - Certificate ARN configured once in IngressClassParams and inherited by all
 633: Ingresses using this IngressClass
 634: 
 635: ### ECR Image Mirroring Pattern
 636: 
 637: - **All third-party images mirrored to ECR**: OpenLDAP, Redis, PostgreSQL images
 638: are automatically pulled from Docker Hub and pushed to ECR during deployment
 639: - **Eliminates external dependencies**: No reliance on Docker Hub availability or
 640: rate limits during pod startup
 641: - **Faster image pulls**: Images pulled from same AWS region as EKS cluster
 642: - **Version pinning**: Specific image versions are tagged and stored in ECR:
 643:   - `redis-latest` tag for Redis (bitnami/redis:latest)
 644:   - `postgresql-latest` tag for PostgreSQL (bitnami/postgresql:latest)
 645:   - `openldap-1.5.0` for OpenLDAP (osixia/openldap:1.5.0) - version-pinned
 646: - **Automatic mirroring**: `setup-application.sh` and GitHub Actions workflow
 647: automatically check and mirror images before Terraform deployment
 648: - **Idempotent operation**: Script only mirrors images that don't already exist
 649: in ECR
 650: - **Multi-account support**: Script properly handles credential switching between
 651: State Account (for reading backend_infra state) and Deployment Account (for ECR
 652: operations)
 653: 
 654: ### CRITICAL: OpenLDAP Environment Variables
 655: 
 656: - The jp-gouin/helm-openldap chart does NOT properly pass `global.ldapDomain` to
 657: the osixia/openldap container
 658: - Must explicitly set these in the `env:` section of Helm values:
 659:   - `LDAP_DOMAIN`: The LDAP domain (e.g., "ldap.talorlik.internal")
 660:   - `LDAP_ADMIN_PASSWORD`: Admin password
 661:   - `LDAP_CONFIG_PASSWORD`: Config password
 662: - Without `LDAP_DOMAIN`, OpenLDAP initializes with empty/default config and
 663: authentication fails
 664: - If authentication fails after deployment, delete PVCs and restart pods to
 665: reinitialize with correct environment variables
 666: 
 667: ### Resource Deployment Order
 668: 
 669: Deployment order matters:
 670: 
 671: 1. Terraform backend state infrastructure (S3 bucket)
 672: 2. Backend infrastructure (VPC  EKS  VPC Endpoints  ECR)
 673: 3. Application layer (Existing Route53 zone + ACM cert lookup  StorageClass 
 674: ALB module  Helm release  Route53 A records  Network policies)
 675: 
 676: ### Module Structure
 677: 
 678: - `backend_infra/modules/` - Reusable infrastructure modules:
 679:   - `ecr/` - ECR repository with lifecycle policies
 680:   - `endpoints/` - VPC endpoints for SSM, STS (IRSA), and SNS (SMS 2FA)
 681:   - `ebs/` - EBS storage (commented out in main.tf)
 682: - `application/modules/` - Application-specific modules:
 683:   - `alb/` - IngressClass and IngressClassParams for EKS Auto Mode ALB
 684:   - `argocd/` - AWS EKS managed ArgoCD capability for GitOps
 685:   - `argocd_app/` - ArgoCD Application CRD for GitOps deployments
 686:   - `cert-manager/` - Optional cert-manager for self-signed TLS certificates
 687:   - `network-policies/` - Kubernetes NetworkPolicies for secure communication
 688:   with cross-namespace access
 689:   - `openldap/` - **NEW**: OpenLDAP Stack HA deployment with multi-master replication,
 690:   Kubernetes secrets, phpLDAPadmin, ltb-passwd, Ingress, and Route53 DNS records
 691:   - `postgresql/` - PostgreSQL database with Kubernetes secrets for user data
 692:   - `redis/` - Redis cache with Kubernetes secrets for SMS OTP storage with TTL
 693:   - `route53/` - Route53 hosted zone creation (exists but commented out, uses
 694:   data sources)
 695:   - `ses/` - AWS SES for email verification and admin notifications
 696:   - `sns/` - SNS resources for SMS-based 2FA with IRSA
 697: - Each module has its own README.md with detailed documentation
 698: - Route53 and ACM certificate resources use data sources to reference existing
 699: resources
 700: - All password-based services (OpenLDAP, PostgreSQL, Redis) now use Kubernetes secrets
 701: instead of plain-text values in Helm charts
 702: 
 703: ## GitHub Actions Workflows
 704: 
 705: ### Available Workflows
 706: 
 707: **Infrastructure Workflows:**
 708: 
 709: - `tfstate_infra_provisioning.yaml` - Create Terraform backend state
 710: - `tfstate_infra_destroying.yaml` - Destroy Terraform backend state
 711: - `backend_infra_provisioning.yaml` - Create backend infrastructure
 712: - `backend_infra_destroying.yaml` - Destroy backend infrastructure
 713: - `application_infra_provisioning.yaml` - Deploy application infrastructure
 714: (OpenLDAP, 2FA app, ArgoCD, SNS)
 715: - `application_infra_destroying.yaml` - Destroy application infrastructure
 716: 
 717: **Application CI/CD Workflows:**
 718: 
 719: - `backend_build_push.yaml` - Build and push 2FA backend Docker image to ECR
 720: - `frontend_build_push.yaml` - Build and push 2FA frontend Docker image to ECR
 721: 
 722: ### Required GitHub Secrets
 723: 
 724: **AWS Authentication:**
 725: 
 726: - `AWS_STATE_ACCOUNT_ROLE_ARN` - ARN of IAM role in Account A (State Account)
 727: that trusts GitHub OIDC provider (used for all backend state operations)
 728: - `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` - ARN of IAM role in Production Account
 729: (Account B) that trusts Account A role (used when `prod` environment is
 730: selected)
 731: - `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` - ARN of IAM role in Development Account
 732: (Account B) that trusts Account A role (used when `dev` environment is selected)
 733: - `AWS_ASSUME_EXTERNAL_ID` - ExternalId for cross-account role assumption
 734: (prevents confused deputy attacks, required in deployment role Trust Relationships)
 735: 
 736: **Terraform Automation:**
 737: 
 738: - `GH_TOKEN` - GitHub PAT with `repo` scope (for updating repository variables)
 739: 
 740: **OpenLDAP Credentials:**
 741: 
 742: - `TF_VAR_OPENLDAP_ADMIN_PASSWORD` - OpenLDAP admin password (for application
 743: workflows)
 744: - `TF_VAR_OPENLDAP_CONFIG_PASSWORD` - OpenLDAP config password (for application
 745: workflows)
 746: 
 747: **Database Credentials:**
 748: 
 749: - `TF_VAR_POSTGRESQL_PASSWORD` - PostgreSQL database password
 750: - `TF_VAR_REDIS_PASSWORD` - Redis cache password
 751: 
 752: > [!NOTE]
 753: >
 754: > This project uses AWS SSO via GitHub OIDC instead of access keys.
 755: > Workflows automatically select the appropriate deployment role ARN based on the
 756: > selected environment. See main [README.md](README.md) for detailed IAM setup
 757: > instructions.
 758: 
 759: ### Required GitHub Variables
 760: 
 761: - `AWS_REGION` - AWS region for deployment
 762: - `BACKEND_PREFIX` - S3 prefix for backend state files
 763: - `BACKEND_BUCKET_NAME` - Auto-generated by backend state provisioning workflow
 764: - `APPLICATION_PREFIX` - S3 prefix for application state files
 765: 
 766: ## Recent Changes (December 2025 - January 2026)
 767: 
 768: ### Public ACM Certificate Architecture Migration (January 18, 2026)
 769: 
 770: - **Public ACM Certificate Architecture**:
 771:   - Uses Public ACM certificates (Amazon-issued) for browser-trusted certificates
 772:   - Public ACM certificates requested in each deployment account (development, production)
 773:   - DNS validation records created in Route53 hosted zone in State Account
 774:   - Certificates stored in respective **deployment accounts** (not State Account)
 775:   - Eliminates cross-account certificate access complexity
 776:   - Compatible with **EKS Auto Mode ALB controller** requirements
 777:   (certificate must be in same account as ALB)
 778:   - Comprehensive Public ACM certificate setup documentation in `application/CROSS-ACCOUNT-ACCESS.md`
 779:   with step-by-step AWS CLI commands
 780:   - Certificate validation workflow documented for both production and
 781:   development accounts
 782:   - Certificates automatically renewed by ACM (no manual intervention required)
 783:   - Browser-trusted certificates (no security warnings)
 784:   - Updated all documentation to reflect Public ACM certificate architecture
 785:   (PRD-ALB.md, README.md, docs/index.html)
 786:   - Private CA setup moved to "Legacy" section (deprecated for public-facing applications)
 787: 
 788: ### Helm Release Deployment Improvements (January 14, 2026)
 789: 
 790: - **Enhanced Helm Release Attributes for Safer Deployments**:
 791:   - Added comprehensive Helm release attributes to all application modules
 792:   (OpenLDAP, PostgreSQL, Redis, cert-manager):
 793:     - `atomic: true` - Prevents partial deployments on failure
 794:     - `force_update: true` - Enables forced updates when needed
 795:     - `replace: true` - Prevents resource name conflicts and allows reusing names
 796:     - `cleanup_on_fail: true` - Cleans up resources on failed deployments
 797:     - `recreate_pods: true` - Forces pod restart on upgrade and rollbacks
 798:     - `wait: true` - Waits for all resources to be ready before marking success
 799:     - `wait_for_jobs: true` - Waits for any jobs to complete before marking success
 800:     - `upgrade_install: true` - Prevents failures if pre-existing resources exist
 801:   - OpenLDAP module timeout set to 5 minutes (300 seconds)
 802:   - PostgreSQL and Redis module timeouts set to 10 minutes (600 seconds)
 803:   - Improved deployment reliability and rollback safety
 804:   - Better error handling during deployment failures
 805: 
 806: - **Standardized Helm Values Passing**:
 807:   - Standardized how Helm values are passed through to all modules
 808:   (OpenLDAP, PostgreSQL, Redis)
 809:   - All modules now use consistent `templatefile()` approach with `values_template_path`
 810:   variable
 811:   - Modules can use default template path or custom path via variable
 812:   - Improved maintainability and consistency across all Helm chart deployments
 813:   - Created comprehensive Helm values templates:
 814:     - `helm/postgresql-values.tpl.yaml` - PostgreSQL Helm chart values template
 815:     - `helm/redis-values.tpl.yaml` - Updated Redis Helm chart values template
 816:     - `helm/openldap-values.tpl.yaml` - Updated OpenLDAP Helm chart values template
 817: 
 818: - **PostgreSQL Chart Repository Fix**:
 819:   - Fixed PostgreSQL Helm chart download issue by changing repository format
 820:   - Changed from `https://charts.bitnami.com/bitnami` to `oci://registry-1.docker.io/bitnamicharts`
 821:   - Uses OCI registry format for better compatibility and reliability
 822:   - Resolves chart download failures during deployment
 823: 
 824: ### Container Image Tag Strategy Update (January 14, 2026)
 825: 
 826: - **Image Tag Standardization**:
 827:   - Changed Redis and PostgreSQL image tags to use descriptive tags instead of
 828:   SHA digests
 829:   - Redis default image tag: `redis-latest` (mirrors `bitnami/redis:8.4.0-debian-12-r6`)
 830:   - PostgreSQL default image tag: `postgresql-latest` (mirrors `bitnami/postgresql:18.1.0-debian-12-r4`)
 831:   - OpenLDAP continues to use specific version tag: `openldap-1.5.0` (mirrors `osixia/openldap:1.5.0`)
 832:   - Image tags correspond to tags created by `mirror-images-to-ecr.sh` script
 833:   - ECR mirroring script updated to push images with consistent naming convention
 834:   - Simplifies image management and updates while maintaining version control
 835:   - Default image tags can be overridden via `variables.tfvars`
 836: 
 837: ### Cross-Account Access for Route53 (January 5, 2026)
 838: 
 839: - **State Account Role ARN Support**:
 840:   - Added support for querying Route53 hosted zones from State Account
 841:   - New variable `state_account_role_arn` for assuming role in State Account
 842:   (where Route53 resides)
 843:   - State account provider alias (`aws.state_account`) configured in `providers.tf`
 844:   - All Route53 data sources and resources now use state account provider when configured
 845:   - Route53 records (phpldapadmin, ltb_passwd, twofa_app, SES verification/DKIM)
 846:   created in State Account
 847:   - Route53 DNS validation records for Public ACM certificates created in
 848:   State Account
 849:   - Public ACM certificates are requested in Deployment Account (not State Account)
 850:   - Scripts automatically inject `state_account_role_arn` into `variables.tfvars`
 851:   - No ExternalId required for state account role assumption (by design)
 852:   - Comprehensive cross-account access documentation in `application/CROSS-ACCOUNT-ACCESS.md`
 853:   - Self-assumption support: State Account role can assume itself when needed
 854: 
 855: ### Route53 Record Module Separation (January 5, 2026)
 856: 
 857: - **Dedicated Route53 Record Module**:
 858:   - Separated Route53 record creation from OpenLDAP module into dedicated `route53_record`
 859:   module
 860:   - New module located at `application/modules/route53_record/` for per-record creation
 861:   - Module uses state account provider (`aws.state_account`) for cross-account access
 862:   - Route53 records created in State Account while ALB deployed in Deployment Account
 863:   - Three separate module calls in `main.tf`:
 864:     - `module.route53_record_phpldapadmin` - Creates A record for phpLDAPadmin
 865:     - `module.route53_record_ltb_passwd` - Creates A record for ltb-passwd
 866:     - `module.route53_record_twofa_app` - Creates A record for 2FA application
 867:   - Module outputs: `record_name`, `record_fqdn`, `record_id`
 868:   - Precondition ensures ALB DNS name is available before record creation
 869:   - Comprehensive ALB zone_id mapping by region (13 AWS regions supported)
 870:   - Proper dependency chain: OpenLDAP module  ALB data source  Route53 records
 871:   - Lifecycle block with `create_before_destroy` for safe updates
 872:   - Comprehensive module documentation in `application/modules/route53_record/README.md`
 873: 
 874: ### ECR Image Mirroring for Third-Party Container Images (January 5, 2026)
 875: 
 876: - **Automated Image Mirroring Script**:
 877:   - Created `application/mirror-images-to-ecr.sh` script (290+ lines) to eliminate
 878:   Docker Hub rate limiting and external dependencies
 879:   - Automatically mirrors third-party container images from Docker Hub to ECR:
 880:     - `bitnami/redis:8.4.0-debian-12-r6`  `redis-8.4.0`
 881:     - `bitnami/postgresql:18.1.0-debian-12-r4`  `postgresql-18.1.0`
 882:     - `osixia/openldap:1.5.0`  `openldap-1.5.0`
 883:   - Checks if images exist in ECR before mirroring (skips if already present)
 884:   - Uses State Account credentials to fetch ECR URL from backend_infra state
 885:   - Assumes Deployment Account role for ECR operations (with ExternalId)
 886:   - Authenticates Docker to ECR automatically using `aws ecr get-login-password`
 887:   - Cleans up local images after pushing to save disk space
 888:   - Lists all images in ECR repository after completion
 889:   - Integrated into `application/setup-application.sh` (runs before Terraform operations)
 890:   - Integrated into GitHub Actions workflow (runs after Terraform validate)
 891:   - Requires Docker to be installed and running
 892:   - Requires `jq` for JSON parsing (with fallback to sed for compatibility)
 893:   - Prevents Docker Hub rate limiting (200 pulls per 6 hours for anonymous) and
 894:   external dependencies
 895:   - Comprehensive error handling and user feedback
 896:   - Proper credential switching for multi-account architecture
 897: - **ECR Image Support for All Modules**:
 898:   - All three modules (OpenLDAP, PostgreSQL, Redis) now use ECR images instead of
 899:   Docker Hub
 900:   - New variables in `application/variables.tf`: `openldap_image_tag`, `postgresql_image_tag`,
 901:   `redis_image_tag`
 902:   - ECR registry and repository computed from backend_infra state (`ecr_url`)
 903:   - All modules updated with ECR configuration variables
 904:   (registry, repository, tag)
 905:   - Helm values templates updated to use ECR images
 906:   - Image tags correspond to tags created by `mirror-images-to-ecr.sh`
 907: - **Application main.tf Enhancements**:
 908:   - Retrieves ECR URL from backend_infra remote state
 909:   - Parses ECR URL to extract registry and repository name
 910:   - Passes ECR configuration to OpenLDAP, Redis, and PostgreSQL modules
 911: - **GitHub Actions Workflow Updates**:
 912:   - Added Docker Buildx setup to `application_infra_provisioning.yaml`
 913:   - Integrated `mirror-images-to-ecr.sh` execution before Terraform deployment
 914:   - Follows same multi-account credential flow as local scripts
 915: - **EKS ECR Permissions**:
 916:   - EKS Auto Mode automatically provides ECR pull permissions to nodes
 917:   - No additional IAM policy configuration required
 918:   - Nodes can pull images from ECR without hardcoded credentials
 919: 
 920: ### Destroy Scripts for Infrastructure Cleanup (December 30, 2025)
 921: 
 922: - **Automated Destroy Scripts**:
 923:   - Created `backend_infra/destroy-backend.sh` for destroying backend infrastructure
 924:   - Created `application/destroy-application.sh` for destroying application infrastructure
 925:   - Both scripts support interactive region and environment selection
 926:   - Automatic retrieval of role ARNs, ExternalId, and secrets from AWS Secrets Manager
 927:   - Automatic backend configuration and variables.tfvars updates
 928:   - Kubernetes environment setup for application destroy script (via `set-k8s-env.sh`)
 929:   - Comprehensive error handling and user guidance
 930: - **Safety Features**:
 931:   - Double confirmation required before destruction (type 'yes' then 'DESTROY')
 932:   - Clear warnings about irreversible actions
 933:   - Validation of user input before proceeding
 934:   - Color-coded output for better visibility
 935: - **GitHub Actions Integration**:
 936:   - Updated destroying workflows with ExternalId support
 937:   - Workflows use same role assumption pattern as provisioning workflows
 938:   - Proper permissions declarations for security compliance
 939: 
 940: ### Terraform Backend State Enhancements (December 30, 2025)
 941: 
 942: - **Simplified Terraform Configuration**:
 943:   - Removed `principal_arn` variable - bucket policy now automatically uses current
 944:   caller's ARN via `data.aws_caller_identity.current.arn`
 945:   - Eliminates need to pass principal ARN as a variable, simplifying configuration
 946:   - Reduces user configuration burden and potential errors
 947: - **Enhanced set-state.sh Script**:
 948:   - Automatic role assumption from AWS Secrets Manager (secret: `github-role`)
 949:   - Intelligent infrastructure provisioning detection via `BACKEND_BUCKET_NAME`
 950:   repository variable
 951:   - Automatic state file download from S3 when bucket exists
 952:   - Terraform validation, plan, and apply workflow integration
 953:   - Bucket name verification and GitHub repository variable management
 954:   - Comprehensive error handling with colored output (INFO, SUCCESS, ERROR)
 955:   - Always updates bucket name and state file to ensure synchronization
 956:   - Enhanced credential extraction with jq fallback to sed for broader compatibility
 957:   - Improved user feedback throughout the process
 958: 
 959: ### ExternalId Security Feature for Cross-Account Role Assumption (Dec 29, 2025)
 960: 
 961: - **ExternalId Support**:
 962:   - Added ExternalId requirement for enhanced security when assuming deployment
 963:   account roles
 964:   - Prevents confused deputy attacks in multi-account deployments
 965:   - ExternalId retrieved from AWS Secrets Manager (secret: `external-id`) for
 966:   local deployment scripts
 967:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
 968:   for GitHub Actions workflows
 969:   - ExternalId passed to Terraform provider's `assume_role` block in both
 970:   `application` and `backend_infra`
 971:   - New variable `deployment_account_external_id` added to `application/variables.tf`
 972:   and `backend_infra/variables.tf`
 973:   - Setup scripts (`setup-application.sh` and `setup-backend.sh`) automatically
 974:   retrieve ExternalId from AWS Secrets Manager
 975:   - Destroy scripts (`destroy-application.sh` and `destroy-backend.sh`) also
 976:   retrieve ExternalId from AWS Secrets Manager
 977:   - GitHub Actions workflows updated to use `AWS_ASSUME_EXTERNAL_ID` secret
 978:   - Deployment account roles must have ExternalId condition in Trust Relationship
 979:   - **Bidirectional Trust Relationships**: Both deployment account roles and state
 980:   account role must trust each other in their respective Trust Relationships
 981:   - State account role's Trust Relationship must include deployment account role
 982:   ARNs to enable proper cross-account role assumption
 983:   - ExternalId generation: `openssl rand -hex 32`
 984: - **Documentation Updates**:
 985:   - Updated `SECRETS_REQUIREMENTS.md` with comprehensive ExternalId setup instructions
 986:   and bidirectional trust relationship requirements
 987:   - Updated all README files with ExternalId configuration steps and destroy script
 988:   usage
 989:   - Updated `SECURITY-IMPROVEMENTS.md` with ExternalId security benefits
 990:   - Updated GitHub Pages documentation (`docs/index.html`)
 991:   - Updated CHANGELOG.md files across all layers with destroy script additions
 992: 
 993: ### Security Enhancements and Code Scanning Fixes (December 28, 2025)
 994: 
 995: - **GitHub Workflow Security Improvements**:
 996:   - Added explicit permissions declarations to all workflow jobs
 997:   - Applied principle of least privilege with `contents: read` or empty
 998:   `permissions: {}`
 999:   where no permissions needed
1000:   - Fixes automated code scanning alerts for missing workflow permissions
1001:   - Affected workflows: all infrastructure provisioning/destroying and build/push
1002:   workflows
1003: - **LDAP Injection Prevention**:
1004:   - Fixed LDAP query injection vulnerability in `application/backend/src/app/ldap/client.py`
1005:   - Added DN component escaping using `ldap3.utils.dn.escape_rdn()`
1006:   - Protects `user_exists()` and `get_user_attribute()` methods from malicious input
1007:   - User-controlled input now properly sanitized before LDAP queries
1008: - **Sensitive Information Logging Protection**:
1009:   - Fixed clear-text logging of phone numbers in `application/backend/src/app/sms/client.py`
1010:   - Replaced phone number logging with SHA-256 hash (first 8 characters)
1011:   - Applied to `opt_in_phone_number()` method
1012:   - Protects PII in application logs
1013: - **API Documentation Always Enabled**:
1014:   - Swagger UI (`/api/docs`) and ReDoc UI (`/api/redoc`) now always accessible in
1015:   production
1016:   - Removed debug mode condition for API documentation endpoints
1017:   - OpenAPI schema available at `/api/openapi.json`
1018:   - Interactive documentation automatically updates when endpoints change
1019: - **Documentation Improvements**:
1020:   - Removed duplication by replacing detailed module descriptions with links to
1021:   module READMEs
1022:   - Enhanced cross-references to module documentation (ALB, ArgoCD, cert-manager,
1023:   Network Policies, PostgreSQL, Redis, SES, SNS, VPC Endpoints, ECR, OpenLDAP)
1024:   - Updated component descriptions to be more concise with links to detailed documentation
1025:   - Improved consistency across documentation files
1026:   - Main README restructured for better clarity and organization
1027: 
1028: ### Kubernetes Secrets Integration and OpenLDAP Module (December 27-28, 2025)
1029: 
1030: - **OpenLDAP Module (`application/modules/openldap/`)**:
1031:   - Modularized OpenLDAP Stack HA deployment with comprehensive configuration
1032:   - Includes phpLDAPadmin and ltb-passwd web interfaces
1033:   - Manages Kubernetes secrets for OpenLDAP passwords
1034:   - Handles Helm release deployment with templated values
1035:   - Creates ALB Ingress resources for public access
1036:   - Route53 DNS records now created separately via `route53_record` module
1037:   - See [OpenLDAP Module Documentation](application/modules/openldap/README.md)
1038:   for details
1039: - **Kubernetes Secrets for All Components**:
1040:   - **OpenLDAP**: Kubernetes secret created by OpenLDAP module for admin/config
1041:   passwords
1042:   - **PostgreSQL**: Uses Kubernetes secret for database password (created by module)
1043:   - **Redis**: Uses Kubernetes secret for authentication password (created by module)
1044:   - Eliminates plain-text passwords in Helm values
1045:   - All secrets created from Terraform variables (sourced from AWS Secrets Manager
1046:   or GitHub Secrets)
1047: - **Secrets Management Consolidation**:
1048:   - Created comprehensive `SECRETS_REQUIREMENTS.md` documentation (located in root)
1049:   - Documents both AWS Secrets Manager setup (for local scripts) and
1050:   GitHub Repository Secrets (for workflows)
1051:   - Two AWS Secrets Manager secrets: `github-role` (IAM role ARNs) and `tf-vars`
1052:   (passwords)
1053:   - Clear distinction between local and GitHub Actions secret retrieval methods
1054:   - Case sensitivity guidance for TF_VAR environment variables
1055: - **Updated Setup Scripts**:
1056:   - `backend_infra/setup-backend.sh`: Now retrieves secrets from AWS Secrets Manager
1057:   - `application/setup-application.sh`: Retrieves both role ARNs and passwords
1058:   from AWS Secrets Manager
1059:   - Eliminated dependency on GitHub CLI for secret retrieval (GitHub CLI cannot
1060:   read secret values)
1061:   - Scripts automatically export secrets as environment variables for Terraform
1062:   - Improved error handling and validation
1063: - **GitHub Workflows Updated**:
1064:   - Added missing `TF_VAR_POSTGRESQL_PASSWORD` and `TF_VAR_REDIS_PASSWORD` to workflows
1065:   - Workflows continue to use GitHub Repository Secrets (unchanged)
1066:   - Added permissions declarations to all jobs
1067: - **Module Improvements**:
1068:   - PostgreSQL module now creates Kubernetes secret with `postgresql-password` key
1069:   - Redis module creates Kubernetes secret with `redis-password` key
1070:   - OpenLDAP module creates Kubernetes secret with admin/config password keys
1071:   - Bitnami Helm charts configured to use `existingSecret` instead of plain-text
1072:   values
1073: 
1074: ### AWS Secrets Manager Integration for Local Scripts (December 27, 2025)
1075: 
1076: - **Local script secret retrieval from AWS Secrets Manager**:
1077:   - Updated `get-state.sh` and `set-state.sh` to retrieve role ARNs from
1078:   AWS Secrets Manager
1079:   - Secret name: `github-role` containing JSON with key `AWS_STATE_ACCOUNT_ROLE_ARN`
1080:   - Replaces previous GitHub CLI secret access (GitHub CLI cannot read secret
1081:   values directly)
1082:   - Scripts automatically assume the role retrieved from AWS Secrets Manager
1083: - **GitHub Actions workflows unchanged**:
1084:   - Workflows continue to retrieve role ARN from GitHub repository secrets
1085:   - No changes to `AWS_STATE_ACCOUNT_ROLE_ARN` GitHub secret configuration
1086: - **Prerequisites for local execution**:
1087:   - AWS Secrets Manager secret `github-role` must exist with proper JSON structure
1088:   - User credentials must have `secretsmanager:GetSecretValue` permission
1089:   - Example secret JSON: `{"AWS_STATE_ACCOUNT_ROLE_ARN": "arn:aws:iam::<account-id>:role/<role-name>"}`
1090: - **Improved error handling**:
1091:   - Comprehensive error messages for secret retrieval failures
1092:   - JSON validation for secret content
1093:   - Key existence validation within secret
1094: - **Updated documentation**:
1095:   - `tf_backend_state/README.md` updated with AWS Secrets Manager setup instructions
1096:   - `tf_backend_state/CHANGELOG.md` updated with latest changes
1097:   - Clarified differences between GitHub Actions (repository secrets) and local
1098:   scripts (AWS Secrets Manager)
1099: 
1100: ## Recent Changes (December 2025)
1101: 
1102: ### Admin Functions and User Profile Management (December 18, 2025)
1103: 
1104: - **Admin Dashboard and User Management**:
1105:   - Admin tab visible only to LDAP admin group members
1106:   - User management with filter by status (pending, complete, active, revoked)
1107:   - View user details: name, email, phone, verification status, MFA method,
1108:   groups
1109:   - Activation and revocation workflow with audit logging
1110:   - Approval requires group assignment (at least one group)
1111:   - Creates user in LDAP with all attributes on approval
1112:   - Revocation removes user from LDAP and all groups
1113: - **User Profile Management**:
1114:   - Profile page with viewable and editable fields
1115:   - Edit restrictions: email/phone read-only after verification
1116:   - Profile fields: username, first/last name, email, phone, MFA method, status
1117: - **Group Management (Full CRUD)**:
1118:   - Create, read, update, delete groups via admin interface
1119:   - Group-user assignment management
1120:   - Sync with LDAP groups on create/update/delete
1121:   - View group members and member counts
1122: - **Admin Notifications**:
1123:   - Email notification to all admins on new user signup
1124:   - Uses AWS SES infrastructure with IRSA
1125:   - Async notification (non-blocking)
1126: - **Top Navigation Bar**:
1127:   - Persistent navigation after login
1128:   - User menu with profile and logout options
1129:   - Admin-specific menu items for admin users
1130: 
1131: ### User Signup Management System (December 18, 2025)
1132: 
1133: - **Self-Service User Registration**:
1134:   - Signup form with fields: first/last name, username, email, phone, password,
1135:   MFA method
1136:   - Username validation (3-64 chars, alphanumeric + underscore/hyphen)
1137:   - Email and phone uniqueness validation
1138:   - Password hashing with bcrypt
1139: - **Email Verification via AWS SES**:
1140:   - UUID token-based verification links
1141:   - 24-hour token expiry (configurable)
1142:   - Resend verification with 60-second cooldown
1143:   - Email delivery via AWS SES with IRSA
1144: - **Phone Verification via AWS SNS**:
1145:   - 6-digit OTP code via SMS
1146:   - 1-hour code expiry
1147:   - Resend code with 60-second cooldown
1148:   - SMS delivery via AWS SNS with IRSA
1149: - **Profile State Management**:
1150:   - PENDING: User registered, verification incomplete
1151:   - COMPLETE: All verifications complete, awaiting admin
1152:   - ACTIVE: Admin activated, exists in LDAP
1153:   - REVOKED: Admin revoked, removed from LDAP
1154: - **Login Restrictions**:
1155:   - PENDING users cannot login (shows missing verifications)
1156:   - COMPLETE users see "awaiting admin approval" message
1157:   - Only ACTIVE users can complete login flow
1158: 
1159: ### Redis SMS OTP Storage (December 18, 2025)
1160: 
1161: - **Redis Module (`modules/redis/`) for SMS OTP Code Storage**:
1162:   - Bitnami Redis Helm chart deployment via Terraform
1163:   - Standalone architecture (sufficient for OTP cache use case)
1164:   - Password authentication via Kubernetes Secret (from GitHub Secrets)
1165:   - PersistentVolume storage with RDB snapshots for data recovery
1166:   - Non-root security context (UID 1001)
1167:   - Network policy restricting Redis access to backend pods only
1168:   - TTL-based automatic expiration for OTP codes
1169: - **Redis Client Module (`app/redis/`)**:
1170:   - `RedisOTPClient` class with TTL-aware storage operations
1171:   - Automatic fallback to in-memory storage when Redis is disabled
1172:   - Methods: `store_code()`, `get_code()`, `delete_code()`, `code_exists()`
1173:   - Connection health checking and error handling
1174:   - Lazy initialization with connection pooling
1175: 
1176: ### PostgreSQL and SES Integration (December 18, 2025)
1177: 
1178: - **PostgreSQL Module (`modules/postgresql/`)**:
1179:   - Bitnami PostgreSQL Helm chart deployment
1180:   - Database for user registrations and verification tokens
1181:   - Password authentication from GitHub Secrets
1182:   - PersistentVolume storage with RDB
1183: - **SES Module (`modules/ses/`)**:
1184:   - AWS SES email identity verification
1185:   - IAM Role with IRSA for secure pod access
1186:   - Email sending for verification and notifications
1187:   - Sender email configuration
1188: - **Database Connection Module (`app/database/`)**:
1189:   - PostgreSQL connection management
1190:   - SQLAlchemy models for users, verification tokens, groups, user-group
1191:   relationships
1192:   - Async database operations
1193: - **Email Client Module (`app/email/`)**:
1194:   - AWS SES integration for sending emails
1195:   - Email templates for verification and welcome emails
1196:   - IRSA-based authentication for SES access
1197: - **New API Endpoints**:
1198:   - `POST /api/auth/signup` - Register new user
1199:   - `POST /api/auth/verify-email` - Verify email with token
1200:   - `POST /api/auth/verify-phone` - Verify phone with code
1201:   - `POST /api/auth/resend-verification` - Resend verification
1202:   - `GET /api/profile/status/{username}` - Get profile status
1203:   - `GET /api/profile/{username}` - Get user profile
1204:   - `PUT /api/profile/{username}` - Update user profile
1205:   - Admin endpoints for user and group management
1206: - **Product Requirements Document**: Comprehensive PRD-SIGNUP-MAN.md documenting
1207: signup system, user stories, and API specifications
1208: 
1209: ### 2FA Application and SMS Integration (December 18, 2025 - Initial Release)
1210: 
1211: - **Full-stack 2FA application deployed**:
1212:   - Python FastAPI backend with LDAP authentication integration
1213:   - Static HTML/JS/CSS frontend with modern, responsive UI
1214:   - Support for **two MFA methods**: TOTP (authenticator apps) and SMS (AWS SNS)
1215:   - Single domain routing (`app.<domain>`) with path-based routing (`/` for
1216:   frontend, `/api/*` for backend)
1217:   - Kubernetes resources: Deployments, Services, Ingresses, ConfigMaps, Secrets,
1218:   ServiceAccounts, HPA
1219:   - Complete Helm charts for both backend and frontend
1220:   - Dockerfiles for containerized deployment
1221: - **SNS module for SMS-based 2FA verification**:
1222:   - SNS Topic for centralized SMS notifications
1223:   - IAM Role configured for IRSA (IAM Roles for Service Accounts)
1224:   - Direct SMS support for sending verification codes to phone numbers
1225:   - E.164 phone number format support
1226:   - Transactional SMS type for higher delivery priority
1227:   - Cost control via monthly spend limits
1228: - **GitHub Actions CI/CD workflows**:
1229:   - `backend_build_push.yaml` - Builds and pushes backend Docker image to ECR
1230:   - `frontend_build_push.yaml` - Builds and pushes frontend Docker image to ECR
1231:   - Triggered on changes to `application/backend/**` and
1232:   `application/frontend/**` paths
1233: - **Product Requirements Document**: Comprehensive PRD-2FA-APP.md documenting
1234: architecture, API specs, and frontend components
1235: 
1236: ### ArgoCD GitOps Integration (December 16, 2025)
1237: 
1238: - **ArgoCD capability module**:
1239:   - Deploys AWS EKS managed ArgoCD service (runs in EKS control plane)
1240:   - Creates IAM role and policies for ArgoCD capability
1241:   - Configures AWS Identity Center (IdC) authentication
1242:   - Registers local EKS cluster with ArgoCD
1243:   - Sets up RBAC mappings for Identity Center groups/users
1244:   - Optional VPC endpoint configuration for private access
1245: - **ArgoCD Application module**:
1246:   - Creates ArgoCD Application CRD for GitOps deployments
1247:   - Supports multiple deployment types (Kubernetes manifests, Helm charts,
1248:   Kustomize)
1249:   - Configurable sync policies (automated/manual)
1250:   - Retry policies with backoff configuration
1251:   - Ignore differences for externally managed fields
1252: 
1253: ### Documentation and Linting Improvements (December 15, 2025)
1254: 
1255: - **Markdown lint compliance**:
1256:   - Corrected row length issues across all documentation files
1257:   - Added `.markdownlint.json` for consistent formatting
1258:   - Updated all README files, CHANGELOGs, and PRD documents
1259: 
1260: ### Deployment Versatility and Security Improvements (December 14, 2025)
1261: 
1262: - **Cross-namespace LDAP access**:
1263:   - Updated network policies to allow services in other namespaces to access
1264:   LDAP service on secure ports (443, 636, 8443)
1265:   - Enables microservices in different namespaces to securely access centralized
1266:   LDAP service
1267: - **Password management via GitHub Secrets**:
1268:   - OpenLDAP passwords now exclusively managed through GitHub repository secrets
1269:   - Setup scripts automatically retrieve and export passwords
1270:   - Removed dependency on local password files
1271: - **Unified application setup script**:
1272:   - New `setup-application.sh` consolidates all application deployment steps
1273:   - Handles role assumption, backend configuration, Terraform operations, and
1274:   Kubernetes environment setup
1275:   - Replaces previous `setup-backend.sh` and `setup-backend-api.sh` scripts
1276: 
1277: ## Earlier Changes (December 2025)
1278: 
1279: ### Multi-Account Architecture and Role Management (Latest)
1280: 
1281: - **Environment-based AWS role ARN selection**: Added support for separate
1282: deployment role ARNs for production and development environments
1283:   - New GitHub secrets: `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` and
1284:   `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
1285:   - Workflows and scripts automatically select the appropriate role ARN based on
1286:   selected environment (`prod` or `dev`)
1287:   - Backend state operations always use `AWS_STATE_ACCOUNT_ROLE_ARN` (Account A)
1288:   - Deployment operations use environment-specific role ARNs via Terraform
1289:   provider `assume_role`
1290: - **Removed `provider_profile` variable**: No longer needed since role
1291: assumption is handled via setup scripts and workflows
1292:   - Removed from `backend_infra/variables.tf`, `backend_infra/variables.tfvars`,
1293:   `backend_infra/providers.tf`
1294:   - Removed from `application/variables.tf`, `application/variables.tfvars`,
1295:   `application/providers.tf`
1296: - **Automated Terraform execution in backend_infra setup script**:
1297:   - `backend_infra/setup-backend.sh` now automatically runs Terraform commands
1298:   (init, workspace, validate, plan, apply)
1299:   - Eliminates the need for manual Terraform command execution after backend
1300:   configuration
1301:   - Script handles workspace creation/selection automatically
1302:   - Script assumes `AWS_STATE_ACCOUNT_ROLE_ARN` for backend operations and
1303:   retrieves environment-specific deployment role ARN
1304: - **Automated backend.hcl creation in backend_infra**:
1305:   - `setup-backend.sh` now automatically creates `backend.hcl` from template if
1306:   it doesn't exist
1307:   - Skips creation if `backend.hcl` already exists (prevents overwriting
1308:   existing configuration)
1309: - **Updated workflows**: All infrastructure and application workflows now use
1310: `AWS_STATE_ACCOUNT_ROLE_ARN` for backend operations and set
1311: `deployment_account_role_arn` variable based on selected environment
1312: - **CI/CD workflows**: New workflows for building and pushing 2FA application
1313: Docker images to ECR
1314: 
1315: ### ALB Annotation Strategy Improvements
1316: 
1317: - **Moved certificate ARN and group name to IngressClassParams**: Centralized
1318: TLS and group configuration at the cluster level
1319: - **Reduced annotation duplication**: Certificate and group configuration
1320: defined once in IngressClassParams, inherited by all Ingresses
1321: - **Simplified Helm values**: Removed `group.name` and `certificate-arn` from
1322: Ingress annotations
1323: - **Updated documentation**: Comprehensive ALB implementation guide in
1324: `PRD-ALB.md` with EKS Auto Mode comparison
1325: 
1326: ### New Outputs and Modules
1327: 
1328: - **Added comprehensive outputs**: Backend infrastructure outputs (VPC
1329: endpoints, ECR) and application outputs (ALB, Route53, network policies)
1330: - **cert-manager module**: Optional module for self-signed TLS certificates
1331: (exists but not actively used)
1332: - **CHANGELOG.md**: Detailed changelog tracking ALB configuration changes, TLS
1333: environment variable updates, and multi-account architecture changes
1334: - **OSIXIA-OPENLDAP-REQUIREMENTS.md**: Documentation for osixia/openldap image
1335: requirements
1336: 
1337: ## Development Workflow
1338: 
1339: ### Making Infrastructure Changes
1340: 
1341: 1. Update `variables.tfvars` with desired changes
1342: 2. For application layer, ensure OpenLDAP passwords are exported as environment
1343: variables (for local use) or available as GitHub secrets (the setup script
1344: handles retrieval automatically)
1345: 3. For backend_infra, run `./setup-backend.sh` to automatically configure and
1346: deploy (includes Terraform init, workspace, validate, plan, apply)
1347: 4. For application layer, run `./setup-application.sh` to automatically
1348: configure and deploy (includes password secret retrieval, Terraform init,
1349: workspace, validate, plan, apply, and Kubernetes environment setup)
1350: 5. For multi-region or multi-environment deployments, run setup scripts again
1351: with different selections
1352: 6. Review `CHANGELOG.md`, `backend_infra/CHANGELOG.md`, and
1353: `application/CHANGELOG.md` for recent changes and verification steps
1354: 
1355: ### Destroying Infrastructure
1356: 
1357: 1. **Application Layer**:
1358:    - Run `./destroy-application.sh` from the `application/` directory
1359:    - Script automatically retrieves credentials and configurations
1360:    - Requires double confirmation (type 'yes' then 'DESTROY')
1361:    - Handles Kubernetes environment setup automatically
1362: 2. **Backend Infrastructure**:
1363:    - Run `./destroy-backend.sh` from the `backend_infra/` directory
1364:    - Script automatically retrieves credentials and configurations
1365:    - Requires double confirmation (type 'yes' then 'DESTROY')
1366: 3. **Backend State**:
1367:    - Use GitHub Actions workflow "TF Backend State Destroying" (recommended)
1368:    - Or manually destroy using Terraform commands after assuming IAM role
1369: 4. **Destroy Order**: Always destroy in reverse order of creation:
1370:    - Application layer  Backend infrastructure  Backend state
1371: 
1372: ### Developing 2FA Application
1373: 
1374: 1. **Backend Changes** (`application/backend/`):
1375:    - Make changes to Python code in `src/`
1376:    - Test locally if possible
1377:    - Commit and push changes to `application/backend/**`
1378:    - GitHub Actions workflow `backend_build_push.yaml` automatically:
1379:      - Builds Docker image
1380:      - Tags with commit SHA
1381:      - Pushes to ECR
1382:      - If using ArgoCD: ArgoCD detects change and syncs
1383:      - If using direct Helm: Update image tag in Helm values and re-apply
1384: 2. **Frontend Changes** (`application/frontend/`):
1385:    - Make changes to HTML/JS/CSS in `src/`
1386:    - Test locally with a simple HTTP server
1387:    - Commit and push changes to `application/frontend/**`
1388:    - GitHub Actions workflow `frontend_build_push.yaml` automatically handles
1389:    build and push
1390:    - Deployment follows same pattern as backend
1391: 3. **Terraform Module Changes** (`application/modules/`):
1392:    - Update module code and test
1393:    - Run `./setup-application.sh` to apply changes
1394:    - Review outputs and verify resources
1395: 
1396: ### Adding New Kubernetes Resources
1397: 
1398: 1. Add resources to `application/main.tf` or create a new module in
1399: `application/modules/`
1400: 2. Update Helm values template if needed
1401: (`application/helm/openldap-values.tpl.yaml`)
1402: 3. Ensure proper `depends_on` relationships (e.g., Helm release, data sources)
1403: 4. For IRSA-enabled resources:
1404:    - Create IAM role with trust policy for EKS OIDC provider
1405:    - Attach necessary permissions
1406:    - Add annotation to ServiceAccount: `eks.amazonaws.com/role-arn`
1407: 5. Plan and apply changes using `./setup-application.sh`
1408: 6. For Ingress changes, ALB will be automatically updated via Kubernetes
1409: controller
1410: 7. If using ArgoCD, commit manifests to Git and let ArgoCD sync
1411: 
1412: ### Troubleshooting
1413: 
1414: - **PVC stuck in Pending**: Normal until a pod uses it (EBS Auto Mode behavior
1415: with WaitForFirstConsumer)
1416: - **Terraform workspace issues**: Ensure workspace exists before selecting
1417: (format: `region-env`, e.g. `us-east-1-prod`)
1418: - **Backend config errors**: Re-run `setup-backend.sh` (backend_infra) or
1419: `setup-application.sh` (application) to regenerate `backend.hcl`
1420: - **SSM access denied**: Check VPC endpoint security groups and IAM policies
1421: - **Cluster name not found**: Ensure backend_infra is deployed first and
1422: `backend.hcl` is configured correctly, or provide `cluster_name` in
1423: variables.tfvars
1424: - **OpenLDAP password errors**: The setup script automatically retrieves
1425: passwords from GitHub secrets. For local use, ensure passwords are exported as
1426: environment variables (`TF_VAR_OPENLDAP_ADMIN_PASSWORD`,
1427: `TF_VAR_OPENLDAP_CONFIG_PASSWORD`) before running the script
1428: - **ALB not created**: Check Ingress resources have proper annotations, ACM
1429: certificate is validated, and IngressClass/IngressClassParams exist
1430: - **Route53 DNS not resolving**: Ensure Route53 A records point to ALB DNS name
1431: and NS records are configured at registrar
1432: - **IngressClass not found**: Ensure ALB module is deployed (via `use_alb =
1433: true` variable)
1434: - **Certificate not applied**: Certificate ARN is configured in
1435: IngressClassParams, not in Ingress annotations
1436: 
1437: ### OpenLDAP Authentication Issues (Error 49: Invalid Credentials)**
1438: 
1439: 1. **Root Cause**: OpenLDAP was initialized without proper `LDAP_DOMAIN`
1440: environment variable
1441:    - Symptoms: `ldap_bind: Invalid credentials (49)` even with correct password
1442:    - The jp-gouin chart's `global.ldapDomain` doesn't pass through to
1443:    osixia/openldap container
1444:    - Must explicitly set `LDAP_DOMAIN`, `LDAP_ADMIN_PASSWORD`, and
1445:    `LDAP_CONFIG_PASSWORD` in `env:` section
1446: 
1447: 2. **Fix**: Delete PVCs to force re-initialization with correct environment
1448: variables:
1449: 
1450:    ```bash
1451:    kubectl delete pvc -n ldap --all
1452:    kubectl delete pod -n ldap openldap-stack-ha-0 openldap-stack-ha-1 openldap-stack-ha-2
1453:    # Wait for pods to restart and PVCs to recreate
1454:    ```
1455: 
1456: 3. **Verify Fix**:
1457: 
1458:    ```bash
1459:    # Check environment variables are set
1460:    kubectl exec -n ldap openldap-stack-ha-0 -- env | grep LDAP_DOMAIN
1461: 
1462:    # Test authentication
1463:    kubectl exec -n ldap openldap-stack-ha-0 -- ldapsearch -x -LLL -H ldap://localhost:389 \
1464:      -D "cn=admin,dc=ldap,dc=talorlik,dc=internal" -w "<password>" \
1465:      -b "dc=ldap,dc=talorlik,dc=internal" "(objectClass=*)" dn
1466:    ```
1467: 
1468: ### ALB Ingress Group Issues (Multiple ALBs Created)**
1469: 
1470: 1. **Root Cause**: AWS Load Balancer Controller creates separate ALBs when
1471: multiple Ingresses with same `group.name` are created simultaneously
1472:    - Symptoms: Each Ingress shows different ALB address; one returns 404 while
1473:    other works
1474:    - Example: `phpldapadmin` on `k8s-ldap-openldap-xxx` and `passwd` on
1475:    `talo-tf-us-east-1-talo-ldap-prod-xxx`
1476: 
1477: 2. **Fix**: Delete all ALBs and Ingresses, then recreate cleanly:
1478: 
1479:    ```bash
1480:    # Delete all LDAP-related ALBs
1481:    aws elbv2 describe-load-balancers --region us-east-1 \
1482:      --query 'LoadBalancers[?contains(LoadBalancerName, `ldap`)].LoadBalancerArn' \
1483:      --output text | xargs -n1 aws elbv2 delete-load-balancer --region us-east-1 --load-balancer-arn
1484: 
1485:    # Delete Ingresses
1486:    kubectl delete ingress -n ldap --all
1487: 
1488:    # Wait for cleanup (60 seconds)
1489:    sleep 60
1490: 
1491:    # Recreate Helm release
1492:    terraform apply -replace="helm_release.openldap" -var-file="variables.tfvars" -auto-approve
1493:    ```
1494: 
1495: 3. **Verify Fix**:
1496: 
1497:    ```bash
1498:    # Both Ingresses should show same ALB address
1499:    kubectl get ingress -n ldap
1500: 
1501:    # Test both sites return 200 OK
1502:    curl -I https://phpldapadmin.talorlik.com
1503:    curl -I https://passwd.talorlik.com
1504:    ```
1505: 
1506: ### Route53 Record State Issues**
1507: 
1508: 1. **Root Cause**: Route53 records reference `local.alb_dns_name` which is empty
1509: when Ingresses don't exist
1510:    - Symptoms: Terraform validation error "expected length of alias.0.name to be
1511:    in the range (1 - 1024), got"
1512: 
1513: 2. **Fix**: Remove records from Terraform state and AWS, then recreate:
1514: 
1515:    ```bash
1516:    # Remove from Terraform state
1517:    terraform state rm aws_route53_record.phpldapadmin aws_route53_record.ltb_passwd
1518: 
1519:    # Delete from AWS (create delete batch)
1520:    cat > /tmp/delete-records.json << 'EOF'
1521:    {
1522:      "Changes": [
1523:        {
1524:          "Action": "DELETE",
1525:          "ResourceRecordSet": {
1526:            "Name": "phpldapadmin.talorlik.com",
1527:            "Type": "A",
1528:            "AliasTarget": {
1529:              "HostedZoneId": "Z35SXDOTRQ7X7K",
1530:              "DNSName": "<old-alb-dns-name>",
1531:              "EvaluateTargetHealth": true
1532:            }
1533:          }
1534:        },
1535:        {
1536:          "Action": "DELETE",
1537:          "ResourceRecordSet": {
1538:            "Name": "passwd.talorlik.com",
1539:            "Type": "A",
1540:            "AliasTarget": {
1541:              "HostedZoneId": "Z35SXDOTRQ7X7K",
1542:              "DNSName": "<old-alb-dns-name>",
1543:              "EvaluateTargetHealth": true
1544:            }
1545:          }
1546:        }
1547:      ]
1548:    }
1549:    EOF
1550:    aws route53 change-resource-record-sets --hosted-zone-id <zone-id> --change-batch file:///tmp/delete-records.json
1551: 
1552:    # Apply Terraform to recreate records
1553:    terraform apply -auto-approve -var-file="variables.tfvars"
1554:    ```
1555: 
1556: ## Important Notes
1557: 
1558: ### MFA Methods
1559: 
1560: The 2FA application supports two multi-factor authentication methods:
1561: 
1562: | Method | Description | Infrastructure Required |
1563: | -------- | ------------- | ------------------------ |
1564: | **TOTP** | Time-based One-Time Password using authenticator apps (Google Authenticator, Authy, etc.) | None (codes generated locally) |
1565: | **SMS** | Verification codes sent via AWS SNS to user's phone | SNS VPC endpoint, IRSA role, SNS module |
1566: 
1567: **Enabling SMS 2FA:**
1568: 
1569: 1. Set `enable_sts_endpoint = true` in `backend_infra/variables.tfvars` (for
1570: IRSA)
1571: 2. Set `enable_sns_endpoint = true` in `backend_infra/variables.tfvars` (for
1572: SNS access)
1573: 3. Deploy backend_infra with VPC endpoints
1574: 4. Set `enable_sms_2fa = true` in `application/variables.tfvars`
1575: 5. Deploy application infrastructure with SNS module
1576: 6. Backend automatically detects SNS configuration and enables SMS MFA method
1577: 
1578: ### TLS Configuration
1579: 
1580: - **Internal LDAP TLS**: osixia/openldap auto-generates self-signed certificates
1581: on first startup
1582:   - Environment variables: `LDAP_TLS: "true"`, `LDAP_TLS_ENFORCE: "false"`,
1583:   `LDAP_TLS_VERIFY_CLIENT: "never"`
1584:   - Filenames: `LDAP_TLS_CRT_FILENAME: "ldap.crt"`, `LDAP_TLS_KEY_FILENAME:
1585:   "ldap.key"`, `LDAP_TLS_CA_CRT_FILENAME: "ca.crt"`
1586: - **ALB TLS**: ACM certificate terminates TLS at ALB for public access
1587: - **cert-manager Module**: Optional module for managing custom certificates
1588: (currently exists but not actively used)
1589: 
1590: ### Storage Configuration
1591: 
1592: - **StorageClass**: Created by application Terraform
1593: (`kubernetes_storage_class_v1` resource)
1594:   - Name pattern: `${prefix}-${region}-${storage_class_name}-${env}` (e.g.,
1595:   `talo-tf-us-east-1-gp3-ldap-prod`)
1596:   - Provisioner: `ebs.csi.eks.amazonaws.com` (built-in to EKS Auto Mode)
1597:   - Volume binding mode: `WaitForFirstConsumer` (PVCs stay Pending until pod is
1598:   scheduled)
1599:   - Type: `gp3` (configurable via `storage_class_type` variable)
1600:   - Encryption: Enabled by default (configurable via `storage_class_encrypted`
1601:   variable)
1602: - **PVC**: Created by Helm chart using the StorageClass
1603:   - Size: 8Gi (configurable in Helm values)
1604:   - Access mode: ReadWriteOnce
1605:   - Replication: 3 replicas, each with its own PVC
1606: 
1607: ### ALB Configuration
1608: 
1609: - **EKS Auto Mode**: Uses built-in load balancer driver (`eks.amazonaws.com/alb`
1610: controller) with automatic IAM permissions
1611: - **IngressClassParams** (cluster-wide): Sets `scheme`, `ipAddressType`,
1612: `group.name`, and `certificateARNs` for all ALBs using the IngressClass
1613:   - Note: EKS Auto Mode IngressClassParams does NOT support subnets, security
1614:   groups, or tags (unlike AWS Load Balancer Controller)
1615: - **Per-Ingress annotations**: Control `load-balancer-name`, `target-type`,
1616: `listen-ports`, `ssl-redirect`
1617:   - Note: `group.name` and `certificate-arn` are configured in
1618:   IngressClassParams, not in Ingress annotations
1619: - **ALB Naming**: Separate configuration for:
1620:   - `alb_group_name`: Kubernetes identifier (max 63 characters)
1621:   - `alb_load_balancer_name`: AWS resource name (max 32 characters)
1622: - **Certificate Management**: ACM certificate ARN configured once in
1623: IngressClassParams and inherited by all Ingresses
1624: - **Single ALB**: All Ingresses (OpenLDAP web UIs + 2FA app) share the same ALB
1625: via `group.name` in IngressClassParams with host-based routing
1626: - **Routing**:
1627:   - `phpldapadmin.<domain>`  phpLDAPadmin service
1628:   - `passwd.<domain>`  LTB-passwd service
1629:   - `app.<domain>/`  2FA frontend service
1630:   - `app.<domain>/api/*`  2FA backend service
1631: 
1632: ## Security Best Practices
1633: 
1634: - Always run Snyk security scans for new first-party code in supported languages
1635: - Fix security issues found by Snyk before committing
1636: - Rescan after fixes to ensure issues are resolved
1637: - Repeat until no new issues are found
1638: - Never commit OpenLDAP passwords to version control - always use environment
1639: variables or GitHub Secrets
1640: - **IRSA (IAM Roles for Service Accounts)**:
1641:   - Pods assume IAM roles via OIDCno long-lived AWS credentials
1642:   - IAM roles scoped to specific service accounts and namespaces
1643:   - Required for SMS 2FA (SNS access)
1644: - **VPC Endpoints**:
1645:   - AWS service access (SSM, STS, SNS) goes through private endpointsno public
1646:   internet exposure
1647:   - STS endpoint required for IRSA
1648:   - SNS endpoint required for SMS 2FA
1649: - **Network Policies**:
1650:   - Pod-to-pod communication restricted to encrypted ports (443, 636, 8443)
1651:   - Cross-namespace access enabled only for LDAP service on secure ports
1652: - EBS volumes are encrypted by default
1653: - LDAP service is ClusterIP only (not exposed externally)
1654: - ALB uses HTTPS with ACM certificates (TLS 1.2/1.3 only)
1655: - 2FA application uses constant-time comparison for code verification
1656: - SMS codes expire after configurable timeout (default: 5 minutes)
1657: - Phone numbers validated in E.164 format
1658: - Phone numbers masked in API responses and logs
````

## File: application/README.md
````markdown
   1: # Application Infrastructure
   2: 
   3: This Terraform configuration deploys the OpenLDAP stack with PhpLdapAdmin and
   4: LTB-passwd UIs, plus a **full 2FA application** (backend + frontend) with LDAP
   5: authentication integration on the EKS cluster created by the backend
   6: infrastructure.
   7: 
   8: ## Overview
   9: 
  10: The application infrastructure provisions:
  11: 
  12: - **Route53 Hosted Zone** for domain management (can be in State Account)
  13: - **ACM Certificate** with DNS validation for HTTPS (public ACM certificate
  14:   requested in Deployment Account, validated via DNS records in State Account)
  15: - **Helm Release** for OpenLDAP Stack HA (High Availability)
  16: - **Application Load Balancer (ALB)** via EKS Auto Mode Ingress
  17: - **Persistent Storage** using EBS-backed PVCs
  18: - **Internet-Facing ALB** for UI access from the internet
  19: - **2FA Application** with Python FastAPI backend and static HTML/JS/CSS
  20: frontend
  21:   - Self-service user registration with email/phone verification
  22:   - Admin dashboard for user management and approval workflows
  23:   - User profile management with edit restrictions
  24: - **ArgoCD Capability** for GitOps deployments (AWS EKS managed service)
  25: - **cert-manager** module available (future improvement for automatic TLS
  26: certificate management)
  27: - **Network Policies** for securing pod-to-pod communication
  28: - **PostgreSQL** (Bitnami Helm chart, OCI registry) for user registration and
  29:   verification token storage
  30: - **Redis** for SMS OTP code storage with TTL-based expiration
  31: - **SES Integration** for email verification and notifications
  32: - **SNS Integration** for SMS-based 2FA verification (optional)
  33: 
  34: ## Architecture
  35: 
  36: ```ascii
  37: 
  38:                          EKS Cluster                               
  39:                                                                    
  40:     
  41:                       LDAP Namespace                             
  42:                                                                  
  43:              
  44:      OpenLDAP        PhpLdapAdmin        LTB-passwd        
  45:      StatefulSet     Deployment          Deployment        
  46:                                                            
  47:      ClusterIP       Ingress (ALB)       Ingress (ALB)     
  48:      (Internal)      (Internet)          (Internet)        
  49:              
  50:                                                                  
  51:                                                  
  52:      EBS PVC                                                   
  53:      (8Gi)                                                     
  54:                                                  
  55:     
  56:                                                                    
  57:     
  58:                      2FA App Namespace                           
  59:                                                                  
  60:                          
  61:      Backend                 Frontend                        
  62:      (FastAPI)               (nginx)                         
  63:                                                              
  64:      Ingress /api/*          Ingress /*                      
  65:                          
  66:                                                                 
  67:               LDAP Auth / User Data                             
  68:                                                                 
  69:                          
  70:      LDAP Service            PostgreSQL                      
  71:      (ClusterIP)             (User Data)                     
  72:                          
  73:                                                                  
  74:                          
  75:      Redis                   SNS/SES                         
  76:      (SMS OTP Cache)         (via IRSA)                      
  77:                          
  78:     
  79:                                                                    
  80:     
  81:                      ArgoCD (EKS Managed)                        
  82:                      GitOps Deployments                          
  83:     
  84:                                                                    
  85: 
  86:          
  87:          
  88:     
  89:       Internet-Facing ALB            
  90:       (HTTPS)                        
  91:       - phpldapadmin.domain          
  92:       - passwd.domain                
  93:       - app.domain (2FA App)         
  94:     
  95:          
  96:          
  97:     
  98:       Internet   
  99:       Access     
 100:     
 101: ```
 102: 
 103: ## Components
 104: 
 105: ### 1. Route53 Hosted Zone and ACM Certificate
 106: 
 107: > [!NOTE]
 108: >
 109: > The Route53 module (`modules/route53/`) exists but is currently
 110: > **commented out** in `main.tf`. The code uses **data sources** to reference
 111: > existing Route53 hosted zone and ACM certificate resources that must already
 112: > exist.
 113: >
 114: > **Cross-Account Access**: Route53 hosted zone and ACM certificate can be in
 115: > the State Account (different from deployment account). When
 116: > `state_account_role_arn` is configured, Terraform automatically queries these
 117: > resources from the State Account. See [Cross-Account Access
 118: > Documentation](./CROSS-ACCOUNT-ACCESS.md) for details.
 119: 
 120: **Current Implementation (Data Sources):**
 121: 
 122: The code references existing resources using data sources:
 123: 
 124: - **Route53 Hosted Zone**: Must already exist (referenced via
 125: `data.aws_route53_zone`)
 126: - **ACM Certificate**: Must already exist and be validated (referenced via
 127: `data.aws_acm_certificate`)
 128:   - Certificate must be a public ACM certificate (Amazon-issued) requested in
 129:     the Deployment Account
 130:   - Certificate must exist in the Deployment Account (not State Account)
 131:   - Certificate must be validated and in `ISSUED` status
 132:   - DNS validation records must be created in Route53 hosted zone in the State
 133:     Account
 134:   - See [Public ACM Certificate Setup and DNS Validation](./CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 135:     for setup instructions
 136: - The certificate must be in the same region as the EKS cluster
 137: 
 138: **Prerequisites:**
 139: 
 140: - Route53 hosted zone must be created beforehand (manually or via another
 141: Terraform configuration)
 142: - **Public ACM Certificate Setup**: Public ACM certificates must be requested in
 143:   each deployment account and validated using DNS records in the State Account's
 144:   Route53 hosted zone. See [Public ACM Certificate Setup and DNS Validation](./CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 145:   for detailed setup instructions with step-by-step AWS CLI commands.
 146: - ACM certificate must be requested in each deployment account (development,
 147:   production) as a public ACM certificate (Amazon-issued)
 148: - Certificate must be validated via DNS validation records created in Route53
 149:   hosted zone in the State Account
 150: - Certificate must be in `ISSUED` status
 151: - Certificate must be in the same region as the EKS cluster
 152: - Certificate must exist in the Deployment Account (not State Account)
 153: 
 154: **Outputs:**
 155: 
 156: Outputs come from data sources (not module outputs):
 157: 
 158: - `route53_acm_cert_arn`: ACM certificate ARN from data source (used by ALB)
 159: - `route53_domain_name`: Root domain name from variable
 160: - `route53_zone_id`: Route53 hosted zone ID from data source
 161: - `route53_name_servers`: Route53 name servers from data source (for registrar
 162: configuration)
 163: 
 164: **Alternative Approach:**
 165: 
 166: If you want to create Route53 zone and ACM certificate via Terraform, uncomment
 167: the Route53 module in `main.tf` (lines 43-53) and update the code to use module
 168: outputs instead of data sources.
 169: 
 170: ### 1a. Route53 Record Module
 171: 
 172: The `modules/route53_record/` module creates Route53 A (alias) records pointing
 173: to the ALB. This module is called separately for each subdomain (phpldapadmin,
 174: ltb_passwd, twofa_app) to create individual DNS records.
 175: 
 176: > [!NOTE]
 177: >
 178: > For detailed Route53 record module documentation, including cross-account
 179: > access, ALB zone_id mapping, dependencies, and usage examples, see the
 180: > [Route53 Record Module Documentation](modules/route53_record/README.md).
 181: 
 182: **Key Features:**
 183: 
 184: - **Cross-Account Support**: Uses state account provider to create records in
 185:   State Account while ALB is in Deployment Account
 186: - **ALB Alias Records**: Creates A (alias) records for optimal performance
 187: - **Health Check Integration**: Supports target health evaluation
 188: - **Precondition Validation**: Ensures ALB DNS name is available before record
 189:   creation
 190: - **Safe Updates**: Uses `create_before_destroy` lifecycle to prevent DNS
 191:   downtime
 192: 
 193: **Module Calls in main.tf:**
 194: 
 195: - `module.route53_record_phpldapadmin` - Creates A record for phpLDAPadmin
 196: - `module.route53_record_ltb_passwd` - Creates A record for ltb-passwd
 197: - `module.route53_record_twofa_app` - Creates A record for 2FA application
 198: 
 199: **Dependencies:**
 200: 
 201: - OpenLDAP module (ensures Ingress is created, which triggers ALB creation)
 202: - ALB data source (ensures ALB exists before creating record)
 203: 
 204: ### 2. OpenLDAP Stack HA Helm Release
 205: 
 206: Deploys the complete OpenLDAP stack using the
 207: [helm-openldap](https://github.com/jp-gouin/helm-openldap) Helm chart:
 208: 
 209: - **OpenLDAP StatefulSet**: Core LDAP server with EBS-backed persistent storage
 210: - **PhpLdapAdmin**: Web-based LDAP administration interface
 211: - **LTB-passwd**: Self-service password management UI
 212: - **Internal LDAP Service**: ClusterIP service (not exposed externally)
 213: 
 214: **Key Configuration:**
 215: 
 216: - Chart: `openldap-stack-ha` version `4.0.1`
 217: - Repository: `https://jp-gouin.github.io/helm-openldap`
 218: - Namespace: `ldap` (created automatically)
 219: - Storage: Creates a new PVC using a StorageClass created by this Terraform
 220: configuration (see Storage Configuration section below)
 221: - LDAP Ports: Standard ports (389 for LDAP, 636 for LDAPS)
 222: - **ECR Images**: Uses ECR images instead of Docker Hub (images mirrored via
 223:   `mirror-images-to-ecr.sh`)
 224:   - Image tags: `redis-latest`, `postgresql-latest`, `openldap-1.5.0`
 225: - **Route53 Records**: Route53 record creation has been moved to the dedicated
 226:   `route53_record` module (see Route53 Record Module section above)
 227: - **Helm Release Safety**: Comprehensive Helm release attributes (atomic,
 228:   force_update, replace, cleanup_on_fail, recreate_pods, wait, wait_for_jobs,
 229:   upgrade_install) for safer deployments
 230: 
 231: ### 3. 2FA Application (Backend + Frontend)
 232: 
 233: A full two-factor authentication application integrated with the LDAP
 234: infrastructure, featuring self-service user registration and admin management.
 235: 
 236: #### Key Features
 237: 
 238: | Feature | Description |
 239: | --------- | ------------- |
 240: | **Self-Service Registration** | User signup with email/phone verification |
 241: | **Email Verification** | UUID token-based verification via AWS SES |
 242: | **Phone Verification** | 6-digit OTP codes via AWS SNS |
 243: | **Profile Management** | User profile editing with verification restrictions |
 244: | **Admin Dashboard** | User management, group CRUD, approval workflows |
 245: | **MFA Methods** | TOTP (authenticator apps) and SMS verification |
 246: 
 247: #### Profile State Management
 248: 
 249: | State | Description |
 250: | ------- | ------------- |
 251: | **PENDING** | User registered, verification incomplete |
 252: | **COMPLETE** | All verifications complete, awaiting admin approval |
 253: | **ACTIVE** | Admin approved, user exists in LDAP |
 254: 
 255: #### MFA Methods Supported
 256: 
 257: | Method | Description | Infrastructure |
 258: | -------- | ------------- | ---------------- |
 259: | **TOTP** | Time-based One-Time Password using authenticator apps (Google Authenticator, Authy, etc.) | None (code generated locally) |
 260: | **SMS** | Verification codes sent via AWS SNS to user's phone | AWS SNS, VPC endpoints, IRSA |
 261: 
 262: #### Backend (Python FastAPI)
 263: 
 264: - **Location**: `backend/src/app/`
 265: - **Framework**: FastAPI with uvicorn
 266: - **Port**: 8000
 267: - **Features**:
 268:   - LDAP authentication (bind operation)
 269:   - TOTP secret generation and verification
 270:   - SMS verification code generation and sending
 271:   - QR code URI generation for authenticator apps
 272:   - MFA method selection and storage
 273:   - Self-service user registration
 274:   - Email/phone verification
 275:   - User profile management
 276:   - Admin functions (user management, group CRUD)
 277: 
 278: **API Endpoints:**
 279: 
 280: | Method | Endpoint | Description |
 281: | -------- | ---------- | ------------- |
 282: | `GET` | `/api/healthz` | Liveness/readiness probe |
 283: | `GET` | `/api/mfa/methods` | List available MFA methods |
 284: | `GET` | `/api/mfa/status/{username}` | Get user's MFA enrollment status |
 285: | `POST` | `/api/auth/enroll` | Enroll user for MFA (TOTP or SMS) |
 286: | `POST` | `/api/auth/login` | Validate LDAP credentials + verification code |
 287: | `POST` | `/api/auth/sms/send-code` | Send SMS verification code |
 288: | `POST` | `/api/auth/signup` | Register new user |
 289: | `POST` | `/api/auth/verify-email` | Verify email with token |
 290: | `POST` | `/api/auth/verify-phone` | Verify phone with code |
 291: | `POST` | `/api/auth/resend-verification` | Resend verification email/SMS |
 292: | `GET` | `/api/profile/{username}` | Get user profile |
 293: | `PUT` | `/api/profile/{username}` | Update user profile |
 294: | `GET` | `/api/admin/users` | List all users (admin only) |
 295: | `POST` | `/api/admin/users/{username}/approve` | Approve user (admin only) |
 296: | `POST` | `/api/admin/users/{username}/revoke` | Revoke user (admin only) |
 297: | `GET` | `/api/admin/groups` | List all groups (admin only) |
 298: | `POST` | `/api/admin/groups` | Create group (admin only) |
 299: | `PUT` | `/api/admin/groups/{group}` | Update group (admin only) |
 300: | `DELETE` | `/api/admin/groups/{group}` | Delete group (admin only) |
 301: 
 302: **API Documentation:**
 303: 
 304: FastAPI automatically generates interactive API documentation that is always
 305: available (not just in debug mode):
 306: 
 307: | Endpoint | Description |
 308: | ---------- | ------------- |
 309: | `GET` `/api/docs` | Swagger UI - Interactive API documentation and testing interface (always enabled) |
 310: | `GET` `/api/redoc` | ReDoc UI - Alternative API documentation interface (always enabled) |
 311: | `GET` `/api/openapi.json` | OpenAPI schema in JSON format |
 312: 
 313: Access the Swagger UI at `https://app.<domain>/api/docs` (e.g., `https://app.talorlik.com/api/docs`)
 314: to explore all available endpoints, view request/response schemas, and test API
 315: calls directly from the browser. The documentation automatically updates when
 316: API endpoints change.
 317: 
 318: #### Frontend (Static HTML/JS/CSS)
 319: 
 320: - **Location**: `frontend/src/`
 321: - **Server**: nginx
 322: - **Port**: 80
 323: - **Features**:
 324:   - Modern, responsive UI
 325:   - Self-service signup form with validation
 326:   - Email/phone verification status panel
 327:   - Enrollment flow with MFA method selection
 328:   - QR code rendering for TOTP setup
 329:   - Phone number input with E.164 validation
 330:   - SMS send button with countdown timer
 331:   - User profile page with edit functionality
 332:   - Admin dashboard for user/group management
 333:   - Top navigation bar with user menu
 334:   - Error handling and user feedback
 335: 
 336: #### Routing Pattern (Single Domain)
 337: 
 338: | Setting | Value |
 339: | --------- | ------- |
 340: | Public hostname | `app.<domain>` (e.g., `app.talorlik.com`) |
 341: | Frontend path | `/` |
 342: | Backend API path | `/api/*` |
 343: | DNS records needed | One A/ALIAS record |
 344: 
 345: ### 4. Application Load Balancer (ALB)
 346: 
 347: The ALB is automatically provisioned by EKS Auto Mode when Ingress resources are
 348: created with the appropriate annotations. The ALB provides:
 349: 
 350: - **Internet-Facing Access**: Accessible from the internet (`scheme: internet-facing`)
 351: - **HTTPS Only**: TLS termination at ALB using ACM certificate
 352: - **Target Type**: IP mode (direct pod targeting)
 353: - **Multiple Hostnames**: Single ALB handles all services via host-based routing
 354: 
 355: The ALB is created via Kubernetes Ingress resources using EKS Auto Mode
 356: (not AWS Load Balancer Controller). The `elastic_load_balancing` capability is
 357: **enabled by default** when EKS Auto Mode is enabled (configured in backend_infra
 358: via `compute_config.enabled = true`).
 359: 
 360: > [!NOTE]
 361: >
 362: > For detailed ALB configuration, annotation strategy, EKS Auto Mode vs
 363: > AWS Load Balancer Controller differences, and implementation details,
 364: > see the [ALB Module Documentation](modules/alb/README.md).
 365: 
 366: ### 5. Storage Configuration
 367: 
 368: Creates a StorageClass and the Helm chart creates a new PVC using that
 369: StorageClass:
 370: 
 371: - **StorageClass**: Created by this Terraform configuration
 372: (`kubernetes_storage_class_v1` resource)
 373:   - Name: `${prefix}-${region}-${storage_class_name}-${env}`
 374:   - Provisioner: `ebs.csi.eks.amazonaws.com`
 375:   - Volume binding mode: `WaitForFirstConsumer`
 376:   - Encryption: Configurable via `storage_class_encrypted` variable
 377:   - Volume type: Configurable via `storage_class_type` variable (gp2, gp3, io1,
 378:   io2, etc.)
 379:   - Can be set as default StorageClass via `storage_class_is_default` variable
 380: - **PVC**: Created by the Helm chart using the StorageClass
 381:   - **Storage Size**: 8Gi (configurable in Helm values)
 382:   - **Access Mode**: ReadWriteOnce
 383:   - The Helm chart creates a new PVC, it does not reuse an existing PVC from
 384:   backend infrastructure
 385: 
 386: ### 6. Network Policies
 387: 
 388: The `modules/network-policies/` module creates Kubernetes Network Policies to secure
 389: internal cluster communication, enforcing secure ports only (443, 636, 8443) and
 390: enabling cross-namespace communication for LDAP service access.
 391: 
 392: > [!NOTE]
 393: >
 394: > For detailed network policy rules, security configuration, and cross-namespace
 395: > communication setup, see the [Network Policies Module Documentation](modules/network-policies/README.md).
 396: 
 397: ### 7. ArgoCD Capability (GitOps)
 398: 
 399: The `modules/argocd/` module deploys the AWS EKS managed ArgoCD service for GitOps
 400: deployments, including IAM integration, Identity Center authentication, and
 401: cluster registration.
 402: 
 403: The `modules/argocd_app/` module creates ArgoCD Application CRDs for GitOps-driven
 404: deployments.
 405: 
 406: > [!NOTE]
 407: >
 408: > For detailed ArgoCD configuration, Identity Center setup, Application CRD creation,
 409: > and deployment examples, see:
 410: >
 411: > - [ArgoCD Module Documentation](modules/argocd/README.md)
 412: > - [ArgoCD Application Module Documentation](modules/argocd_app/README.md)
 413: 
 414: ### 8. cert-manager Module
 415: 
 416: > [!NOTE]
 417: >
 418: > **Current Status**: The cert-manager module exists in the codebase but is
 419: > **not currently used** by the OpenLDAP module. OpenLDAP currently uses auto-generated
 420: > self-signed certificates from the osixia/openldap image. Integrating cert-manager
 421: > for automatic TLS certificate management is a **future improvement** that
 422: > would provide:
 423: >
 424: > - Automatic certificate generation and renewal
 425: > - Better certificate lifecycle management
 426: > - Integration with Let's Encrypt or other certificate authorities
 427: > - Consistent certificate management across services
 428: >
 429: > For detailed cert-manager configuration, certificate management, and usage examples,
 430: > see the [cert-manager Module Documentation](modules/cert-manager/README.md).
 431: 
 432: ### 9. SNS Module (SMS 2FA)
 433: 
 434: The `modules/sns/` module creates AWS SNS resources for SMS-based 2FA verification,
 435: including SNS Topic, IAM Role (IRSA), direct SMS support, and cost control via
 436: monthly spend limits.
 437: 
 438: > [!NOTE]
 439: >
 440: > For detailed SNS configuration, IRSA setup, SMS sending methods, phone number
 441: > format requirements, and cost considerations, see the [SNS Module Documentation](modules/sns/README.md).
 442: 
 443: ### 10. PostgreSQL Module (User Data Storage)
 444: 
 445: The `modules/postgresql/` module deploys PostgreSQL for storing user registration
 446: and verification data using the Bitnami Helm chart with persistent EBS-backed storage.
 447: 
 448: **ECR Image Support:**
 449: 
 450: - Uses ECR images instead of Docker Hub (images mirrored via
 451:   `mirror-images-to-ecr.sh`)
 452: - Image tag: `postgresql-latest` (default, corresponds to
 453:   `bitnami/postgresql:18.1.0-debian-12-r4`)
 454: - ECR registry and repository computed from backend_infra state
 455: - PostgreSQL Helm chart uses OCI registry format (`oci://registry-1.docker.io/bitnamicharts`)
 456: 
 457: > [!NOTE]
 458: >
 459: > For detailed PostgreSQL configuration, connection strings, database schema,
 460: > ECR image setup, and usage examples, see the [PostgreSQL Module Documentation](modules/postgresql/README.md).
 461: 
 462: ### 11. SES Module (Email Verification)
 463: 
 464: The `modules/ses/` module configures AWS SES for sending verification emails,
 465: including email identity verification, DKIM setup, IRSA configuration, and optional
 466: Route53 integration.
 467: 
 468: > [!NOTE]
 469: >
 470: > For detailed SES configuration, email verification setup, IRSA configuration,
 471: > and usage examples, see the [SES Module Documentation](modules/ses/README.md).
 472: 
 473: ### 12. Redis Module (SMS OTP Storage)
 474: 
 475: The `modules/redis/` module deploys Redis for SMS OTP code storage using the
 476: Bitnami Helm chart with TTL-based expiration, shared state across replicas, and
 477: persistent storage.
 478: 
 479: **ECR Image Support:**
 480: 
 481: - Uses ECR images instead of Docker Hub (images mirrored via
 482:   `mirror-images-to-ecr.sh`)
 483: - Image tag: `redis-latest` (default, corresponds to
 484:   `bitnami/redis:8.4.0-debian-12-r6`)
 485: - ECR registry and repository computed from backend_infra state
 486: 
 487: > [!NOTE]
 488: >
 489: > For detailed Redis architecture, key schema, debugging commands, ECR image setup,
 490: > and configuration options, see the [Redis Module Documentation](modules/redis/README.md).
 491: 
 492: ## Module Structure
 493: 
 494: ```bash
 495: application/
 496:  main.tf                    # Main application configuration
 497:  variables.tf               # Variable definitions
 498:  variables.tfvars          # Variable values (customize for your environment)
 499:  outputs.tf                 # Output values
 500:  providers.tf               # Provider configuration (AWS, Kubernetes, Helm)
 501:  backend.hcl                # Terraform backend configuration template
 502:  tfstate-backend-values-template.hcl  # Backend state configuration template
 503:  CHANGELOG.md              # Change log for this module
 504:  setup-application.sh       # Application setup script
 505:  set-k8s-env.sh            # Kubernetes environment setup script
 506:  helm/
 507:     openldap-values.tpl.yaml  # OpenLDAP Helm values template
 508:     redis-values.tpl.yaml   # Redis Helm values template
 509:  backend/
 510:     src/
 511:        app/
 512:            main.py           # FastAPI application entry point
 513:            config.py         # Configuration management
 514:            api/
 515:               __init__.py
 516:               routes.py    # API route definitions
 517:            database/
 518:               __init__.py
 519:               connection.py # Database connection management
 520:               models.py    # Database models
 521:            email/
 522:               __init__.py
 523:               client.py     # Email client for SES integration
 524:            ldap/
 525:               __init__.py
 526:               client.py     # LDAP client for authentication
 527:            mfa/
 528:               __init__.py
 529:               totp.py      # TOTP secret generation/verification
 530:            redis/
 531:               __init__.py
 532:               client.py     # Redis client for OTP storage
 533:            sms/
 534:                __init__.py
 535:                client.py     # SMS client for SNS integration
 536:     src/
 537:        requirements.txt     # Python dependencies
 538:     helm/
 539:        ldap-2fa-backend/    # Backend Helm chart
 540:            Chart.yaml
 541:            values.yaml
 542:            templates/
 543:                _helpers.tpl
 544:                configmap.yaml
 545:                deployment.yaml
 546:                hpa.yaml
 547:                ingress.yaml
 548:                NOTES.txt
 549:                secret.yaml
 550:                service.yaml
 551:                serviceaccount.yaml
 552:                tests/
 553:                    test-connection.yaml
 554:     Dockerfile               # Backend container image
 555:  frontend/
 556:     src/
 557:        index.html          # Main HTML page
 558:        css/
 559:           styles.css      # Styling
 560:        js/
 561:            api.js          # API client
 562:            main.js         # Main application logic
 563:     helm/
 564:        ldap-2fa-frontend/  # Frontend Helm chart
 565:            Chart.yaml
 566:            values.yaml
 567:            templates/
 568:                _helpers.tpl
 569:                deployment.yaml
 570:                hpa.yaml
 571:                ingress.yaml
 572:                NOTES.txt
 573:                service.yaml
 574:                serviceaccount.yaml
 575:                tests/
 576:                    test-connection.yaml
 577:     nginx.conf              # nginx configuration
 578:     Dockerfile              # Frontend container image
 579:  modules/
 580:     alb/                    # ALB module - creates IngressClass and IngressClassParams for EKS Auto Mode
 581:        main.tf
 582:        variables.tf
 583:        outputs.tf
 584:        README.md
 585:     argocd/                 # ArgoCD Capability module - deploys managed ArgoCD
 586:        main.tf
 587:        variables.tf
 588:        outputs.tf
 589:        README.md
 590:     argocd_app/             # ArgoCD Application module - creates Application CRDs
 591:        main.tf
 592:        variables.tf
 593:        outputs.tf
 594:        README.md
 595:     cert-manager/           # cert-manager module - TLS certificate management
 596:        main.tf
 597:        variables.tf
 598:        outputs.tf
 599:        README.md
 600:     network-policies/       # Network Policies module - secures pod-to-pod communication
 601:        main.tf
 602:        variables.tf
 603:        outputs.tf
 604:        README.md
 605:     openldap/               # OpenLDAP module - LDAP directory service deployment
 606:        main.tf
 607:        variables.tf
 608:        outputs.tf
 609:        README.md
 610:     postgresql/             # PostgreSQL module - User data storage
 611:        main.tf
 612:        variables.tf
 613:        outputs.tf
 614:        README.md
 615:     redis/                  # Redis module - SMS OTP storage
 616:        main.tf
 617:        variables.tf
 618:        outputs.tf
 619:        README.md
 620:     route53/                # Route53 module - hosted zone and DNS management
 621:        main.tf
 622:        variables.tf
 623:        outputs.tf
 624:     route53_record/         # Route53 Record module - A (alias) records for ALB
 625:        main.tf
 626:        variables.tf
 627:        outputs.tf
 628:        providers.tf
 629:        README.md
 630:     ses/                    # SES module - Email verification
 631:        main.tf
 632:        variables.tf
 633:        outputs.tf
 634:        README.md
 635:     sns/                    # SNS module - SMS 2FA verification
 636:         main.tf
 637:         variables.tf
 638:         outputs.tf
 639:         README.md
 640:  PRD-2FA-APP.md              # 2FA Application Product Requirements Document
 641:  PRD-ADMIN-FUNCS.md          # Admin Functions and Profile Management PRD
 642:  PRD-ALB.md                  # ALB configuration PRD
 643:  PRD-ArgoCD.md               # ArgoCD configuration PRD
 644:  PRD-DOMAIN.md               # Domain configuration PRD
 645:  PRD-SIGNUP-MAN.md           # User Signup Management PRD
 646:  PRD-SMS-MAN.md              # SMS OTP Management with Redis PRD
 647:  PRD.md                      # Main PRD
 648:  OPENLDAP-README.md          # OpenLDAP deployment documentation
 649:  OSIXIA-OPENLDAP-REQUIREMENTS.md  # OpenLDAP requirements documentation
 650:  SECURITY-IMPROVEMENTS.md   # Security improvements documentation
 651:  CROSS-ACCOUNT-ACCESS.md    # Cross-account Route53/ACM access documentation
 652:  README.md                   # This file
 653: ```
 654: 
 655: ## Prerequisites
 656: 
 657: 1. **Backend Infrastructure**: The backend infrastructure must be deployed first
 658: (see [backend_infra/README.md](../backend_infra/README.md))
 659: 2. **Multi-Account Setup**:
 660:    - **Account A (State Account)**: Stores Terraform state in S3, Route53
 661:      hosted zones, and ACM certificates
 662:    - **Account B (Deployment Account)**: Contains application resources (EKS,
 663:      ALB, etc.)
 664:    - Route53 hosted zone and ACM certificate can be in State Account
 665:      (accessed via `state_account_role_arn`)
 666:    - Route53 records are created in State Account while ALB is deployed in
 667:      Deployment Account
 668:    - ALB in Deployment Account can use ACM certificate from State Account
 669:      (same region required)
 670:    - GitHub Actions uses Account A role for backend access and Route53/ACM
 671:      access
 672:    - Terraform provider assumes Account B role for resource deployment
 673:    - See [Cross-Account Access Documentation](./CROSS-ACCOUNT-ACCESS.md) for
 674:      details
 675: 3. **AWS SSO/OIDC**: Configured GitHub OIDC provider and IAM roles (see main
 676: [README.md](../README.md))
 677: 4. **EKS Cluster**: The EKS cluster must be running with Auto Mode enabled
 678: 5. **Route53 Hosted Zone**: Must already exist (the Route53 module is commented
 679: out, code uses data sources)
 680: 6. **Public ACM Certificate Setup**: Public ACM certificates must be requested in
 681:    each deployment account and validated using DNS records in the State Account's
 682:    Route53 hosted zone
 683:    - See [Public ACM Certificate Setup and DNS Validation](./CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 684:      for detailed setup instructions with step-by-step AWS CLI commands
 685:    - Each deployment account (development, production) has its own public ACM
 686:      certificate
 687:    - Certificates are automatically renewed by ACM
 688: 7. **ACM Certificate**: Must already exist and be validated in the same region
 689:    as the EKS cluster
 690:    - Certificate must be a public ACM certificate (Amazon-issued) requested in
 691:      the Deployment Account
 692:    - Certificate must exist in the Deployment Account (not State Account)
 693:    - Certificate must be validated and in `ISSUED` status
 694:    - DNS validation records must be created in Route53 hosted zone in the State
 695:      Account
 696:    - See [Cross-Account Access Documentation](./CROSS-ACCOUNT-ACCESS.md) for
 697:      details
 698: 8. **Domain Registration**: The domain name must be registered (can be with any
 699: registrar)
 700: 9. **DNS Configuration**: After deployment, point your domain registrar's NS
 701: records to the Route53 name servers (output from data source)
 702: 10. **Environment Variables**: OpenLDAP passwords must be set via environment
 703: variables (see Configuration section)
 704: 11. **AWS Identity Center**: Required for ArgoCD RBAC configuration
 705: 12. **VPC Endpoints (for SMS 2FA)**: STS and SNS endpoints must be enabled in
 706: backend_infra
 707: 13. **Secrets Configuration**: All required secrets must be configured.
 708: See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for complete setup instructions.
 709: 14. **Docker (for Local Deployment)**: Docker must be installed and running for
 710: ECR image mirroring. The `mirror-images-to-ecr.sh` script requires Docker to
 711: pull images from Docker Hub and push them to ECR.
 712: 15. **jq (for Local Deployment)**: The `jq` command-line tool is required for
 713: JSON parsing in the image mirroring script (with fallback to sed for
 714: compatibility).
 715: 
 716: ## Configuration
 717: 
 718: ### Required Variables
 719: 
 720: #### Core Variables
 721: 
 722: - `env`: Deployment environment (prod, dev)
 723: - `region`: AWS region (must match backend infrastructure)
 724: - `prefix`: Prefix for resource names (must match backend infrastructure)
 725: - `cluster_name`: **Automatically retrieved** from backend_infra remote state
 726: (see Cluster Name section below)
 727: - `deployment_account_role_arn`: (Optional, for GitHub Actions) ARN of IAM role
 728: in Account B to assume for resource deployment
 729:   - Automatically injected by GitHub workflows
 730:   - Required when using multi-account setup
 731:   - Format: `arn:aws:iam::ACCOUNT_B_ID:role/github-actions-deployment-role`
 732: - `deployment_account_external_id`: (Optional, for security) ExternalId for
 733: cross-account role assumption
 734:   - Automatically retrieved from AWS Secrets Manager (secret: `external-id`) for
 735:   local deployment
 736:   - Automatically retrieved from GitHub secret (`AWS_ASSUME_EXTERNAL_ID`) for
 737:   GitHub Actions
 738:   - Required when deployment account roles have ExternalId condition in Trust Relationship
 739:   - Must match the ExternalId configured in the deployment account role's
 740:   Trust Relationship
 741:   - Generated using: `openssl rand -hex 32`
 742: - `state_account_role_arn`: (Optional) ARN of IAM role in State Account for
 743:   Route53/ACM access
 744:   - Automatically injected by `setup-application.sh` and `set-k8s-env.sh`
 745:     scripts
 746:   - Automatically injected by GitHub workflows
 747:   - Required when Route53 hosted zone and ACM certificate are in a different account
 748:   - Format: `arn:aws:iam::STATE_ACCOUNT_ID:role/terraform-state-role`
 749:   - See [Cross-Account Access Documentation](./CROSS-ACCOUNT-ACCESS.md) for details
 750: 
 751: #### Cluster Name Injection
 752: 
 753: The cluster name is automatically retrieved using a fallback chain:
 754: 
 755: 1. **First**: Attempts to retrieve from `backend_infra` Terraform remote state
 756: (if `backend.hcl` exists)
 757: 2. **Second**: Uses `cluster_name` variable if provided in `variables.tfvars`
 758: 3. **Third**: Calculates cluster name using pattern:
 759: `${prefix}-${region}-${cluster_name_component}-${env}`
 760: 
 761: The backend configuration (bucket, key, region) is read from `backend.hcl`
 762: (created by `setup-application.sh`).
 763: 
 764: If `backend.hcl` doesn't exist or remote state is not available, you can provide
 765: the cluster name directly in `variables.tfvars`:
 766: 
 767: ```hcl
 768: cluster_name = "talo-tf-us-east-1-kc-prod"
 769: ```
 770: 
 771: #### Kubernetes Kubeconfig Auto-Update
 772: 
 773: The `set-k8s-env.sh` script automatically updates the kubeconfig file on every
 774: run to ensure it always contains the latest cluster endpoint. This prevents issues
 775: with stale kubeconfig entries that can occur when:
 776: 
 777: - The EKS cluster is recreated (new cluster endpoint)
 778: - The cluster endpoint changes due to AWS infrastructure updates
 779: - Kubeconfig becomes stale between deployment runs
 780: 
 781: **Behavior**:
 782: 
 783: - **Automatic Update**: The script runs `aws eks update-kubeconfig` on every execution
 784: - **Uses Deployment Account Credentials**: The update uses the deployment account
 785: role credentials (already assumed by the script)
 786: - **Creates Directory if Needed**: Automatically creates the kubeconfig directory
 787: if it doesn't exist
 788: - **Error Handling**: Script exits with error if kubeconfig update fails
 789: 
 790: **Kubeconfig Path**:
 791: 
 792: - Default: `~/.kube/config`
 793: - Can be overridden via `KUBE_CONFIG_PATH` environment variable
 794: - Path is exported as `KUBE_CONFIG_PATH` for use by Terraform and kubectl commands
 795: 
 796: This ensures that all `kubectl` commands (including those executed by Terraform
 797: provisioners) use the current cluster endpoint, preventing DNS lookup errors.
 798: 
 799: #### OpenLDAP Passwords (Environment Variables)
 800: 
 801: > [!IMPORTANT]
 802: >
 803: > Passwords must be set via environment variables, NOT in `variables.tfvars`.
 804: 
 805: The `setup-application.sh` script automatically retrieves these passwords from
 806: AWS Secrets Manager (for local use) or GitHub repository secrets (for GitHub Actions)
 807: and exports them as environment variables for Terraform.
 808: 
 809: > [!NOTE]
 810: >
 811: > For complete secrets configuration details, including AWS Secrets Manager setup,
 812: > GitHub repository secrets, and troubleshooting, see [Secrets Requirements](../SECRETS_REQUIREMENTS.md).
 813: 
 814: #### Route53 and Domain Variables
 815: 
 816: - `domain_name`: Root domain name for Route53 hosted zone and ACM certificate
 817: (e.g., `talorlik.com`)
 818:   - The Route53 hosted zone and ACM certificate must already exist (code uses
 819:   data sources)
 820:   - The ACM certificate should cover the domain and any subdomains you plan to
 821:   use
 822: 
 823: > [!NOTE]
 824: >
 825: > Hostnames for all services can be configured via variables or are
 826: > automatically derived:
 827: >
 828: > - PhpLdapAdmin: `phpldapadmin.${domain_name}` (or set `phpldapadmin_host` variable)
 829: > - LTB-passwd: `passwd.${domain_name}` (or set `ltb_passwd_host` variable)
 830: > - 2FA App: `app.${domain_name}` (or set `app_host` variable)
 831: 
 832: #### Other OpenLDAP Variables
 833: 
 834: - `openldap_ldap_domain`: LDAP domain (e.g., `ldap.talorlik.internal`)
 835: 
 836: #### ALB Variables
 837: 
 838: - `use_alb`: Whether to create ALB resources (default: `true`)
 839: - `ingressclass_alb_name`: Name component for ingress class (required if
 840: `use_alb` is true)
 841: - `ingressclassparams_alb_name`: Name component for ingress class params
 842: (required if `use_alb` is true)
 843: - `alb_group_name`: ALB group name for grouping multiple Ingresses (optional,
 844: defaults to `app_name`)
 845:   - Kubernetes identifier (max 63 characters)
 846:   - Used to group multiple Ingresses to share a single ALB
 847:   - Configured in IngressClassParams (cluster-wide)
 848: - `alb_load_balancer_name`: Custom AWS ALB name (optional, defaults to
 849: `alb_group_name` truncated to 32 chars)
 850:   - AWS resource name (max 32 characters per AWS constraints)
 851:   - Appears in AWS console
 852:   - Configured in Ingress annotations (per-Ingress)
 853: - `alb_scheme`: ALB scheme - `internet-facing` or `internal` (default:
 854: `internet-facing`)
 855: - `alb_ip_address_type`: ALB IP address type - `ipv4` or `dualstack` (default:
 856: `ipv4`)
 857: - `alb_target_type`: ALB target type - `ip` or `instance` (default: `ip`)
 858: - `alb_ssl_policy`: ALB SSL policy for HTTPS listeners (default:
 859: `ELBSecurityPolicy-TLS13-1-0-PQ-2025-09`)
 860: - `phpldapadmin_host`: Hostname for PhpLdapAdmin ingress (optional, defaults to
 861: `phpldapadmin.${domain_name}`)
 862: - `ltb_passwd_host`: Hostname for LTB-passwd ingress (optional, defaults to
 863: `passwd.${domain_name}`)
 864: 
 865: #### Storage Variables
 866: 
 867: - `storage_class_name`: Name component for the StorageClass (e.g., `gp3-ldap`)
 868: - `storage_class_type`: EBS volume type (gp2, gp3, io1, io2, etc.)
 869: - `storage_class_encrypted`: Whether to encrypt EBS volumes (default: `true`)
 870: - `storage_class_is_default`: Whether to mark StorageClass as default (default:
 871: `false`)
 872: 
 873: #### ArgoCD Variables
 874: 
 875: - `enable_argocd`: Whether to enable ArgoCD capability (default: `false`)
 876: - `idc_instance_arn`: ARN of the AWS Identity Center instance
 877: - `idc_region`: Region of the Identity Center instance
 878: - `rbac_role_mappings`: List of RBAC role mappings for Identity Center
 879: - `argocd_vpce_ids`: List of VPC endpoint IDs for private access (optional)
 880: - `enable_ecr_access`: Whether to enable ECR access in ArgoCD IAM policy
 881: 
 882: #### SNS (SMS 2FA) Variables
 883: 
 884: - `enable_sms_2fa`: Enable SMS 2FA resources (default: `false`)
 885: - `sns_topic_name`: SNS topic name component (default: `2fa-sms`)
 886: - `sns_display_name`: SMS sender display name (default: `2FA Verification`)
 887: - `sms_sender_id`: SMS sender ID (max 11 chars, default: `2FA`)
 888: - `sms_type`: SMS type - `Transactional` or `Promotional` (default:
 889: `Transactional`)
 890: - `sms_monthly_spend_limit`: Monthly SMS budget (default: `10`)
 891: 
 892: #### PostgreSQL Variables
 893: 
 894: - `enable_postgresql`: Enable PostgreSQL deployment (default: `true`)
 895: - `postgresql_namespace`: Kubernetes namespace (default: `ldap-2fa`)
 896: - `postgresql_database_name`: Database name (default: `ldap2fa`)
 897: - `postgresql_database_username`: Database username (default: `ldap2fa`)
 898: - `postgresql_storage_size`: Storage size for PVC (default: `8Gi`)
 899: 
 900: > [!IMPORTANT]
 901: >
 902: > PostgreSQL password must be set via environment variable `TF_VAR_postgresql_database_password`.
 903: > See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for configuration details.
 904: 
 905: #### SES Variables
 906: 
 907: - `enable_ses`: Enable SES email resources (default: `true`)
 908: - `ses_sender_email`: Verified sender email address
 909: (set in `variables.tfvars`, default: `"noreply@example.com"`)
 910: - `ses_sender_domain`: Optional domain to verify (for DKIM)
 911: - `ses_route53_zone_id`: Optional Route53 zone ID for automatic DNS records
 912: 
 913: #### Redis Variables
 914: 
 915: - `enable_redis`: Enable Redis deployment (default: `true`)
 916: - `redis_namespace`: Kubernetes namespace (default: `redis`)
 917: - `redis_storage_size`: Storage size for PVC (default: `1Gi`)
 918: - `redis_persistence_enabled`: Enable data persistence (default: `true`)
 919: 
 920: > [!IMPORTANT]
 921: >
 922: > Redis password must be set via environment variable `TF_VAR_redis_password`
 923: > (minimum 8 characters). See [Secrets Requirements](../SECRETS_REQUIREMENTS.md)
 924: > for configuration details.
 925: 
 926: #### ECR Image Tag Variables
 927: 
 928: These variables specify the image tags for container images stored in ECR. The
 929: images are automatically mirrored from Docker Hub to ECR by the
 930: `mirror-images-to-ecr.sh` script before Terraform operations.
 931: 
 932: - `openldap_image_tag`: OpenLDAP image tag in ECR (default: `"openldap-1.5.0"`)
 933:   - Corresponds to `osixia/openldap:1.5.0` from Docker Hub
 934:   - Tag created by `mirror-images-to-ecr.sh`
 935: - `postgresql_image_tag`: PostgreSQL image tag in ECR (default: `"postgresql-latest"`)
 936:   - Corresponds to `bitnami/postgresql:18.1.0-debian-12-r4` from Docker Hub
 937:   - Tag created by `mirror-images-to-ecr.sh`
 938:   - Uses 'latest' tag instead of SHA digests for simplified image management
 939: - `redis_image_tag`: Redis image tag in ECR (default: `"redis-latest"`)
 940:   - Corresponds to `bitnami/redis:8.4.0-debian-12-r6` from Docker Hub
 941:   - Tag created by `mirror-images-to-ecr.sh`
 942:   - Uses 'latest' tag instead of SHA digests for simplified image management
 943: 
 944: > [!NOTE]
 945: >
 946: > The ECR registry and repository are automatically computed from the
 947: > `backend_infra` Terraform state (`ecr_url`). You don't need to configure these
 948: > manually.
 949: 
 950: ### Example Configuration
 951: 
 952: **variables.tfvars:**
 953: 
 954: ```hcl
 955: env                         = "prod"
 956: region                      = "us-east-1"
 957: prefix                      = "talo-tf"
 958: 
 959: # Cluster name from remote state
 960: backend_bucket = "talo-tf-395323424870-s3-tfstate"
 961: backend_key    = "backend_state/terraform.tfstate"
 962: 
 963: # OpenLDAP Configuration
 964: # Passwords set via environment variables (see above)
 965: openldap_ldap_domain        = "ldap.talorlik.internal"
 966: 
 967: # Route53 and Domain Configuration
 968: domain_name                 = "talorlik.com"
 969: # Note: Route53 zone and ACM certificate must already exist
 970: # The ACM certificate should cover the domain and wildcard subdomains (*.talorlik.com)
 971: 
 972: # ArgoCD Configuration (optional)
 973: enable_argocd               = true
 974: idc_instance_arn            = "arn:aws:sso:::instance/ssoins-1234567890abcdef"
 975: idc_region                  = "us-east-1"
 976: 
 977: # SMS 2FA Configuration (optional)
 978: enable_sms_2fa              = true
 979: sms_monthly_spend_limit     = 50
 980: 
 981: # PostgreSQL Configuration
 982: enable_postgresql           = true
 983: postgresql_storage_size     = "10Gi"
 984: 
 985: # Redis Configuration
 986: enable_redis                = true
 987: redis_storage_size          = "1Gi"
 988: 
 989: # SES Configuration
 990: enable_ses                  = true
 991: ```
 992: 
 993: > [!NOTE]
 994: >
 995: > For secrets configuration (passwords), see [Secrets Requirements](../SECRETS_REQUIREMENTS.md).
 996: > The `setup-application.sh` script automatically retrieves passwords from
 997: > AWS Secrets Manager.
 998: 
 999: ## Deployment
1000: 
1001: ### Destroying Infrastructure
1002: 
1003: > [!WARNING]
1004: >
1005: > Destroying infrastructure is a **destructive operation** that permanently
1006: > deletes all resources. This action **cannot be undone**. Always ensure you have
1007: > backups and understand the consequences before proceeding.
1008: 
1009: #### Option 1: Using Destroy Script (Local)
1010: 
1011: ```bash
1012: cd application
1013: ./destroy-application.sh
1014: ```
1015: 
1016: The script will:
1017: 
1018: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
1019: - Retrieve repository variables from GitHub
1020: - Retrieve role ARNs and ExternalId from AWS Secrets Manager
1021: - Retrieve password secrets from AWS Secrets Manager
1022: - Generate `backend.hcl` from template (if it doesn't exist)
1023: - Update `variables.tfvars` with selected region, environment, deployment account
1024:   role ARN, and ExternalId
1025: - Set Kubernetes environment variables using `set-k8s-env.sh`
1026: - Run Terraform destroy commands (init, workspace, validate, plan destroy, apply
1027:   destroy) automatically
1028: - **Requires confirmation**: Type 'yes' to confirm, then 'DESTROY' to proceed
1029: 
1030: #### Option 2: Using GitHub Actions Workflow
1031: 
1032: 1. Go to GitHub  Actions tab
1033: 2. Select "Application Infrastructure Destroying" workflow
1034: 3. Click "Run workflow"
1035: 4. Select environment (prod or dev) and region
1036: 5. Click "Run workflow"
1037: 
1038: The workflow will:
1039: 
1040: - Use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations and
1041:   Route53/ACM access
1042: - Use environment-specific deployment account role ARN
1043: - Use `AWS_ASSUME_EXTERNAL_ID` for cross-account role assumption
1044: - Export `STATE_ACCOUNT_ROLE_ARN` for automatic injection into `variables.tfvars`
1045: - Retrieve password secrets from GitHub repository secrets
1046: - Run Terraform destroy operations automatically
1047: 
1048: > [!IMPORTANT]
1049: >
1050: > **Destroy Order**: Application infrastructure should be destroyed before backend
1051: > infrastructure. See [Backend Infrastructure README](../backend_infra/README.md)
1052: > for backend destroy instructions.
1053: 
1054: ### Step 1: Configure Variables
1055: 
1056: 1. Update `variables.tfvars` with your values:
1057:    - Configure LDAP domain
1058:    - Set domain name (must match existing Route53 hosted zone)
1059:    - Ensure ACM certificate exists and covers your domain/subdomains
1060:    - Configure ArgoCD settings if using GitOps
1061:    - Configure SMS 2FA settings if using SMS verification
1062: 
1063: ### Step 2: Configure Secrets
1064: 
1065: > [!NOTE]
1066: >
1067: > The `setup-application.sh` script automatically retrieves passwords from
1068: > AWS Secrets Manager (for local use) or GitHub repository secrets (for GitHub Actions).
1069: 
1070: **Setup Instructions:**
1071: 
1072: See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for complete configuration
1073: instructions, including:
1074: 
1075: - AWS Secrets Manager setup (for local scripts)
1076: - GitHub Repository Secrets setup (for GitHub Actions)
1077: - Secret names and descriptions
1078: - Troubleshooting guide
1079: 
1080: ### Step 3: ECR Image Mirroring (Automatic)
1081: 
1082: > [!NOTE]
1083: >
1084: > The `setup-application.sh` script automatically runs `mirror-images-to-ecr.sh`
1085: > before Terraform operations. This step is documented here for reference.
1086: 
1087: **Purpose:**
1088: 
1089: The `mirror-images-to-ecr.sh` script eliminates Docker Hub rate limiting and
1090: external dependencies by mirroring third-party container images to a private
1091: ECR repository. This ensures reliable deployments without depending on Docker
1092: Hub availability or rate limits.
1093: 
1094: **Images Mirrored:**
1095: 
1096: - `bitnami/redis:8.4.0-debian-12-r6`  `redis-latest`
1097: - `bitnami/postgresql:18.1.0-debian-12-r4`  `postgresql-latest`
1098: - `osixia/openldap:1.5.0`  `openldap-1.5.0`
1099: 
1100: **How It Works:**
1101: 
1102: 1. **ECR Discovery**: Uses State Account credentials to fetch ECR URL from
1103:    `backend_infra` Terraform state
1104: 2. **Image Check**: Checks if images already exist in ECR (skips mirroring if
1105:    present)
1106: 3. **Docker Authentication**: Assumes Deployment Account role (with ExternalId)
1107:    and authenticates Docker to ECR
1108: 4. **Image Pull**: Pulls images from Docker Hub
1109: 5. **Image Push**: Tags and pushes images to ECR with standardized tags
1110: 6. **Cleanup**: Removes local images after pushing to save disk space
1111: 7. **Verification**: Lists all images in ECR repository after completion
1112: 
1113: **Requirements:**
1114: 
1115: - Docker must be installed and running
1116: - `jq` command-line tool (with fallback to sed for compatibility)
1117: - AWS credentials configured (State Account for S3, Deployment Account for ECR)
1118: - ECR repository must exist (created by `backend_infra`)
1119: 
1120: **Manual Execution (if needed):**
1121: 
1122: ```bash
1123: cd application
1124: chmod +x ./mirror-images-to-ecr.sh
1125: ./mirror-images-to-ecr.sh
1126: ```
1127: 
1128: **Integration:**
1129: 
1130: - **Local Deployment**: Automatically executed by `setup-application.sh` before
1131:   Terraform operations
1132: - **GitHub Actions**: Automatically executed in workflow after Terraform
1133:   validate, before `set-k8s-env.sh`
1134: 
1135: ### Step 4: Deploy Application Infrastructure
1136: 
1137: #### Option 1: Using GitHub CLI (Recommended)
1138: 
1139: ```bash
1140: cd application
1141: ./setup-application.sh
1142: ```
1143: 
1144: This script will:
1145: 
1146: - Prompt you to select an AWS region (us-east-1 or us-east-2)
1147: - Prompt you to select an environment (prod or dev)
1148: - Retrieve repository variables from GitHub
1149: - Retrieve `AWS_STATE_ACCOUNT_ROLE_ARN` and assume it for backend state and
1150:   Route53/ACM access
1151: operations
1152: - Retrieve the appropriate deployment account role ARN from AWS Secrets Manager
1153: based on the selected environment:
1154:   - `prod`  uses `AWS_PRODUCTION_ACCOUNT_ROLE_ARN`
1155:   - `dev`  uses `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
1156: - Retrieve ExternalId from AWS Secrets Manager (secret: `external-id`) for
1157: cross-account role assumption security
1158: - **Mirror Docker images to ECR** (runs `mirror-images-to-ecr.sh` before
1159:   Terraform operations):
1160:   - Checks if images exist in ECR before mirroring (skips if already present)
1161:   - Pulls images from Docker Hub: `bitnami/redis:8.4.0-debian-12-r6`,
1162:     `bitnami/postgresql:18.1.0-debian-12-r4`, `osixia/openldap:1.5.0`
1163:   - Pushes images to ECR with tags: `redis-latest`, `postgresql-latest`,
1164:     `openldap-1.5.0`
1165:   - Uses State Account credentials to fetch ECR URL from backend_infra state
1166:   - Assumes Deployment Account role for ECR operations (with ExternalId)
1167:   - Authenticates Docker to ECR automatically
1168:   - Cleans up local images after pushing to save disk space
1169:   - Requires Docker to be installed and running
1170:   - Requires `jq` for JSON parsing (with fallback to sed for compatibility)
1171: - Retrieve password secrets from AWS Secrets Manager and export them as
1172: environment variables
1173: - Create `backend.hcl` from `tfstate-backend-values-template.hcl` with the
1174: actual values (if it doesn't exist)
1175: - Update `variables.tfvars` with the selected region, environment,
1176: deployment account role ARN, and ExternalId
1177: - Set Kubernetes environment variables using `set-k8s-env.sh`
1178: - Run Terraform commands (init, workspace, validate, plan, apply) automatically
1179: 
1180: > [!NOTE]
1181: >
1182: > The generated `backend.hcl` file is automatically ignored by git (see
1183: > `.gitignore`). Only the placeholder template
1184: > (`tfstate-backend-values-template.hcl`) is committed to the repository.
1185: 
1186: ### Step 4: Configure Domain Registrar
1187: 
1188: After deployment, configure your domain registrar to use the Route53 name
1189: servers:
1190: 
1191: ```bash
1192: # Get Route53 name servers
1193: terraform output -json | jq -r '.route53_name_servers.value'
1194: 
1195: # Or view in AWS Console: Route53 > Hosted zones > Your domain > NS record
1196: ```
1197: 
1198: Update your domain registrar's NS records to point to these Route53 name
1199: servers.
1200: 
1201: ### Step 5: Verify Deployment
1202: 
1203: ```bash
1204: # Check Helm release status
1205: helm list -n ldap
1206: helm list -n redis
1207: helm list -n ldap-2fa
1208: 
1209: # Check OpenLDAP pods
1210: kubectl get pods -n ldap
1211: 
1212: # Check 2FA application pods
1213: kubectl get pods -n 2fa-app
1214: 
1215: # Check PostgreSQL pods
1216: kubectl get pods -n ldap-2fa
1217: 
1218: # Check Redis pods
1219: kubectl get pods -n redis
1220: 
1221: # Check Ingress resources
1222: kubectl get ingress -n ldap
1223: kubectl get ingress -n 2fa-app
1224: 
1225: # Check ALB status (via AWS CLI)
1226: aws elbv2 describe-load-balancers --region us-east-1
1227: 
1228: # Check Route53 hosted zone
1229: aws route53 list-hosted-zones --query "HostedZones[?Name=='talorlik.com.']"
1230: 
1231: # Check ACM certificate status
1232: aws acm list-certificates --region us-east-1
1233: 
1234: # Check ArgoCD capability (if enabled)
1235: aws eks describe-capability \
1236:   --cluster-name <cluster-name> \
1237:   --capability-name <argocd-capability-name> \
1238:   --capability-type ARGOCD
1239: 
1240: # Check ArgoCD applications
1241: kubectl get application -n argocd
1242: ```
1243: 
1244: ## Accessing the Services
1245: 
1246: ### PhpLdapAdmin
1247: 
1248: - **URL**: `https://phpldapadmin.${domain_name}` (e.g.,
1249: `https://phpldapadmin.talorlik.com`)
1250: - **Access**: Internet-facing (via internet-facing ALB)
1251: - **Login**: Use OpenLDAP admin credentials
1252: - **Note**: Ensure DNS is properly configured at your registrar
1253: 
1254: ### LTB-passwd
1255: 
1256: - **URL**: `https://passwd.${domain_name}` (e.g., `https://passwd.talorlik.com`)
1257: - **Access**: Internet-facing (via internet-facing ALB)
1258: - **Purpose**: Self-service password management for LDAP users
1259: - **Note**: Ensure DNS is properly configured at your registrar
1260: 
1261: ### 2FA Application
1262: 
1263: - **URL**: `https://app.${domain_name}` (e.g., `https://app.talorlik.com`)
1264: - **Access**: Internet-facing (via internet-facing ALB)
1265: - **Purpose**: Two-factor authentication, user registration, and management
1266: - **Features**:
1267:   - Self-service user registration
1268:   - Email verification (click link in email)
1269:   - Phone verification (enter 6-digit SMS code)
1270:   - TOTP enrollment with QR code
1271:   - SMS enrollment with phone number verification
1272:   - Login with LDAP credentials + verification code
1273:   - User profile management
1274:   - Admin dashboard (visible to LDAP admin group members only):
1275:     - User list with filtering and sorting
1276:     - Approve/revoke users
1277:     - Group CRUD operations
1278:     - User-group assignment
1279: 
1280: ### LDAP Service
1281: 
1282: - **Access**: Cluster-internal only (ClusterIP service)
1283: - **Port**: 389 (LDAP), 636 (LDAPS)
1284: - **Not Exposed**: LDAP ports are not accessible outside the cluster
1285: 
1286: ### ArgoCD (if enabled)
1287: 
1288: - **URL**: Retrieved from Terraform output `argocd_server_url`
1289: - **Access**: Depends on configuration (private via VPC endpoints or
1290: internet-facing)
1291: - **Authentication**: AWS Identity Center (SSO)
1292: 
1293: ## Security Considerations
1294: 
1295: 1. **Internet-Facing ALB**: All UIs are accessible from the internet via a
1296: single ALB with host-based routing (ensure proper security measures are in
1297: place)
1298: 2. **HTTPS Only**: TLS termination at ALB with ACM certificate (automatically
1299: validated via Route53)
1300: 3. **LDAP Internal**: LDAP service is ClusterIP only, not exposed externally
1301: 4. **Sensitive Variables**: Passwords are marked as sensitive in Terraform and
1302: must be set via environment variables, never in `variables.tfvars`.
1303: See [Secrets Requirements](../SECRETS_REQUIREMENTS.md) for configuration details.
1304: 5. **Encrypted Storage**: EBS volumes are encrypted by default (configurable via
1305: `storage_class_encrypted`)
1306: 6. **Network Isolation**: Services run in private subnets
1307: 7. **Network Policies**: Kubernetes Network Policies restrict pod-to-pod
1308: communication to secure ports only (443, 636, 8443), with cross-namespace access
1309: enabled for LDAP service access
1310: 8. **Password Injection**: Passwords are injected at runtime via environment
1311: variables from AWS Secrets Manager (local scripts) or GitHub Secrets (GitHub Actions),
1312: ensuring they never appear in version control. See [Secrets Requirements](../SECRETS_REQUIREMENTS.md)
1313: for details.
1314: 9. **DNS Validation**: ACM certificate uses DNS validation via Route53, ensuring
1315: secure certificate provisioning
1316: 10. **EKS Auto Mode Security**: IAM permissions are automatically handled by EKS
1317: Auto Mode (no manual policy attachment required)
1318: 11. **IRSA for SNS**: SMS 2FA uses IAM Roles for Service Accounts (no hardcoded
1319: AWS credentials)
1320: 12. **VPC Endpoints**: SNS and STS access goes through VPC endpoints (no public
1321: internet for SMS)
1322: 13. **Phone Number Validation**: E.164 format validation for SMS phone numbers
1323: 14. **SMS Code Expiration**: Verification codes expire after configurable
1324: timeout
1325: 15. **Rate Limiting**: Consider implementing rate limiting for authentication
1326: attempts
1327: 
1328: ## Customization
1329: 
1330: ### Modifying Helm Values
1331: 
1332: Edit `helm/openldap-values.tpl.yaml` to customize:
1333: 
1334: - LDAP ports
1335: - Storage size
1336: - Image tags
1337: - Environment variables
1338: - Ingress annotations
1339: 
1340: After modifying the template, run `terraform plan` and `terraform apply`.
1341: 
1342: ### Using Secrets Instead of Plain Text
1343: 
1344: To use Kubernetes secrets instead of plain text passwords:
1345: 
1346: 1. Create a Kubernetes secret with keys `LDAP_ADMIN_PASSWORD` and
1347: `LDAP_CONFIG_ADMIN_PASSWORD`
1348: 2. Update the Helm values template to use `global.existingSecret`
1349: 3. Remove `adminPassword` and `configPassword` from the template
1350: 
1351: Example:
1352: 
1353: ```yaml
1354: global:
1355:   existingSecret: "openldap-secrets"
1356:   # Remove adminPassword and configPassword
1357: ```
1358: 
1359: ## Troubleshooting
1360: 
1361: ### Common Issues
1362: 
1363: 1. **Helm Release Fails**
1364:    - Verify EKS cluster is accessible: `kubectl get nodes`
1365:    - Check Helm repository is accessible: `helm repo list`
1366:    - Verify PVC exists: `kubectl get pvc -n ldap`
1367: 
1368: 2. **ALB Not Created**
1369:    - Ensure EKS Auto Mode has `elastic_load_balancing.enabled = true`
1370:    - Check Ingress annotations are correct
1371:    - Verify ACM certificate validation completed (check Route53 validation
1372:    records)
1373:    - Ensure certificate is in the same region as the EKS cluster
1374: 
1375: 3. **PVC Not Found**
1376:    - Verify PVC name matches exactly (case-sensitive)
1377:    - Check PVC exists: `kubectl get pvc -A`
1378:    - Ensure PVC is in the same namespace or update namespace in Helm values
1379: 
1380: 4. **Cannot Access UIs**
1381:    - Verify ALB is created: `aws elbv2 describe-load-balancers`
1382:    - Check DNS resolution: `dig phpldapadmin.${domain_name}` or `nslookup
1383:    phpldapadmin.${domain_name}`
1384:    - Verify domain registrar NS records point to Route53 name servers
1385:    - Verify security groups allow HTTPS traffic
1386:    - Check Ingress status: `kubectl describe ingress -n ldap`
1387:    - Verify ACM certificate is validated: `aws acm describe-certificate
1388:    --certificate-arn <arn>`
1389: 
1390: 5. **2FA Application Issues**
1391:    - Check backend pods: `kubectl logs -n 2fa-app -l app=ldap-2fa-backend`
1392:    - Check frontend pods: `kubectl logs -n 2fa-app -l app=ldap-2fa-frontend`
1393:    - Verify LDAP connectivity from backend: test internal DNS resolution
1394:    - Check IRSA role assumption: verify service account annotations
1395: 
1396: 6. **SMS 2FA Not Working**
1397:    - Verify SNS topic exists: `aws sns list-topics`
1398:    - Check IAM role permissions: `aws iam get-role-policy`
1399:    - Verify VPC endpoints for SNS and STS
1400:    - Check backend logs for SNS errors
1401:    - Verify phone number format (E.164)
1402: 
1403: 7. **ArgoCD Issues**
1404:    - Check capability status: `aws eks describe-capability`
1405:    - Verify cluster registration secret: `kubectl get secret -n argocd`
1406:    - Check Application sync status: `kubectl describe application -n argocd`
1407: 
1408: 8. **PostgreSQL Issues**
1409:    - Check pods: `kubectl get pods -n ldap-2fa -l app.kubernetes.io/name=postgresql`
1410:    - Check logs: `kubectl logs -n ldap-2fa -l app.kubernetes.io/name=postgresql`
1411:    - Check PVC: `kubectl get pvc -n ldap-2fa`
1412:    - Test connection: `kubectl exec -it -n ldap-2fa postgresql-0 -- \
1413:      psql -U ldap2fa -d ldap2fa`
1414: 
1415: 9. **Redis Issues**
1416:    - Check pods: `kubectl get pods -n redis -l app.kubernetes.io/name=redis`
1417:    - Check logs: `kubectl logs -n redis -l app.kubernetes.io/name=redis`
1418:    - Check PVC: `kubectl get pvc -n redis`
1419:    - Test connection: `kubectl exec -it -n redis redis-master-0 -- \
1420:      redis-cli -a $REDIS_PASSWORD ping`
1421: 
1422: 10. **SES Issues**
1423:     - Check email identity: `aws ses get-identity-verification-attributes \
1424:       --identities your@email.com`
1425:     - Check send quota: `aws ses get-send-quota`
1426:     - Verify IRSA: Check service account annotation for SES IAM role
1427: 
1428: 11. **User Registration Issues**
1429:     - Check backend logs for registration errors
1430:     - Verify PostgreSQL connectivity
1431:     - Check SES sending limits (sandbox mode restricts recipients)
1432:     - Verify SNS SMS spending limit
1433: 
1434: ### Useful Commands
1435: 
1436: ```bash
1437: # View Helm release values
1438: helm get values openldap-stack-ha -n ldap
1439: 
1440: # Check OpenLDAP logs
1441: kubectl logs -n ldap -l app=openldap
1442: 
1443: # Check PhpLdapAdmin logs
1444: kubectl logs -n ldap -l app=phpldapadmin
1445: 
1446: # Check LTB-passwd logs
1447: kubectl logs -n ldap -l app=ltb-passwd
1448: 
1449: # Check 2FA Backend logs
1450: kubectl logs -n 2fa-app -l app=ldap-2fa-backend
1451: 
1452: # Check 2FA Frontend logs
1453: kubectl logs -n 2fa-app -l app=ldap-2fa-frontend
1454: 
1455: # View Ingress details
1456: kubectl describe ingress -n ldap
1457: kubectl describe ingress -n 2fa-app
1458: 
1459: # Check ALB target health
1460: aws elbv2 describe-target-health --target-group-arn <target-group-arn>
1461: 
1462: # Test LDAP connectivity (from within cluster)
1463: kubectl run -it --rm ldap-test --image=osixia/openldap --restart=Never -- bash
1464: ldapsearch -x -H ldap://openldap-stack-ha:389 -b "dc=corp,dc=internal"
1465: 
1466: # Check ArgoCD applications
1467: kubectl get application -n argocd
1468: kubectl describe application -n argocd <app-name>
1469: 
1470: # Test 2FA API endpoints
1471: curl -X GET https://app.${domain_name}/api/healthz
1472: curl -X GET https://app.${domain_name}/api/mfa/methods
1473: 
1474: # Check PostgreSQL
1475: kubectl logs -n ldap-2fa -l app.kubernetes.io/name=postgresql
1476: kubectl exec -it -n ldap-2fa postgresql-0 -- psql -U ldap2fa -d ldap2fa -c "\dt"
1477: 
1478: # Check Redis
1479: kubectl logs -n redis -l app.kubernetes.io/name=redis
1480: kubectl exec -it -n redis redis-master-0 -- redis-cli -a $REDIS_PASSWORD KEYS "*"
1481: 
1482: # Check SES identity status
1483: aws ses get-identity-verification-attributes --identities ${domain_name}
1484: ```
1485: 
1486: ## Outputs
1487: 
1488: The application provides outputs for:
1489: 
1490: - `alb_dns_name`: DNS name of the ALB (extracted from Ingress resources created
1491: by Helm chart)
1492:   - Empty string if ALB is still provisioning or not created
1493:   - Retrieved from either phpldapadmin or ltb-passwd Ingress status
1494: - `route53_acm_cert_arn`: ACM certificate ARN (from data source, not module)
1495: - `route53_domain_name`: Root domain name (from variable)
1496: - `route53_zone_id`: Route53 hosted zone ID (from data source)
1497: - `route53_name_servers`: Route53 name servers (from data source, for registrar
1498: configuration)
1499: - `argocd_server_url`: ArgoCD UI/API endpoint URL (if ArgoCD is enabled)
1500: - `sns_topic_arn`: SNS topic ARN for SMS 2FA (if SMS 2FA is enabled)
1501: - `sns_iam_role_arn`: IAM role ARN for IRSA (if SMS 2FA is enabled)
1502: - `postgresql_host`: PostgreSQL service hostname (if PostgreSQL is enabled)
1503: - `postgresql_port`: PostgreSQL service port (if PostgreSQL is enabled)
1504: - `postgresql_database`: PostgreSQL database name (if PostgreSQL is enabled)
1505: - `redis_host`: Redis service hostname (if Redis is enabled)
1506: - `redis_port`: Redis service port (if Redis is enabled)
1507: - `ses_sender_email`: Verified SES sender email (if SES is enabled)
1508: - `ses_iam_role_arn`: IAM role ARN for SES IRSA (if SES is enabled)
1509: 
1510: View all outputs:
1511: 
1512: ```bash
1513: terraform output
1514: ```
1515: 
1516: > [!IMPORTANT]
1517: >
1518: > After deployment, update your domain registrar's NS records to
1519: > point to the Route53 name servers shown in the `route53_name_servers` output.
1520: 
1521: ## References
1522: 
1523: - [Helm OpenLDAP Chart](https://github.com/jp-gouin/helm-openldap)
1524: - [AWS EKS Auto Mode Documentation](https://docs.aws.amazon.com/eks/latest/userguide/eks-auto-mode.html)
1525: - [EKS Auto Mode IngressClassParams](https://docs.aws.amazon.com/eks/latest/userguide/eks-auto-mode-ingress.html)
1526: - [Kubernetes Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)
1527: - [OpenLDAP Documentation](https://www.openldap.org/doc/)
1528: - [PhpLdapAdmin Documentation](https://www.phpldapadmin.org/)
1529: - [LTB-passwd Documentation](https://ltb-project.org/documentation/self-service-password)
1530: - [FastAPI Documentation](https://fastapi.tiangolo.com/)
1531: - [AWS SNS SMS Documentation](https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html)
1532: - [IRSA (IAM Roles for Service Accounts)](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html)
1533: - [ArgoCD Documentation](https://argo-cd.readthedocs.io/)
1534: - [cert-manager Documentation](https://cert-manager.io/docs/)
1535: - [AWS SES Documentation](https://docs.aws.amazon.com/ses/)
1536: - [Bitnami PostgreSQL Helm Chart](https://github.com/bitnami/charts/tree/main/bitnami/postgresql)
1537: - [Bitnami Redis Helm Chart](https://github.com/bitnami/charts/tree/main/bitnami/redis)
1538: 
1539: ## Architecture Notes
1540: 
1541: ### Route53 A Records
1542: 
1543: The Terraform configuration automatically creates Route53 A (alias) records for
1544: the subdomains:
1545: 
1546: - `phpldapadmin.${domain_name}`  ALB DNS name
1547: - `passwd.${domain_name}`  ALB DNS name
1548: - `app.${domain_name}`  ALB DNS name (2FA application)
1549: 
1550: These records are created after the Helm release and Ingress resources are
1551: provisioned, ensuring the ALB DNS name is available.
1552: 
1553: ### Internet-Facing ALB Configuration
1554: 
1555: The ALB is configured as `internet-facing` to enable:
1556: 
1557: - Access to UIs from anywhere on the internet
1558: - Public accessibility for user convenience
1559: - HTTPS-only access for secure communication
1560: - Proper DNS configuration required for public access
1561: 
1562: ### Why ClusterIP for LDAP?
1563: 
1564: The LDAP service uses ClusterIP (not LoadBalancer or NodePort) to:
1565: 
1566: - Keep LDAP ports strictly internal to the cluster
1567: - Prevent external access to LDAP
1568: - Only allow access from pods within the cluster
1569: - Follow security best practices for sensitive services
1570: 
1571: ### EKS Auto Mode Benefits
1572: 
1573: Using EKS Auto Mode provides:
1574: 
1575: - Automatic ALB provisioning via Ingress annotations
1576: - No need to manually install or configure AWS Load Balancer Controller
1577: - Simplified IAM permissions (handled automatically by EKS)
1578: - Built-in EBS CSI driver (no manual installation needed)
1579: - IngressClassParams support for cluster-wide ALB defaults (scheme,
1580: ipAddressType)
1581: - Direct integration with EKS cluster (no separate controller pods)
1582: 
1583: ### Network Policies
1584: 
1585: The Network Policies module enforces security at the pod level:
1586: 
1587: - **Secure Ports Only**: Pods can only communicate on encrypted ports (443,
1588: 636, 8443)
1589: - **Namespace Isolation**: Policies apply to all pods in the `ldap` namespace
1590: - **Cross-Namespace Access**: Services in other namespaces can access the LDAP
1591: service on secure ports (443, 636, 8443)
1592: - **DNS Required**: DNS resolution is allowed for service discovery
1593: - **External Access**: HTTPS/HTTP egress is allowed for external API calls
1594: - **Default Deny**: All other ports are implicitly denied
1595: 
1596: This provides defense-in-depth security, ensuring that even if a pod is
1597: compromised, it can only communicate on secure, encrypted ports. Cross-namespace
1598: communication enables microservices in different namespaces to securely access
1599: the centralized LDAP service.
1600: 
1601: ### 2FA Application Architecture
1602: 
1603: The 2FA application follows a single-domain pattern:
1604: 
1605: - **Single ALB Entry Point**: Both frontend and backend share the same ALB
1606: - **Path-Based Routing**: `/api/*` routes to backend, `/` routes to frontend
1607: - **No CORS Required**: Same-origin requests since both share `app.${domain}`
1608: - **LDAP Integration**: Backend authenticates against internal LDAP service
1609: - **PostgreSQL Integration**: Stores user registrations and verification tokens
1610: - **Redis Integration**: Caches SMS OTP codes with TTL-based expiration
1611: - **IRSA for AWS Services**: Backend uses IAM Roles for Service Accounts for
1612: SNS and SES access
1613: - **VPC Private Access**: SNS/STS calls go through VPC endpoints (no NAT
1614: gateway)
1615: 
1616: ### User Registration Flow
1617: 
1618: 1. **Signup**: User submits registration form  stored in PostgreSQL (PENDING)
1619: 2. **Email Verification**: SES sends verification link  user clicks  email verified
1620: 3. **Phone Verification**: SNS sends OTP  user enters code  phone verified
1621: 4. **Profile Complete**: Both verified  status changes to COMPLETE
1622: 5. **Admin Approval**: Admin approves  user created in LDAP  status ACTIVE
1623: 6. **Welcome Email**: SES sends welcome email on activation
1624: 
1625: ### GitOps with ArgoCD
1626: 
1627: ArgoCD provides continuous delivery:
1628: 
1629: - **Managed Service**: Runs in EKS control plane (no worker node resources)
1630: - **Git as Source of Truth**: All application state defined in Git
1631: - **Automatic Sync**: Changes in Git trigger automatic deployments
1632: - **Self-Healing**: Automatically corrects drift from desired state
1633: - **Identity Center Auth**: SSO authentication via AWS Identity Center
````

## File: application/CHANGELOG.md
````markdown
   1: # Changelog
   2: 
   3: All notable changes to the OpenLDAP application infrastructure will be
   4: documented in this file.
   5: 
   6: The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
   7: and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
   8: 
   9: ## [2026-01-18] - Documentation Updates and Certificate Architecture Migration
  10: 
  11: ### Changed
  12: 
  13: - **Certificate Architecture Migration to Public ACM**
  14:   - Migrated from Private CA-based certificates to Public ACM certificates
  15:     (Amazon-issued) for browser-trusted certificates
  16:   - Public ACM certificates are requested in each deployment account and
  17:     validated via DNS records in State Account's Route53 hosted zone
  18:   - Certificates are automatically renewed by ACM (no manual intervention
  19:     required)
  20:   - Eliminates browser security warnings and simplifies certificate management
  21:   - Updated all documentation to reflect Public ACM certificate architecture
  22:   - Comprehensive Public ACM certificate setup documentation in
  23:     `CROSS-ACCOUNT-ACCESS.md` with step-by-step AWS CLI commands
  24:   - Private CA setup moved to "Legacy" section (deprecated for public-facing
  25:     applications)
  26: 
  27: - **Image Tag Standardization Update**
  28:   - Updated Redis and PostgreSQL image tags to use 'latest' tag instead of
  29:     version-specific tags
  30:   - Redis default image tag changed from `redis-8.4.0` to `redis-latest`
  31:   - PostgreSQL default image tag changed from `postgresql-18.1.0` to
  32:     `postgresql-latest`
  33:   - Updated ECR image mirroring script to use 'latest' tags
  34:   - Updated all documentation to reflect new image tag naming convention
  35: 
  36: - **Comprehensive Documentation Updates**
  37:   - Updated `application/README.md` with latest features and certificate
  38:     architecture
  39:   - Updated all prerequisites to reference Public ACM certificate setup
  40:   - Updated API documentation references to clarify always-enabled status
  41:   - Added Helm release safety, ECR image support, and Kubeconfig auto-update
  42:     documentation
  43: 
  44: ### Fixed
  45: 
  46: - **Documentation Consistency**
  47:   - Fixed inconsistent references to Private CA vs Public ACM certificates
  48:   - Updated all prerequisites to reference Public ACM certificate setup
  49:   - Corrected image tag references across all documentation files
  50:   - Ensured all documentation reflects current implementation state
  51: 
  52: ## [2026-01-15] - Helm Release Safety, ECR Image Support, and Infrastructure Improvements
  53: 
  54: ### Added
  55: 
  56: - **Helm Release Attributes for Safer Deployments**
  57:   - Added comprehensive Helm release attributes to all modules
  58:   (OpenLDAP, PostgreSQL, Redis, cert-manager) for safer and more reliable deployments:
  59:     - `atomic: true` - Prevents partial deployments by rolling back on failure
  60:     - `force_update: true` - Enables forced updates when needed
  61:     - `replace: true` - Prevents resource name conflicts and allows reuse of names
  62:     - `cleanup_on_fail: true` - Automatically cleans up resources on failed deployments
  63:     - `recreate_pods: true` - Forces pod restart on upgrade and rollbacks
  64:     - `wait: true` - Waits for all resources to be ready before marking as successful
  65:     - `wait_for_jobs: true` - Waits for any jobs to be completed for success state
  66:     - `upgrade_install: true` - Prevents failures if there are pre-existing resources
  67:   - OpenLDAP module timeout set to 5 minutes (300 seconds)
  68:   - PostgreSQL and Redis module timeouts set to 10 minutes (600 seconds)
  69:   - Improves deployment reliability and prevents stuck deployments
  70: 
  71: - **Standardized Helm Values Passing**
  72:   - Standardized how Helm values are passed through to all modules
  73:   (OpenLDAP, PostgreSQL, Redis)
  74:   - All modules now use consistent `templatefile()` approach with `values_template_path`
  75:   variable
  76:   - Modules can use default template path or custom path via variable
  77:   - Improved maintainability and consistency across all Helm chart deployments
  78:   - Created comprehensive Helm values templates:
  79:     - `helm/postgresql-values.tpl.yaml` - PostgreSQL Helm chart values template
  80:     - `helm/redis-values.tpl.yaml` - Updated Redis Helm chart values template
  81:     - `helm/openldap-values.tpl.yaml` - Updated OpenLDAP Helm chart values template
  82: 
  83: - **PostgreSQL Chart Repository Fix**
  84:   - Fixed PostgreSQL Helm chart download issue by changing repository from
  85:   `https://charts.bitnami.com/bitnami` to `oci://registry-1.docker.io/bitnamicharts`
  86:   - Uses OCI registry format for better compatibility and reliability
  87:   - Resolves chart download failures during deployment
  88: 
  89: - **Image Tag Standardization**
  90:   - Changed Redis and PostgreSQL image tags to use 'latest' tag instead of SHA digests
  91:   - Redis default image tag: `redis-latest`
  92:   - PostgreSQL default image tag: `postgresql-latest`
  93:   - OpenLDAP continues to use specific version tag: `openldap-1.5.0`
  94:   - Image tags correspond to tags created by `mirror-images-to-ecr.sh` script
  95:   - Simplifies image management and updates
  96: 
  97: - **Public ACM Certificate Architecture**
  98:   - Migrated to Public ACM certificates (Amazon-issued) for browser-trusted
  99:     certificates
 100:   - Public ACM certificates requested in each deployment account (development,
 101:     production)
 102:   - DNS validation records created in Route53 hosted zone in State Account
 103:   - Certificates stored in respective deployment accounts (not State Account)
 104:   - Eliminates cross-account certificate access complexity
 105:   - Compatible with EKS Auto Mode ALB controller requirements (certificate must
 106:     be in same account as ALB)
 107:   - Comprehensive Public ACM certificate setup documentation in
 108:     `CROSS-ACCOUNT-ACCESS.md` with step-by-step AWS CLI commands
 109:   - Certificate validation workflow documented for both production and development
 110:     accounts
 111:   - Certificates automatically renewed by ACM (no manual intervention required)
 112:   - Browser-trusted certificates (no security warnings)
 113: 
 114: - **State Account Role ARN Support for Route53 Cross-Account Access**
 115:   - Added support for querying Route53 hosted zones from State Account
 116:   - New variable `state_account_role_arn` for assuming role in State Account
 117:     (where Route53 hosted zone resides)
 118:   - State account provider alias (`aws.state_account`) configured in
 119:     `providers.tf`
 120:   - All Route53 data sources and resources now use state account provider when
 121:     configured
 122:   - Route53 records (phpldapadmin, ltb_passwd, twofa_app, SES
 123:     verification/DKIM) created in State Account
 124:   - Route53 DNS validation records for Public ACM certificates created in State
 125:     Account
 126:   - ACM certificates are Public ACM certificates (Amazon-issued) requested in
 127:     Deployment Account (not State Account)
 128:   - Scripts automatically inject `state_account_role_arn` into
 129:     `variables.tfvars`:
 130:     - `setup-application.sh` exports `STATE_ACCOUNT_ROLE_ARN` environment
 131:       variable
 132:     - `set-k8s-env.sh` injects `state_account_role_arn` into
 133:       `variables.tfvars`
 134:   - GitHub Actions workflows export `STATE_ACCOUNT_ROLE_ARN` for automatic
 135:     injection
 136:   - No ExternalId required for state account role assumption (by design)
 137:   - Comprehensive cross-account access documentation in
 138:     `CROSS-ACCOUNT-ACCESS.md`
 139:   - Updated ALB module to handle null certificate ARN gracefully
 140:   - Added certificate ARN to ALB module triggers for proper
 141:     IngressClassParams updates
 142: 
 143: - **ExternalId Support for Cross-Account Role Assumption**
 144:   - Added ExternalId requirement for enhanced security when assuming deployment
 145:   account roles
 146:   - ExternalId retrieved from AWS Secrets Manager (secret: `external-id`) for
 147:   local deployment
 148:   - ExternalId retrieved from GitHub repository secret (`AWS_ASSUME_EXTERNAL_ID`)
 149:   for GitHub Actions
 150:   - ExternalId passed to Terraform provider's `assume_role` block
 151:   - New variable `deployment_account_external_id` added to `variables.tf`
 152:   - Setup script (`setup-application.sh`) automatically retrieves ExternalId from
 153:   AWS Secrets Manager
 154:   - GitHub Actions workflow (`application_infra_provisioning.yaml`) updated to use
 155:   `AWS_ASSUME_EXTERNAL_ID` secret
 156:   - Deployment account roles must have ExternalId condition in Trust Relationship
 157:   - **Bidirectional Trust Relationships**: Both deployment account roles and state
 158:     account role must trust each other in their respective Trust Relationships
 159:   - State account role's Trust Relationship must include deployment account role
 160:     ARNs to enable proper cross-account role assumption
 161:   - Prevents confused deputy attacks in multi-account deployments
 162:   - ExternalId generation: `openssl rand -hex 32`
 163: 
 164: - **Destroy Script for Application Infrastructure**
 165:   - Created `destroy-application.sh` script for destroying application
 166:   infrastructure
 167:   - Interactive region and environment selection
 168:   - Automatic retrieval of role ARNs, ExternalId, and password secrets from AWS
 169:   Secrets Manager
 170:   - Automatic backend configuration and variables.tfvars updates
 171:   - Kubernetes environment setup using `set-k8s-env.sh`
 172:   - Safety confirmations required before destruction (type 'yes' then 'DESTROY')
 173:   - Comprehensive error handling and user guidance
 174:   - Updated GitHub Actions destroying workflow with ExternalId support
 175: 
 176: - **Route53 Record Module Separation**
 177:   - Separated Route53 record creation from OpenLDAP module into dedicated
 178:     `route53_record` module
 179:   - New module located at `application/modules/route53_record/` for per-record
 180:     creation
 181:   - Module uses state account provider (`aws.state_account`) for cross-account
 182:     access
 183:   - Route53 records created in State Account while ALB deployed in Deployment
 184:     Account
 185:   - Three separate module calls in `main.tf`:
 186:     - `module.route53_record_phpldapadmin` - Creates A record for phpLDAPadmin
 187:     - `module.route53_record_ltb_passwd` - Creates A record for ltb-passwd
 188:     - `module.route53_record_twofa_app` - Creates A record for 2FA application
 189:   - Module outputs: `record_name`, `record_fqdn`, `record_id`
 190:   - Precondition ensures ALB DNS name is available before record creation
 191:   - Comprehensive ALB zone_id mapping by region (13 AWS regions supported:
 192:     us-east-1, us-east-2, us-west-1, us-west-2, eu-west-1, eu-west-2, eu-west-3,
 193:     eu-central-1, ap-southeast-1, ap-southeast-2, ap-northeast-1,
 194:     ap-northeast-2, sa-east-1)
 195:   - Proper dependency chain: OpenLDAP module  ALB data source  Route53 records
 196:   - All records use consistent ALB data source approach to avoid timing issues
 197:   - Lifecycle block with `create_before_destroy` for safe updates
 198:   - Comprehensive module documentation in
 199:     `application/modules/route53_record/README.md`
 200: 
 201: - **ECR Image Mirroring Script**
 202:   - Created `application/mirror-images-to-ecr.sh` script (290 lines) to eliminate
 203:     Docker Hub rate limiting and external dependencies
 204:   - Automatically mirrors third-party container images from Docker Hub to ECR:
 205:     - `bitnami/redis:8.4.0-debian-12-r6`  `redis-latest`
 206:     - `bitnami/postgresql:18.1.0-debian-12-r4`  `postgresql-latest`
 207:     - `osixia/openldap:1.5.0`  `openldap-1.5.0`
 208:   - Checks if images exist in ECR before mirroring (skips if already present)
 209:   - Uses State Account credentials to fetch ECR URL from backend_infra state
 210:   - Assumes Deployment Account role for ECR operations (with ExternalId)
 211:   - Authenticates Docker to ECR automatically using `aws ecr get-login-password`
 212:   - Cleans up local images after pushing to save disk space
 213:   - Lists all images in ECR repository after completion
 214:   - Integrated into `application/setup-application.sh` (runs before Terraform
 215:     operations)
 216:   - Integrated into GitHub Actions workflow (runs after Terraform validate, before
 217:     set-k8s-env.sh)
 218:   - Requires Docker to be installed and running
 219:   - Requires `jq` for JSON parsing (with fallback to sed for compatibility)
 220:   - Prevents Docker Hub rate limiting and external dependencies during
 221:     deployments
 222:   - Comprehensive error handling and user feedback
 223: 
 224: - **ECR Image Support for OpenLDAP, PostgreSQL, and Redis Modules**
 225:   - All three modules now use ECR images instead of Docker Hub
 226:   - New variables in `application/variables.tf`:
 227:     - `openldap_image_tag` (default: "openldap-1.5.0")
 228:     - `postgresql_image_tag` (default: "postgresql-latest")
 229:     - `redis_image_tag` (default: "redis-latest")
 230:   - ECR registry and repository computed from backend_infra state (`ecr_url`)
 231:   - All modules updated with ECR configuration variables:
 232:     - `ecr_registry`: ECR registry URL (e.g., account.dkr.ecr.region.amazonaws.com)
 233:     - `ecr_repository`: ECR repository name
 234:     - `image_tag` or module-specific tag variable
 235:   - Helm values templates updated to use ECR images
 236:   - Image tags correspond to tags created by `mirror-images-to-ecr.sh`
 237:   - **OpenLDAP module**: Updated `helm/openldap-values.tpl.yaml` to use ECR
 238:     registry/repository/tag
 239:   - **PostgreSQL module**: Updated Helm values to use ECR image configuration
 240:   - **Redis module**: Updated Helm values to use ECR image configuration
 241: 
 242: ### Changed
 243: 
 244: - **Module Documentation Updates**
 245:   - Updated module READMEs with standardized Helm values passing documentation
 246:   - Enhanced PostgreSQL module README with chart repository information
 247:   - Updated Redis module README with latest configuration details
 248:   - Improved ALB module README with latest annotation strategy
 249:   - Enhanced cert-manager and ArgoCD module documentation
 250:   - Added comprehensive Route53 module README documentation
 251: 
 252: - **Helm Values Template Organization**
 253:   - Standardized Helm values template structure across all modules
 254:   - Improved template variable naming and organization
 255:   - Enhanced template documentation and comments
 256:   - Better separation of concerns between module logic and Helm values
 257: 
 258: - **Setup Script Improvements**
 259:   - Enhanced `setup-application.sh` with improved error handling and ExternalId
 260:   support
 261:   - Automatic ExternalId retrieval from AWS Secrets Manager
 262:   - Improved role assumption logic with better error messages
 263:   - Enhanced secret retrieval with validation and error handling
 264:   - Better integration with GitHub repository variables and secrets
 265:   - Improved Kubernetes environment setup using `set-k8s-env.sh`
 266:   - Enhanced user guidance and confirmation prompts
 267:   - Automatic injection of `state_account_role_arn` for Route53 access
 268:   - Integrated ECR image mirroring script execution (runs before Terraform
 269:     operations)
 270:   - Improved credential handling to prevent conflicts between different AWS
 271:     credentials
 272:   - Better dependency chain organization to prevent failures
 273:   - Enhanced script error handling in destroy scripts
 274: 
 275: - **GitHub Actions Workflow Updates**
 276:   - Updated `application_infra_provisioning.yaml` with ExternalId support and
 277:   improved error handling
 278:   - Updated `application_infra_destroying.yaml` with ExternalId support and
 279:   improved error handling
 280:   - Workflows now use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state
 281:     operations
 282:   - Workflows now export `STATE_ACCOUNT_ROLE_ARN` for Route53
 283:     cross-account access
 284:   - Workflows now use `AWS_ASSUME_EXTERNAL_ID` for cross-account role
 285:     assumption
 286:   security
 287:   - Improved environment variable handling for password secrets
 288:   - Added Docker Buildx setup step for image operations
 289:   - Added "Mirror Docker images to ECR" step (runs after Terraform validate,
 290:     before set-k8s-env.sh)
 291:   - Workflow now handles image mirroring automatically
 292:   - Improved credential handling to prevent conflicts between different AWS
 293:     credentials
 294: 
 295: - **Documentation Improvements**
 296:   - Removed duplication by replacing detailed module descriptions with links to
 297:   module READMEs
 298:   - Enhanced cross-references to module documentation (ALB, ArgoCD, cert-manager,
 299:   Network Policies, PostgreSQL, Redis, SES, SNS, Route53 Record)
 300:   - Updated component descriptions to be more concise with links to detailed documentation
 301:   - Improved consistency across documentation files
 302:   - Added comprehensive documentation for Route53 record module
 303:   - Added documentation for ECR image mirroring script
 304:   - Updated module documentation to reflect ECR image usage
 305: 
 306: - **Backend API Configuration**
 307:   - Removed debug mode condition for API documentation endpoints
 308:   - Swagger UI, ReDoc UI, and OpenAPI schema are now always accessible in production
 309:   - API documentation always enabled (not just in debug mode)
 310: 
 311: - **Kubeconfig Auto-Update to Prevent Stale Cluster Endpoints**
 312:   - Fixed issue where kubeconfig could contain stale cluster endpoints after
 313:     cluster recreation or endpoint changes
 314:   - `set-k8s-env.sh` now automatically updates kubeconfig on every run using
 315:     `aws eks update-kubeconfig`
 316:   - Ensures kubeconfig always contains the latest cluster endpoint before any
 317:     kubectl commands are executed
 318:   - Prevents DNS lookup errors like: `dial tcp: lookup
 319:     26A3426590C00FBB5A84A506D1F8B14A.gr7.us-east-1.eks.amazonaws.com: no such host`
 320:   - Uses deployment account credentials (already assumed by the script) for
 321:     kubeconfig update
 322:   - Automatically creates kubeconfig directory if it doesn't exist
 323:   - Script exits with error if kubeconfig update fails, preventing deployment
 324:     with incorrect configuration
 325:   - Fixes issues with Terraform provisioners (e.g., ALB IngressClassParams) that
 326:     use kubectl commands
 327: 
 328: ## [2025-12-20] - Swagger UI for API Documentation
 329: 
 330: - **API Documentation (Swagger UI)**
 331:   - FastAPI Swagger UI now always enabled at `/api/docs` (previously only available
 332:   in debug mode)
 333:   - ReDoc UI always available at `/api/redoc`
 334:   - OpenAPI schema accessible at `/api/openapi.json`
 335:   - Interactive API documentation automatically updates when endpoints change
 336:   - Documentation updated in README.md and PRD-2FA-APP.md to reflect availability
 337: 
 338: ## [2025-12-18] - Admin Functions and User Profile Management
 339: 
 340: ### Added
 341: 
 342: - **Admin Dashboard and User Management**
 343:   - Admin tab visible only to LDAP admin group members
 344:   - User management section with comprehensive user details view
 345:   - Filter users by status (pending, complete, active, revoked)
 346:   - View user details: name, email, phone, verification status, MFA method,
 347:   group memberships
 348:   - Activation and revocation workflow with audit logging
 349: 
 350: - **User Profile Management**
 351:   - Profile page with viewable and editable fields
 352:   - Edit restrictions: email/phone read-only after verification
 353:   - Profile fields: username, first/last name, email, phone, MFA method, status
 354: 
 355: - **Group Management (Full CRUD)**
 356:   - Create, read, update, delete groups via admin interface
 357:   - Group-user assignment management
 358:   - Sync with LDAP groups on create/update/delete
 359:   - View group members and member counts
 360: 
 361: - **Approve/Revoke Workflow**
 362:   - Approval requires group assignment (at least one group)
 363:   - Creates user in LDAP with all attributes on approval
 364:   - Adds user to selected LDAP groups
 365:   - Sends welcome email on activation
 366:   - Revocation removes user from LDAP and all groups
 367: 
 368: - **List Features**
 369:   - Sortable columns with visual indicators
 370:   - Filtering by status and group membership
 371:   - Real-time search for users and groups
 372: 
 373: - **Admin Notifications**
 374:   - Email notification to all admins on new user signup
 375:   - Uses existing AWS SES infrastructure
 376:   - Async notification (non-blocking)
 377: 
 378: - **Top Navigation Bar**
 379:   - Persistent navigation after login
 380:   - User menu with profile and logout options
 381:   - Admin-specific menu items for admin users
 382: 
 383: - **Email Client Module (`app/email/`)**
 384:   - AWS SES integration for sending emails
 385:   - Email templates for verification and welcome emails
 386:   - IRSA-based authentication for SES access
 387: 
 388: - **Database Models**
 389:   - Extended user model with profile fields
 390:   - Group model for LDAP group management
 391:   - UserGroup model for user-group relationships
 392: 
 393: ### Changed
 394: 
 395: - **Updated `routes.py`**
 396:   - Added profile management endpoints (`/api/profile/{username}`)
 397:   - Added admin endpoints for user and group management
 398:   - Added admin authentication and authorization checks
 399: 
 400: - **Updated Frontend**
 401:   - Added admin dashboard UI components
 402:   - Added profile page with edit functionality
 403:   - Added top navigation bar component
 404:   - Enhanced CSS with admin-specific styles
 405: 
 406: ## [2025-12-18] - User Signup Management System
 407: 
 408: ### Added
 409: 
 410: - **Self-Service User Registration**
 411:   - Signup form with fields: first name, last name, username, email, phone,
 412:   password, MFA method
 413:   - Username validation (3-64 chars, alphanumeric + underscore/hyphen)
 414:   - Email and phone uniqueness validation
 415:   - Password hashing with bcrypt
 416: 
 417: - **Email Verification via AWS SES**
 418:   - UUID token-based verification links
 419:   - 24-hour token expiry (configurable)
 420:   - Resend verification with 60-second cooldown
 421:   - Email delivery via AWS SES with IRSA
 422: 
 423: - **Phone Verification via AWS SNS**
 424:   - 6-digit OTP code via SMS
 425:   - 1-hour code expiry
 426:   - Resend code with 60-second cooldown
 427:   - SMS delivery via AWS SNS with IRSA
 428: 
 429: - **Profile State Management**
 430:   - PENDING: User registered, verification incomplete
 431:   - COMPLETE: All verifications complete, awaiting admin
 432:   - ACTIVE: Admin activated, exists in LDAP
 433: 
 434: - **Login Restrictions**
 435:   - PENDING users cannot login (shows missing verifications)
 436:   - COMPLETE users see "awaiting admin approval" message
 437:   - Only ACTIVE users can complete login flow
 438: 
 439: - **PostgreSQL Module (`modules/postgresql/`)**
 440:   - Bitnami PostgreSQL Helm chart deployment
 441:   - Database for user registrations and verification tokens
 442:   - Password authentication from GitHub Secrets
 443:   - PersistentVolume storage with RDB
 444: 
 445: - **SES Module (`modules/ses/`)**
 446:   - AWS SES email identity verification
 447:   - IAM Role with IRSA for secure pod access
 448:   - Email sending for verification and notifications
 449:   - Sender email configuration
 450: 
 451: - **Database Connection Module (`app/database/`)**
 452:   - PostgreSQL connection management
 453:   - SQLAlchemy models for users and verification tokens
 454:   - Async database operations
 455: 
 456: - **New API Endpoints**
 457:   - `POST /api/auth/signup` - Register new user
 458:   - `POST /api/auth/verify-email` - Verify email with token
 459:   - `POST /api/auth/verify-phone` - Verify phone with code
 460:   - `POST /api/auth/resend-verification` - Resend verification
 461:   - `GET /api/profile/status/{username}` - Get profile status
 462: 
 463: - **Product Requirements Document (PRD-SIGNUP-MAN.md)**
 464:   - Comprehensive documentation of signup system
 465:   - User stories and acceptance criteria
 466:   - Data models and API specifications
 467:   - UI mockups and deployment checklist
 468: 
 469: ### Changed
 470: 
 471: - **Updated `main.tf`**
 472:   - Added PostgreSQL module invocation
 473:   - Added SES module invocation
 474:   - Added related variables and outputs
 475: 
 476: - **Updated `variables.tf`**
 477:   - Added PostgreSQL configuration variables
 478:   - Added SES configuration variables
 479:   - Added database URL and email settings
 480: 
 481: - **Updated Backend Helm Chart**
 482:   - Added PostgreSQL environment variables
 483:   - Added SES environment variables
 484:   - Added database connection configuration
 485: 
 486: - **Updated Frontend**
 487:   - Added signup form with validation
 488:   - Added verification status panel
 489:   - Added resend verification functionality
 490:   - Enhanced error messages for login restrictions
 491: 
 492: ## [2025-12-18] - Redis SMS OTP Storage
 493: 
 494: ### Added
 495: 
 496: - **Redis Module (`modules/redis/`) for SMS OTP Code Storage**
 497:   - Bitnami Redis Helm chart deployment via Terraform
 498:   - Standalone architecture (sufficient for OTP cache use case)
 499:   - Password authentication via Kubernetes Secret (from GitHub Secrets)
 500:   - PersistentVolume storage with RDB snapshots for data recovery
 501:   - Non-root security context (UID 1001)
 502:   - Network policy restricting Redis access to backend pods only
 503:   - TTL-based automatic expiration for OTP codes
 504: 
 505: - **Redis Client Module (`app/redis/`)**
 506:   - `RedisOTPClient` class with TTL-aware storage operations
 507:   - Automatic fallback to in-memory storage when Redis is disabled
 508:   - Methods: `store_code()`, `get_code()`, `delete_code()`, `code_exists()`
 509:   - Connection health checking and error handling
 510:   - Lazy initialization with connection pooling
 511: 
 512: - **Configuration Updates**
 513:   - Redis configuration settings in `config.py`
 514:   - Helm chart values for Redis connection parameters
 515:   - ConfigMap entries for Redis environment variables
 516:   - Secret reference for Redis password in deployment
 517: 
 518: - **GitHub Actions Updates**
 519:   - Added `TF_VAR_redis_password` environment variable for Redis password
 520:   - Password sourced from `TF_VAR_REDIS_PASSWORD` GitHub Secret (secret name remains
 521:   uppercase, but exported as lowercase to match `variables.tf`)
 522: 
 523: ### Changed
 524: 
 525: - **Updated `routes.py` for Redis Integration**
 526:   - `send_sms_code` endpoint now stores OTP codes in Redis with automatic TTL
 527:   - `login` endpoint now retrieves and verifies OTP codes from Redis
 528:   - Graceful fallback to in-memory storage when Redis is disabled
 529:   - Returns 503 Service Unavailable if Redis fails during code storage
 530: 
 531: - **Updated Backend Helm Chart**
 532:   - Added Redis configuration section in `values.yaml`
 533:   - Added Redis environment variables in `configmap.yaml`
 534:   - Added Redis password secret reference in `deployment.yaml`
 535: 
 536: ### Documentation
 537: 
 538: - Added `modules/redis/README.md` with:
 539:   - Architecture diagram showing backend-Redis communication
 540:   - Redis key schema documentation
 541:   - Debugging commands for Redis CLI
 542:   - Usage examples and configuration options
 543: 
 544: ## [2025-12-18] - 2FA Application and SMS Integration
 545: 
 546: ### Added
 547: 
 548: - **Full 2FA Application (Backend + Frontend)**
 549:   - Python FastAPI backend with LDAP authentication integration
 550:   - Support for **two MFA methods**:
 551:     - **TOTP (Time-based One-Time Password)** - Using authenticator apps (Google
 552:     Authenticator, Authy, etc.)
 553:     - **SMS** - Verification codes sent via AWS SNS
 554:   - Static HTML/JS/CSS frontend with modern, responsive UI
 555:   - Single domain routing pattern (`app.<domain>`) with path-based routing:
 556:     - `/`  Frontend
 557:     - `/api/*`  Backend API
 558:   - Complete Helm charts for both backend and frontend deployments
 559:   - Docker files for containerized deployment
 560:   - Kubernetes resources: Deployment, Service, Ingress, ConfigMap, Secret,
 561:   ServiceAccount, HPA
 562: 
 563: - **SNS Module for SMS-based 2FA Verification**
 564:   - SNS Topic for centralized SMS notifications
 565:   - IAM Role configured for IRSA (IAM Roles for Service Accounts)
 566:   - Direct SMS support for sending verification codes to phone numbers
 567:   - E.164 phone number format support
 568:   - Transactional SMS type for higher delivery priority
 569:   - Cost control via monthly spend limits
 570: 
 571: - **Product Requirements Document (PRD-2FA-APP.md)**
 572:   - Comprehensive documentation of 2FA application architecture
 573:   - API endpoint specifications for all authentication flows
 574:   - Frontend component and state machine documentation
 575:   - Security considerations and error handling patterns
 576: 
 577: ### Changed
 578: 
 579: - **Updated variables.tf and variables.tfvars**
 580:   - Added 2FA application configuration variables
 581:   - Added SNS topic configuration
 582:   - Added backend/frontend deployment settings
 583: 
 584: ## [2025-12-16] - ArgoCD GitOps Integration
 585: 
 586: ### Added
 587: 
 588: - **ArgoCD Capability Module (`modules/argocd/`)**
 589:   - Deploys AWS EKS managed ArgoCD service (runs in EKS control plane)
 590:   - Creates IAM role and policies for ArgoCD capability
 591:   - Configures AWS Identity Center (IdC) authentication
 592:   - Registers local EKS cluster with ArgoCD
 593:   - Sets up RBAC mappings for Identity Center groups/users
 594:   - Optional VPC endpoint configuration for private access
 595:   - Support for ECR and CodeCommit access policies
 596:   - Comprehensive documentation with usage examples
 597: 
 598: - **ArgoCD Application Module (`modules/argocd_app/`)**
 599:   - Creates ArgoCD Application CRD for GitOps deployments
 600:   - Configures source (Git repository, path, revision) and destination
 601:   (cluster, namespace)
 602:   - Supports multiple deployment types:
 603:     - Plain Kubernetes manifests
 604:     - Helm charts with value files and parameters
 605:     - Kustomize with image overrides and common labels
 606:   - Sync policy configuration (automated/manual)
 607:   - Retry policies with backoff configuration
 608:   - Ignore differences for externally managed fields
 609:   - Multi-application pattern support
 610: 
 611: ### Changed
 612: 
 613: - **Updated main.tf**
 614:   - Added ArgoCD capability module integration
 615:   - Added ArgoCD application module calls
 616:   - Configured cluster registration for GitOps
 617: 
 618: - **Updated variables.tf and variables.tfvars**
 619:   - Added ArgoCD configuration variables
 620:   - Added Identity Center configuration (instance ARN, region)
 621:   - Added RBAC role mapping configuration
 622:   - Added VPC endpoint configuration options
 623: 
 624: ## [2025-12-15] - Documentation and Linting Improvements
 625: 
 626: ### Changed
 627: 
 628: - **Updated documentation across all files for Markdown lint compliance**
 629:   - Corrected row length issues to comply with markdownlint rules
 630:   - Improved formatting consistency across all documentation files
 631:   - Updated CHANGELOG.md, OPENLDAP-README.md, OSIXIA-OPENLDAP-REQUIREMENTS.md
 632:   - Updated PRD-ALB.md, PRD-DOMAIN.md, PRD.md, README.md
 633:   - Updated SECURITY-IMPROVEMENTS.md and module README files
 634: 
 635: - **Added Markdown lint configuration**
 636:   - Added `.markdownlint.json` for consistent documentation formatting
 637: 
 638: - **Enhanced Network Policies module**
 639:   - Added additional network policy rules in `modules/network-policies/main.tf`
 640:   - Updated documentation in `modules/network-policies/README.md`
 641: 
 642: ## [2025-12-14] - Deployment Versatility and Security Improvements
 643: 
 644: ### Changed
 645: 
 646: - **Network Policies: Enabled cross-namespace communication for LDAP service
 647: access**
 648:   - Updated network policies to allow services in other namespaces to access the
 649:   LDAP service on secure ports (443, 636, 8443)
 650:   - Added ingress rules using `namespace_selector {}` to enable cross-namespace
 651:   communication
 652:   - Maintains security by only allowing encrypted ports (HTTPS, LDAPS)
 653:   - Updated documentation across all relevant files to reflect cross-namespace
 654:   communication capability
 655:   - Enables microservices in different namespaces to securely access the
 656:   centralized LDAP service
 657: 
 658: - **Password management workflow**
 659:   - OpenLDAP passwords are now exclusively managed through GitHub repository
 660:   secrets
 661:   - Removed dependency on local password files or manual environment variable
 662:   setup
 663:   - Setup script automatically handles password retrieval and export
 664:   - Updated documentation to reflect new password management approach
 665: 
 666: - **Updated AWS provider configuration for multi-account architecture**
 667:   - Removed `provider_profile` variable from `variables.tf` and
 668:   `variables.tfvars`
 669:   - Removed `profile = var.provider_profile` from `providers.tf`
 670:   - Provider now uses role assumption via `deployment_account_role_arn` variable
 671:   instead of AWS profiles
 672:   - Aligns with environment-based role selection (production/development
 673:   accounts)
 674:   - Backend state operations use `AWS_STATE_ACCOUNT_ROLE_ARN` (configured in
 675:   workflows/setup scripts)
 676:   - Deployment operations use environment-specific role ARNs via `assume_role`
 677:   configuration
 678: 
 679: - **Updated GitHub Actions workflows for application infrastructure**
 680:   - `application_infra_provisioning.yaml`: Now uses `AWS_STATE_ACCOUNT_ROLE_ARN`
 681:   for backend operations
 682:   - `application_infra_destroying.yaml`: Now uses `AWS_STATE_ACCOUNT_ROLE_ARN`
 683:   for backend operations
 684:   - Both workflows automatically set `deployment_account_role_arn` variable
 685:   based on selected environment:
 686:     - `prod` environment  uses `AWS_PRODUCTION_ACCOUNT_ROLE_ARN`
 687:     - `dev` environment  uses `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN`
 688:   - Ensures proper separation between state account (S3) and deployment accounts
 689:   (resource creation)
 690: 
 691: ### Added
 692: 
 693: - **Automated OpenLDAP password retrieval from GitHub secrets**
 694:   - `setup-application.sh` now automatically retrieves OpenLDAP passwords from
 695:   GitHub repository secrets
 696:   - Script checks for `TF_VAR_OPENLDAP_ADMIN_PASSWORD` and
 697:   `TF_VAR_OPENLDAP_CONFIG_PASSWORD`, `TF_VAR_POSTGRESQL_PASSWORD`,
 698:   and `TF_VAR_REDIS_PASSWORD` secrets (exported as lowercase `TF_VAR_openldap_admin_password`,
 699:   `TF_VAR_openldap_config_password`, `TF_VAR_postgresql_database_password`,
 700:   and `TF_VAR_redis_password` to match `variables.tf`)
 701:   - Automatically exports passwords as environment variables for Terraform
 702:   - Supports both GitHub Actions (secrets automatically available) and local
 703:   execution (requires exported environment variables)
 704:   - Eliminates need for manual password file management
 705: 
 706: - **Unified application setup script**
 707:   - New `setup-application.sh` script consolidates all application deployment
 708:   steps
 709:   - Handles role assumption, backend configuration, Terraform operations, and
 710:   Kubernetes environment setup
 711:   - Automatically retrieves all required secrets and variables from GitHub
 712:   - Replaces previous `setup-backend.sh` and `setup-backend-api.sh` scripts
 713:   - Includes comprehensive error handling and user guidance
 714: 
 715: ### Removed
 716: 
 717: - **Legacy setup scripts**
 718:   - Removed `setup-backend.sh` (replaced by unified `setup-application.sh`)
 719:   - Removed `setup-backend-api.sh` (replaced by unified `setup-application.sh`)
 720:   - Consolidated functionality improves maintainability and reduces complexity
 721: 
 722: ### Fixed
 723: 
 724: - Corrected documentation to reflect new password management via GitHub
 725: repository secrets
 726:   - Updated README.md with accurate password setup instructions
 727:   - Clarified local vs. GitHub Actions execution differences
 728: 
 729: ## [2025-12-10] - Ingress Configuration Updates
 730: 
 731: ### Changed
 732: 
 733: - **Moved certificate ARN and group name to IngressClassParams (cluster-wide
 734: configuration)**
 735:   - Certificate ARN (`certificateARNs`) is now configured in IngressClassParams
 736:   instead of Ingress annotations
 737:   - ALB group name (`group.name`) is now configured in IngressClassParams
 738:   instead of Ingress annotations
 739:   - This centralizes TLS and group configuration at the cluster level, reducing
 740:   annotation duplication
 741:   - Updated `modules/alb/main.tf` to include `certificateARNs` and `group.name`
 742:   in IngressClassParams
 743:   - Updated Helm values template to remove `group.name` and `certificate-arn`
 744:   from Ingress annotations
 745:   - All Ingresses now use the same annotations (no leader/secondary distinction
 746:   needed for group/certificate config)
 747:   - Updated documentation in `PRD-ALB.md` and `README.md` to reflect new
 748:   annotation strategy
 749: 
 750: ### Verified
 751: 
 752: - Multi-ingress single ALB configuration is correctly implemented with EKS Auto
 753: Mode
 754:   - Both Ingresses share the same ALB via `group.name` configured in
 755:   IngressClassParams
 756:   - Certificate ARN configured once in IngressClassParams (cluster-wide)
 757:   - `load-balancer-name` annotation on both Ingresses (per-Ingress setting)
 758:   - Per-Ingress settings (target-type, listen-ports, ssl-redirect) configured in
 759:   Ingress annotations
 760:   - Cluster-wide defaults (`scheme`, `ipAddressType`, `group.name`,
 761:   `certificateARNs`) inherited from IngressClassParams
 762: 
 763: ## [2025-12-08] - ALB and TLS Configuration Updates
 764: 
 765: ### Changed
 766: 
 767: - **Migrated from AWS Load Balancer Controller to EKS Auto Mode**
 768:   - Updated ALB controller from `alb.ingress.kubernetes.io` to
 769:   `eks.amazonaws.com/alb`
 770:   - Changed IngressClassParams API group from `elbv2.k8s.aws` to
 771:   `eks.amazonaws.com`
 772:   - EKS Auto Mode provides built-in load balancer driver (no separate controller
 773:   installation needed)
 774:   - IAM permissions are automatically handled by EKS Auto Mode (no manual policy
 775:   attachment required)
 776:   - Updated `modules/alb/main.tf` to use EKS Auto Mode controller and API group
 777: 
 778: - **Improved ALB naming with separate group name and load balancer name**
 779:   - Added distinction between `alb_group_name` (Kubernetes identifier, max 63
 780:   chars) and `alb_load_balancer_name` (AWS resource name, max 32 chars)
 781:   - Added automatic truncation logic to ensure names don't exceed Kubernetes (63
 782:   chars) and AWS (32 chars) limits
 783:   - Updated `main.tf` to handle name concatenation with prefix, region, and env,
 784:   with proper truncation
 785:   - Added `alb_load_balancer_name` variable to `variables.tf` with proper
 786:   description
 787:   - Updated Helm values template to use `alb_load_balancer_name` for AWS ALB
 788:   name annotation
 789: 
 790: - **Optimized Ingress annotations to minimize duplication** (superseded by
 791: cluster-wide IngressClassParams configuration)
 792:   - Certificate ARN and group name moved to IngressClassParams (see latest
 793:   changes above)
 794:   - Ingress annotations now only contain per-Ingress settings
 795:   (load-balancer-name, target-type, listen-ports, ssl-redirect)
 796: 
 797: - Updated TLS environment variables in `helm/openldap-values.tpl.yaml` to match
 798: osixia/openldap image requirements
 799:   - Changed `LDAP_TLS_CERT_FILE`  `LDAP_TLS_CRT_FILENAME` (filename only, not
 800:   full path)
 801:   - Changed `LDAP_TLS_KEY_FILE`  `LDAP_TLS_KEY_FILENAME` (filename only, not
 802:   full path)
 803:   - Changed `LDAP_TLS_CA_FILE`  `LDAP_TLS_CA_CRT_FILENAME` (filename only, not
 804:   full path)
 805:   - Added explicit `LDAP_TLS: "true"` to enable TLS
 806:   - Updated comments to clarify osixia/openldap-specific behavior
 807: 
 808: ### Added
 809: 
 810: - **New variable `alb_load_balancer_name`** for custom AWS ALB naming
 811:   - Allows separate control over Kubernetes group identifier vs AWS resource
 812:   name
 813:   - Supports AWS naming constraints (max 32 characters)
 814:   - Defaults to `alb_group_name` (truncated to 32 chars if needed)
 815: 
 816: - **Comprehensive documentation updates in `PRD-ALB.md`**
 817:   - Added detailed explanation of EKS Auto Mode vs AWS Load Balancer Controller
 818:   differences
 819:   - Added comparison table highlighting key differences between the two
 820:   approaches
 821:   - Documented IngressClassParams limitations (only `scheme` and `ipAddressType`
 822:   supported in EKS Auto Mode)
 823:   - Clarified annotation strategy and inheritance patterns
 824:   - Added implementation details section explaining Terraform and Helm chart
 825:   responsibilities
 826: 
 827: ### Fixed
 828: 
 829: - Fixed TLS configuration compatibility issue between Helm chart (designed for
 830: Bitnami) and osixia/openldap image
 831:   - osixia/openldap uses different environment variable names than Bitnami
 832:   OpenLDAP
 833:   - Certificates are now referenced by filename only (not full paths)
 834:   - osixia/openldap will auto-generate self-signed certificates if they don't
 835:   exist
 836: 
 837: ## [2025-12-02] - Initial Configuration
 838: 
 839: ### Added
 840: 
 841: - Initial OpenLDAP deployment using osixia/openldap:1.5.0 image
 842: - Helm chart from jp-gouin/helm-openldap (version 4.0.1)
 843: - Multi-master replication configuration (3 replicas)
 844: - Persistent storage with EBS volumes (8Gi, ReadWriteOnce)
 845: - ALB configuration with IngressGroup for multiple Ingresses
 846: - TLS termination at ALB using ACM certificates
 847: - Two Ingress resources:
 848:   - phpldapadmin.talorlik.com  phpLDAPadmin service
 849:   - passwd.talorlik.com  ltb-passwd service
 850: - Route53 DNS records for both hostnames pointing to ALB
 851: 
 852: ### Configuration Details
 853: 
 854: - **Image**: osixia/openldap:1.5.0 (overriding chart's default Bitnami image)
 855: - **Replication**: Multi-master replication enabled
 856: - **Storage**: Persistent volumes with gp3 storage class
 857: - **ALB**: Internet-facing, IP target type, TLS 1.2/1.3 only
 858: - **TLS**: Auto-generated certificates for internal communication, ACM
 859: certificates for ALB
 860: 
 861: ## Planned Changes
 862: 
 863: ### [Future] - Custom Certificate Support
 864: 
 865: - [ ] Add support for mounting custom TLS certificates from Kubernetes Secrets
 866: - [ ] Implement cert-manager integration for automatic certificate management
 867: - [ ] Add documentation for using ACM certificates with OpenLDAP
 868: 
 869: ### [Future] - Security Enhancements
 870: 
 871: - [ ] Enforce TLS for all LDAP connections (`LDAP_TLS_ENFORCE: "true"`)
 872: - [ ] Implement client certificate verification for enhanced security
 873: - [x] ~~Add network policies for stricter pod-to-pod communication~~ (Completed
 874: 2025-12-14)
 875: 
 876: ### [Future] - Monitoring and Observability
 877: 
 878: - [ ] Add Prometheus metrics export for OpenLDAP
 879: - [ ] Implement logging aggregation for LDAP operations
 880: - [ ] Add health check endpoints for better monitoring
 881: 
 882: ### [Future] - High Availability Improvements
 883: 
 884: - [ ] Evaluate read-only replica configuration
 885: - [ ] Implement backup automation for LDAP data
 886: - [ ] Add disaster recovery procedures
 887: 
 888: ### [Future] - GitOps Enhancements
 889: 
 890: - [x] ~~Implement ArgoCD for GitOps deployments~~ (Completed 2025-12-16)
 891: - [ ] Add ApplicationSet for multi-cluster deployments
 892: - [ ] Implement progressive delivery with Argo Rollouts
 893: 
 894: ### [Future] - 2FA Application Enhancements
 895: 
 896: - [x] ~~Implement 2FA application with TOTP support~~ (Completed 2025-12-18)
 897: - [x] ~~Add SMS-based verification via AWS SNS~~ (Completed 2025-12-18)
 898: - [x] ~~Replace in-memory SMS OTP storage with Redis~~ (Completed 2025-12-18)
 899: - [x] ~~Add self-service user signup with email/phone verification~~ (Completed
 900: 2025-12-18)
 901: - [x] ~~Implement admin dashboard for user management~~ (Completed 2025-12-18)
 902: - [x] ~~Add group management and user-group assignment~~ (Completed 2025-12-18)
 903: - [x] ~~Add user profile management~~ (Completed 2025-12-18)
 904: - [ ] Add email-based MFA verification option
 905: - [ ] Implement backup codes for account recovery
 906: - [ ] Add rate limiting for authentication attempts
 907: - [ ] Add password reset functionality
 908: 
 909: ## Verification Steps
 910: 
 911: After applying changes, verify the configuration:
 912: 
 913: ### TLS Configuration Verification
 914: 
 915: ```bash
 916: kubectl get configmap -n ldap openldap-stack-ha-openldap-env -o yaml | grep LDAP_TLS
 917: ```
 918: 
 919: Expected output:
 920: 
 921: - `LDAP_TLS: "true"`
 922: - `LDAP_TLS_CRT_FILENAME: "ldap.crt"`
 923: - `LDAP_TLS_KEY_FILENAME: "ldap.key"`
 924: - `LDAP_TLS_CA_CRT_FILENAME: "ca.crt"`
 925: 
 926: ### ALB Configuration Verification
 927: 
 928: ```bash
 929: kubectl get ingress -n ldap
 930: kubectl describe ingress -n ldap openldap-stack-ha-ltb-passwd
 931: kubectl describe ingress -n ldap openldap-stack-ha-phpldapadmin
 932: ```
 933: 
 934: Both Ingresses should:
 935: 
 936: - Use the same IngressClass (which references IngressClassParams with
 937: `group.name` and `certificateARNs`)
 938: - Point to the same ALB DNS name
 939: - Have the same `alb.ingress.kubernetes.io/load-balancer-name` annotation
 940: 
 941: ### TLS Connection Testing
 942: 
 943: ```bash
 944: # Test LDAPS connection (port 636)
 945: ldapsearch -x -H ldaps://openldap-stack-ha-openldap-0.openldap-stack-ha-openldap-headless.ldap.svc.cluster.local:636 -b dc=example,dc=org -D "cn=admin,dc=example,dc=org" -w <password>
 946: 
 947: # Test LDAP connection (port 389)
 948: ldapsearch -x -H ldap://openldap-stack-ha-openldap-0.openldap-stack-ha-openldap-headless.ldap.svc.cluster.local:389 -b dc=example,dc=org -D "cn=admin,dc=example,dc=org" -w <password>
 949: ```
 950: 
 951: ### ALB TLS Verification
 952: 
 953: ```bash
 954: # Check ALB listeners
 955: aws elbv2 describe-listeners --load-balancer-arn <alb-arn>
 956: ```
 957: 
 958: Expected:
 959: 
 960: - HTTP listener on port 80 (redirecting to HTTPS)
 961: - HTTPS listener on port 443 with ACM certificate
 962: 
 963: ## Notes
 964: 
 965: ### Certificate Auto-Generation
 966: 
 967: osixia/openldap will automatically generate self-signed certificates on first
 968: startup if they don't exist. These certificates:
 969: 
 970: -  Work for internal cluster communication
 971: -  Enable LDAPS (port 636)
 972: -  Won't be trusted by external clients (self-signed)
 973: -  Will be regenerated if the container is recreated without persistent
 974: storage
 975: 
 976: ### Using Custom Certificates
 977: 
 978: To use custom certificates (e.g., from cert-manager or ACM):
 979: 
 980: 1. Create a Kubernetes Secret:
 981: 
 982:     ```bash
 983:     kubectl create secret generic openldap-tls-certs \
 984:       --from-file=ldap.crt=/path/to/cert.pem \
 985:       --from-file=ldap.key=/path/to/key.pem \
 986:       --from-file=ca.crt=/path/to/ca.pem \
 987:       -n ldap
 988:     ```
 989: 
 990: 2. Add volume mounts to Helm values:
 991: 
 992:     ```yaml
 993:     extraVolumes:
 994:       - name: tls-certs
 995:         secret:
 996:           secretName: openldap-tls-certs
 997: 
 998:     extraVolumeMounts:
 999:       - name: tls-certs
1000:         mountPath: /container/service/slapd/assets/certs
1001:         readOnly: true
1002:     ```
1003: 
1004: ### Multi-Ingress Single ALB
1005: 
1006: The configuration implements a single ALB with multiple Ingresses:
1007: 
1008: -  Both Ingresses share the same `group.name` (configured in
1009: IngressClassParams)
1010: -  Certificate ARN configured once in IngressClassParams (cluster-wide)
1011: -  `load-balancer-name` annotation on both Ingresses (per-Ingress setting)
1012: -  Per-Ingress settings (target-type, listen-ports, ssl-redirect) in Ingress
1013: annotations
1014: -  Host-based routing (different hosts for each service)
1015: 
1016: The ALB routes traffic based on the `Host` header:
1017: 
1018: - `phpldapadmin.talorlik.com`  phpLDAPadmin service
1019: - `passwd.talorlik.com`  ltb-passwd service
1020: 
1021: ## References
1022: 
1023: - [osixia/openldap GitHub](https://github.com/osixia/docker-openldap)
1024: - [osixia/openldap TLS Documentation](https://github.com/osixia/docker-openldap#tls)
1025: - [AWS Load Balancer Controller IngressGroups](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/guide/ingress/annotations/#ingressgroup)
1026: - [jp-gouin/helm-openldap GitHub](https://github.com/jp-gouin/helm-openldap)
1027: - [Keep a Changelog](https://keepachangelog.com/)
1028: - [Semantic Versioning](https://semver.org/)
````

## File: README.md
````markdown
  1: # ldap-2fa-on-k8s
  2: 
  3: LDAP authentication with 2FA deployed on Kubernetes (EKS)
  4: 
  5: This project deploys a complete LDAP authentication solution with two-factor
  6: authentication (2FA), self-service password management, and GitOps capabilities
  7: on Amazon EKS using Terraform. The infrastructure includes:
  8: 
  9: **Core Infrastructure:**
 10: 
 11: - **EKS Cluster** (Auto Mode) with IRSA for secure pod-to-AWS-service
 12: authentication
 13: - **VPC** with public/private subnets and VPC endpoints for private AWS service
 14: access
 15: - **Application Load Balancer (ALB)** via EKS Auto Mode for internet-facing
 16: access
 17: - **Route53 DNS** integration for domain management
 18: - **ACM Certificates** for HTTPS/TLS termination
 19: 
 20: **LDAP Stack:**
 21: 
 22: - **OpenLDAP Stack** with high availability and multi-master replication
 23: - **PhpLdapAdmin** web interface for LDAP administration
 24: - **LTB-passwd** self-service password management UI
 25: 
 26: **2FA Application:**
 27: 
 28: - **Full-stack 2FA application** with Python FastAPI backend and static
 29: HTML/JS/CSS frontend
 30: - **Dual MFA methods**: TOTP (authenticator apps) and SMS (AWS SNS)
 31: - **LDAP integration** for centralized user authentication
 32: - **Self-service user registration** with email/phone verification
 33: - **Admin dashboard** for user management, group CRUD, and approval workflows
 34: 
 35: **Supporting Infrastructure:**
 36: 
 37: - **PostgreSQL** for user registration and verification token storage
 38: - **Redis** for SMS OTP code storage with TTL-based expiration
 39: - **AWS SES** for email verification and notifications
 40: - **AWS SNS** for SMS-based 2FA verification
 41: 
 42: **DevOps & Security:**
 43: 
 44: - **ArgoCD** (AWS EKS managed service) for GitOps deployments
 45: - **cert-manager** for automatic TLS certificate management
 46: - **Network Policies** for securing pod-to-pod communication
 47: - **IRSA** (IAM Roles for Service Accounts) for secure AWS API access from pods
 48: 
 49: ## Prerequisites
 50: 
 51: - AWS Account(s) with appropriate permissions
 52:   - **State Account (Account A)**: For Terraform state storage (S3)
 53:   - **Deployment Account (Account B)**: For infrastructure resources (EKS, ALB,
 54:   Route53, etc.)
 55: - GitHub Account
 56: - Fork the repository:
 57: [ldap-2fa-on-k8s](https://github.com/talorlik/ldap-2fa-on-k8s.git)
 58: - AWS SSO/OIDC configured (see [GitHub Repository
 59: Configuration](#github-repository-configuration))
 60: - Route53 hosted zone must already exist (or create it manually)
 61: - **Public ACM Certificate Setup**: Public ACM certificates must be requested in
 62:   each deployment account and validated using DNS records in the State Account's
 63:   Route53 hosted zone. See [Public ACM Certificate Setup and DNS Validation](application/CROSS-ACCOUNT-ACCESS.md#public-acm-certificate-setup-and-dns-validation)
 64:   for detailed setup instructions with step-by-step AWS CLI commands.
 65: - ACM certificate must already exist and be validated in the same region as the
 66:   EKS cluster
 67:   - Certificate must be a public ACM certificate (Amazon-issued) requested in
 68:     the Deployment Account
 69:   - Certificate must exist in the Deployment Account (not State Account)
 70:   - Certificate must be validated and in `ISSUED` status
 71:   - DNS validation records must be created in Route53 hosted zone in the State
 72:     Account
 73:   - See [Cross-Account Access Documentation](application/CROSS-ACCOUNT-ACCESS.md)
 74:     for details
 75: - **Docker (for Local Deployment)**: Docker must be installed and running for
 76:   ECR image mirroring. The `mirror-images-to-ecr.sh` script requires Docker to
 77:   pull images from Docker Hub and push them to ECR. This step is automatically
 78:   executed by `setup-application.sh` before Terraform operations.
 79: - **jq (for Local Deployment)**: The `jq` command-line tool is required for
 80:   JSON parsing in the image mirroring script (with fallback to sed for
 81:   compatibility).
 82: - **ECR Image Tags**: Images are mirrored to ECR with standardized tags:
 83:   - `redis-latest` (corresponds to `bitnami/redis:8.4.0-debian-12-r6`)
 84:   - `postgresql-latest` (corresponds to `bitnami/postgresql:18.1.0-debian-12-r4`)
 85:   - `openldap-1.5.0` (corresponds to `osixia/openldap:1.5.0`)
 86: 
 87: ## Project Structure
 88: 
 89: ```text
 90: ldap-2fa-on-k8s/
 91:  SECRETS_REQUIREMENTS.md  # Secrets management documentation (AWS Secrets Manager & GitHub Secrets)
 92:  tf_backend_state/      # Terraform state backend infrastructure (S3) - Account A
 93:  backend_infra/         # Core AWS infrastructure (VPC, EKS, VPC endpoints, IRSA) - Account B
 94:  application/           # Application infrastructure and deployments - Account B
 95:     backend/           # 2FA Backend (Python FastAPI)
 96:     frontend/          # 2FA Frontend (HTML/JS/CSS + nginx)
 97:     helm/              # Helm values for OpenLDAP stack
 98:     modules/           # Terraform modules (ALB, ArgoCD, SNS, cert-manager, etc.)
 99:  .github/workflows/     # GitHub Actions workflows for CI/CD
100: ```
101: 
102: For detailed information about each component, see:
103: 
104: - [Terraform Backend State](tf_backend_state/README.md) - S3 state management
105:   with file-based locking (v1.0.0), AWS provider 6.21.0, Terraform 1.14.0
106: - [Backend Infrastructure](backend_infra/README.md) - VPC, EKS, IRSA, VPC
107:   endpoints
108: - [Application Infrastructure](application/README.md) - OpenLDAP, 2FA app,
109:   ArgoCD
110: 
111: ## Multi-Account Architecture
112: 
113: This project uses a **multi-account architecture** for enhanced security:
114: 
115: - **Account A (State Account)**: Stores Terraform state files in S3
116:   - S3 bucket with versioning enabled and server-side encryption (AES256)
117:   - S3 file-based locking (`use_lockfile = true`) for state file
118:     concurrency control
119:   - IAM-based access control with OIDC authentication (no access keys
120:     required)
121:   - GitHub Actions authenticates with Account A for backend operations
122:   - Provides isolation between state storage and resource deployment
123: 
124: - **Account B (Deployment Account)**: Contains all infrastructure resources
125:   - EKS cluster, VPC, ALB, Route53, and other AWS resources
126:   - Terraform provider assumes Account B role via cross-account role assumption
127:   - Provides isolation and separation of concerns
128: 
129: ### How It Works
130: 
131: 1. **GitHub Actions** assumes Account A role (via OIDC) for Terraform backend
132: access
133: 2. **Terraform backend** uses Account A credentials to read/write state files
134: 3. **Terraform AWS provider** assumes Account B role (via `assume_role`) for
135: resource deployment
136: 4. **Remote state** data sources use Account A credentials to read state from
137: Account A
138: 
139: This architecture ensures:
140: 
141: - State files are isolated in a dedicated account
142: - Resource deployment uses separate credentials
143: - Enhanced security through account separation
144: - Better compliance and audit capabilities
145: 
146: ## GitHub Repository Configuration
147: 
148: ### AWS SSO/OIDC Setup
149: 
150: This project uses **AWS SSO via GitHub OIDC** instead of access keys for
151: enhanced security.
152: 
153: #### AWS IAM Setup
154: 
155: **Account A (State Account):**
156: 
157: ##### Step 1: Create OIDC Identity Provider
158: 
159: The OIDC Identity Provider establishes trust between GitHub Actions and AWS,
160: allowing GitHub to authenticate without access keys.
161: 
162: 1. **Navigate to IAM Console**:
163:    - Go to AWS IAM Console  **Identity providers** (left sidebar)
164:    - Click **Add provider**
165: 
166: 2. **Configure Provider**:
167:    - Select **OpenID Connect**
168:    - **Provider URL**: `https://token.actions.githubusercontent.com`
169:    - Click **Get thumbprint** (AWS will automatically fetch GitHub's certificate
170:    thumbprint)
171:    - **Audience**: `sts.amazonaws.com`
172:    - Click **Add provider**
173: 
174: 3. **Verify Creation**:
175:    - You should see the provider listed with ARN format:
176:    `arn:aws:iam::ACCOUNT_A_ID:oidc-provider/token.actions.githubusercontent.com`
177:    - Note this ARN - you'll need it for the role trust policy
178: 
179: ##### Step 2: Create IAM Role and Assign to Identity Provider
180: 
181: Now create an IAM Role that uses this Identity Provider for authentication.
182: 
183: 1. **Navigate to IAM Roles**:
184:    - Go to AWS IAM Console  **Roles** (left sidebar)
185:    - Click **Create role**
186: 
187: 2. **Select Trusted Entity Type**:
188:    - Under **Trusted entity type**, select **Web identity**
189:    - Under **Web identity**, select the Identity Provider you just created:
190:    `token.actions.githubusercontent.com`
191:    - **Audience**: Select `sts.amazonaws.com` from the dropdown
192:    - Click **Next**
193: 
194: 3. **Configure Trust Policy Conditions** (Optional but Recommended):
195:    - Click **Add condition** to restrict which repositories can assume this role
196:    - **Condition key**: `token.actions.githubusercontent.com:sub`
197:    - **Operator**: `StringLike`
198:    - **Value**: `repo:YOUR_ORG/YOUR_REPO:*` (replace `YOUR_ORG/YOUR_REPO` with
199:    your GitHub organization and repository name)
200:      - Example: `repo:talorlik/ldap-2fa-on-k8s:*`
201:    - This ensures only workflows from your specific repository can assume the
202:    role
203:    - Click **Next**
204: 
205: 4. **Add Permissions**:
206:    - Create or attach a policy with S3 permissions for the state bucket
207:    - **Minimum required permissions**:
208: 
209:      ```json
210:      {
211:        "Version": "2012-10-17",
212:        "Statement": [
213:          {
214:            "Effect": "Allow",
215:            "Action": [
216:              "s3:GetObject",
217:              "s3:PutObject",
218:              "s3:DeleteObject",
219:              "s3:ListBucket"
220:            ],
221:            "Resource": [
222:              "arn:aws:s3:::your-state-bucket-name",
223:              "arn:aws:s3:::your-state-bucket-name/*"
224:            ]
225:          }
226:        ]
227:      }
228:      ```
229: 
230:    - For initial setup, you can use a broader policy and restrict it later once
231:    you know the exact bucket name
232:    - Click **Next**
233: 
234: 5. **Name and Create Role**:
235:    - **Role name**: `github-actions-state-role` (or your preferred name)
236:    - **Description**: "Role for GitHub Actions to access Terraform state bucket"
237:    - Click **Create role**
238: 
239: 6. **Copy Role ARN**:
240:    - After creation, click on the role name
241:    - Copy the **Role ARN** (format:
242:    `arn:aws:iam::STATE_ACCOUNT_ID:role/github-actions-state-role`)
243:    - Set this as the `AWS_STATE_ACCOUNT_ROLE_ARN` secret in GitHub
244: 
245: **Important Notes:**
246: 
247: - The Identity Provider must be created **before** the IAM Role
248: - The IAM Role's trust policy automatically references the Identity Provider you
249: selected
250: - The condition on `token.actions.githubusercontent.com:sub` restricts access to
251: your specific repository
252: - You can update the trust policy later to add more repositories or adjust
253: conditions
254: 
255: **Account B (Production/Development Accounts):**
256: 
257: For each deployment account (Production and Development), create separate IAM
258: roles:
259: 
260: 1. **Production Account**: Create an IAM Role that trusts the State Account
261: role:
262: 
263:    ```json
264:    {
265:      "Version": "2012-10-17",
266:      "Statement": [
267:        {
268:          "Effect": "Allow",
269:          "Principal": {
270:            "AWS": "arn:aws:iam::STATE_ACCOUNT_ID:role/github-actions-state-role"
271:          },
272:          "Action": "sts:AssumeRole",
273:          "Condition": {
274:            "StringEquals": {
275:              "sts:ExternalId": "<generated-external-id>"
276:            }
277:          }
278:        }
279:      ]
280:    }
281:    ```
282: 
283:    Replace `<generated-external-id>` with the ExternalId value (generate using
284:    `openssl rand -hex 32`). This ExternalId must match the value stored in
285:    `AWS_ASSUME_EXTERNAL_ID` secret (for GitHub Actions) or AWS Secrets Manager
286:    (for local deployment).
287: 
288: 2. Attach permissions policy with full resource deployment permissions
289: 
290: 3. Copy the role ARN  Set as `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` secret
291: 
292: 4. **Development Account**: Repeat steps 1-3 for the Development account
293: 
294: 5. Copy the Development account role ARN  Set as
295: `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` secret
296: 
297: #### State Account Role Trust Relationship Update
298: 
299: > [!IMPORTANT]
300: >
301: > In addition to the deployment account roles trusting the state account role, the
302: > state account role's Trust Relationship must also be updated to allow the
303: > deployment account roles. This bidirectional trust is required for proper
304: > cross-account role assumption.
305: >
306: > **Note:** The ExternalId security mechanism is still required when the state
307: > account role assumes deployment account roles. The ExternalId condition must be
308: > present in the deployment account roles' Trust Relationships (as documented
309: > above), and the state account role must provide the ExternalId when assuming
310: > those roles.
311: 
312: Update the state account role's (`github-actions-state-role`) Trust Relationship
313: to include the deployment account roles:
314: 
315: 1. Navigate to the state account role in IAM Console
316: 2. Go to **Trust relationships** tab
317: 3. Click **Edit trust policy**
318: 4. Add the deployment account role ARNs to the trust policy:
319: 
320:    ```json
321:    {
322:      "Version": "2012-10-17",
323:      "Statement": [
324:        {
325:          "Effect": "Allow",
326:          "Principal": {
327:            "Federated": "arn:aws:iam::STATE_ACCOUNT_ID:oidc-provider/token.actions.githubusercontent.com"
328:          },
329:          "Action": "sts:AssumeRoleWithWebIdentity",
330:          "Condition": {
331:            "StringLike": {
332:              "token.actions.githubusercontent.com:sub": "repo:YOUR_ORG/YOUR_REPO:*"
333:            }
334:          }
335:        },
336:        {
337:          "Effect": "Allow",
338:          "Principal": {
339:            "AWS": [
340:              "arn:aws:iam::PRODUCTION_ACCOUNT_ID:role/github-role",
341:              "arn:aws:iam::DEVELOPMENT_ACCOUNT_ID:role/github-role",
342:              "arn:aws:iam::STATE_ACCOUNT_ID:role/github-role"
343:            ]
344:          },
345:          "Action": "sts:AssumeRole"
346:        }
347:      ]
348:    }
349:    ```
350: 
351:    Replace `PRODUCTION_ACCOUNT_ID` and `DEVELOPMENT_ACCOUNT_ID` with your actual
352:    account IDs, and `github-role` with your actual deployment role names.
353: 
354:    > [!IMPORTANT]
355:    >
356:    > **Self-Assumption Statement**: The last statement allows the role to assume
357:    > itself. This is required when:
358:    > - The State Account role is used for both backend state operations and
359:    > Route53/ACM access
360:    > - Terraform providers need to assume the same role that was already assumed
361:    > by the initial authentication
362:    > - You encounter errors like "User: arn:aws:sts::ACCOUNT_ID:assumed-role/github-role/SESSION
363:    > is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::ACCOUNT_ID:role/github-role"
364: 
365: 5. Click **Update policy**
366: 
367: > [!NOTE]
368: >
369: > Remember that the deployment account roles' Trust Relationships must still
370: > include the ExternalId condition (as shown in step 1 above), and the state
371: > account role must provide this ExternalId when assuming the deployment account
372: > roles. The ExternalId is retrieved from `AWS_ASSUME_EXTERNAL_ID` secret (for
373: > GitHub Actions) or AWS Secrets Manager (for local deployment).
374: 
375: > [!NOTE]
376: >
377: > - The State Account role (`AWS_STATE_ACCOUNT_ROLE_ARN`) is used for backend
378: state operations (S3)
379: > - The Production/Development roles are used by the Terraform provider via
380: `assume_role` for resource deployment
381: > - The workflow automatically selects the appropriate deployment role ARN based
382: on whether `prod` or `dev` environment is chosen
383: > - For single-account setups, you can use the same role ARN for state and
384: deployment, but multi-account is recommended for better security isolation
385: > - **Bidirectional Trust**: Both the deployment account roles and the state
386: account role must trust each other in their respective Trust Relationships
387: 
388: ## Secrets Configuration
389: 
390: **Required Secret Values:**
391: 
392: - `AWS_STATE_ACCOUNT_ROLE_ARN` - IAM role ARN for state account (backend operations)
393: - `AWS_PRODUCTION_ACCOUNT_ROLE_ARN` - IAM role ARN for production deployments
394: - `AWS_DEVELOPMENT_ACCOUNT_ROLE_ARN` - IAM role ARN for development deployments
395: - `AWS_ASSUME_EXTERNAL_ID` - ExternalId for cross-account role assumption security
396: (must match value in deployment account role Trust Relationship)
397: - `TF_VAR_OPENLDAP_ADMIN_PASSWORD` - OpenLDAP admin password
398: - `TF_VAR_OPENLDAP_CONFIG_PASSWORD` - OpenLDAP config password
399: - `TF_VAR_POSTGRESQL_PASSWORD` - PostgreSQL database password
400: - `TF_VAR_REDIS_PASSWORD` - Redis password (minimum 8 characters)
401: - `GH_TOKEN` - GitHub Personal Access Token with `repo` scope
402: 
403: > [!IMPORTANT]
404: >
405: > Read the complete secrets configuration details here [Secrets Requirements](SECRETS_REQUIREMENTS.md).
406: 
407: ### For GitHub Actions
408: 
409: Configure these secrets in your GitHub repository:
410: **Repository  Settings  Secrets and variables  Actions  Secrets**
411: 
412: ### For Local Development
413: 
414: - Store secrets in AWS Secrets Manager (scripts automatically retrieve them)
415: - **ExternalId**: Store as plain text secret named `external-id` in
416: AWS Secrets Manager
417:   - Generate using: `openssl rand -hex 32`
418:   - Must match the ExternalId in deployment account role Trust Relationships
419: 
420: ## Deployment Methods
421: 
422: This project supports two deployment methods: **GitHub Actions** (recommended)
423: and **Local Development** (for testing and development).
424: Both methods follow the same three-tier deployment approach.
425: 
426: ### Deployment Overview
427: 
428: The deployment follows a three-tier approach that must be executed in order:
429: 
430: 1. **Terraform Backend State Infrastructure** - S3 state storage (Account A)
431: 2. **Backend Infrastructure** - VPC, EKS, VPC endpoints, IRSA, ECR (Account B)
432: 3. **Application Infrastructure** - OpenLDAP, 2FA app, ALB, Route53, ArgoCD
433: (Account B)
434: 
435: > [!IMPORTANT]
436: >
437: > Before deploying, ensure:
438: >
439: > - Route53 hosted zone exists for your domain
440: > - ACM certificate exists and is validated in the same region as your EKS cluster
441: > - Secrets are configured (see [Secrets Configuration](#secrets-configuration))
442: 
443: ### Method 1: GitHub Actions (CI/CD)
444: 
445: Deploy infrastructure using GitHub Actions workflows for automated, repeatable deployments.
446: 
447: #### Step 1. Deploy Terraform Backend State Infrastructure
448: 
449: Run the `tfstate_infra_provisioning.yaml` workflow via the GitHub UI.
450: 
451: > [!NOTE]
452: >
453: >  **For detailed setup instructions**, including required GitHub Secrets,
454: > Variables, and configuration, see the [Terraform Backend State README](tf_backend_state/README.md).
455: 
456: > [!IMPORTANT]
457: >
458: > Make sure to alter the values in `variables.tfvars` according to your setup
459: > and commit and push them.
460: 
461: #### Step 2. Deploy Backend Infrastructure
462: 
463: Deploy the main backend infrastructure (VPC, EKS cluster, VPC endpoints, IRSA, ECR).
464: 
465: This creates the foundational infrastructure including:
466: 
467: - VPC with public/private subnets
468: - EKS cluster with Auto Mode
469: - IRSA (OIDC provider for pod IAM roles)
470: - VPC endpoints (SSM, STS, and optionally SNS for SMS 2FA)
471: - ECR repository for container images
472: 
473: > [!NOTE]
474: >
475: >  **For detailed information about the backend infrastructure**, including
476: > architecture, components, and module documentation,
477: > see the [Backend Infrastructure README](backend_infra/README.md).
478: 
479: > [!IMPORTANT]
480: >
481: > For SMS 2FA functionality, the SNS VPC endpoint must be enabled in
482: > backend_infra (`enable_sns_endpoint = true`). See [Backend Infrastructure
483: > README](backend_infra/README.md#vpc-endpoints-module) for details.
484: 
485: #### Step 3. Deploy Application Infrastructure
486: 
487: Deploy the application infrastructure (OpenLDAP stack, 2FA application, ALB,
488: Route53 records, and optionally ArgoCD).
489: 
490: This deploys:
491: 
492: - OpenLDAP Stack HA with PhpLdapAdmin and LTB-passwd
493: - 2FA Application (backend + frontend) with TOTP and SMS support
494: - ALB with host-based routing for all services
495: - cert-manager for TLS certificates
496: - Network policies for security
497: - ArgoCD for GitOps (optional)
498: - SNS resources for SMS 2FA (optional)
499: 
500: > [!NOTE]
501: >
502: >  **For detailed information about the application infrastructure**, including
503: > OpenLDAP configuration, 2FA app setup, ALB configuration, and deployment steps,
504: > see the [Application Infrastructure README](application/README.md).
505: 
506: ### Method 2: Local Development
507: 
508: Deploy infrastructure locally using automated setup scripts that handle configuration,
509: secrets retrieval, and Terraform operations.
510: 
511: #### Prerequisites
512: 
513: - GitHub CLI (`gh`) installed and authenticated
514: - AWS CLI configured with appropriate permissions
515: - Secrets stored in AWS Secrets Manager (see [Secrets Requirements](SECRETS_REQUIREMENTS.md))
516: 
517: #### Step 1. Deploy Terraform Backend State Infrastructure
518: 
519: For local deployment of `tf_backend_state`, use the provided automation scripts:
520: 
521: ```bash
522: cd tf_backend_state
523: ./set-state.sh  # For initial deployment
524: # or
525: ./get-state.sh  # For subsequent operations
526: ```
527: 
528: These scripts automatically handle:
529: 
530: - Role assumption for Account A
531: - Terraform operations
532: - State file management
533: - Repository variable updates
534: 
535: The scripts retrieve `AWS_STATE_ACCOUNT_ROLE_ARN` from AWS Secrets Manager and
536: assume the role automatically.
537: 
538: > [!NOTE]
539: >
540: >  See [Terraform Backend State README](tf_backend_state/README.md#option-2-local-execution)
541: > for detailed instructions.
542: 
543: #### Step 2. Deploy Backend Infrastructure
544: 
545: ```bash
546: cd backend_infra
547: ./setup-backend.sh
548: ```
549: 
550: The script will:
551: 
552: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
553: - Retrieve repository variables from GitHub
554: - Retrieve role ARNs from AWS Secrets Manager
555: - Generate `backend.hcl` from template (automatically ignored by git)
556: - Update `variables.tfvars` with selected region, environment, and deployment
557: account role ARN
558: - Run Terraform commands (init, workspace, validate, plan, apply) automatically
559: 
560: > [!NOTE]
561: >
562: > The generated `backend.hcl` file is automatically ignored by git.
563: > Only the placeholder template (`tfstate-backend-values-template.hcl`) is committed
564: > to the repository.
565: 
566: > [!IMPORTANT]
567: >
568: > For SMS 2FA functionality, ensure `enable_sns_endpoint = true` is set in
569: > `backend_infra/variables.tfvars` before deploying. See [Backend Infrastructure
570: > README](backend_infra/README.md#vpc-endpoints-module) for details.
571: 
572: #### Step 3. Deploy Application Infrastructure
573: 
574: ```bash
575: cd application
576: ./setup-application.sh
577: ```
578: 
579: The script will:
580: 
581: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
582: - Retrieve repository variables from GitHub
583: - Retrieve role ARNs and password secrets from AWS Secrets Manager
584: - Export password secrets as environment variables
585: - Generate `backend.hcl` from template (if it doesn't exist)
586: - Update `variables.tfvars` with selected region, environment, and deployment
587: account role ARN
588: - Set Kubernetes environment variables using `set-k8s-env.sh`
589: - Run Terraform commands (init, workspace, validate, plan, apply) automatically
590: 
591: #### Manual Terraform Commands (Alternative)
592: 
593: If you prefer to run Terraform commands manually instead of using the setup scripts:
594: 
595: **Step 1. Terraform Backend State Infrastructure:**
596: 
597: ```bash
598: cd tf_backend_state
599: terraform init -backend-config="backend.hcl"
600: terraform workspace select <region>-<environment> || terraform workspace new <region>-<environment>
601: terraform plan -var-file="variables.tfvars" -out "terraform.tfplan"
602: terraform apply -auto-approve "terraform.tfplan"
603: ```
604: 
605: **Step 2. Backend Infrastructure:**
606: 
607: ```bash
608: cd backend_infra
609: terraform init -backend-config="backend.hcl"
610: terraform workspace select <region>-<environment> || terraform workspace new <region>-<environment>
611: terraform plan -var-file="variables.tfvars" -out "terraform.tfplan"
612: terraform apply -auto-approve "terraform.tfplan"
613: ```
614: 
615: **Step 3. Application Infrastructure:**
616: 
617: ```bash
618: cd application
619: terraform init -backend-config="backend.hcl"
620: terraform workspace select <region>-<environment> || terraform workspace new <region>-<environment>
621: terraform plan -var-file="variables.tfvars" -out "terraform.tfplan"
622: terraform apply -auto-approve "terraform.tfplan"
623: ```
624: 
625: > [!NOTE]
626: >
627: > Workspace names are dynamic based on region and environment
628: > (e.g., `us-east-1-prod`, `us-east-2-dev`).
629: 
630: ## Destroying Infrastructure
631: 
632: This project provides automated destroy scripts for both backend and application
633: infrastructure, as well as GitHub Actions workflows for destroying infrastructure.
634: 
635: > [!WARNING]
636: >
637: > Destroying infrastructure is a **destructive operation** that permanently
638: > deletes all resources. This action **cannot be undone**. Always ensure you have
639: > backups and understand the consequences before proceeding.
640: 
641: ### Destroy Scripts (Local Development)
642: 
643: #### Destroy Application Infrastructure
644: 
645: ```bash
646: cd application
647: ./destroy-application.sh
648: ```
649: 
650: The script will:
651: 
652: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
653: - Retrieve repository variables from GitHub
654: - Retrieve role ARNs and ExternalId from AWS Secrets Manager
655: - Retrieve password secrets from AWS Secrets Manager
656: - Generate `backend.hcl` from template (if it doesn't exist)
657: - Update `variables.tfvars` with selected region, environment, deployment account
658:   role ARN, and ExternalId
659: - Set Kubernetes environment variables using `set-k8s-env.sh`
660: - Run Terraform destroy commands (init, workspace, validate, plan destroy, apply
661:   destroy) automatically
662: - **Requires confirmation**: Type 'yes' to confirm, then 'DESTROY' to proceed
663: 
664: #### Destroy Backend Infrastructure
665: 
666: ```bash
667: cd backend_infra
668: ./destroy-backend.sh
669: ```
670: 
671: The script will:
672: 
673: - Prompt for AWS region (us-east-1 or us-east-2) and environment (prod or dev)
674: - Retrieve repository variables from GitHub
675: - Retrieve role ARNs and ExternalId from AWS Secrets Manager
676: - Generate `backend.hcl` from template (if it doesn't exist)
677: - Update `variables.tfvars` with selected region, environment, deployment account
678:   role ARN, and ExternalId
679: - Run Terraform destroy commands (init, workspace, validate, plan destroy, apply
680:   destroy) automatically
681: - **Requires confirmation**: Type 'yes' to confirm, then 'DESTROY' to proceed
682: 
683: > [!IMPORTANT]
684: >
685: > **Destroy Order**: Destroy infrastructure in reverse order of deployment:
686: >
687: > 1. **Application Infrastructure** (destroy first)
688: > 2. **Backend Infrastructure** (destroy second)
689: > 3. **Terraform Backend State Infrastructure** (destroy last, if needed)
690: 
691: ### Destroy Workflows (GitHub Actions)
692: 
693: #### Destroy Application Infrastructure
694: 
695: 1. Go to GitHub  Actions tab
696: 2. Select "Application Infrastructure Destroying" workflow
697: 3. Click "Run workflow"
698: 4. Select environment (prod or dev) and region
699: 5. Click "Run workflow"
700: 
701: The workflow will:
702: 
703: - Use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations
704: - Use environment-specific deployment account role ARN
705: - Use `AWS_ASSUME_EXTERNAL_ID` for cross-account role assumption
706: - Retrieve password secrets from GitHub repository secrets
707: - Run Terraform destroy operations automatically
708: 
709: #### Destroy Backend Infrastructure
710: 
711: 1. Go to GitHub  Actions tab
712: 2. Select "Backend Infrastructure Destroying" workflow
713: 3. Click "Run workflow"
714: 4. Select environment (prod or dev) and region
715: 5. Click "Run workflow"
716: 
717: The workflow will:
718: 
719: - Use `AWS_STATE_ACCOUNT_ROLE_ARN` for backend state operations
720: - Use environment-specific deployment account role ARN
721: - Use `AWS_ASSUME_EXTERNAL_ID` for cross-account role assumption
722: - Run Terraform destroy operations automatically
723: 
724: > [!NOTE]
725: >
726: > For destroying Terraform backend state infrastructure, see the
727: > [Terraform Backend State README](tf_backend_state/README.md#destroying-remove-infrastructure).
728: 
729: ## Architecture Overview
730: 
731: ### Backend Infrastructure Components
732: 
733: The backend infrastructure provides the foundational AWS resources for deploying
734: containerized applications on Kubernetes. Key components include:
735: 
736: - **VPC** with public and private subnets across multiple availability zones
737: - **EKS Cluster** in Auto Mode with automatic node provisioning
738: - **IRSA (IAM Roles for Service Accounts)** for secure pod-to-AWS-service authentication
739: - **VPC Endpoints** for private AWS service access (SSM, STS, SNS)
740: - **ECR Repository** for container image storage
741: 
742: For detailed architecture diagrams, component descriptions, and configuration options,
743: see the [Backend Infrastructure README](backend_infra/README.md).
744: 
745: ### Application Infrastructure Components
746: 
747: The application infrastructure deploys the LDAP stack, 2FA application, and supporting
748: services on the EKS cluster. Key components include:
749: 
750: - **OpenLDAP Stack HA** with PhpLdapAdmin and LTB-passwd UIs
751: - **2FA Application** with self-service registration and admin dashboard
752: - **Application Load Balancer (ALB)** via EKS Auto Mode for internet-facing access
753: - **Supporting Services**: PostgreSQL, Redis, SES, SNS (optional)
754: - **GitOps**: ArgoCD (AWS managed service) for declarative deployments
755: - **Security**: cert-manager for TLS, Network Policies for pod-to-pod security
756: 
757: For detailed architecture diagrams, component descriptions, API specifications,
758: and deployment instructions, see the [Application Infrastructure README](application/README.md).
759: 
760: ## Key Features
761: 
762: - **EKS Auto Mode**: Simplified cluster management with automatic load balancer
763: provisioning and built-in EBS CSI driver
764: - **Two-Factor Authentication**: Full-stack 2FA application with dual MFA
765: methods (TOTP and SMS)
766: - **Self-Service User Registration**: Email and phone verification with profile
767: state management (PENDING  COMPLETE  ACTIVE)
768: - **Admin Dashboard**: User management, group CRUD operations, and approval
769: workflows for user activation
770: - **IRSA Integration**: Secure AWS API access from pods without hardcoded
771: credentials
772: - **High Availability**: Multi-master OpenLDAP replication with persistent
773: storage
774: - **GitOps Ready**: ArgoCD (AWS managed service) for declarative, Git-driven
775: deployments
776: - **Internet-Facing Access**: Secure HTTPS access to UIs via single ALB with
777: host-based routing
778: - **Self-Service Password Management**: LTB-passwd for user password resets
779: - **Automated DNS**: Route53 integration for seamless domain management
780: - **Secure by Default**: TLS termination, encrypted storage, network policies,
781: VPC endpoints for private AWS access
782: - **Multi-Account Architecture**: Separation of state storage and resource
783: deployment for enhanced security
784: - **Helm Release Safety**: Comprehensive Helm release attributes for safer
785: deployments with automatic rollbacks and resource readiness checks
786: - **ECR Image Support**: All modules use ECR images instead of Docker Hub to
787: prevent rate limiting and external dependencies
788: - **Public ACM Certificates**: Browser-trusted certificates with automatic renewal
789: via Amazon-issued public ACM certificates
790: - **Kubeconfig Auto-Update**: Automatic kubeconfig updates prevent stale cluster
791: endpoints and DNS lookup errors
792: 
793: ## MFA Methods
794: 
795: The 2FA application supports two multi-factor authentication methods:
796: 
797: | Method | Description | Infrastructure Required |
798: | -------- | ------------- | ------------------------ |
799: | **TOTP** | Time-based One-Time Password using authenticator apps (Google Authenticator, Authy, etc.) | None (codes generated locally) |
800: | **SMS** | Verification codes sent via AWS SNS to user's phone | SNS VPC endpoint, IRSA role |
801: 
802: For detailed API specifications, frontend architecture, and implementation details,
803: see:
804: 
805: - [2FA Application PRD](application/PRD-2FA-APP.md) - Complete API and frontend
806: specifications
807: - [SMS OTP Management PRD](application/PRD-SMS-MAN.md) - Redis-based SMS OTP
808: storage implementation
809: - [SNS Module Documentation](application/modules/sns/README.md) - SMS 2FA
810: infrastructure setup
811: 
812: ## Accessing the Services
813: 
814: After deployment:
815: 
816: - **2FA Application**: `https://app.${domain_name}` (e.g.,
817: `https://app.talorlik.com`)
818:   - Self-service user registration with email/phone verification
819:   - Two-factor authentication enrollment and login
820:   - TOTP setup with QR code or SMS verification
821:   - User profile management
822:   - Admin dashboard (for LDAP admin group members)
823:   - **API Documentation**: `https://app.${domain_name}/api/docs` - Interactive
824:   Swagger UI for API exploration and testing (always enabled, not just in
825:   debug mode)
826:   - **ReDoc Documentation**: `https://app.${domain_name}/api/redoc` - Alternative
827:   API documentation interface (always enabled)
828:   - **OpenAPI Schema**: `https://app.${domain_name}/api/openapi.json` - OpenAPI
829:   schema in JSON format
830: - **PhpLdapAdmin**: `https://phpldapadmin.${domain_name}` (e.g.,
831: `https://phpldapadmin.talorlik.com`)
832:   - LDAP administration interface
833: - **LTB-passwd**: `https://passwd.${domain_name}` (e.g.,
834: `https://passwd.talorlik.com`)
835:   - Self-service password management
836: - **ArgoCD** (if enabled): URL from Terraform output `argocd_server_url`
837:   - GitOps deployment management (AWS Identity Center authentication)
838: - **LDAP Service**: Cluster-internal only (not exposed externally)
839: 
840: ## Documentation
841: 
842: ### Infrastructure Documentation
843: 
844: - [Terraform Backend State README](tf_backend_state/README.md) - S3 state
845:   management with file-based locking (v1.0.0), AWS Secrets Manager
846:   integration, and GitHub variable configuration
847: - [Backend Infrastructure README](backend_infra/README.md) - VPC, EKS, IRSA, VPC
848: endpoints, and ECR documentation
849: - [Application Infrastructure README](application/README.md) - OpenLDAP, 2FA
850: app, ALB, ArgoCD, and deployment instructions
851: 
852: ### Application Documentation
853: 
854: - [2FA Application PRD](application/PRD-2FA-APP.md) - Product requirements for
855: the 2FA application (API specs, frontend architecture)
856: - [User Signup Management PRD](application/PRD-SIGNUP-MAN.md) - Self-service
857: user registration with email/phone verification
858: - [Admin Functions PRD](application/PRD-ADMIN-FUNCS.md) - Admin dashboard, group
859: management, and approval workflows
860: - [SMS OTP Management PRD](application/PRD-SMS-MAN.md) - Redis-based SMS OTP
861: storage with TTL
862: - [OpenLDAP README](application/OPENLDAP-README.md) - OpenLDAP configuration and
863: TLS setup
864: - [Security Improvements](application/SECURITY-IMPROVEMENTS.md) - Security
865: enhancements and best practices
866: 
867: ### Module Documentation
868: 
869: - [ALB Module](application/modules/alb/README.md) - EKS Auto Mode ALB configuration
870: - [ArgoCD Module](application/modules/argocd/README.md) - AWS managed ArgoCD
871: setup
872: - [ArgoCD Application Module](application/modules/argocd_app/README.md) -
873: GitOps application deployment
874: - [cert-manager Module](application/modules/cert-manager/README.md) - TLS
875: certificate management
876: - [Network Policies Module](application/modules/network-policies/README.md) -
877: Pod-to-pod security
878: - [PostgreSQL Module](application/modules/postgresql/README.md) - User data and
879: verification token storage
880: - [Redis Module](application/modules/redis/README.md) - SMS OTP code storage
881: - [SES Module](application/modules/ses/README.md) - Email verification and
882: notifications
883: - [SNS Module](application/modules/sns/README.md) - SMS 2FA integration
884: - [Route53 Record Module](application/modules/route53_record/README.md) - Route53
885: A (alias) records for ALB
886: - [VPC Endpoints Module](backend_infra/modules/endpoints/README.md) - Private
887: AWS service access
888: - [ECR Module](backend_infra/modules/ecr/README.md) - Container registry setup
889: 
890: ### Changelogs
891: 
892: - [Project Changelog](CHANGELOG.md) - All project changes
893: - [Backend Infrastructure Changelog](backend_infra/CHANGELOG.md) - VPC, EKS,
894: VPC endpoints, and ECR changes
895: - [Application Infrastructure Changelog](application/CHANGELOG.md) - OpenLDAP,
896: 2FA app, and supporting services changes
897: - [Terraform Backend State Changelog](tf_backend_state/CHANGELOG.md) - S3 state
898: management changes
899: 
900: ## Security Considerations
901: 
902: - **Secrets Management**: See [Secrets Configuration](#secrets-configuration) for
903: details on managing passwords via AWS Secrets Manager (local) and GitHub repository
904: secrets (CI/CD)
905: - **IRSA**: Pods assume IAM roles via OIDCno long-lived AWS credentials
906: - **VPC Endpoints**: AWS service access (SSM, STS, SNS) goes through private
907: endpointsno public internet exposure
908: - **TLS Termination**: HTTPS at ALB using ACM certificates; internal TLS via
909: cert-manager
910: - **LDAP Security**: ClusterIP only (not exposed externally), cross-namespace
911: access on secure ports only
912: - **Network Policies**: Pod-to-pod communication restricted to encrypted ports
913: (443, 636, 8443)
914: - **Storage Encryption**: EBS volumes encrypted by default
915: - **Network Isolation**: EKS nodes run in private subnets
916: - **Multi-Account Isolation**: State storage separated from resource deployment
917: - **Helm Release Safety**: Comprehensive Helm release attributes for safer deployments
918: with automatic rollbacks
919: - **ECR Image Support**: All modules use ECR images instead of Docker Hub to prevent
920: rate limiting
921: - **Kubeconfig Auto-Update**: Automatic kubeconfig updates prevent stale cluster
922: endpoints
923: - **Public ACM Certificates**: Browser-trusted certificates with automatic renewal
924: 
925: See [Security Improvements](application/SECURITY-IMPROVEMENTS.md) for detailed
926: security documentation.
927: 
928: ## Troubleshooting
929: 
930: See the individual README files for troubleshooting guides:
931: 
932: - [Backend Infrastructure Troubleshooting](backend_infra/README.md#troubleshooting)
933: - [Application Infrastructure Troubleshooting](application/README.md#troubleshooting)
934: 
935: ## License
936: 
937: See [LICENSE](LICENSE) file for details.
````
